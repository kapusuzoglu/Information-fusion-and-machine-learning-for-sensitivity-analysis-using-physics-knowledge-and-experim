{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.spatial.distance as spdist\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from numpy.linalg import cholesky, det, lstsq\n",
    "from scipy.optimize import minimize\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def pass_arg(Xx, nsim, tr_size):\n",
    "    \n",
    "    # Compute the RMSE\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred-y_true)**2))\n",
    "\n",
    "    print(\"tr_Size:\",tr_size)\n",
    "    # Making sure final porosity is less than initial\n",
    "    def poros(poroi, porof):\n",
    "        porofn = -porof*(porof<0)\n",
    "        porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "        return porofp+porofn\n",
    "\n",
    "\n",
    "    # Load labeled data\n",
    "    data = np.loadtxt('../data/labeled_data.dat')\n",
    "    x_labeled = data[:, :2].astype(np.float64) # -2 because we do not need porosity predictions\n",
    "    y_labeled = data[:, -2:-1].astype(np.float64) # dimensionless bond length and porosity measurements\n",
    "\n",
    "    # normalize dataset with MinMaxScaler\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "    x_labeled = scaler.fit_transform(x_labeled)\n",
    "    # y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "    tr_size = int(tr_size)\n",
    "\n",
    "    # train and test data\n",
    "    trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    testX, testY = x_labeled[30:,:], y_labeled[30:]\n",
    "\n",
    "\n",
    "    # trainY = np.transpose(trainY)\n",
    "    # testY = np.transpose(testY)\n",
    "\n",
    "    data_phyloss = np.loadtxt('../data/unlabeled_data_BK_constw_v2_1525.dat')\n",
    "    x_unlabeled = data_phyloss[:, :]\n",
    "\n",
    "    # initial porosity\n",
    "    initporo = x_unlabeled[:, -1]\n",
    "\n",
    "    x_unlabeled1 = x_unlabeled[:1303, :2]\n",
    "    x_unlabeled2 = x_unlabeled[-6:, :2]\n",
    "    x_unlabeled = np.vstack((x_unlabeled1,x_unlabeled2))\n",
    "\n",
    "    x_unlabeled = scaler.fit_transform(x_unlabeled)\n",
    "    init_poro1 = initporo[:1303]\n",
    "    init_poro2 = initporo[-6:]\n",
    "    init_poro = np.hstack((init_poro1,init_poro2))\n",
    "    \n",
    "    \n",
    "    def covSEard(hyp=None, x=None, z=None):\n",
    "        ''' Squared Exponential covariance function with Automatic Relevance Detemination\n",
    "         (ARD) distance measure. The covariance function is parameterized as:\n",
    "\n",
    "         k(x^p,x^q) = sf2 * exp(-(x^p - x^q)' * inv(P) * (x^p - x^q)/2)\n",
    "\n",
    "         where the P matrix is diagonal with ARD parameters ell_1^2,...,ell_D^2, where\n",
    "         D is the dimension of the input space and sf2 is the signal variance.\n",
    "\n",
    "         The hyperparameters are:\n",
    "\n",
    "         hyp = [ log(ell_1)\n",
    "                 log(ell_2)\n",
    "                 ...\n",
    "                 log(ell_D)\n",
    "                 log(sqrt(sf2)) ]\n",
    "        '''\n",
    "\n",
    "        [n, D] = x.shape\n",
    "        ell = 1/np.array(hyp[0:D])        # characteristic length scale\n",
    "        \n",
    "        \n",
    "        sf2 = np.array(hyp[D])**2         # signal variance\n",
    "        tmp = np.dot(np.diag(ell),x.T).T\n",
    "        A = spdist.cdist(np.dot(np.diag(ell),x.T).T, np.dot(np.diag(ell),z.T).T, 'sqeuclidean') # cross covariances\n",
    "        A = sf2*np.exp(-0.5*A)  \n",
    "\n",
    "        return A\n",
    "\n",
    "\n",
    "    def posterior_predictive(X_s, X_train, Y_train, l1=.1, l2=.1, sigma_f=.1, sigma_y=1e-5):\n",
    "        '''  \n",
    "        Computes the suffifient statistics of the GP posterior predictive distribution \n",
    "        from m training data X_train and Y_train and n new inputs X_s.\n",
    "\n",
    "        Args:\n",
    "            X_s: New input locations (n x d).\n",
    "            X_train: Training locations (m x d).\n",
    "            Y_train: Training targets (m x 1).\n",
    "            l: Kernel length parameter.\n",
    "            sigma_f: Kernel vertical variation parameter.\n",
    "            sigma_y: Noise parameter.\n",
    "\n",
    "        Returns:\n",
    "            Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "        '''\n",
    "\n",
    "\n",
    "        K = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_train) + sigma_y**2 * np.eye(len(X_train))\n",
    "        K_s = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_s)\n",
    "        K_ss = covSEard(hyp=[l1,l2,sigma_f], x=X_s, z=X_s)  + 1e-8 * np.eye(len(X_s))\n",
    "#         K_inv = inv(K)\n",
    "        K_inv = np.linalg.pinv(K)\n",
    "    \n",
    "        # Equation (4)\n",
    "        mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "\n",
    "        # Equation (5)\n",
    "        cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "        \n",
    "        return mu_s, cov_s\n",
    "\n",
    "\n",
    "    def nll_fn(X_train, Y_train, x_unlabeled, init_poro, naive=False):\n",
    "        '''\n",
    "        Returns a function that computes the negative log marginal\n",
    "        likelihood for training data X_train and Y_train and given \n",
    "        noise level.\n",
    "\n",
    "        Args:\n",
    "            X_train: training locations (m x d).\n",
    "            Y_train: training targets (m x 1).\n",
    "            noise: known noise level of Y_train.\n",
    "            naive: if True use a naive implementation of Eq. (7), if \n",
    "                   False use a numerically more stable implementation. \n",
    "\n",
    "        Returns:\n",
    "            Minimization objective.\n",
    "        '''\n",
    "\n",
    "        def nll_stable(theta):\n",
    "            # Numerically more stable implementation of Eq. (7) as described\n",
    "            # in http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, Section\n",
    "            # 2.2, Algorithm 2.1.\n",
    "            K = covSEard(hyp=[theta[0],theta[1],theta[2]], x=X_train, z=X_train) + \\\n",
    "                theta[3]**2 * np.eye(len(X_train))\n",
    "            \n",
    "            \n",
    "            K += 1e-6 * np.eye(*K.shape)\n",
    "            L = cholesky(K)\n",
    "        \n",
    "\n",
    "            mu_un, _ = posterior_predictive(x_unlabeled, X_train, Y_train, l1=theta[0], l2=theta[1], sigma_f=theta[2], sigma_y=theta[3])\n",
    "            phyloss_poro = np.mean(poros(init_poro, mu_un))\n",
    "\n",
    "            log_loss = np.sum(np.log(np.diagonal(L))) + \\\n",
    "                   0.5 * Y_train.T.dot(lstsq(L.T, lstsq(L, Y_train)[0])[0]) + \\\n",
    "                   0.5 * len(X_train) * np.log(2*np.pi)\n",
    "        \n",
    "            # print(500000*phyloss_poro,log_loss, theta)\n",
    "            return 500000*phyloss_poro + log_loss\n",
    "\n",
    "        if naive:\n",
    "            return nll_naive\n",
    "        else:\n",
    "            return nll_stable\n",
    "\n",
    "    \n",
    "    # Optimization\n",
    "    res = minimize(nll_fn(trainX, trainY, x_unlabeled, init_poro), x0 = [.1, .1, .1, 1e-3], \n",
    "                   bounds=((1e-5, None), (1e-5, None), (1e-5, None),(1e-7, None)),\n",
    "                    method='L-BFGS-B')\n",
    "    \n",
    "#     print(f'After parameter optimization: l1={res.x[0]:.5f} l2={res.x[1]:.5f} sigma_f={res.x[2]:.5f}')\n",
    "#     print(np.exp(res.x[0]),np.exp(res.x[1]), np.exp(res.x[2]))\n",
    "    mu_s, cov_s = posterior_predictive(testX, trainX, trainY, *res.x)\n",
    "    \n",
    "    RMSE = []\n",
    "    for ii in range(int(nsim)):\n",
    "        samples = np.random.multivariate_normal(mu_s.ravel(), cov_s, 1)\n",
    "        RMSE.append(root_mean_squared_error(testY, samples))\n",
    "        \n",
    "        print(\"RMSE:\", root_mean_squared_error(testY, samples))\n",
    "\n",
    "\n",
    "    RMSE = []\n",
    "    for ii in range(int(nsim)):\n",
    "        samples = np.random.multivariate_normal(mu_s.ravel(), cov_s, 1)\n",
    "        RMSE.append(root_mean_squared_error(testY, samples))\n",
    "        \n",
    "        print(\"RMSE:\", root_mean_squared_error(testY, samples))\n",
    "\n",
    "#     return samples, RMSE\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:160: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.016412071690600622\n",
      "RMSE: 0.015635332931227326\n",
      "RMSE: 0.015435295685587058\n",
      "RMSE: 0.020962162944846117\n",
      "RMSE: 0.01919575237496423\n",
      "RMSE: 0.021164275705192366\n",
      "RMSE: 0.019146090992351053\n",
      "RMSE: 0.015792679392809574\n",
      "RMSE: 0.020684835696496453\n",
      "RMSE: 0.015362988390504711\n",
      "RMSE: 0.01611694926107186\n",
      "RMSE: 0.02393729482671284\n",
      "RMSE: 0.023816844795969207\n",
      "RMSE: 0.02211793863655151\n",
      "RMSE: 0.025892827856918803\n",
      "RMSE: 0.015070830659711933\n",
      "RMSE: 0.015291823183537535\n",
      "RMSE: 0.01853706811929761\n",
      "RMSE: 0.014462837421753983\n",
      "RMSE: 0.015379637863317449\n",
      "RMSE: 0.016387134939032308\n",
      "RMSE: 0.018240720418088732\n",
      "RMSE: 0.020258044928782845\n",
      "RMSE: 0.019654957884162317\n",
      "RMSE: 0.014540601935301234\n",
      "RMSE: 0.02000458862756367\n",
      "RMSE: 0.019163975873393465\n",
      "RMSE: 0.020005295437418816\n",
      "RMSE: 0.01717103482270023\n",
      "RMSE: 0.01702137406019109\n",
      "RMSE: 0.02388169292551761\n",
      "RMSE: 0.023657032757602794\n",
      "RMSE: 0.017896558938459324\n",
      "RMSE: 0.023841020300320315\n",
      "RMSE: 0.02305901975880227\n",
      "RMSE: 0.014463664018344091\n",
      "RMSE: 0.024222525244129444\n",
      "RMSE: 0.0149503402659289\n",
      "RMSE: 0.020233096697798502\n",
      "RMSE: 0.01466736237098106\n",
      "RMSE: 0.017942098896151167\n",
      "RMSE: 0.018141666971200416\n",
      "RMSE: 0.016635502163640674\n",
      "RMSE: 0.019929412076157033\n",
      "RMSE: 0.020479238678001485\n",
      "RMSE: 0.018146723706579656\n",
      "RMSE: 0.01536813255262007\n",
      "RMSE: 0.022537978994707754\n",
      "RMSE: 0.025639768884973397\n",
      "RMSE: 0.021584533709202467\n",
      "RMSE: 0.014595026683169985\n",
      "RMSE: 0.014606019041745634\n",
      "RMSE: 0.021099025939417905\n",
      "RMSE: 0.014694083387032746\n",
      "RMSE: 0.01484787609509743\n",
      "RMSE: 0.01956930899005623\n",
      "RMSE: 0.02180361715265081\n",
      "RMSE: 0.015230608608474227\n",
      "RMSE: 0.017230104380351732\n",
      "RMSE: 0.016345578554439216\n",
      "RMSE: 0.021892418033687026\n",
      "RMSE: 0.020089442183497182\n",
      "RMSE: 0.01918813007951071\n",
      "RMSE: 0.020020626701514367\n",
      "RMSE: 0.02757439882590904\n",
      "RMSE: 0.017812608209282578\n",
      "RMSE: 0.015523107814018612\n",
      "RMSE: 0.018474491559798873\n",
      "RMSE: 0.026947272762444883\n",
      "RMSE: 0.019215308372248226\n",
      "RMSE: 0.029750656682476853\n",
      "RMSE: 0.019565936949253376\n",
      "RMSE: 0.017133788701588704\n",
      "RMSE: 0.034534497183827166\n",
      "RMSE: 0.0148085903285308\n",
      "RMSE: 0.015413042345871243\n",
      "RMSE: 0.018188130836814975\n",
      "RMSE: 0.015427180669838912\n",
      "RMSE: 0.022461753050018823\n",
      "RMSE: 0.025732296639862245\n",
      "RMSE: 0.014744442258203282\n",
      "RMSE: 0.025642405250845757\n",
      "RMSE: 0.024381160782921435\n",
      "RMSE: 0.023005641715470926\n",
      "RMSE: 0.016154752550739674\n",
      "RMSE: 0.014953105741532498\n",
      "RMSE: 0.0189664810573291\n",
      "RMSE: 0.01499580634646349\n",
      "RMSE: 0.01782144688106554\n",
      "RMSE: 0.027850244461542707\n",
      "RMSE: 0.016385874588738882\n",
      "RMSE: 0.01473844756290122\n",
      "RMSE: 0.0212470633470869\n",
      "RMSE: 0.016529512646650132\n",
      "RMSE: 0.019380450531082814\n",
      "RMSE: 0.028557297033474423\n",
      "RMSE: 0.021817561848158147\n",
      "RMSE: 0.01833914897608066\n",
      "RMSE: 0.02015850500585421\n",
      "RMSE: 0.018570082235482132\n",
      "tr_Size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:160: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.022136781514408833\n",
      "RMSE: 0.025826825582971485\n",
      "RMSE: 0.041902775284299386\n",
      "RMSE: 0.02510905888201999\n",
      "RMSE: 0.02190792662589942\n",
      "RMSE: 0.022858916677862363\n",
      "RMSE: 0.025324857514797395\n",
      "RMSE: 0.028180496872388484\n",
      "RMSE: 0.023220280390706834\n",
      "RMSE: 0.02056616309811056\n",
      "RMSE: 0.028397146408566522\n",
      "RMSE: 0.025178373919666215\n",
      "RMSE: 0.02953853931661119\n",
      "RMSE: 0.026513540833087886\n",
      "RMSE: 0.024864051562616063\n",
      "RMSE: 0.02514809509800361\n",
      "RMSE: 0.03306768153064278\n",
      "RMSE: 0.02620476318599672\n",
      "RMSE: 0.028928776934042527\n",
      "RMSE: 0.03863615775674751\n",
      "RMSE: 0.029651623820534333\n",
      "RMSE: 0.037149654165196506\n",
      "RMSE: 0.02051504960119097\n",
      "RMSE: 0.023476065859725115\n",
      "RMSE: 0.02490523818405401\n",
      "RMSE: 0.02581242782085304\n",
      "RMSE: 0.032903884706565106\n",
      "RMSE: 0.027899227411386535\n",
      "RMSE: 0.025997268378496027\n",
      "RMSE: 0.032677191837594655\n",
      "RMSE: 0.027299000757914912\n",
      "RMSE: 0.036434733240291464\n",
      "RMSE: 0.020812972898982682\n",
      "RMSE: 0.023448077883229473\n",
      "RMSE: 0.02271406294470637\n",
      "RMSE: 0.02216620439826946\n",
      "RMSE: 0.02148758347490934\n",
      "RMSE: 0.03103216581417839\n",
      "RMSE: 0.030227963919008144\n",
      "RMSE: 0.03365511475502492\n",
      "RMSE: 0.029784492789624334\n",
      "RMSE: 0.024479467816882282\n",
      "RMSE: 0.03531919302554526\n",
      "RMSE: 0.03553989442766766\n",
      "RMSE: 0.021219001047463836\n",
      "RMSE: 0.045922974922816405\n",
      "RMSE: 0.026910934597211895\n",
      "RMSE: 0.02089198485016899\n",
      "RMSE: 0.028525965745457536\n",
      "RMSE: 0.03026150556990003\n",
      "RMSE: 0.022641705083243528\n",
      "RMSE: 0.03716829926570349\n",
      "RMSE: 0.019926520715225892\n",
      "RMSE: 0.022213240000306046\n",
      "RMSE: 0.026271240493739124\n",
      "RMSE: 0.025697169357721417\n",
      "RMSE: 0.023517783173008216\n",
      "RMSE: 0.028429269436182267\n",
      "RMSE: 0.024684308160845294\n",
      "RMSE: 0.0258782684942242\n",
      "RMSE: 0.025301519547517914\n",
      "RMSE: 0.02402563689393716\n",
      "RMSE: 0.037625060249178686\n",
      "RMSE: 0.025568513499174897\n",
      "RMSE: 0.03151409140866244\n",
      "RMSE: 0.021866581468843214\n",
      "RMSE: 0.026140239461066583\n",
      "RMSE: 0.02327688405923303\n",
      "RMSE: 0.02313107979830383\n",
      "RMSE: 0.02814162617467292\n",
      "RMSE: 0.02291595334108136\n",
      "RMSE: 0.022412926657574928\n",
      "RMSE: 0.026607517447474124\n",
      "RMSE: 0.02610895193352257\n",
      "RMSE: 0.03063852829730571\n",
      "RMSE: 0.025372440539592582\n",
      "RMSE: 0.025933638906439637\n",
      "RMSE: 0.02628781475662789\n",
      "RMSE: 0.020357208188982463\n",
      "RMSE: 0.02856073958833017\n",
      "RMSE: 0.0348109928796456\n",
      "RMSE: 0.02407520336647525\n",
      "RMSE: 0.023321318169571933\n",
      "RMSE: 0.03136218516999534\n",
      "RMSE: 0.030112856887280843\n",
      "RMSE: 0.021611502365547146\n",
      "RMSE: 0.02449940660223184\n",
      "RMSE: 0.020059269251865512\n",
      "RMSE: 0.03053936336855805\n",
      "RMSE: 0.024698551977833962\n",
      "RMSE: 0.025786482056370064\n",
      "RMSE: 0.0344643351726248\n",
      "RMSE: 0.0293957238548908\n",
      "RMSE: 0.02270621731529634\n",
      "RMSE: 0.024316486283403296\n",
      "RMSE: 0.029245770300574504\n",
      "RMSE: 0.02909371498456701\n",
      "RMSE: 0.028483772136733098\n",
      "RMSE: 0.02401122360922115\n",
      "RMSE: 0.025714851746492535\n",
      "tr_Size: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:160: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.02535434592471112\n",
      "RMSE: 0.0260586820990922\n",
      "RMSE: 0.019639648478873138\n",
      "RMSE: 0.01942118388471454\n",
      "RMSE: 0.02242275080784647\n",
      "RMSE: 0.019521798024463403\n",
      "RMSE: 0.023641434170339544\n",
      "RMSE: 0.02050653259058473\n",
      "RMSE: 0.02520831614429359\n",
      "RMSE: 0.026686643200485003\n",
      "RMSE: 0.02500306682130456\n",
      "RMSE: 0.022968560913452098\n",
      "RMSE: 0.027908922902179226\n",
      "RMSE: 0.027460418622189252\n",
      "RMSE: 0.029234031466095392\n",
      "RMSE: 0.029162005610610962\n",
      "RMSE: 0.032492335711742225\n",
      "RMSE: 0.02652106938180153\n",
      "RMSE: 0.02451273072335821\n",
      "RMSE: 0.020965827333195547\n",
      "RMSE: 0.02074708658979768\n",
      "RMSE: 0.030063870129090235\n",
      "RMSE: 0.02083807383493902\n",
      "RMSE: 0.025342995119208192\n",
      "RMSE: 0.025268133278438732\n",
      "RMSE: 0.023991868228753797\n",
      "RMSE: 0.02989219345298879\n",
      "RMSE: 0.02340363400668046\n",
      "RMSE: 0.029287040946715547\n",
      "RMSE: 0.018018419037360744\n",
      "RMSE: 0.024944357037120387\n",
      "RMSE: 0.027065891085742064\n",
      "RMSE: 0.02718108160237113\n",
      "RMSE: 0.028856265831120737\n",
      "RMSE: 0.03448776144074567\n",
      "RMSE: 0.031386623158655196\n",
      "RMSE: 0.026253077754595736\n",
      "RMSE: 0.025180111163019277\n",
      "RMSE: 0.024300675149306214\n",
      "RMSE: 0.02143198530361761\n",
      "RMSE: 0.028154819969505696\n",
      "RMSE: 0.02732828532084221\n",
      "RMSE: 0.022805058887071187\n",
      "RMSE: 0.029335678400356644\n",
      "RMSE: 0.030197861421931434\n",
      "RMSE: 0.022937093299329758\n",
      "RMSE: 0.02789844167965316\n",
      "RMSE: 0.026560547584504296\n",
      "RMSE: 0.026770675475453358\n",
      "RMSE: 0.024658536186464106\n",
      "RMSE: 0.02689581265084619\n",
      "RMSE: 0.021404930812608185\n",
      "RMSE: 0.024083490800025698\n",
      "RMSE: 0.026244927108138662\n",
      "RMSE: 0.018822263744529846\n",
      "RMSE: 0.024499560208803527\n",
      "RMSE: 0.028974450601469068\n",
      "RMSE: 0.02008254864002883\n",
      "RMSE: 0.02302659997890266\n",
      "RMSE: 0.020185494027156234\n",
      "RMSE: 0.03354682167693408\n",
      "RMSE: 0.020479168776316628\n",
      "RMSE: 0.024697225275274893\n",
      "RMSE: 0.02307497055625654\n",
      "RMSE: 0.020139170376354484\n",
      "RMSE: 0.02450527488359542\n",
      "RMSE: 0.02652298918725439\n",
      "RMSE: 0.024634931667452984\n",
      "RMSE: 0.02782597757706467\n",
      "RMSE: 0.03483258381887409\n",
      "RMSE: 0.0216225207341194\n",
      "RMSE: 0.02424759439538492\n",
      "RMSE: 0.022723402642078575\n",
      "RMSE: 0.026784021182577313\n",
      "RMSE: 0.021491853671147268\n",
      "RMSE: 0.02095357340659017\n",
      "RMSE: 0.0365302141354334\n",
      "RMSE: 0.018170069641227943\n",
      "RMSE: 0.024002633891223472\n",
      "RMSE: 0.028383646817788478\n",
      "RMSE: 0.026865994906705406\n",
      "RMSE: 0.02404473669752476\n",
      "RMSE: 0.01987161815264486\n",
      "RMSE: 0.022037691087992684\n",
      "RMSE: 0.030437808524642822\n",
      "RMSE: 0.022207377448968633\n",
      "RMSE: 0.026119238036792208\n",
      "RMSE: 0.018991623217501\n",
      "RMSE: 0.022460684239447734\n",
      "RMSE: 0.027360279911335793\n",
      "RMSE: 0.03125419721686671\n",
      "RMSE: 0.018746755808102082\n",
      "RMSE: 0.02213445074122154\n",
      "RMSE: 0.02741853008099756\n",
      "RMSE: 0.022658709849658423\n",
      "RMSE: 0.024625279406953766\n",
      "RMSE: 0.023339991715922177\n",
      "RMSE: 0.02193463596399097\n",
      "RMSE: 0.01920217753304049\n",
      "RMSE: 0.020984214471736796\n",
      "tr_Size: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:160: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.019311742410967902\n",
      "RMSE: 0.021921628849234952\n",
      "RMSE: 0.02783926933222161\n",
      "RMSE: 0.021611622778368766\n",
      "RMSE: 0.02304333078415535\n",
      "RMSE: 0.01870202757054808\n",
      "RMSE: 0.020998536440851413\n",
      "RMSE: 0.020392046317860842\n",
      "RMSE: 0.025742739799538297\n",
      "RMSE: 0.020208380839829832\n",
      "RMSE: 0.01965865082444535\n",
      "RMSE: 0.02222731786547079\n",
      "RMSE: 0.020190280873231277\n",
      "RMSE: 0.018654693573851987\n",
      "RMSE: 0.02094584269670194\n",
      "RMSE: 0.021880608441937205\n",
      "RMSE: 0.024942238597272685\n",
      "RMSE: 0.018480600536875575\n",
      "RMSE: 0.026072602323194537\n",
      "RMSE: 0.019284689677401375\n",
      "RMSE: 0.021592205096091912\n",
      "RMSE: 0.024527725181328622\n",
      "RMSE: 0.022532203417867432\n",
      "RMSE: 0.023216221884951895\n",
      "RMSE: 0.01806776085165412\n",
      "RMSE: 0.02475151579176292\n",
      "RMSE: 0.020081642481429195\n",
      "RMSE: 0.021877055063058058\n",
      "RMSE: 0.026483067891251478\n",
      "RMSE: 0.023983360888491928\n",
      "RMSE: 0.025426082319884757\n",
      "RMSE: 0.02407291238921117\n",
      "RMSE: 0.01917710030126644\n",
      "RMSE: 0.018092522333443765\n",
      "RMSE: 0.022112324807397624\n",
      "RMSE: 0.01695972000351397\n",
      "RMSE: 0.02088861370322523\n",
      "RMSE: 0.020561557606316973\n",
      "RMSE: 0.021211983236543212\n",
      "RMSE: 0.01866218638775429\n",
      "RMSE: 0.02100642326935943\n",
      "RMSE: 0.01980939767260576\n",
      "RMSE: 0.020172030475638824\n",
      "RMSE: 0.02179852212332703\n",
      "RMSE: 0.026777442304858564\n",
      "RMSE: 0.022466643657174264\n",
      "RMSE: 0.020282326078173294\n",
      "RMSE: 0.020120645229873488\n",
      "RMSE: 0.020010282888938653\n",
      "RMSE: 0.019370646575714398\n",
      "RMSE: 0.02370762446793722\n",
      "RMSE: 0.02533656510090399\n",
      "RMSE: 0.02081248514930702\n",
      "RMSE: 0.018647712532439787\n",
      "RMSE: 0.02229888559129455\n",
      "RMSE: 0.01958562839782628\n",
      "RMSE: 0.02890211649013655\n",
      "RMSE: 0.026793095676186894\n",
      "RMSE: 0.023203998669923107\n",
      "RMSE: 0.016820362882331526\n",
      "RMSE: 0.023812094482024117\n",
      "RMSE: 0.021638633804043586\n",
      "RMSE: 0.024005142231614953\n",
      "RMSE: 0.020795168368589332\n",
      "RMSE: 0.018212442446676337\n",
      "RMSE: 0.02068238254279536\n",
      "RMSE: 0.02134688309323914\n",
      "RMSE: 0.023417020134421377\n",
      "RMSE: 0.017502418466432867\n",
      "RMSE: 0.02552035151964359\n",
      "RMSE: 0.024352799341011044\n",
      "RMSE: 0.019849981325143148\n",
      "RMSE: 0.02160722037225033\n",
      "RMSE: 0.024219531978661574\n",
      "RMSE: 0.020808009323180405\n",
      "RMSE: 0.019126138592192036\n",
      "RMSE: 0.019702095550445855\n",
      "RMSE: 0.019171858169907168\n",
      "RMSE: 0.0200765598053705\n",
      "RMSE: 0.019695026350850405\n",
      "RMSE: 0.019097342210698726\n",
      "RMSE: 0.018793254959871726\n",
      "RMSE: 0.02353979808533788\n",
      "RMSE: 0.02329449005963531\n",
      "RMSE: 0.029028900437290475\n",
      "RMSE: 0.024189547631488128\n",
      "RMSE: 0.02238022518038023\n",
      "RMSE: 0.0220838045316599\n",
      "RMSE: 0.022734591271643557\n",
      "RMSE: 0.01962775747304418\n",
      "RMSE: 0.02206042117352143\n",
      "RMSE: 0.021706428460781566\n",
      "RMSE: 0.019444921789670604\n",
      "RMSE: 0.019140269143234672\n",
      "RMSE: 0.022580922918758847\n",
      "RMSE: 0.02028015362980907\n",
      "RMSE: 0.021639830325093583\n",
      "RMSE: 0.024486661687469487\n",
      "RMSE: 0.02208925615718602\n",
      "RMSE: 0.02015278751134757\n",
      "tr_Size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:160: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.018538710387197902\n",
      "RMSE: 0.017840475580751372\n",
      "RMSE: 0.018126444116799933\n",
      "RMSE: 0.019136335686455133\n",
      "RMSE: 0.019830326202197508\n",
      "RMSE: 0.019248231046417593\n",
      "RMSE: 0.02026410177030685\n",
      "RMSE: 0.01913838891654585\n",
      "RMSE: 0.01968416281998671\n",
      "RMSE: 0.02094719412058828\n",
      "RMSE: 0.01808900942331259\n",
      "RMSE: 0.01923549245371473\n",
      "RMSE: 0.01802368206155001\n",
      "RMSE: 0.02082540299058159\n",
      "RMSE: 0.01908392235357878\n",
      "RMSE: 0.018234002585016146\n",
      "RMSE: 0.019900908365564535\n",
      "RMSE: 0.021998723963374208\n",
      "RMSE: 0.021514604416244944\n",
      "RMSE: 0.021087444955822984\n",
      "RMSE: 0.02176079307241127\n",
      "RMSE: 0.019508700095652764\n",
      "RMSE: 0.020396717952979315\n",
      "RMSE: 0.01947425055025196\n",
      "RMSE: 0.01919837068152196\n",
      "RMSE: 0.019326318152424443\n",
      "RMSE: 0.01971137869715115\n",
      "RMSE: 0.017902778337879694\n",
      "RMSE: 0.018817375035114978\n",
      "RMSE: 0.01913757757529994\n",
      "RMSE: 0.019493025359160664\n",
      "RMSE: 0.0191685860903915\n",
      "RMSE: 0.019425582552543265\n",
      "RMSE: 0.019970155030736167\n",
      "RMSE: 0.01941186900035874\n",
      "RMSE: 0.018573661214905907\n",
      "RMSE: 0.019440665271430034\n",
      "RMSE: 0.017446517776545063\n",
      "RMSE: 0.020597386221698155\n",
      "RMSE: 0.02093260007762677\n",
      "RMSE: 0.01972345118414737\n",
      "RMSE: 0.019259145336102134\n",
      "RMSE: 0.019807084945198946\n",
      "RMSE: 0.019055090852500484\n",
      "RMSE: 0.021867982440883685\n",
      "RMSE: 0.01954707718922519\n",
      "RMSE: 0.01915266578474868\n",
      "RMSE: 0.019688699822493768\n",
      "RMSE: 0.018666389723357293\n",
      "RMSE: 0.019297282658926822\n",
      "RMSE: 0.01865626720959925\n",
      "RMSE: 0.020338910237663963\n",
      "RMSE: 0.020533177248041625\n",
      "RMSE: 0.01971427134259102\n",
      "RMSE: 0.019712723897494067\n",
      "RMSE: 0.019258985435909853\n",
      "RMSE: 0.020252029274916095\n",
      "RMSE: 0.017809973952972343\n",
      "RMSE: 0.02232502605371232\n",
      "RMSE: 0.018782722751547788\n",
      "RMSE: 0.01940327679561865\n",
      "RMSE: 0.017890556887726616\n",
      "RMSE: 0.022075399815064088\n",
      "RMSE: 0.018905231808603307\n",
      "RMSE: 0.020185785058935993\n",
      "RMSE: 0.019639174615415433\n",
      "RMSE: 0.018863001491358902\n",
      "RMSE: 0.020072834574083563\n",
      "RMSE: 0.020955444090176478\n",
      "RMSE: 0.019948672908482592\n",
      "RMSE: 0.019233269142641306\n",
      "RMSE: 0.02027321815865047\n",
      "RMSE: 0.020097952315133512\n",
      "RMSE: 0.0192698728303095\n",
      "RMSE: 0.020375804909830385\n",
      "RMSE: 0.01966488997132174\n",
      "RMSE: 0.01919118052299667\n",
      "RMSE: 0.018888348174688593\n",
      "RMSE: 0.01927308264323532\n",
      "RMSE: 0.020241638278760535\n",
      "RMSE: 0.018871742871515294\n",
      "RMSE: 0.020087410914897054\n",
      "RMSE: 0.018637817192649616\n",
      "RMSE: 0.020385728690318\n",
      "RMSE: 0.01798914763637599\n",
      "RMSE: 0.019400582317066897\n",
      "RMSE: 0.01904447947165423\n",
      "RMSE: 0.02031399454030079\n",
      "RMSE: 0.020971871858901987\n",
      "RMSE: 0.019663872253253244\n",
      "RMSE: 0.023674660083466775\n",
      "RMSE: 0.02199457484673693\n",
      "RMSE: 0.019830535114249308\n",
      "RMSE: 0.019564384916509126\n",
      "RMSE: 0.02052429103982735\n",
      "RMSE: 0.01962697423888733\n",
      "RMSE: 0.020560854469606323\n",
      "RMSE: 0.019461905366399978\n",
      "RMSE: 0.018360390183835708\n",
      "RMSE: 0.020115522035110737\n"
     ]
    }
   ],
   "source": [
    "mean_rmses=[]\n",
    "std_rmses=[]\n",
    "for ii in ([5,10,15,20,30]):\n",
    "    test_rmse = pass_arg(1,50, ii)\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    mean_rmses.append(mean_rmse)\n",
    "    std_rmses.append(std_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.019680287151681092,\n",
       " 0.026330479677938015,\n",
       " 0.024241694357950084,\n",
       " 0.021800031949894057,\n",
       " 0.019818269248780895]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.004639653160830472,\n",
       " 0.00406660048479454,\n",
       " 0.0041254337913148725,\n",
       " 0.0026375730760001674,\n",
       " 0.0011028689857341442]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:160: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.01887178119891527\n",
      "RMSE: 0.022422125472662455\n",
      "RMSE: 0.01709485051420006\n",
      "RMSE: 0.01894643997926025\n",
      "RMSE: 0.024926161122790655\n",
      "RMSE: 0.02088521855032978\n",
      "RMSE: 0.02123508813025256\n",
      "RMSE: 0.017469613535328905\n",
      "RMSE: 0.02082993830179254\n",
      "RMSE: 0.019368945066724246\n",
      "RMSE: 0.021151389805499684\n",
      "RMSE: 0.016658314991575485\n",
      "RMSE: 0.021130084199330715\n",
      "RMSE: 0.01908215000508387\n",
      "RMSE: 0.01939684132909302\n",
      "RMSE: 0.020203666011849638\n",
      "RMSE: 0.01970623097466492\n",
      "RMSE: 0.0190532637895618\n",
      "RMSE: 0.018216483685318384\n",
      "RMSE: 0.01974181719310583\n",
      "RMSE: 0.02034516659833612\n",
      "RMSE: 0.018584352201264587\n",
      "RMSE: 0.02271928636080908\n",
      "RMSE: 0.017779981884677682\n",
      "RMSE: 0.024036591140256997\n",
      "RMSE: 0.019111905320128877\n",
      "RMSE: 0.02280856459857227\n",
      "RMSE: 0.017998203325819247\n",
      "RMSE: 0.018034947546228416\n",
      "RMSE: 0.019466857744585567\n",
      "RMSE: 0.021510992271884966\n",
      "RMSE: 0.01890676622351696\n",
      "RMSE: 0.020457298453895458\n",
      "RMSE: 0.01941486616834205\n",
      "RMSE: 0.020304294711812124\n",
      "RMSE: 0.019659313038087448\n",
      "RMSE: 0.017278456134758792\n",
      "RMSE: 0.018787267351328487\n",
      "RMSE: 0.01907569663746207\n",
      "RMSE: 0.017728250244809313\n",
      "RMSE: 0.020989539925798655\n",
      "RMSE: 0.018974529133562054\n",
      "RMSE: 0.020296287542742417\n",
      "RMSE: 0.018166108193092095\n",
      "RMSE: 0.01969864994873792\n",
      "RMSE: 0.019068283563889045\n",
      "RMSE: 0.017930347133424895\n",
      "RMSE: 0.020278643832217124\n",
      "RMSE: 0.023801772279813303\n",
      "RMSE: 0.019342482003840346\n",
      "RMSE: 0.02364872300626923\n",
      "RMSE: 0.02050193941227498\n",
      "RMSE: 0.02033122020840356\n",
      "RMSE: 0.019231788646600023\n",
      "RMSE: 0.019531753828251577\n",
      "RMSE: 0.020920897839963662\n",
      "RMSE: 0.017577682055843626\n",
      "RMSE: 0.02244643493902261\n",
      "RMSE: 0.018327826631939027\n",
      "RMSE: 0.02081730579269\n",
      "RMSE: 0.019427396541394457\n",
      "RMSE: 0.018950873438468883\n",
      "RMSE: 0.018868309631465532\n",
      "RMSE: 0.02060083514734719\n",
      "RMSE: 0.021508245421576297\n",
      "RMSE: 0.020488238867502173\n",
      "RMSE: 0.01819914511269821\n",
      "RMSE: 0.02208061906007221\n",
      "RMSE: 0.019566137776715845\n",
      "RMSE: 0.019707148432951953\n",
      "RMSE: 0.020389015181996907\n",
      "RMSE: 0.01788352845479479\n",
      "RMSE: 0.018677819383938227\n",
      "RMSE: 0.016777942935998866\n",
      "RMSE: 0.023032072849746874\n",
      "RMSE: 0.019882318520109618\n",
      "RMSE: 0.019629531789847866\n",
      "RMSE: 0.022500205893223834\n",
      "RMSE: 0.018603065001233862\n",
      "RMSE: 0.018694746576729135\n",
      "RMSE: 0.022526515092215777\n",
      "RMSE: 0.02155993559086671\n",
      "RMSE: 0.019861881204937502\n",
      "RMSE: 0.018986963584533913\n",
      "RMSE: 0.01957716698290589\n",
      "RMSE: 0.020947927619008606\n",
      "RMSE: 0.01921695290389749\n",
      "RMSE: 0.01817386224143254\n",
      "RMSE: 0.02253074573185414\n",
      "RMSE: 0.019860083487148492\n",
      "RMSE: 0.020554817801712918\n",
      "RMSE: 0.022476338273600915\n",
      "RMSE: 0.01914933237767348\n",
      "RMSE: 0.021036478656928804\n",
      "RMSE: 0.018662248640136568\n",
      "RMSE: 0.02253779766891499\n",
      "RMSE: 0.021678000355755466\n",
      "RMSE: 0.02000480843235223\n",
      "RMSE: 0.023579016828811045\n",
      "RMSE: 0.02223854393722379\n"
     ]
    }
   ],
   "source": [
    "Xx = np.random.uniform(size=(3, 2))\n",
    "ss, rmse = pass_arg(Xx, 100, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02002908291162017"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_size = 500\n",
    "use_YPhy = 0\n",
    "\n",
    "#List of lakes to choose from\n",
    "lake = ['mendota' , 'mille_lacs']\n",
    "lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "lake_name = lake[lake_num]\n",
    "\n",
    "# Load features (Xc) and target values (Y)\n",
    "data_dir = '../../data/'\n",
    "filename = lake_name + '.mat'\n",
    "mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "Xc = mat['Xc_doy']\n",
    "Y = mat['Y']\n",
    "\n",
    "Xc = Xc[:,:-1]\n",
    "# train and test data\n",
    "trainX, testX, trainY, testY = train_test_split(Xc, Y, train_size=tr_size/Xc.shape[0], \n",
    "                                                test_size=tr_size/Xc.shape[0], random_state=42, shuffle=True)\n",
    "\n",
    "# # train and test data\n",
    "# trainX, trainY = Xc[:tr_size,:-1], Y[:tr_size]\n",
    "# testX, testY = Xc[-50:,:-1], Y[-50:]\n",
    "\n",
    "# Loading unsupervised data\n",
    "unsup_filename = lake_name + '_sampled.mat'\n",
    "unsup_mat = spio.loadmat(data_dir+unsup_filename, squeeze_me=True,\n",
    "variable_names=['Xc_doy1','Xc_doy2'])\n",
    "\n",
    "uX1 = unsup_mat['Xc_doy1'] # Xc at depth i for every pair of consecutive depth values\n",
    "uX2 = unsup_mat['Xc_doy2'] # Xc at depth i + 1 for every pair of consecutive depth values\n",
    "uX1 = uX1[3000:5000,:]\n",
    "uX2 = uX2[3000:5000,:]\n",
    "\n",
    "if use_YPhy == 0:\n",
    "    # Removing the last column from uX (corresponding to Y_PHY)\n",
    "    uX1 = uX1[:,:-1]\n",
    "    uX2 = uX2[:,:-1]\n",
    "            \n",
    "            \n",
    "#function for computing the density given the temperature(nx1 matrix)\n",
    "def density(temp):\n",
    "    return 1000 * ( 1 - (temp + 288.9414) * (temp - 3.9863)**2 / (508929.2 * (temp + 68.12963) ) )\n",
    "\n",
    "def density_diff(densityf, densityi):\n",
    "    diff = densityf-densityi\n",
    "    mean_diff = np.mean(diff*[diff>0])\n",
    "    return mean_diff\n",
    "\n",
    "    \n",
    "def log_marginal_likeli(self, theta=None, eval_gradient=False,\n",
    "                            clone_kernel=True):\n",
    "    \"\"\"Returns log-marginal likelihood of theta for training data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array-like of shape (n_kernel_params,) default=None\n",
    "        Kernel hyperparameters for which the log-marginal likelihood is\n",
    "        evaluated. If None, the precomputed log_marginal_likelihood\n",
    "        of ``self.kernel_.theta`` is returned.\n",
    "    eval_gradient : bool, default=False\n",
    "        If True, the gradient of the log-marginal likelihood with respect\n",
    "        to the kernel hyperparameters at position theta is returned\n",
    "        additionally. If True, theta must not be None.\n",
    "    clone_kernel : bool, default=True\n",
    "        If True, the kernel attribute is copied. If False, the kernel\n",
    "        attribute is modified, but may result in a performance improvement.\n",
    "    Returns\n",
    "    -------\n",
    "    log_likelihood : float\n",
    "        Log-marginal likelihood of theta for training data.\n",
    "    log_likelihood_gradient : ndarray of shape (n_kernel_params,), optional\n",
    "        Gradient of the log-marginal likelihood with respect to the kernel\n",
    "        hyperparameters at position theta.\n",
    "        Only returned when eval_gradient is True.\n",
    "    \"\"\"\n",
    "    if theta is None:\n",
    "        if eval_gradient:\n",
    "            raise ValueError(\n",
    "                \"Gradient can only be evaluated for theta!=None\")\n",
    "        return self.log_marginal_likelihood_value_\n",
    "\n",
    "    if clone_kernel:\n",
    "        kernel = self.kernel_.clone_with_theta(theta)\n",
    "    else:\n",
    "        kernel = self.kernel_\n",
    "        kernel.theta = theta\n",
    "\n",
    "    if eval_gradient:\n",
    "        K, K_gradient = kernel(self.X_train_, eval_gradient=True)\n",
    "    else:\n",
    "        K = kernel(self.X_train_)\n",
    "\n",
    "    K[np.diag_indices_from(K)] += self.alpha\n",
    "    try:\n",
    "        L = cholesky(K, lower=True)  # Line 2\n",
    "    except np.linalg.LinAlgError:\n",
    "        return (-np.inf, np.zeros_like(theta)) \\\n",
    "            if eval_gradient else -np.inf\n",
    "\n",
    "    # Support multi-dimensional output of self.y_train_\n",
    "    y_train = self.y_train_\n",
    "    if y_train.ndim == 1:\n",
    "        y_train = y_train[:, np.newaxis]\n",
    "\n",
    "    alpha = cho_solve((L, True), y_train)  # Line 3\n",
    "\n",
    "    # Compute log-likelihood (compare line 7)\n",
    "    log_likelihood_dims = -0.5 * np.einsum(\"ik,ik->k\", y_train, alpha)\n",
    "    log_likelihood_dims -= np.log(np.diag(L)).sum()\n",
    "    log_likelihood_dims -= K.shape[0] / 2 * np.log(2 * np.pi)\n",
    "    log_likelihood = log_likelihood_dims.sum(-1)  # sum over dimensions\n",
    "    \n",
    "    \n",
    "    # Precompute quantities required for predictions which are independent\n",
    "    # of actual query points\n",
    "    K = self.kernel_(self.X_train_)\n",
    "    K[np.diag_indices_from(K)] += self.alpha\n",
    "    try:\n",
    "        self.L_ = cholesky(K, lower=True)  # Line 2\n",
    "        # self.L_ changed, self._K_inv needs to be recomputed\n",
    "        self._K_inv = None\n",
    "    except np.linalg.LinAlgError as exc:\n",
    "        exc.args = (\"The kernel, %s, is not returning a \"\n",
    "                    \"positive definite matrix. Try gradually \"\n",
    "                    \"increasing the 'alpha' parameter of your \"\n",
    "                    \"GaussianProcessRegressor estimator.\"\n",
    "                    % self.kernel_,) + exc.args\n",
    "        raise\n",
    "    self.alpha_ = cho_solve((self.L_, True), self.y_train_)  # Line 3\n",
    "\n",
    "    pred1 = self.predict(uX1)\n",
    "    pred2 = self.predict(uX2)\n",
    "    phyloss = density_diff(density(pred1), density(pred2))\n",
    "    print(\"phyLoss:\", 500*phyloss)\n",
    "    log_likelihood -= 500*phyloss\n",
    "    print(log_likelihood)\n",
    "    \n",
    "    if eval_gradient:  # compare Equation 5.9 from GPML\n",
    "        tmp = np.einsum(\"ik,jk->ijk\", alpha, alpha)  # k: output-dimension\n",
    "        tmp -= cho_solve((L, True), np.eye(K.shape[0]))[:, :, np.newaxis]\n",
    "        # Compute \"0.5 * trace(tmp.dot(K_gradient))\" without\n",
    "        # constructing the full matrix tmp.dot(K_gradient) since only\n",
    "        # its diagonal is required\n",
    "        log_likelihood_gradient_dims = \\\n",
    "            0.5 * np.einsum(\"ijl,jik->kl\", tmp, K_gradient)\n",
    "        log_likelihood_gradient = log_likelihood_gradient_dims.sum(-1)\n",
    "\n",
    "    if eval_gradient:\n",
    "        return log_likelihood, log_likelihood_gradient\n",
    "    else:\n",
    "        return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phyLoss: 2.4622529571305165\n",
      "-2746.819048067093\n",
      "phyLoss: 0.0\n",
      "-5199.508580325815\n",
      "phyLoss: 0.0\n",
      "-4893.950614519985\n",
      "phyLoss: 0.0\n",
      "-1436.2454445253054\n",
      "phyLoss: 0.0\n",
      "-1166.805261033404\n",
      "phyLoss: 0.10893089088622787\n",
      "-1052.214250121358\n",
      "phyLoss: 0.49904882079366075\n",
      "-1035.7856191382768\n",
      "phyLoss: 0.5764596892759641\n",
      "-1015.0321944046996\n",
      "phyLoss: 0.4141165654523036\n",
      "-987.0162797460026\n",
      "phyLoss: 0.34896351374516144\n",
      "-979.3523854125837\n",
      "phyLoss: 0.36795789489309527\n",
      "-974.8140560378622\n",
      "phyLoss: 0.35770268768692404\n",
      "-970.7277102217163\n",
      "phyLoss: 0.36102290896434397\n",
      "-970.2634836490613\n",
      "phyLoss: 0.37030503016575267\n",
      "-968.8924635294834\n",
      "phyLoss: 0.3769279434241639\n",
      "-968.1020477253073\n",
      "phyLoss: 0.3703775357640495\n",
      "-967.0647690565232\n",
      "phyLoss: 0.38690627159883206\n",
      "-963.0538789640784\n",
      "phyLoss: 0.5516145128549113\n",
      "-975.55298742744\n",
      "phyLoss: 0.41895494309775927\n",
      "-959.0302824801452\n",
      "phyLoss: 0.4656557057963653\n",
      "-961.5081332839482\n",
      "phyLoss: 0.4302922546271759\n",
      "-958.2009586148432\n",
      "phyLoss: 0.40529254452644636\n",
      "-954.8747669751855\n",
      "phyLoss: 0.34432617220133466\n",
      "-953.8152847422631\n",
      "phyLoss: 0.362610163309256\n",
      "-953.4406114236558\n",
      "phyLoss: 0.35919106921153343\n",
      "-953.3720366478545\n",
      "phyLoss: 0.35915632206106807\n",
      "-953.3448220976078\n",
      "phyLoss: 0.3538510322107129\n",
      "-953.303927288726\n",
      "phyLoss: 0.3527117558937505\n",
      "-953.2505981060505\n",
      "phyLoss: 0.35569610871644386\n",
      "-953.1699450427033\n",
      "phyLoss: 0.36538345687415585\n",
      "-952.9943671162995\n",
      "phyLoss: 0.3588851210984956\n",
      "-953.0695173238672\n",
      "phyLoss: 0.36344787286788005\n",
      "-952.9811062512176\n",
      "phyLoss: 0.38143911068829084\n",
      "-954.6867946846539\n",
      "phyLoss: 0.3645049819370456\n",
      "-952.9709335396326\n",
      "phyLoss: 0.36452224171307535\n",
      "-952.9004485532303\n",
      "phyLoss: 0.3642249714778245\n",
      "-952.8567058672365\n",
      "phyLoss: 0.3631010759428932\n",
      "-952.8453864936318\n",
      "phyLoss: 0.36222320356799287\n",
      "-952.8417255564299\n",
      "phyLoss: 0.3623571858744299\n",
      "-952.8407543512527\n",
      "phyLoss: 0.3612706826364729\n",
      "-952.8379933728883\n",
      "phyLoss: 0.3623605349830825\n",
      "-952.8373016541645\n",
      "phyLoss: 0.3630996757285061\n",
      "-952.8363536146708\n",
      "phyLoss: 0.3630180581057516\n",
      "-952.8357251953714\n",
      "phyLoss: 0.3630526380600827\n",
      "-952.8357049164385\n",
      "phyLoss: 0.3629667388145492\n",
      "-952.8356044554677\n",
      "phyLoss: 0.3629458538363508\n",
      "-952.8355830049045\n",
      "phyLoss: 0.36294347152497153\n",
      "-952.8355805816501\n",
      "phyLoss: 0.3629430651537575\n",
      "-952.8355801375174\n",
      "phyLoss: 0.0\n",
      "-5187.973605833483\n",
      "phyLoss: 0.0\n",
      "-5194.180121431968\n",
      "phyLoss: 0.0\n",
      "-5186.176270072756\n",
      "phyLoss: 0.0\n",
      "-5181.644611697134\n",
      "phyLoss: 0.0\n",
      "-5181.551365060669\n",
      "phyLoss: 0.0\n",
      "-5181.239322970494\n",
      "phyLoss: 0.0\n",
      "-4756.697895443786\n",
      "phyLoss: 2.4066082460194593e-09\n",
      "-3576.3460199190986\n",
      "phyLoss: 1.7273833918807213e-08\n",
      "-3599.82807904071\n",
      "phyLoss: 5.607688535747002e-09\n",
      "-3544.715481401055\n",
      "phyLoss: 0.00021990003480709674\n",
      "-3571.5215174308187\n",
      "phyLoss: 0.0\n",
      "-4216.456381237755\n",
      "phyLoss: 2.4158453015843406e-10\n",
      "-3594.963722568144\n",
      "phyLoss: 4.250239271641476e-09\n",
      "-3483.4202911564353\n",
      "phyLoss: 2.968951662296604e-08\n",
      "-3424.6064497678417\n",
      "phyLoss: 3.7772451833006926e-11\n",
      "-3538.0662512288177\n",
      "phyLoss: 1.8180969618697418e-08\n",
      "-3419.507994504147\n",
      "phyLoss: 3.06442871078616e-09\n",
      "-3418.194621665459\n",
      "phyLoss: 3.674955451060668e-09\n",
      "-3417.275012407165\n",
      "phyLoss: 3.4034144391625887e-09\n",
      "-3416.8175970045777\n",
      "phyLoss: 3.2887896850297693e-09\n",
      "-3415.8677947405367\n",
      "phyLoss: 3.074404730796232e-09\n",
      "-3412.3795814575637\n",
      "phyLoss: 6.403291763490415e-08\n",
      "-3545.196922927692\n",
      "phyLoss: 5.373408384912182e-09\n",
      "-3319.5753504446466\n",
      "phyLoss: 2.6619176196618355e-08\n",
      "-3156.6379039952044\n",
      "phyLoss: 1.682406036707107e-08\n",
      "-3147.3685299731023\n",
      "phyLoss: 4.187345711007055\n",
      "-5488.731742317812\n",
      "phyLoss: 0.0\n",
      "-4582.432072475235\n",
      "phyLoss: 2.112869879056234e-09\n",
      "-3174.319090898095\n",
      "phyLoss: 1.6661999779898906e-08\n",
      "-3128.381365435226\n",
      "phyLoss: 0.39599919797024086\n",
      "-5618.1652842148815\n",
      "phyLoss: 1.4209319942892762e-08\n",
      "-3134.433359343258\n",
      "phyLoss: 1.6275123471132247e-08\n",
      "-3128.3763272222955\n",
      "phyLoss: 4.187345866409203\n",
      "-5488.7317400188\n",
      "phyLoss: 1.5882562820479507e-08\n",
      "-3128.380889695898\n",
      "phyLoss: 1.6273048686343827e-08\n",
      "-3128.3763270890418\n",
      "phyLoss: 0.0\n",
      "-6787.82524916954\n",
      "phyLoss: 0.0\n",
      "-2779.3526089372117\n",
      "phyLoss: 0.0\n",
      "-3497.696353647467\n",
      "phyLoss: 0.0\n",
      "-2747.492237121649\n",
      "phyLoss: 0.0\n",
      "-2747.708613552363\n",
      "phyLoss: 0.0\n",
      "-2746.982400467048\n",
      "phyLoss: 0.0\n",
      "-2746.720024493363\n",
      "phyLoss: 0.0\n",
      "-2746.713002063937\n",
      "phyLoss: 0.0\n",
      "-2746.7129415283807\n",
      "phyLoss: 0.0\n",
      "-2746.7128831964164\n",
      "phyLoss: 0.0\n",
      "-2746.7126109746905\n",
      "phyLoss: 0.0\n",
      "-2746.71200158135\n",
      "phyLoss: 0.0\n",
      "-2746.7101805650645\n",
      "phyLoss: 0.0\n",
      "-2746.7045872075078\n",
      "phyLoss: 0.0\n",
      "-2746.668495357362\n",
      "phyLoss: 0.0\n",
      "-2746.600182023305\n",
      "phyLoss: 0.0\n",
      "-2746.6430464500927\n",
      "phyLoss: 0.0\n",
      "-2746.4923688759745\n",
      "phyLoss: 0.0\n",
      "-2746.479876507645\n",
      "phyLoss: 0.0\n",
      "-2761.0211875133473\n",
      "phyLoss: 0.0\n",
      "-2746.477854360951\n",
      "phyLoss: 0.0\n",
      "-2746.3475324745486\n",
      "phyLoss: 0.0\n",
      "-2745.9721809527255\n",
      "phyLoss: 0.0\n",
      "-2745.757474987233\n",
      "phyLoss: 0.0\n",
      "-2745.7233148893256\n",
      "phyLoss: 0.0\n",
      "-2745.721789356141\n",
      "phyLoss: 0.0\n",
      "-2745.7217749181327\n",
      "phyLoss: 0.0\n",
      "-2745.721774894352\n",
      "phyLoss: 0.04222436740303692\n",
      "-2595.121730734578\n",
      "phyLoss: 34.154334874959005\n",
      "-4964.197464488247\n",
      "phyLoss: 0.166684106012724\n",
      "-3844.7708800963696\n",
      "phyLoss: 0.0\n",
      "-1197.8410378928484\n",
      "phyLoss: 0.00042624594104268\n",
      "-1143.4055653896694\n",
      "phyLoss: 0.4480208682710156\n",
      "-1033.6228085549396\n",
      "phyLoss: 0.34373834825828453\n",
      "-1009.3486956362693\n",
      "phyLoss: 0.3464068083318068\n",
      "-990.8849984795326\n",
      "phyLoss: 0.3598323804801282\n",
      "-990.0470548846438\n",
      "phyLoss: 0.38697617570792886\n",
      "-988.5781143538262\n",
      "phyLoss: 0.3773059828108387\n",
      "-988.2220428855223\n",
      "phyLoss: 0.36507425837589835\n",
      "-987.8300477141365\n",
      "phyLoss: 0.364105394503639\n",
      "-987.3377783538004\n",
      "phyLoss: 0.36330969466177976\n",
      "-987.0500539475203\n",
      "phyLoss: 0.365586903818496\n",
      "-986.9923371509306\n",
      "phyLoss: 0.36773652059704887\n",
      "-986.9651892970553\n",
      "phyLoss: 0.3517204040385309\n",
      "-986.9381868028681\n",
      "phyLoss: 0.36545778056242284\n",
      "-986.9214349690396\n",
      "phyLoss: 0.3683229902557059\n",
      "-986.9183783455157\n",
      "phyLoss: 0.3684613566747714\n",
      "-986.9147522812718\n",
      "phyLoss: 0.3689183719978928\n",
      "-986.9171381786484\n",
      "phyLoss: 0.36864065717253425\n",
      "-986.9126949673187\n",
      "phyLoss: 0.36717621921835075\n",
      "-986.9082412190054\n",
      "phyLoss: 0.36613928032051035\n",
      "-986.9052818958628\n",
      "phyLoss: 0.3662023504473666\n",
      "-986.9040549272066\n",
      "phyLoss: 0.36621299775836746\n",
      "-986.9020896761928\n",
      "phyLoss: 0.36693086013039533\n",
      "-986.8955082344205\n",
      "phyLoss: 0.36698560162037097\n",
      "-986.895405349257\n",
      "phyLoss: 0.3669547070793442\n",
      "-986.8953251783502\n",
      "phyLoss: 0.36688777196388855\n",
      "-986.8952179257561\n",
      "phyLoss: 0.3665978182870333\n",
      "-986.8947439775358\n",
      "phyLoss: 0.3661849665591035\n",
      "-986.8939474150711\n",
      "phyLoss: 0.3654618907905842\n",
      "-986.8920928169999\n",
      "phyLoss: 0.36426361852741707\n",
      "-986.8875043106933\n",
      "phyLoss: 0.3588477121447795\n",
      "-986.8125331954973\n",
      "phyLoss: 0.3826057665798146\n",
      "-1005.1522250138592\n",
      "phyLoss: 0.35947873513782724\n",
      "-986.2079110223489\n",
      "phyLoss: 0.3722377109616559\n",
      "-984.2737252800218\n",
      "phyLoss: 0.37055563974189454\n",
      "-984.2145945452526\n",
      "phyLoss: 0.37055563974189454\n",
      "-984.2145945452526\n",
      "phyLoss: 0.36442043784816747\n",
      "-986.8824052955395\n",
      "phyLoss: 0.3713837665192159\n",
      "-984.4452644290309\n",
      "phyLoss: 0.37203911532975553\n",
      "-984.1590182366253\n",
      "phyLoss: 0.3895090505675398\n",
      "-983.8591082939653\n",
      "phyLoss: 0.40236242911271347\n",
      "-983.4875006152209\n",
      "phyLoss: 0.4118522043411872\n",
      "-983.4614165985383\n",
      "phyLoss: 0.4123253391544779\n",
      "-983.4517901458888\n",
      "phyLoss: 0.41524323314902745\n",
      "-983.4475843528325\n",
      "phyLoss: 0.4104534759677847\n",
      "-983.4368022493696\n",
      "phyLoss: 0.40775958878978713\n",
      "-983.4296788868276\n",
      "phyLoss: 0.40422038694376283\n",
      "-983.4152998431225\n",
      "phyLoss: 0.4105195931004175\n",
      "-983.4168571147981\n",
      "phyLoss: 0.40636949557745083\n",
      "-983.4131474314349\n",
      "phyLoss: 0.40901576875026535\n",
      "-983.4139490223909\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n",
      "phyLoss: 0.4092786361040055\n",
      "-983.4141933294978\n",
      "phyLoss: 0.4073646595795424\n",
      "-983.4130513146077\n",
      "phyLoss: 0.4070648037255751\n",
      "-983.4130133775425\n",
      "phyLoss: 0.40700714487311984\n",
      "-983.413010362608\n",
      "phyLoss: 0.4069956255777356\n",
      "-983.4130099189606\n",
      "phyLoss: 0.4069933096049567\n",
      "-983.4130098361334\n",
      "phyLoss: 0.4069928433821701\n",
      "-983.413009819717\n",
      "phyLoss: 0.4069927495037575\n",
      "-983.4130098164217\n",
      "phyLoss: 0.4069927305997112\n",
      "-983.4130098157586\n",
      "phyLoss: 0.40699272679265164\n",
      "-983.4130098156247\n",
      "phyLoss: 0.40699272602626024\n",
      "-983.4130098155982\n",
      "phyLoss: 0.4069927258718735\n",
      "-983.4130098155925\n",
      "phyLoss: 0.4069927258406949\n",
      "-983.4130098155919\n",
      "phyLoss: 0.40699272583458423\n",
      "-983.4130098155917\n",
      "phyLoss: 0.40699272583344737\n",
      "-983.4130098155919\n",
      "phyLoss: 0.4069927258329926\n",
      "-983.4130098155919\n",
      "phyLoss: 0.4069927258329642\n",
      "-983.4130098155923\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phyLoss: 0.4069927258330779\n",
      "-983.4130098155922\n",
      "phyLoss: 0.274626007919494\n",
      "-991.0060963231836\n",
      "phyLoss: 0.4099777016441237\n",
      "-983.4153001627371\n",
      "phyLoss: 0.4072686929925453\n",
      "-983.4131396345838\n",
      "phyLoss: 0.4070211499790162\n",
      "-983.4130224389269\n",
      "phyLoss: 0.4069956779162567\n",
      "-983.4130111186628\n",
      "phyLoss: 0.40699303269565235\n",
      "-983.4130099509578\n",
      "phyLoss: 0.4069927577331782\n",
      "-983.4130098296625\n",
      "phyLoss: 0.40699272914909557\n",
      "-983.4130098170543\n",
      "phyLoss: 0.4069927261776911\n",
      "-983.4130098157432\n",
      "phyLoss: 0.4069927258687187\n",
      "-983.4130098156073\n",
      "phyLoss: 0.4069927258364885\n",
      "-983.4130098155924\n",
      "phyLoss: 0.4069927258336179\n",
      "-983.413009815592\n",
      "phyLoss: 0.4069927258330779\n",
      "-983.413009815592\n",
      "phyLoss: 0.4069927258329926\n",
      "-983.4130098155922\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155921\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n",
      "phyLoss: 0.40699272583302104\n",
      "-983.4130098155916\n",
      "phyLoss: 9.034894787873782e-08\n",
      "-6515.587865890812\n",
      "phyLoss: 0.0\n",
      "-5203.182290223363\n",
      "phyLoss: 0.0\n",
      "-5203.124515638443\n",
      "phyLoss: 0.0\n",
      "-5202.871860648567\n",
      "phyLoss: 0.0\n",
      "-5201.4089972670945\n",
      "phyLoss: 0.0\n",
      "-5170.617760306434\n",
      "phyLoss: 0.0\n",
      "-3607.0573675561536\n",
      "phyLoss: 32.50006670568109\n",
      "-3633.0045244147223\n",
      "phyLoss: 0.02144685533389179\n",
      "-3585.03623775316\n",
      "phyLoss: 0.5462946863025024\n",
      "-3577.2311378635723\n",
      "phyLoss: 33.203033045970585\n",
      "-3578.8763113155833\n",
      "phyLoss: 3.305787712086129\n",
      "-3568.5342391723175\n",
      "phyLoss: 8.951085778351285\n",
      "-3552.2834513459234\n",
      "phyLoss: 13.200234241574776\n",
      "-3549.3780513168754\n",
      "phyLoss: 17.90986035938286\n",
      "-3551.4519369727304\n",
      "phyLoss: 20.869151877945313\n",
      "-4877.649634986142\n",
      "phyLoss: 20.18315956752872\n",
      "-3490.3986794620805\n",
      "phyLoss: 28.45354365343408\n",
      "-3232.6394507311434\n",
      "phyLoss: 26.493135115131253\n",
      "-3061.108244998943\n",
      "phyLoss: 26.551684337255267\n",
      "-2945.9297664751666\n",
      "phyLoss: 32.33353315856246\n",
      "-3322.2964649274995\n",
      "phyLoss: 27.1860054151133\n",
      "-2903.9507765709245\n",
      "phyLoss: 7.638917529106948e-05\n",
      "-5652.349297770314\n",
      "phyLoss: 27.192562824927904\n",
      "-2903.953544635951\n",
      "phyLoss: 27.186788093882484\n",
      "-2903.951035105245\n",
      "phyLoss: 27.1861070212492\n",
      "-2903.9508091800953\n",
      "phyLoss: 27.18601865858514\n",
      "-2903.950780805127\n",
      "phyLoss: 27.186007142187293\n",
      "-2903.9507771228305\n",
      "phyLoss: 27.186005640354892\n",
      "-2903.950776642897\n",
      "phyLoss: 27.18600544448927\n",
      "-2903.9507765803105\n",
      "phyLoss: 27.186005418943893\n",
      "-2903.9507765721464\n",
      "phyLoss: 27.186005415612584\n",
      "-2903.9507765710837\n",
      "phyLoss: 27.18600541517813\n",
      "-2903.9507765709436\n",
      "phyLoss: 27.18600541512157\n",
      "-2903.9507765709272\n",
      "phyLoss: 27.18600541511418\n",
      "-2903.9507765709245\n",
      "phyLoss: 27.186005415118927\n",
      "-2903.9507765709245\n",
      "phyLoss: 27.18600541512103\n",
      "-2903.950776570927\n",
      "phyLoss: 27.186005415118984\n",
      "-2903.9507765709245\n",
      "phyLoss: 27.18600541512035\n",
      "-2903.950776570926\n",
      "phyLoss: 27.186005415119013\n",
      "-2903.9507765709236\n",
      "phyLoss: 27.186005415119098\n",
      "-2903.950776570924\n",
      "phyLoss: 27.186005415119013\n",
      "-2903.9507765709236\n",
      "phyLoss: 5.291073607378735\n",
      "-12964.546168492834\n",
      "phyLoss: 0.0\n",
      "-6492.219136209888\n",
      "phyLoss: 0.0\n",
      "-6456.19304661934\n",
      "phyLoss: 0.0\n",
      "-6397.058896061961\n",
      "phyLoss: 0.0\n",
      "-6394.615982304284\n",
      "phyLoss: 0.0\n",
      "-6389.2639740007235\n",
      "phyLoss: 0.0\n",
      "-6266.627577920039\n",
      "phyLoss: 0.0\n",
      "-6110.577671451354\n",
      "phyLoss: 0.0\n",
      "-6089.055508388173\n",
      "phyLoss: 0.0\n",
      "-6085.412001760231\n",
      "phyLoss: 0.0\n",
      "-5695.80850271707\n",
      "phyLoss: 0.0\n",
      "-5695.808502714655\n",
      "phyLoss: 0.0\n",
      "-5695.808502704987\n",
      "phyLoss: 0.0\n",
      "-5695.808502666329\n",
      "phyLoss: 0.0\n",
      "-5695.808502511537\n",
      "phyLoss: 0.0\n",
      "-5695.8085018899055\n",
      "phyLoss: 0.0\n",
      "-5695.808499363741\n",
      "phyLoss: 0.0\n",
      "-5695.808488595231\n",
      "phyLoss: 0.0\n",
      "-5695.8084327355145\n",
      "phyLoss: 0.0\n",
      "-5695.80774633182\n",
      "phyLoss: 0.0\n",
      "-5695.206093375589\n",
      "phyLoss: 0.0\n",
      "-5051.011064102746\n",
      "phyLoss: 0.0\n",
      "-5051.011064083481\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.linalg import cholesky,cho_solve\n",
    "\n",
    "def obj_funct(theta, eval_gradient=True):\n",
    "#     print(\"theta\",theta)\n",
    "    if eval_gradient:\n",
    "        lml, grad = log_marginal_likeli(gp1,theta, eval_gradient=True, clone_kernel=False)\n",
    "        return -lml, -grad\n",
    "    else:\n",
    "        return -log_marginal_likeli(gp1, theta, clone_kernel=False)\n",
    "    \n",
    "def custom_optimizer(obj_func, initial_theta, bounds):\n",
    "    custom_optimizer_method = fmin_l_bfgs_b(obj_funct, x0=initial_theta, bounds=bounds)\n",
    "    # custom_optimizer_method[0]: optimized values can be accessed using\n",
    "    # custom_optimizer_method[1]: resulting value of the function to be minimized\n",
    "    return (custom_optimizer_method[0], custom_optimizer_method[1])\n",
    "\n",
    "# trust_region_method.x: the optimized values can be accessed using:\n",
    "# trust_region_method.fun: resulting value of the function to be minimized\n",
    "\n",
    "kernel1 = C(5.0, (0.5, 1e1)) * RBF(length_scale = [1] * trainX.shape[1], length_scale_bounds=(1e-1, 1e7))\n",
    "gp1 = GaussianProcessRegressor(optimizer = custom_optimizer, kernel=kernel1, alpha =1.5, n_restarts_optimizer=5)\n",
    "gp1.fit(trainX, trainY)\n",
    "y_pred1, sigma1 = gp1.predict(testX, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.16**2 * RBF(length_scale=[0.933, 10.7, 1.11, 12.7, 6.59e+03, 4.4, 22.1, 5.93e+03, 16, 9.57e+03, 1.23e+05])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp1.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586861128774503"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp1.score(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324754827966752"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp1.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predTr, sigma_tr = gp1.predict(trainX, return_std=True)\n",
    "# y_predTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "def pass_arg_upd(tr_size, pre_trained_hyperparamters):\n",
    "\n",
    "    print(\"tr_Size:\",tr_size)\n",
    "    #pre_tr_size = 100\n",
    "    tr_size = int(tr_size)\n",
    "\n",
    "    #List of lakes to choose from\n",
    "    lake = ['mendota' , 'mille_lacs']\n",
    "    lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "    lake_name = lake[lake_num]\n",
    "\n",
    "    # Load features (Xc) and target values (Y)\n",
    "    data_dir = '../../data/'\n",
    "    filename = lake_name + '.mat'\n",
    "    mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "    variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "    Xc = mat['Xc_doy']\n",
    "    Y = mat['Y']\n",
    "\n",
    "    Xc = Xc[:,:-1]\n",
    "    # train and test data\n",
    "    trainX, testX, trainY, testY = train_test_split(Xc, Y, train_size=tr_size/Xc.shape[0], \n",
    "                                                    test_size=tr_size/Xc.shape[0], random_state=42, shuffle=True)\n",
    "\n",
    "    # Updated model\n",
    "    gp2 = GaussianProcessRegressor(kernel=pre_trained_hyperparamters, alpha =1.5, n_restarts_optimizer=5)\n",
    "    gp2.fit(trainX, trainY)\n",
    "\n",
    "    print(gp2.kernel_)\n",
    "    print(gp2.score(trainX, trainY))\n",
    "    print(gp2.score(testX, testY))\n",
    "#     # scale the uniform numbers to original space\n",
    "#     # max and min value in each column \n",
    "#     max_in_column_Xc = np.max(trainX,axis=0)\n",
    "#     min_in_column_Xc = np.min(trainX,axis=0)\n",
    "        \n",
    "#     # Xc_scaled = (Xc-min_in_column_Xc)/(max_in_column_Xc-min_in_column_Xc)\n",
    "#     Xc_org = Xx*(max_in_column_Xc-min_in_column_Xc) + min_in_column_Xc\n",
    "        \n",
    "#     samples = gp2.sample_y(Xc_org, n_samples=int(nsim)).T\n",
    "    return gp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 500\n",
      "6.95**2 * RBF(length_scale=[0.891, 73.4, 1.07, 8.83e+03, 39.1, 6.61, 0.167, 8.44e+04, 3.51e+03, 4.43e+03, 1e+05])\n",
      "0.9602232617153119\n",
      "0.9300650812151675\n"
     ]
    }
   ],
   "source": [
    "pre_hyper = 1.12**2 * RBF(length_scale=[0.628, 2.72e+04, 1.81, 9.48e+06, 1.18e+03, 1e+08, 3.51e+03, 8.38e+03, 1.1e+03, 3.24e+05, 771])\n",
    "gp2 = pass_arg_upd(500, pre_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
