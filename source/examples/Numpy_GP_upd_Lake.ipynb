{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train GP model & use its hyperparameters as initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "pre_tr_size = 100\n",
    "tr_size = 100\n",
    "\n",
    "#List of lakes to choose from\n",
    "lake = ['mendota' , 'mille_lacs']\n",
    "lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "lake_name = lake[lake_num]\n",
    "\n",
    "# Load features (Xc) and target values (Y)\n",
    "data_dir = '../../data/'\n",
    "filename = lake_name + '.mat'\n",
    "mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "Xc = mat['Xc_doy']\n",
    "Y = mat['Y']\n",
    "\n",
    "# train and test data\n",
    "trainX, trainY = Xc[:tr_size,:-1], Y[:tr_size]\n",
    "testX, testY = Xc[-50:,:-1], Y[-50:]\n",
    "\n",
    "# Loading unsupervised data\n",
    "unsup_filename = lake_name + '_sampled.mat'\n",
    "unsup_mat = spio.loadmat(data_dir+unsup_filename, squeeze_me=True,\n",
    "variable_names=['Xc_doy1','Xc_doy2'])\n",
    "\n",
    "uX1 = unsup_mat['Xc_doy1'] # Xc at depth i for every pair of consecutive depth values\n",
    "uX2 = unsup_mat['Xc_doy2'] # Xc at depth i + 1 for every pair of consecutive depth values\n",
    "uX1 = uX1[:pre_tr_size,:-1]\n",
    "uX2 = uX2[:pre_tr_size,:-1]\n",
    "uY1 = uX1[:pre_tr_size,-1:]\n",
    "uY2 = uX2[:pre_tr_size,-1:]\n",
    "       \n",
    "kernel = C(5.0, (1e-2, 1e3)) * RBF(length_scale = [1] * trainX.shape[1], length_scale_bounds=(1e-3, 1e4))\n",
    "gp1 = GaussianProcessRegressor(kernel=kernel, alpha =1.2, n_restarts_optimizer=0)\n",
    "gp1.fit(uX1, uY1)\n",
    "y_pred1, sigma1 = gp1.predict(testX, return_std=True)\n",
    "# y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.01**2 * RBF(length_scale=[0.69, 1, 1.79, 2.46e+03, 1.29e+03, 146, 1, 171, 1.58e+03, 5.9, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_trained_hyperparamters = gp.kernel_\n",
    "pre_trained_hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07136956, 0.07402991, 0.0756865 , 0.0763058 , 0.0758895 ,\n",
       "       0.07447484, 0.0721333 , 0.06896762, 0.06510731, 0.06070288,\n",
       "       0.05834775, 0.05591911, 0.05343858, 0.05092776, 0.04589997,\n",
       "       0.04099902, 0.03637353, 0.03215173, 0.02843685, 0.025304  ,\n",
       "       0.02279852, 0.0209359 , 0.01970315, 0.01945097, 0.01122844,\n",
       "       0.01275301, 0.01415673, 0.01540332, 0.01646052, 0.01730157,\n",
       "       0.01790639, 0.01826255, 0.01836581, 0.01822044, 0.01783898,\n",
       "       0.01724169, 0.01645568, 0.01551363, 0.01445232, 0.01331099,\n",
       "       0.01212961, 0.01094714, 0.0098    , 0.00872056, 0.00773606,\n",
       "       0.00686771, 0.00613021, 0.00553153, 0.00507312, 0.0049282 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp2 = GaussianProcessRegressor(kernel=pre_trained_hyperparamters, alpha =1.2, n_restarts_optimizer=0)\n",
    "gp2.fit(trainX, trainY)\n",
    "y_pred2, sigma1 = gp2.predict(testX, return_std=True)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9517674027619413"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp2.score(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-34.48705759352189"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp2.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a GP model discrepancy term and add it to correct predictions of another GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "pre_tr_size = 100\n",
    "tr_size = 100\n",
    "\n",
    "#List of lakes to choose from\n",
    "lake = ['mendota' , 'mille_lacs']\n",
    "lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "lake_name = lake[lake_num]\n",
    "\n",
    "# Load features (Xc) and target values (Y)\n",
    "data_dir = '../../data/'\n",
    "filename = lake_name + '.mat'\n",
    "mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "Xc = mat['Xc_doy']\n",
    "Y = mat['Y']\n",
    "\n",
    "# train and test data\n",
    "trainX, trainY = Xc[:tr_size,:-1], Y[:tr_size]\n",
    "testX, testY = Xc[-50:,:-1], Y[-50:]\n",
    "\n",
    "# Loading unsupervised data\n",
    "unsup_filename = lake_name + '_sampled.mat'\n",
    "unsup_mat = spio.loadmat(data_dir+unsup_filename, squeeze_me=True,\n",
    "variable_names=['Xc_doy1','Xc_doy2'])\n",
    "\n",
    "uX1 = unsup_mat['Xc_doy1'] # Xc at depth i for every pair of consecutive depth values\n",
    "uX2 = unsup_mat['Xc_doy2'] # Xc at depth i + 1 for every pair of consecutive depth values\n",
    "uX1 = uX1[:pre_tr_size,:-1]\n",
    "uX2 = uX2[:pre_tr_size,:-1]\n",
    "uY1 = uX1[:pre_tr_size,-1:]\n",
    "uY2 = uX2[:pre_tr_size,-1:]\n",
    "       \n",
    "kernel = C(5.0, (1e-2, 1e3)) * RBF(length_scale = [1] * trainX.shape[1], length_scale_bounds=(1e-3, 1e4))\n",
    "gp1 = GaussianProcessRegressor(kernel=kernel, alpha =1.2, n_restarts_optimizer=0)\n",
    "gp1.fit(uX1, uY1)\n",
    "y_pred1, sigma1 = gp1.predict(testX, return_std=True)\n",
    "# y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Optimization - GP1 - for physics\n",
    "    res1 = minimize(nll_fn(x_unlabeled, y_unlabeled), x0 = [.1, .1, .1], \n",
    "                   bounds=((1e-5, None), (1e-5, None), (1e-5, None)),\n",
    "                    method='L-BFGS-B')\n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    mu_s1, cov_s1 = posterior_predictive(trainX, x_unlabeled, y_unlabeled, *res1.x)\n",
    "    \n",
    "    # discrepancy\n",
    "    discp = trainY - mu_s1\n",
    "    \n",
    "    # Optimization - GP2 - for discrepency\n",
    "    res2 = minimize(nll_fn_discp(trainX, discp), x0 = [.1, .1, .1, 1e-3], \n",
    "                   bounds=((1e-5, None), (1e-5, None), (1e-5, None), (1e-7, None)),\n",
    "                    method='L-BFGS-B')\n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    # mu_s2, cov_s2 = posterior_predictive_discp(trainX, trainX, discp, *res2.x)\n",
    "    \n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    mu_s3, cov_s3 = posterior_predictive(testX, x_unlabeled, y_unlabeled, *res1.x)\n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    mu_s4, cov_s4 = posterior_predictive_discp(testX, trainX, discp, *res2.x)\n",
    "    \n",
    "#     print(mu_s2+mu_s1, discp)\n",
    "    pred_mu = mu_s3+mu_s4\n",
    "    pred_cov = cov_s3+cov_s4\n",
    "    \n",
    "#     print(f'After parameter optimization: l1={res.x[0]:.5f} l2={res.x[1]:.5f} sigma_f={res.x[2]:.5f}')\n",
    "#     print(np.exp(res.x[0]),np.exp(res.x[1]), np.exp(res.x[2]))\n",
    "    RMSE = []\n",
    "    for ii in range(int(nsim)):\n",
    "        samples = np.random.multivariate_normal(pred_mu.ravel(), pred_cov, 1)\n",
    "        RMSE.append(root_mean_squared_error(testY, samples))\n",
    "        \n",
    "#         print(\"RMSE:\", root_mean_squared_error(testY, samples))\n",
    "\n",
    "#     return samples, RMSE\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from numpy.linalg import cholesky, det, lstsq\n",
    "from scipy.optimize import minimize\n",
    "import scipy.spatial.distance as spdist\n",
    "\n",
    "def pass_arg(Xx, nsim, tr_size):\n",
    "\n",
    "    print(\"tr_Size:\",tr_size)\n",
    "    \n",
    "#     Compute the RMSE\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred-y_true)**2))\n",
    "    \n",
    "    # Experimental data\n",
    "    data = np.loadtxt('../data/labeled_data.dat')\n",
    "    x_labeled = data[:, :2].astype(np.float64) # -2 because we do not need porosity predictions\n",
    "    y_labeled = data[:, -2:-1].astype(np.float64) # dimensionless bond length and porosity measurements\n",
    "\n",
    "    # normalize dataset with MinMaxScaler\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "    x_labeled = scaler.fit_transform(x_labeled)\n",
    "    # y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "    tr_size = int(tr_size)\n",
    "\n",
    "    # train and test data\n",
    "    trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    testX, testY = x_labeled[30:,:], y_labeled[30:]\n",
    "\n",
    "    # Physics data\n",
    "    data_phyloss = np.loadtxt('../data/unlabeled_data_BK_constw_v2_1525.dat')\n",
    "    x_unlabeled = data_phyloss[:, :]\n",
    "\n",
    "    x_unlabeled1 = x_unlabeled[:1303, :2]\n",
    "    x_unlabeled2 = x_unlabeled[-6:, :2]\n",
    "    y_unlabeled1 = data_phyloss[:1303, -2:-1]\n",
    "    y_unlabeled2 = data_phyloss[-6:, -2:-1]\n",
    "\n",
    "    x_unlabeled = np.vstack((x_unlabeled1,x_unlabeled2))\n",
    "    y_unlabeled = np.vstack((y_unlabeled1,y_unlabeled2))\n",
    "\n",
    "    # normalize dataset with MinMaxScaler\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "    x_unlabeled = scaler.fit_transform(x_unlabeled)\n",
    "\n",
    "\n",
    "    def covSEard(hyp=None, x=None, z=None):\n",
    "        ''' Squared Exponential covariance function with Automatic Relevance Detemination\n",
    "         (ARD) distance measure. The covariance function is parameterized as:\n",
    "\n",
    "         k(x^p,x^q) = sf2 * exp(-(x^p - x^q)' * inv(P) * (x^p - x^q)/2)\n",
    "\n",
    "         where the P matrix is diagonal with ARD parameters ell_1^2,...,ell_D^2, where\n",
    "         D is the dimension of the input space and sf2 is the signal variance.\n",
    "\n",
    "         The hyperparameters are:\n",
    "\n",
    "         hyp = [ log(ell_1)\n",
    "                 log(ell_2)\n",
    "                 ...\n",
    "                 log(ell_D)\n",
    "                 log(sqrt(sf2)) ]\n",
    "        '''\n",
    "\n",
    "        [n, D] = x.shape\n",
    "        ell = 1/np.array(hyp[0:D])        # characteristic length scale\n",
    "        \n",
    "        \n",
    "        sf2 = np.array(hyp[D])**2         # signal variance\n",
    "        tmp = np.dot(np.diag(ell),x.T).T\n",
    "        A = spdist.cdist(np.dot(np.diag(ell),x.T).T, np.dot(np.diag(ell),z.T).T, 'sqeuclidean') # cross covariances\n",
    "        A = sf2*np.exp(-0.5*A)  \n",
    "\n",
    "        return A\n",
    "\n",
    "\n",
    "    def posterior_predictive(X_s, X_train, Y_train, l1=.1, l2=.1, sigma_f=.1, sigma_y=0):\n",
    "        '''  \n",
    "        Computes the suffifient statistics of the GP posterior predictive distribution \n",
    "        from m training data X_train and Y_train and n new inputs X_s.\n",
    "\n",
    "        Args:\n",
    "            X_s: New input locations (n x d).\n",
    "            X_train: Training locations (m x d).\n",
    "            Y_train: Training targets (m x 1).\n",
    "            l: Kernel length parameter.\n",
    "            sigma_f: Kernel vertical variation parameter.\n",
    "            sigma_y: Noise parameter.\n",
    "\n",
    "        Returns:\n",
    "            Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "        '''\n",
    "        K = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_train) + sigma_y**2 * np.eye(len(X_train))\n",
    "        K_s = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_s)\n",
    "        K_ss = covSEard(hyp=[l1,l2,sigma_f], x=X_s, z=X_s)  + 1e-8 * np.eye(len(X_s))\n",
    "#         K_inv = inv(K)\n",
    "        K_inv = np.linalg.pinv(K)\n",
    "    \n",
    "        # Equation (4)\n",
    "        mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "\n",
    "        # Equation (5)\n",
    "        cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "        \n",
    "        return mu_s, cov_s\n",
    "\n",
    "\n",
    "    def nll_fn(X_train, Y_train, noise=0, naive=False):\n",
    "        '''\n",
    "        Returns a function that computes the negative log marginal\n",
    "        likelihood for training data X_train and Y_train and given \n",
    "        noise level.\n",
    "\n",
    "        Args:\n",
    "            X_train: training locations (m x d).\n",
    "            Y_train: training targets (m x 1).\n",
    "            noise: known noise level of Y_train.\n",
    "            naive: if True use a naive implementation of Eq. (7), if \n",
    "                   False use a numerically more stable implementation. \n",
    "\n",
    "        Returns:\n",
    "            Minimization objective.\n",
    "        '''\n",
    "\n",
    "        def nll_stable(theta):\n",
    "            # Numerically more stable implementation of Eq. (7) as described\n",
    "            # in http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, Section\n",
    "            # 2.2, Algorithm 2.1.\n",
    "            K = covSEard(hyp=[theta[0],theta[1],theta[2]], x=X_train, z=X_train) + \\\n",
    "                noise**2 * np.eye(len(X_train))\n",
    "            \n",
    "            K += 1e-6 * np.eye(*K.shape)\n",
    "            L = cholesky(K)\n",
    "            return np.sum(np.log(np.diagonal(L))) + \\\n",
    "                   0.5 * Y_train.T.dot(lstsq(L.T, lstsq(L, Y_train)[0])[0]) + \\\n",
    "                   0.5 * len(X_train) * np.log(2*np.pi)\n",
    "\n",
    "        if naive:\n",
    "            return nll_naive\n",
    "        else:\n",
    "            return nll_stable\n",
    "\n",
    "        \n",
    "    def posterior_predictive_discp(X_s, X_train, Y_train, l1=.1, l2=.1, sigma_f=.1, sigma_y=1e-2):\n",
    "        '''  \n",
    "        Computes the suffifient statistics of the GP posterior predictive distribution \n",
    "        from m training data X_train and Y_train and n new inputs X_s.\n",
    "\n",
    "        Args:\n",
    "            X_s: New input locations (n x d).\n",
    "            X_train: Training locations (m x d).\n",
    "            Y_train: Training targets (m x 1).\n",
    "            l: Kernel length parameter.\n",
    "            sigma_f: Kernel vertical variation parameter.\n",
    "            sigma_y: Noise parameter.\n",
    "\n",
    "        Returns:\n",
    "            Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "        '''\n",
    "        K = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_train) + sigma_y**2 * np.eye(len(X_train))\n",
    "        K_s = covSEard(hyp=[l1,l2,sigma_f], x=X_train, z=X_s)\n",
    "        K_ss = covSEard(hyp=[l1,l2,sigma_f], x=X_s, z=X_s)  + 1e-8 * np.eye(len(X_s))\n",
    "#         K_inv = inv(K)\n",
    "        K_inv = np.linalg.pinv(K)\n",
    "    \n",
    "        # Equation (4)\n",
    "        mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "\n",
    "        # Equation (5)\n",
    "        cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "        \n",
    "        return mu_s, cov_s\n",
    "\n",
    "\n",
    "    def nll_fn_discp(X_train, Y_train, naive=False):\n",
    "        '''\n",
    "        Returns a function that computes the negative log marginal\n",
    "        likelihood for training data X_train and Y_train and given \n",
    "        noise level.\n",
    "\n",
    "        Args:\n",
    "            X_train: training locations (m x d).\n",
    "            Y_train: training targets (m x 1).\n",
    "            noise: known noise level of Y_train.\n",
    "            naive: if True use a naive implementation of Eq. (7), if \n",
    "                   False use a numerically more stable implementation. \n",
    "\n",
    "        Returns:\n",
    "            Minimization objective.\n",
    "        '''\n",
    "\n",
    "        def nll_stable_discp(theta):\n",
    "            # Numerically more stable implementation of Eq. (7) as described\n",
    "            # in http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, Section\n",
    "            # 2.2, Algorithm 2.1.\n",
    "            K = covSEard(hyp=[theta[0],theta[1],theta[2]], x=X_train, z=X_train) + \\\n",
    "                theta[3]**2 * np.eye(len(X_train))\n",
    "            \n",
    "            K += 1e-6 * np.eye(*K.shape)\n",
    "            L = cholesky(K)\n",
    "            return np.sum(np.log(np.diagonal(L))) + \\\n",
    "                   0.5 * Y_train.T.dot(lstsq(L.T, lstsq(L, Y_train)[0])[0]) + \\\n",
    "                   0.5 * len(X_train) * np.log(2*np.pi)\n",
    "\n",
    "        return nll_stable_discp\n",
    "\n",
    "        \n",
    "    \n",
    "    # Optimization - GP1 - for physics\n",
    "    res1 = minimize(nll_fn(x_unlabeled, y_unlabeled), x0 = [.1, .1, .1], \n",
    "                   bounds=((1e-5, None), (1e-5, None), (1e-5, None)),\n",
    "                    method='L-BFGS-B')\n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    mu_s1, cov_s1 = posterior_predictive(trainX, x_unlabeled, y_unlabeled, *res1.x)\n",
    "    \n",
    "    # discrepancy\n",
    "    discp = trainY - mu_s1\n",
    "    \n",
    "    # Optimization - GP2 - for discrepency\n",
    "    res2 = minimize(nll_fn_discp(trainX, discp), x0 = [.1, .1, .1, 1e-3], \n",
    "                   bounds=((1e-5, None), (1e-5, None), (1e-5, None), (1e-7, None)),\n",
    "                    method='L-BFGS-B')\n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    # mu_s2, cov_s2 = posterior_predictive_discp(trainX, trainX, discp, *res2.x)\n",
    "    \n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    mu_s3, cov_s3 = posterior_predictive(testX, x_unlabeled, y_unlabeled, *res1.x)\n",
    "    \n",
    "    # GP (physics) predictions\n",
    "    mu_s4, cov_s4 = posterior_predictive_discp(testX, trainX, discp, *res2.x)\n",
    "    \n",
    "#     print(mu_s2+mu_s1, discp)\n",
    "    pred_mu = mu_s3+mu_s4\n",
    "    pred_cov = cov_s3+cov_s4\n",
    "    \n",
    "#     print(f'After parameter optimization: l1={res.x[0]:.5f} l2={res.x[1]:.5f} sigma_f={res.x[2]:.5f}')\n",
    "#     print(np.exp(res.x[0]),np.exp(res.x[1]), np.exp(res.x[2]))\n",
    "    RMSE = []\n",
    "    for ii in range(int(nsim)):\n",
    "        samples = np.random.multivariate_normal(pred_mu.ravel(), pred_cov, 1)\n",
    "        RMSE.append(root_mean_squared_error(testY, samples))\n",
    "        \n",
    "#         print(\"RMSE:\", root_mean_squared_error(testY, samples))\n",
    "\n",
    "#     return samples, RMSE\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:138: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:205: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:246: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:138: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:205: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:246: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:138: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:205: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:246: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:138: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:205: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:246: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:138: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:205: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:246: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    }
   ],
   "source": [
    "mean_rmses=[]\n",
    "std_rmses=[]\n",
    "for ii in ([5,10,15,20,30]):\n",
    "    test_rmse = pass_arg(1,50, ii)\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    mean_rmses.append(mean_rmse)\n",
    "    std_rmses.append(std_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.021543634321098407,\n",
       " 0.027948028638562494,\n",
       " 0.020109929168299172,\n",
       " 0.02091854865278942,\n",
       " 0.019663648751933157]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0037020347401265346,\n",
       " 0.0034834139754568987,\n",
       " 0.0011804664389471484,\n",
       " 0.0018174825550800135,\n",
       " 0.0009194508446077711]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_Size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:138: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:205: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:246: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.020248739201087725\n",
      "RMSE: 0.019855318666829564\n",
      "RMSE: 0.019753682170980807\n",
      "RMSE: 0.020510976336362362\n",
      "RMSE: 0.019201797328938643\n",
      "RMSE: 0.0186904441945714\n",
      "RMSE: 0.018464260807579735\n",
      "RMSE: 0.021234568169793792\n",
      "RMSE: 0.02057109689190307\n",
      "RMSE: 0.019163702462285836\n",
      "RMSE: 0.019672958289076666\n",
      "RMSE: 0.01926100939483477\n",
      "RMSE: 0.02145115203116223\n",
      "RMSE: 0.01974547784345481\n",
      "RMSE: 0.022133649104951157\n",
      "RMSE: 0.018763336781457845\n",
      "RMSE: 0.01996252772084699\n",
      "RMSE: 0.018483726565608326\n",
      "RMSE: 0.02124211093074169\n",
      "RMSE: 0.018850085798463992\n",
      "RMSE: 0.020056987272245298\n",
      "RMSE: 0.020856763115576972\n",
      "RMSE: 0.019361501332954424\n",
      "RMSE: 0.021012623379733076\n",
      "RMSE: 0.0201465208908012\n",
      "RMSE: 0.018728153094267033\n",
      "RMSE: 0.020493567535124355\n",
      "RMSE: 0.019195348355886002\n",
      "RMSE: 0.020272897074870944\n",
      "RMSE: 0.019333228407999083\n",
      "RMSE: 0.020052841557409176\n",
      "RMSE: 0.018911206909689122\n",
      "RMSE: 0.020808837789034917\n",
      "RMSE: 0.018913012491508438\n",
      "RMSE: 0.02098433582315564\n",
      "RMSE: 0.020003814372168676\n",
      "RMSE: 0.01978540531134652\n",
      "RMSE: 0.01914297403780994\n",
      "RMSE: 0.021357069981227453\n",
      "RMSE: 0.019371493149744085\n",
      "RMSE: 0.021650991726426125\n",
      "RMSE: 0.020677766124801128\n",
      "RMSE: 0.020835979986647147\n",
      "RMSE: 0.01970764742648036\n",
      "RMSE: 0.01937026011510054\n",
      "RMSE: 0.021144350344311984\n",
      "RMSE: 0.019782724531449202\n",
      "RMSE: 0.01919872550037938\n",
      "RMSE: 0.01967834085715616\n",
      "RMSE: 0.019475496240717597\n",
      "RMSE: 0.019319763231473545\n",
      "RMSE: 0.020623311047636303\n",
      "RMSE: 0.019010293909600014\n",
      "RMSE: 0.020493244462925823\n",
      "RMSE: 0.022169949355123387\n",
      "RMSE: 0.020110349657186867\n",
      "RMSE: 0.018536608671130318\n",
      "RMSE: 0.021406205850873782\n",
      "RMSE: 0.01996272236057645\n",
      "RMSE: 0.01931612744042312\n",
      "RMSE: 0.01908441142423251\n",
      "RMSE: 0.020062187609181274\n",
      "RMSE: 0.020074675323880468\n",
      "RMSE: 0.020571502468301108\n",
      "RMSE: 0.01918262373695418\n",
      "RMSE: 0.019724210765289782\n",
      "RMSE: 0.01989385509461781\n",
      "RMSE: 0.019385841992443472\n",
      "RMSE: 0.021057253012551146\n",
      "RMSE: 0.01780415465856293\n",
      "RMSE: 0.01872389670439265\n",
      "RMSE: 0.019226834302403375\n",
      "RMSE: 0.02103482067097342\n",
      "RMSE: 0.021778289113117664\n",
      "RMSE: 0.020544140477088375\n",
      "RMSE: 0.020369016202867393\n",
      "RMSE: 0.019242771409527664\n",
      "RMSE: 0.019865677611502677\n",
      "RMSE: 0.019625634528607626\n",
      "RMSE: 0.020594014442230996\n",
      "RMSE: 0.019582310231841538\n",
      "RMSE: 0.02158868841253417\n",
      "RMSE: 0.020394337857876914\n",
      "RMSE: 0.021165410675946184\n",
      "RMSE: 0.02071880070298199\n",
      "RMSE: 0.01947718321927184\n",
      "RMSE: 0.019098031070411844\n",
      "RMSE: 0.019400325576518232\n",
      "RMSE: 0.020931826881565516\n",
      "RMSE: 0.018179201944451866\n",
      "RMSE: 0.018251143429834322\n",
      "RMSE: 0.020686029704081246\n",
      "RMSE: 0.018319677978463615\n",
      "RMSE: 0.01912780383584863\n",
      "RMSE: 0.020031778851520434\n",
      "RMSE: 0.020224791887333938\n",
      "RMSE: 0.020190611530226277\n",
      "RMSE: 0.020769666769761462\n",
      "RMSE: 0.022374319220827735\n",
      "RMSE: 0.019637161144837642\n"
     ]
    }
   ],
   "source": [
    "Xx = np.random.uniform(size=(3, 2))\n",
    "ss, rmse = pass_arg(Xx, 100, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01996514973888765"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\R\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: scipy.arange is deprecated and will be removed in SciPy 2.0.0, use numpy.arange instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x134ea56fdd8>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 15\n",
    "x = scipy.arange(size)\n",
    "pdf_fitted = dist.pdf(x, *param[:-2], loc=param[-2], scale=param[-1]) * size\n",
    "plt.plot(pdf_fitted, label='gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
