{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "import scipy.io as spio\n",
    "\n",
    "def pass_arg(nsim, tr_size, dropoutrate):\n",
    "    print(\"Tr_size:\", tr_size)\n",
    "    def fix_seeds(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    #     K.set_session(sess)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    ss = 1\n",
    "    fix_seeds(ss)\n",
    "\n",
    "    # MC dropout\n",
    "    class MCDropout(Dropout):\n",
    "        def call(self, inputs, training=None):\n",
    "            return super(MCDropout, self).call(inputs, training=True)\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # def save_obj(obj, name):\n",
    "    #     with open(name, 'wb') as f:\n",
    "    #         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "    # Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "            return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "\n",
    "    #function for computing the density given the temperature(nx1 matrix)\n",
    "    def density(temp):\n",
    "        return 1000 * ( 1 - (temp + 288.9414) * (temp - 3.9863)**2 / (508929.2 * (temp + 68.12963) ) )\n",
    "\n",
    "    def phy_loss_mean(params):\n",
    "        # useful for cross-checking training\n",
    "        udendiff, lam = params\n",
    "        def loss(y_true,y_pred):\n",
    "            return K.mean(K.relu(udendiff))\n",
    "        return loss\n",
    "\n",
    "    #function to calculate the combined loss = sum of rmse and phy based loss\n",
    "    def combined_loss(params):\n",
    "        udendiff, lam = params\n",
    "        def loss(y_true,y_pred):\n",
    "            return mean_squared_error(y_true, y_pred) + lam * K.mean(K.relu(udendiff))\n",
    "        return loss\n",
    "\n",
    "    def PGNN_train_test(lake_name, optimizer_name, optimizer_val, drop_frac, \n",
    "                        use_YPhy, iteration, n_layers, n_nodes, tr_size, lamda, reg):\n",
    "\n",
    "    #     fix_seeds(ss)\n",
    "\n",
    "        # Hyper-parameters of the training process\n",
    "    #     batch_size = tr_size\n",
    "        batch_size = 1000\n",
    "        num_epochs = 1000\n",
    "        val_frac = 0.2\n",
    "        patience_val = 100\n",
    "\n",
    "        # Initializing results filename\n",
    "        exp_name = \"DNN_loss\" + optimizer_name + '_drop' + str(drop_frac) + '_usePhy' + str(use_YPhy) +  '_nL' + str(n_layers) + '_nN' + str(n_nodes) + '_trsize' + str(tr_size) + '_lamda' + str(lamda) + '_iter' + str(iteration)\n",
    "        exp_name = exp_name.replace('.','pt')\n",
    "        results_dir = '../results/'\n",
    "        model_name = results_dir + exp_name + '_model.h5' # storing the trained model\n",
    "\n",
    "#         if reg==True and samp==25:\n",
    "#             results_name = results_dir + exp_name + '_results_25_regularizer.dat' # storing the results of the model\n",
    "#         elif reg==False and samp==25:\n",
    "#             results_name = results_dir + exp_name + '_results_25.dat' # storing the results of the model\n",
    "#         elif reg==True and samp==1519:\n",
    "#             results_name = results_dir + exp_name + '_results_1519_regularizer.dat' # storing the results of the model\n",
    "#         elif reg==False and samp==1519:\n",
    "#             results_name = results_dir + exp_name + '_results_1519.dat' # storing the results of the model\n",
    "\n",
    "\n",
    "        # Load features (Xc) and target values (Y)\n",
    "        data_dir = '../../data/'\n",
    "        filename = lake_name + '.mat'\n",
    "        mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "        variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "        Xc = mat['Xc_doy']\n",
    "        Y = mat['Y']\n",
    "\n",
    "        # normalize dataset with MinMaxScaler\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "        Xc = scaler.fit_transform(Xc)\n",
    "        # y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "        # train and test data\n",
    "        trainX, trainY = Xc[:tr_size,:-1], Y[:tr_size]\n",
    "        testX, testY = Xc[-1500:,:-1], Y[-1500:]\n",
    "\n",
    "        \n",
    "        # Loading unsupervised data\n",
    "        unsup_filename = lake_name + '_sampled.mat'\n",
    "        unsup_mat = spio.loadmat(data_dir+unsup_filename, squeeze_me=True,\n",
    "        variable_names=['Xc_doy1','Xc_doy2'])\n",
    "\n",
    "        uX1 = unsup_mat['Xc_doy1'] # Xc at depth i for every pair of consecutive depth values\n",
    "        uX2 = unsup_mat['Xc_doy2'] # Xc at depth i + 1 for every pair of consecutive depth values\n",
    "        \n",
    "#         uX1 = uX1[range(0,649723,51),:]\n",
    "#         uX2 = uX2[range(0,649723,51),:]\n",
    "        \n",
    "#         uX1 = uX1[range(0,286738,25),:]\n",
    "#         uX2 = uX2[range(0,286738,25),:]\n",
    "        \n",
    "#         uX1 = uX1[:100000,:]\n",
    "#         uX2 = uX2[:100000,:]\n",
    "\n",
    "        if use_YPhy == 0:\n",
    "            # Removing the last column from uX (corresponding to Y_PHY)\n",
    "            uX1 = uX1[:,:-1]\n",
    "            uX2 = uX2[:,:-1]\n",
    "\n",
    "        uX1 = scaler.fit_transform(uX1)\n",
    "        uX2 = scaler.fit_transform(uX2)\n",
    "        \n",
    "        # Creating the model\n",
    "        model = Sequential()\n",
    "        for layer in np.arange(n_layers):\n",
    "            if layer == 0:\n",
    "                model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "            else:\n",
    "                if reg:\n",
    "                    model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.00, l2=.00)))\n",
    "                else:\n",
    "                    model.add(Dense(n_nodes, activation='relu'))\n",
    "            # model.add(Dropout(rate=drop_frac))\n",
    "            model.add(MCDropout(rate=drop_frac))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        # physics-based regularization\n",
    "        uin1 = K.constant(value=uX1) # input at depth i\n",
    "        uin2 = K.constant(value=uX2) # input at depth i + 1\n",
    "        lam = K.constant(value=lamda) # regularization hyper-parameter\n",
    "        uout1 = model(uin1) # model output at depth i\n",
    "        uout2 = model(uin2) # model output at depth i + 1\n",
    "        udendiff = (density(uout1) - density(uout2)) # difference in density estimates at every pair of depth values\n",
    "\n",
    "        totloss = combined_loss([udendiff, lam])\n",
    "        phyloss = phy_loss_mean([udendiff, lam])\n",
    "    \n",
    "        model.compile(loss=totloss,\n",
    "                      optimizer=optimizer_val,\n",
    "                      metrics=[phyloss, root_mean_squared_error])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val, verbose=1)\n",
    "\n",
    "    #     print('Running...' + optimizer_name)\n",
    "        history = model.fit(trainX, trainY,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=num_epochs,\n",
    "                            verbose=1,\n",
    "                            validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "    \n",
    "        test_score = model.evaluate(testX, testY, verbose=1)\n",
    "        print(test_score)\n",
    "\n",
    "        test_scores = []\n",
    "        for i in range(int(nsim)):\n",
    "#             print(\"simulation num:\",i)\n",
    "#             predictions = model.predict(testX)\n",
    "#             samples.append(predictions)\n",
    "            test_score = model.evaluate(testX, testY, verbose=0)\n",
    "            test_scores.append(test_score[2])\n",
    "        return np.array(test_scores), history\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Main Function\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        fix_seeds(1)\n",
    "\n",
    "        # List of optimizers to choose from    \n",
    "        optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "        optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "\n",
    "        # selecting the optimizer\n",
    "        optimizer_num = 2\n",
    "        optimizer_name = optimizer_names[optimizer_num]\n",
    "        optimizer_val = optimizer_vals[optimizer_num]\n",
    "\n",
    "        # Selecting Other Hyper-parameters\n",
    "        drop_frac = dropoutrate # Fraction of nodes to be dropped out\n",
    "        use_YPhy = 0 # Whether YPhy is used as another feature in the NN model or not\n",
    "        n_layers = 2 # Number of hidden layers\n",
    "        n_nodes = 15 # Number of nodes per hidden layer\n",
    "\n",
    "        #set lamda\n",
    "        lamda = 10 # Physics-based regularization constant  \n",
    "#         lamda = 1500\n",
    "        \n",
    "        tr_size = int(tr_size)\n",
    "\n",
    "        # use regularizer\n",
    "        reg = True\n",
    "\n",
    "        #List of lakes to choose from\n",
    "        lake = ['mendota' , 'mille_lacs']\n",
    "        lake_num = 0  # 0 : mendota , 1 : mille_lacs\n",
    "        lake_name = lake[lake_num]\n",
    "        \n",
    "        # total number of runs\n",
    "        iter_range = np.arange(1)\n",
    "        testrmse=[]\n",
    "        # iterating through all possible params\n",
    "        for iteration in iter_range:\n",
    "#             results, result_file, pred, obs, rmse, obs_train = PGNN_train_test(optimizer_name, optimizer_val, drop_frac, use_YPhy, \n",
    "#                             iteration, n_layers, n_nodes, tr_size, lamda, reg, samp)\n",
    "#             testrmse.append(rmse)\n",
    "            test_rmse,history = PGNN_train_test(lake_name, optimizer_name, optimizer_val, drop_frac, use_YPhy, \n",
    "                            iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "            \n",
    "\n",
    "    return np.squeeze(test_rmse), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 12000\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/1000\n",
      "9600/9600 [==============================] - 1s 119us/step - loss: 231.0116 - loss_1: 0.0044 - root_mean_squared_error: 14.0083 - val_loss: 219.5777 - val_loss_1: 0.0039 - val_root_mean_squared_error: 13.5917\n",
      "Epoch 2/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 225.8631 - loss_1: 0.0038 - root_mean_squared_error: 13.8299 - val_loss: 214.5443 - val_loss_1: 0.0037 - val_root_mean_squared_error: 13.4105\n",
      "Epoch 3/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 220.6966 - loss_1: 0.0039 - root_mean_squared_error: 13.6487 - val_loss: 209.6728 - val_loss_1: 0.0043 - val_root_mean_squared_error: 13.2312\n",
      "Epoch 4/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 215.4617 - loss_1: 0.0047 - root_mean_squared_error: 13.4614 - val_loss: 204.6116 - val_loss_1: 0.0052 - val_root_mean_squared_error: 13.0437\n",
      "Epoch 5/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 210.2273 - loss_1: 0.0056 - root_mean_squared_error: 13.2713 - val_loss: 199.2215 - val_loss_1: 0.0061 - val_root_mean_squared_error: 12.8424\n",
      "Epoch 6/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 204.8836 - loss_1: 0.0066 - root_mean_squared_error: 13.0723 - val_loss: 194.1698 - val_loss_1: 0.0071 - val_root_mean_squared_error: 12.6450\n",
      "Epoch 7/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 199.2746 - loss_1: 0.0075 - root_mean_squared_error: 12.8577 - val_loss: 188.3504 - val_loss_1: 0.0081 - val_root_mean_squared_error: 12.4198\n",
      "Epoch 8/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 193.1864 - loss_1: 0.0084 - root_mean_squared_error: 12.6259 - val_loss: 182.7341 - val_loss_1: 0.0089 - val_root_mean_squared_error: 12.1978\n",
      "Epoch 9/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 186.4358 - loss_1: 0.0091 - root_mean_squared_error: 12.3562 - val_loss: 175.2351 - val_loss_1: 0.0093 - val_root_mean_squared_error: 11.8963\n",
      "Epoch 10/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 178.5739 - loss_1: 0.0094 - root_mean_squared_error: 12.0403 - val_loss: 166.2050 - val_loss_1: 0.0093 - val_root_mean_squared_error: 11.5364\n",
      "Epoch 11/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 168.3699 - loss_1: 0.0090 - root_mean_squared_error: 11.6249 - val_loss: 156.5249 - val_loss_1: 0.0086 - val_root_mean_squared_error: 11.1223\n",
      "Epoch 12/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 157.7354 - loss_1: 0.0079 - root_mean_squared_error: 11.1788 - val_loss: 146.0755 - val_loss_1: 0.0069 - val_root_mean_squared_error: 10.6770\n",
      "Epoch 13/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 146.0780 - loss_1: 0.0058 - root_mean_squared_error: 10.6843 - val_loss: 133.9607 - val_loss_1: 0.0047 - val_root_mean_squared_error: 10.1535\n",
      "Epoch 14/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 134.3312 - loss_1: 0.0044 - root_mean_squared_error: 10.1498 - val_loss: 122.1714 - val_loss_1: 0.0047 - val_root_mean_squared_error: 9.5724\n",
      "Epoch 15/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 122.3553 - loss_1: 0.0062 - root_mean_squared_error: 9.5745 - val_loss: 111.0825 - val_loss_1: 0.0087 - val_root_mean_squared_error: 9.0011\n",
      "Epoch 16/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 109.3608 - loss_1: 0.0120 - root_mean_squared_error: 8.8993 - val_loss: 98.3162 - val_loss_1: 0.0167 - val_root_mean_squared_error: 8.3243\n",
      "Epoch 17/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 96.2683 - loss_1: 0.0215 - root_mean_squared_error: 8.2005 - val_loss: 86.0912 - val_loss_1: 0.0280 - val_root_mean_squared_error: 7.6230\n",
      "Epoch 18/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 84.1876 - loss_1: 0.0341 - root_mean_squared_error: 7.4918 - val_loss: 75.7555 - val_loss_1: 0.0423 - val_root_mean_squared_error: 7.0077\n",
      "Epoch 19/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 72.9873 - loss_1: 0.0499 - root_mean_squared_error: 6.8116 - val_loss: 65.1093 - val_loss_1: 0.0598 - val_root_mean_squared_error: 6.2743\n",
      "Epoch 20/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 62.4943 - loss_1: 0.0689 - root_mean_squared_error: 6.1551 - val_loss: 56.7056 - val_loss_1: 0.0807 - val_root_mean_squared_error: 5.7580\n",
      "Epoch 21/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 53.3391 - loss_1: 0.0917 - root_mean_squared_error: 5.6059 - val_loss: 49.6199 - val_loss_1: 0.1053 - val_root_mean_squared_error: 5.2869\n",
      "Epoch 22/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 46.2019 - loss_1: 0.1179 - root_mean_squared_error: 5.2202 - val_loss: 43.8599 - val_loss_1: 0.1338 - val_root_mean_squared_error: 5.0403\n",
      "Epoch 23/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 41.1691 - loss_1: 0.1474 - root_mean_squared_error: 4.9937 - val_loss: 40.5075 - val_loss_1: 0.1645 - val_root_mean_squared_error: 4.9501\n",
      "Epoch 24/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 38.9389 - loss_1: 0.1765 - root_mean_squared_error: 4.9707 - val_loss: 40.3581 - val_loss_1: 0.1865 - val_root_mean_squared_error: 5.0357\n",
      "Epoch 25/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 37.6724 - loss_1: 0.1859 - root_mean_squared_error: 4.9051 - val_loss: 39.2227 - val_loss_1: 0.1815 - val_root_mean_squared_error: 5.0038\n",
      "Epoch 26/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 36.8117 - loss_1: 0.1757 - root_mean_squared_error: 4.8274 - val_loss: 37.0798 - val_loss_1: 0.1697 - val_root_mean_squared_error: 4.8314\n",
      "Epoch 27/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 35.0272 - loss_1: 0.1679 - root_mean_squared_error: 4.7001 - val_loss: 37.2471 - val_loss_1: 0.1668 - val_root_mean_squared_error: 4.8059\n",
      "Epoch 28/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 33.6953 - loss_1: 0.1665 - root_mean_squared_error: 4.6139 - val_loss: 34.5433 - val_loss_1: 0.1669 - val_root_mean_squared_error: 4.6175\n",
      "Epoch 29/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 32.3746 - loss_1: 0.1653 - root_mean_squared_error: 4.5050 - val_loss: 33.3841 - val_loss_1: 0.1644 - val_root_mean_squared_error: 4.5310\n",
      "Epoch 30/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 31.3977 - loss_1: 0.1652 - root_mean_squared_error: 4.4330 - val_loss: 32.5036 - val_loss_1: 0.1644 - val_root_mean_squared_error: 4.5094\n",
      "Epoch 31/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 30.5887 - loss_1: 0.1619 - root_mean_squared_error: 4.3791 - val_loss: 31.6324 - val_loss_1: 0.1577 - val_root_mean_squared_error: 4.4250\n",
      "Epoch 32/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 29.9487 - loss_1: 0.1562 - root_mean_squared_error: 4.3077 - val_loss: 30.2753 - val_loss_1: 0.1537 - val_root_mean_squared_error: 4.2527\n",
      "Epoch 33/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 28.6522 - loss_1: 0.1520 - root_mean_squared_error: 4.2096 - val_loss: 28.9755 - val_loss_1: 0.1520 - val_root_mean_squared_error: 4.2240\n",
      "Epoch 34/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 27.6732 - loss_1: 0.1525 - root_mean_squared_error: 4.1176 - val_loss: 27.5872 - val_loss_1: 0.1525 - val_root_mean_squared_error: 4.0866\n",
      "Epoch 35/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 26.6391 - loss_1: 0.1505 - root_mean_squared_error: 4.0448 - val_loss: 27.0898 - val_loss_1: 0.1490 - val_root_mean_squared_error: 4.0132\n",
      "Epoch 36/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 26.0643 - loss_1: 0.1493 - root_mean_squared_error: 3.9896 - val_loss: 25.8144 - val_loss_1: 0.1489 - val_root_mean_squared_error: 3.9605\n",
      "Epoch 37/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 25.9166 - loss_1: 0.1482 - root_mean_squared_error: 3.9588 - val_loss: 25.7738 - val_loss_1: 0.1464 - val_root_mean_squared_error: 3.8948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 24.7986 - loss_1: 0.1473 - root_mean_squared_error: 3.8741 - val_loss: 24.3210 - val_loss_1: 0.1481 - val_root_mean_squared_error: 3.8203\n",
      "Epoch 39/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 23.8182 - loss_1: 0.1479 - root_mean_squared_error: 3.7983 - val_loss: 23.7362 - val_loss_1: 0.1463 - val_root_mean_squared_error: 3.7513\n",
      "Epoch 40/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 23.6679 - loss_1: 0.1448 - root_mean_squared_error: 3.7647 - val_loss: 23.0972 - val_loss_1: 0.1450 - val_root_mean_squared_error: 3.6412\n",
      "Epoch 41/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 23.7910 - loss_1: 0.1462 - root_mean_squared_error: 3.7553 - val_loss: 22.2667 - val_loss_1: 0.1453 - val_root_mean_squared_error: 3.5959\n",
      "Epoch 42/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 22.4294 - loss_1: 0.1439 - root_mean_squared_error: 3.6243 - val_loss: 21.0987 - val_loss_1: 0.1432 - val_root_mean_squared_error: 3.4491\n",
      "Epoch 43/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 22.1041 - loss_1: 0.1460 - root_mean_squared_error: 3.5997 - val_loss: 20.9854 - val_loss_1: 0.1451 - val_root_mean_squared_error: 3.4826\n",
      "Epoch 44/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 21.6239 - loss_1: 0.1432 - root_mean_squared_error: 3.5506 - val_loss: 21.2504 - val_loss_1: 0.1432 - val_root_mean_squared_error: 3.4549\n",
      "Epoch 45/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 21.1535 - loss_1: 0.1442 - root_mean_squared_error: 3.4962 - val_loss: 20.6986 - val_loss_1: 0.1427 - val_root_mean_squared_error: 3.4337\n",
      "Epoch 46/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 20.6112 - loss_1: 0.1427 - root_mean_squared_error: 3.4584 - val_loss: 20.6261 - val_loss_1: 0.1429 - val_root_mean_squared_error: 3.4104\n",
      "Epoch 47/1000\n",
      "9600/9600 [==============================] - 1s 106us/step - loss: 20.1997 - loss_1: 0.1414 - root_mean_squared_error: 3.4029 - val_loss: 19.9319 - val_loss_1: 0.1409 - val_root_mean_squared_error: 3.3551\n",
      "Epoch 48/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 20.2820 - loss_1: 0.1409 - root_mean_squared_error: 3.4104 - val_loss: 20.0748 - val_loss_1: 0.1428 - val_root_mean_squared_error: 3.3547\n",
      "Epoch 49/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 19.7340 - loss_1: 0.1422 - root_mean_squared_error: 3.3572 - val_loss: 20.3638 - val_loss_1: 0.1422 - val_root_mean_squared_error: 3.3700\n",
      "Epoch 50/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 19.3291 - loss_1: 0.1410 - root_mean_squared_error: 3.3205 - val_loss: 18.4944 - val_loss_1: 0.1405 - val_root_mean_squared_error: 3.2021\n",
      "Epoch 51/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 19.3038 - loss_1: 0.1394 - root_mean_squared_error: 3.3133 - val_loss: 19.7002 - val_loss_1: 0.1380 - val_root_mean_squared_error: 3.3115\n",
      "Epoch 52/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 19.4176 - loss_1: 0.1394 - root_mean_squared_error: 3.3260 - val_loss: 18.7387 - val_loss_1: 0.1415 - val_root_mean_squared_error: 3.2370\n",
      "Epoch 53/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 19.5869 - loss_1: 0.1387 - root_mean_squared_error: 3.3333 - val_loss: 19.2258 - val_loss_1: 0.1404 - val_root_mean_squared_error: 3.3079\n",
      "Epoch 54/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 18.9916 - loss_1: 0.1409 - root_mean_squared_error: 3.2809 - val_loss: 18.3360 - val_loss_1: 0.1365 - val_root_mean_squared_error: 3.1925\n",
      "Epoch 55/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 18.2580 - loss_1: 0.1373 - root_mean_squared_error: 3.2126 - val_loss: 18.7280 - val_loss_1: 0.1392 - val_root_mean_squared_error: 3.2566\n",
      "Epoch 56/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 18.5270 - loss_1: 0.1363 - root_mean_squared_error: 3.2416 - val_loss: 19.0909 - val_loss_1: 0.1365 - val_root_mean_squared_error: 3.2657\n",
      "Epoch 57/1000\n",
      "9600/9600 [==============================] - 1s 105us/step - loss: 18.3224 - loss_1: 0.1367 - root_mean_squared_error: 3.2299 - val_loss: 18.0896 - val_loss_1: 0.1340 - val_root_mean_squared_error: 3.1694\n",
      "Epoch 58/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 18.3347 - loss_1: 0.1360 - root_mean_squared_error: 3.1975 - val_loss: 18.8852 - val_loss_1: 0.1374 - val_root_mean_squared_error: 3.2417\n",
      "Epoch 59/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 18.5458 - loss_1: 0.1341 - root_mean_squared_error: 3.2398 - val_loss: 18.9068 - val_loss_1: 0.1359 - val_root_mean_squared_error: 3.2434\n",
      "Epoch 60/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 18.3833 - loss_1: 0.1379 - root_mean_squared_error: 3.2370 - val_loss: 18.2849 - val_loss_1: 0.1355 - val_root_mean_squared_error: 3.1897\n",
      "Epoch 61/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 18.1124 - loss_1: 0.1340 - root_mean_squared_error: 3.1861 - val_loss: 18.3853 - val_loss_1: 0.1324 - val_root_mean_squared_error: 3.1969\n",
      "Epoch 62/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 18.3693 - loss_1: 0.1317 - root_mean_squared_error: 3.2227 - val_loss: 17.8547 - val_loss_1: 0.1343 - val_root_mean_squared_error: 3.1408\n",
      "Epoch 63/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 18.1655 - loss_1: 0.1344 - root_mean_squared_error: 3.2132 - val_loss: 17.1131 - val_loss_1: 0.1313 - val_root_mean_squared_error: 3.0662\n",
      "Epoch 64/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 18.0278 - loss_1: 0.1293 - root_mean_squared_error: 3.1870 - val_loss: 18.4531 - val_loss_1: 0.1291 - val_root_mean_squared_error: 3.2376\n",
      "Epoch 65/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 17.6941 - loss_1: 0.1303 - root_mean_squared_error: 3.1691 - val_loss: 18.0677 - val_loss_1: 0.1330 - val_root_mean_squared_error: 3.1579\n",
      "Epoch 66/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 17.2788 - loss_1: 0.1319 - root_mean_squared_error: 3.1228 - val_loss: 17.9266 - val_loss_1: 0.1289 - val_root_mean_squared_error: 3.1582\n",
      "Epoch 67/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 17.5637 - loss_1: 0.1289 - root_mean_squared_error: 3.1733 - val_loss: 18.1198 - val_loss_1: 0.1316 - val_root_mean_squared_error: 3.1679\n",
      "Epoch 68/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 17.3366 - loss_1: 0.1297 - root_mean_squared_error: 3.1322 - val_loss: 17.6541 - val_loss_1: 0.1287 - val_root_mean_squared_error: 3.1349\n",
      "Epoch 69/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 17.7653 - loss_1: 0.1284 - root_mean_squared_error: 3.1705 - val_loss: 17.4981 - val_loss_1: 0.1282 - val_root_mean_squared_error: 3.1473\n",
      "Epoch 70/1000\n",
      "9600/9600 [==============================] - 1s 105us/step - loss: 17.4898 - loss_1: 0.1280 - root_mean_squared_error: 3.1393 - val_loss: 18.0117 - val_loss_1: 0.1280 - val_root_mean_squared_error: 3.1650\n",
      "Epoch 71/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 17.3616 - loss_1: 0.1283 - root_mean_squared_error: 3.1240 - val_loss: 17.3745 - val_loss_1: 0.1262 - val_root_mean_squared_error: 3.1191\n",
      "Epoch 72/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 17.0638 - loss_1: 0.1247 - root_mean_squared_error: 3.1085 - val_loss: 17.8773 - val_loss_1: 0.1273 - val_root_mean_squared_error: 3.1564\n",
      "Epoch 73/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 17.5381 - loss_1: 0.1282 - root_mean_squared_error: 3.1435 - val_loss: 17.3575 - val_loss_1: 0.1256 - val_root_mean_squared_error: 3.0977\n",
      "Epoch 74/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 16.8809 - loss_1: 0.1245 - root_mean_squared_error: 3.0954 - val_loss: 18.3012 - val_loss_1: 0.1246 - val_root_mean_squared_error: 3.1850\n",
      "Epoch 75/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 16.7756 - loss_1: 0.1239 - root_mean_squared_error: 3.0756 - val_loss: 17.6568 - val_loss_1: 0.1262 - val_root_mean_squared_error: 3.1039\n",
      "Epoch 76/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 16.8067 - loss_1: 0.1266 - root_mean_squared_error: 3.0826 - val_loss: 16.7049 - val_loss_1: 0.1229 - val_root_mean_squared_error: 3.0343\n",
      "Epoch 77/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 16.7348 - loss_1: 0.1228 - root_mean_squared_error: 3.0674 - val_loss: 16.7471 - val_loss_1: 0.1224 - val_root_mean_squared_error: 3.0711\n",
      "Epoch 78/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 16.6062 - loss_1: 0.1238 - root_mean_squared_error: 3.0678 - val_loss: 17.0266 - val_loss_1: 0.1239 - val_root_mean_squared_error: 3.0509\n",
      "Epoch 79/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 16.6602 - loss_1: 0.1233 - root_mean_squared_error: 3.0708 - val_loss: 17.2830 - val_loss_1: 0.1213 - val_root_mean_squared_error: 3.1002\n",
      "Epoch 80/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 16.4099 - loss_1: 0.1223 - root_mean_squared_error: 3.0472 - val_loss: 16.3912 - val_loss_1: 0.1218 - val_root_mean_squared_error: 3.0110\n",
      "Epoch 81/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 16.2392 - loss_1: 0.1218 - root_mean_squared_error: 3.0262 - val_loss: 16.7218 - val_loss_1: 0.1218 - val_root_mean_squared_error: 3.0425\n",
      "Epoch 82/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 16.3427 - loss_1: 0.1229 - root_mean_squared_error: 3.0489 - val_loss: 16.2625 - val_loss_1: 0.1203 - val_root_mean_squared_error: 2.9877\n",
      "Epoch 83/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 16.0426 - loss_1: 0.1184 - root_mean_squared_error: 3.0030 - val_loss: 16.8559 - val_loss_1: 0.1216 - val_root_mean_squared_error: 3.0721\n",
      "Epoch 84/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 16.1916 - loss_1: 0.1225 - root_mean_squared_error: 3.0220 - val_loss: 16.0909 - val_loss_1: 0.1207 - val_root_mean_squared_error: 3.0344\n",
      "Epoch 85/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 16.3062 - loss_1: 0.1205 - root_mean_squared_error: 3.0330 - val_loss: 16.8221 - val_loss_1: 0.1214 - val_root_mean_squared_error: 3.0611\n",
      "Epoch 86/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 16.2226 - loss_1: 0.1199 - root_mean_squared_error: 3.0138 - val_loss: 15.3904 - val_loss_1: 0.1183 - val_root_mean_squared_error: 2.9193\n",
      "Epoch 87/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 15.5461 - loss_1: 0.1196 - root_mean_squared_error: 2.9618 - val_loss: 16.0583 - val_loss_1: 0.1216 - val_root_mean_squared_error: 2.9926\n",
      "Epoch 88/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 15.8618 - loss_1: 0.1196 - root_mean_squared_error: 2.9952 - val_loss: 16.2935 - val_loss_1: 0.1165 - val_root_mean_squared_error: 2.9823\n",
      "Epoch 89/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 16.1633 - loss_1: 0.1181 - root_mean_squared_error: 3.0143 - val_loss: 15.9538 - val_loss_1: 0.1195 - val_root_mean_squared_error: 2.9649\n",
      "Epoch 90/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 15.8672 - loss_1: 0.1188 - root_mean_squared_error: 2.9996 - val_loss: 16.2346 - val_loss_1: 0.1186 - val_root_mean_squared_error: 2.9964\n",
      "Epoch 91/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 15.4890 - loss_1: 0.1186 - root_mean_squared_error: 2.9581 - val_loss: 15.6770 - val_loss_1: 0.1165 - val_root_mean_squared_error: 2.9594\n",
      "Epoch 92/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 15.5027 - loss_1: 0.1182 - root_mean_squared_error: 2.9533 - val_loss: 15.3378 - val_loss_1: 0.1195 - val_root_mean_squared_error: 2.9258\n",
      "Epoch 93/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 15.1418 - loss_1: 0.1196 - root_mean_squared_error: 2.9166 - val_loss: 15.5637 - val_loss_1: 0.1186 - val_root_mean_squared_error: 2.9472\n",
      "Epoch 94/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 15.7833 - loss_1: 0.1192 - root_mean_squared_error: 2.9690 - val_loss: 15.1079 - val_loss_1: 0.1183 - val_root_mean_squared_error: 2.8685\n",
      "Epoch 95/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 15.2318 - loss_1: 0.1182 - root_mean_squared_error: 2.9204 - val_loss: 15.7015 - val_loss_1: 0.1186 - val_root_mean_squared_error: 2.9778\n",
      "Epoch 96/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.9884 - loss_1: 0.1188 - root_mean_squared_error: 2.9031 - val_loss: 15.3690 - val_loss_1: 0.1182 - val_root_mean_squared_error: 2.9188\n",
      "Epoch 97/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 15.1653 - loss_1: 0.1176 - root_mean_squared_error: 2.9206 - val_loss: 15.5928 - val_loss_1: 0.1172 - val_root_mean_squared_error: 2.9320\n",
      "Epoch 98/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.8087 - loss_1: 0.1182 - root_mean_squared_error: 2.8711 - val_loss: 15.2965 - val_loss_1: 0.1175 - val_root_mean_squared_error: 2.9333\n",
      "Epoch 99/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.3872 - loss_1: 0.1162 - root_mean_squared_error: 2.8310 - val_loss: 14.8236 - val_loss_1: 0.1161 - val_root_mean_squared_error: 2.8897\n",
      "Epoch 100/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.6780 - loss_1: 0.1160 - root_mean_squared_error: 2.8569 - val_loss: 14.5227 - val_loss_1: 0.1171 - val_root_mean_squared_error: 2.8357\n",
      "Epoch 101/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 14.8390 - loss_1: 0.1172 - root_mean_squared_error: 2.8758 - val_loss: 15.1574 - val_loss_1: 0.1169 - val_root_mean_squared_error: 2.9160\n",
      "Epoch 102/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.5565 - loss_1: 0.1168 - root_mean_squared_error: 2.8674 - val_loss: 15.0282 - val_loss_1: 0.1162 - val_root_mean_squared_error: 2.8803\n",
      "Epoch 103/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 14.2545 - loss_1: 0.1166 - root_mean_squared_error: 2.8110 - val_loss: 14.5872 - val_loss_1: 0.1150 - val_root_mean_squared_error: 2.8626\n",
      "Epoch 104/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.3335 - loss_1: 0.1154 - root_mean_squared_error: 2.8277 - val_loss: 14.2862 - val_loss_1: 0.1161 - val_root_mean_squared_error: 2.7958\n",
      "Epoch 105/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.3633 - loss_1: 0.1164 - root_mean_squared_error: 2.8119 - val_loss: 14.1122 - val_loss_1: 0.1147 - val_root_mean_squared_error: 2.7464\n",
      "Epoch 106/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.4593 - loss_1: 0.1152 - root_mean_squared_error: 2.8169 - val_loss: 14.5433 - val_loss_1: 0.1168 - val_root_mean_squared_error: 2.7995\n",
      "Epoch 107/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.1607 - loss_1: 0.1163 - root_mean_squared_error: 2.8019 - val_loss: 13.8442 - val_loss_1: 0.1155 - val_root_mean_squared_error: 2.7453\n",
      "Epoch 108/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 14.1135 - loss_1: 0.1143 - root_mean_squared_error: 2.7947 - val_loss: 14.5419 - val_loss_1: 0.1157 - val_root_mean_squared_error: 2.7988\n",
      "Epoch 109/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.9210 - loss_1: 0.1151 - root_mean_squared_error: 2.7711 - val_loss: 14.3076 - val_loss_1: 0.1129 - val_root_mean_squared_error: 2.7915\n",
      "Epoch 110/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.8438 - loss_1: 0.1139 - root_mean_squared_error: 2.7682 - val_loss: 14.0279 - val_loss_1: 0.1145 - val_root_mean_squared_error: 2.7847\n",
      "Epoch 111/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 14.0069 - loss_1: 0.1144 - root_mean_squared_error: 2.7914 - val_loss: 13.9503 - val_loss_1: 0.1163 - val_root_mean_squared_error: 2.7702\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 1s 98us/step - loss: 14.2637 - loss_1: 0.1159 - root_mean_squared_error: 2.8113 - val_loss: 13.6229 - val_loss_1: 0.1130 - val_root_mean_squared_error: 2.7541\n",
      "Epoch 113/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.8509 - loss_1: 0.1126 - root_mean_squared_error: 2.7585 - val_loss: 14.0751 - val_loss_1: 0.1151 - val_root_mean_squared_error: 2.7705\n",
      "Epoch 114/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 13.9694 - loss_1: 0.1151 - root_mean_squared_error: 2.7781 - val_loss: 14.1028 - val_loss_1: 0.1113 - val_root_mean_squared_error: 2.7323\n",
      "Epoch 115/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 13.6464 - loss_1: 0.1111 - root_mean_squared_error: 2.7450 - val_loss: 14.6741 - val_loss_1: 0.1104 - val_root_mean_squared_error: 2.7961\n",
      "Epoch 116/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 13.6401 - loss_1: 0.1110 - root_mean_squared_error: 2.7457 - val_loss: 14.0297 - val_loss_1: 0.1129 - val_root_mean_squared_error: 2.7557\n",
      "Epoch 117/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 13.0973 - loss_1: 0.1131 - root_mean_squared_error: 2.6781 - val_loss: 13.4669 - val_loss_1: 0.1142 - val_root_mean_squared_error: 2.7065\n",
      "Epoch 118/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 13.0148 - loss_1: 0.1128 - root_mean_squared_error: 2.6720 - val_loss: 13.2292 - val_loss_1: 0.1104 - val_root_mean_squared_error: 2.6861\n",
      "Epoch 119/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 13.2726 - loss_1: 0.1123 - root_mean_squared_error: 2.6970 - val_loss: 13.9565 - val_loss_1: 0.1125 - val_root_mean_squared_error: 2.7256\n",
      "Epoch 120/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 13.0208 - loss_1: 0.1114 - root_mean_squared_error: 2.6669 - val_loss: 12.7043 - val_loss_1: 0.1120 - val_root_mean_squared_error: 2.6368\n",
      "Epoch 121/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.1938 - loss_1: 0.1125 - root_mean_squared_error: 2.6791 - val_loss: 13.2538 - val_loss_1: 0.1096 - val_root_mean_squared_error: 2.6856\n",
      "Epoch 122/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.0487 - loss_1: 0.1117 - root_mean_squared_error: 2.6708 - val_loss: 13.5166 - val_loss_1: 0.1131 - val_root_mean_squared_error: 2.6712\n",
      "Epoch 123/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.1007 - loss_1: 0.1105 - root_mean_squared_error: 2.6764 - val_loss: 12.7845 - val_loss_1: 0.1098 - val_root_mean_squared_error: 2.6320\n",
      "Epoch 124/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 13.4680 - loss_1: 0.1121 - root_mean_squared_error: 2.7184 - val_loss: 13.6819 - val_loss_1: 0.1145 - val_root_mean_squared_error: 2.6826\n",
      "Epoch 125/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.7832 - loss_1: 0.1116 - root_mean_squared_error: 2.6391 - val_loss: 13.4097 - val_loss_1: 0.1103 - val_root_mean_squared_error: 2.6655\n",
      "Epoch 126/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.0454 - loss_1: 0.1121 - root_mean_squared_error: 2.6517 - val_loss: 13.3912 - val_loss_1: 0.1138 - val_root_mean_squared_error: 2.6438\n",
      "Epoch 127/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 12.7577 - loss_1: 0.1120 - root_mean_squared_error: 2.6203 - val_loss: 12.7174 - val_loss_1: 0.1108 - val_root_mean_squared_error: 2.6182\n",
      "Epoch 128/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 13.0811 - loss_1: 0.1107 - root_mean_squared_error: 2.6659 - val_loss: 12.9129 - val_loss_1: 0.1101 - val_root_mean_squared_error: 2.6154\n",
      "Epoch 129/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 13.0258 - loss_1: 0.1105 - root_mean_squared_error: 2.6495 - val_loss: 12.6489 - val_loss_1: 0.1119 - val_root_mean_squared_error: 2.5801\n",
      "Epoch 130/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.6859 - loss_1: 0.1108 - root_mean_squared_error: 2.6219 - val_loss: 12.7450 - val_loss_1: 0.1099 - val_root_mean_squared_error: 2.5846\n",
      "Epoch 131/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.6018 - loss_1: 0.1107 - root_mean_squared_error: 2.6062 - val_loss: 12.1751 - val_loss_1: 0.1102 - val_root_mean_squared_error: 2.5180\n",
      "Epoch 132/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.6946 - loss_1: 0.1107 - root_mean_squared_error: 2.6260 - val_loss: 12.5655 - val_loss_1: 0.1105 - val_root_mean_squared_error: 2.5645\n",
      "Epoch 133/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.3754 - loss_1: 0.1103 - root_mean_squared_error: 2.5753 - val_loss: 12.8883 - val_loss_1: 0.1124 - val_root_mean_squared_error: 2.6024\n",
      "Epoch 134/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.3956 - loss_1: 0.1113 - root_mean_squared_error: 2.5635 - val_loss: 12.6603 - val_loss_1: 0.1094 - val_root_mean_squared_error: 2.5521\n",
      "Epoch 135/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.4493 - loss_1: 0.1104 - root_mean_squared_error: 2.5839 - val_loss: 12.7272 - val_loss_1: 0.1111 - val_root_mean_squared_error: 2.5720\n",
      "Epoch 136/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 12.4159 - loss_1: 0.1102 - root_mean_squared_error: 2.5663 - val_loss: 12.4416 - val_loss_1: 0.1112 - val_root_mean_squared_error: 2.5566\n",
      "Epoch 137/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 12.2911 - loss_1: 0.1113 - root_mean_squared_error: 2.5685 - val_loss: 12.2858 - val_loss_1: 0.1091 - val_root_mean_squared_error: 2.5264\n",
      "Epoch 138/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 11.9629 - loss_1: 0.1094 - root_mean_squared_error: 2.5286 - val_loss: 12.6710 - val_loss_1: 0.1104 - val_root_mean_squared_error: 2.5589\n",
      "Epoch 139/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 11.9892 - loss_1: 0.1106 - root_mean_squared_error: 2.5209 - val_loss: 12.1469 - val_loss_1: 0.1107 - val_root_mean_squared_error: 2.5088\n",
      "Epoch 140/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.7621 - loss_1: 0.1110 - root_mean_squared_error: 2.4935 - val_loss: 12.4631 - val_loss_1: 0.1126 - val_root_mean_squared_error: 2.5453\n",
      "Epoch 141/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 11.9416 - loss_1: 0.1107 - root_mean_squared_error: 2.5312 - val_loss: 12.0831 - val_loss_1: 0.1107 - val_root_mean_squared_error: 2.4791\n",
      "Epoch 142/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.7724 - loss_1: 0.1101 - root_mean_squared_error: 2.5007 - val_loss: 12.2156 - val_loss_1: 0.1094 - val_root_mean_squared_error: 2.5114\n",
      "Epoch 143/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 11.7298 - loss_1: 0.1099 - root_mean_squared_error: 2.4918 - val_loss: 11.9258 - val_loss_1: 0.1098 - val_root_mean_squared_error: 2.4857\n",
      "Epoch 144/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 11.6772 - loss_1: 0.1091 - root_mean_squared_error: 2.4930 - val_loss: 12.0341 - val_loss_1: 0.1129 - val_root_mean_squared_error: 2.5203\n",
      "Epoch 145/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.7762 - loss_1: 0.1114 - root_mean_squared_error: 2.4938 - val_loss: 12.1119 - val_loss_1: 0.1081 - val_root_mean_squared_error: 2.5155\n",
      "Epoch 146/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 12.0937 - loss_1: 0.1104 - root_mean_squared_error: 2.5235 - val_loss: 11.4534 - val_loss_1: 0.1120 - val_root_mean_squared_error: 2.4011\n",
      "Epoch 147/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.7315 - loss_1: 0.1096 - root_mean_squared_error: 2.4716 - val_loss: 11.7810 - val_loss_1: 0.1087 - val_root_mean_squared_error: 2.4733\n",
      "Epoch 148/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 11.6166 - loss_1: 0.1100 - root_mean_squared_error: 2.4814 - val_loss: 12.3046 - val_loss_1: 0.1106 - val_root_mean_squared_error: 2.5270\n",
      "Epoch 149/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.4619 - loss_1: 0.1091 - root_mean_squared_error: 2.4396 - val_loss: 11.8120 - val_loss_1: 0.1081 - val_root_mean_squared_error: 2.4670\n",
      "Epoch 150/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.4562 - loss_1: 0.1102 - root_mean_squared_error: 2.4523 - val_loss: 11.7835 - val_loss_1: 0.1110 - val_root_mean_squared_error: 2.4320\n",
      "Epoch 151/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 11.4388 - loss_1: 0.1106 - root_mean_squared_error: 2.4553 - val_loss: 11.7018 - val_loss_1: 0.1115 - val_root_mean_squared_error: 2.4435\n",
      "Epoch 152/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 11.7402 - loss_1: 0.1101 - root_mean_squared_error: 2.4814 - val_loss: 12.0062 - val_loss_1: 0.1106 - val_root_mean_squared_error: 2.4404\n",
      "Epoch 153/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 11.2876 - loss_1: 0.1093 - root_mean_squared_error: 2.4121 - val_loss: 12.0249 - val_loss_1: 0.1093 - val_root_mean_squared_error: 2.4438\n",
      "Epoch 154/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.3188 - loss_1: 0.1111 - root_mean_squared_error: 2.4508 - val_loss: 11.8310 - val_loss_1: 0.1116 - val_root_mean_squared_error: 2.4277\n",
      "Epoch 155/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 11.3376 - loss_1: 0.1104 - root_mean_squared_error: 2.4345 - val_loss: 11.8882 - val_loss_1: 0.1084 - val_root_mean_squared_error: 2.4456\n",
      "Epoch 156/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 11.2566 - loss_1: 0.1087 - root_mean_squared_error: 2.4190 - val_loss: 11.4572 - val_loss_1: 0.1105 - val_root_mean_squared_error: 2.4004\n",
      "Epoch 157/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 11.0438 - loss_1: 0.1097 - root_mean_squared_error: 2.4043 - val_loss: 11.1198 - val_loss_1: 0.1079 - val_root_mean_squared_error: 2.3686\n",
      "Epoch 158/1000\n",
      "9600/9600 [==============================] - 1s 105us/step - loss: 11.2260 - loss_1: 0.1091 - root_mean_squared_error: 2.4089 - val_loss: 11.7290 - val_loss_1: 0.1106 - val_root_mean_squared_error: 2.4045\n",
      "Epoch 159/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 11.3736 - loss_1: 0.1084 - root_mean_squared_error: 2.4364 - val_loss: 10.9217 - val_loss_1: 0.1074 - val_root_mean_squared_error: 2.3812\n",
      "Epoch 160/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.9465 - loss_1: 0.1083 - root_mean_squared_error: 2.3835 - val_loss: 11.2352 - val_loss_1: 0.1099 - val_root_mean_squared_error: 2.3653\n",
      "Epoch 161/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.7953 - loss_1: 0.1102 - root_mean_squared_error: 2.3719 - val_loss: 11.9106 - val_loss_1: 0.1100 - val_root_mean_squared_error: 2.4481\n",
      "Epoch 162/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.1654 - loss_1: 0.1086 - root_mean_squared_error: 2.4076 - val_loss: 11.9423 - val_loss_1: 0.1075 - val_root_mean_squared_error: 2.4126\n",
      "Epoch 163/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 11.0634 - loss_1: 0.1089 - root_mean_squared_error: 2.4007 - val_loss: 11.8763 - val_loss_1: 0.1091 - val_root_mean_squared_error: 2.4474\n",
      "Epoch 164/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 10.7950 - loss_1: 0.1091 - root_mean_squared_error: 2.3724 - val_loss: 11.1375 - val_loss_1: 0.1100 - val_root_mean_squared_error: 2.3696\n",
      "Epoch 165/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.9222 - loss_1: 0.1098 - root_mean_squared_error: 2.3862 - val_loss: 11.7542 - val_loss_1: 0.1082 - val_root_mean_squared_error: 2.4127\n",
      "Epoch 166/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.9304 - loss_1: 0.1090 - root_mean_squared_error: 2.3808 - val_loss: 11.5912 - val_loss_1: 0.1075 - val_root_mean_squared_error: 2.4287\n",
      "Epoch 167/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 11.0683 - loss_1: 0.1079 - root_mean_squared_error: 2.4041 - val_loss: 11.0561 - val_loss_1: 0.1099 - val_root_mean_squared_error: 2.3472\n",
      "Epoch 168/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 11.1876 - loss_1: 0.1098 - root_mean_squared_error: 2.3973 - val_loss: 11.7898 - val_loss_1: 0.1094 - val_root_mean_squared_error: 2.4472\n",
      "Epoch 169/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 11.0297 - loss_1: 0.1080 - root_mean_squared_error: 2.3785 - val_loss: 11.2464 - val_loss_1: 0.1095 - val_root_mean_squared_error: 2.3530\n",
      "Epoch 170/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.7881 - loss_1: 0.1098 - root_mean_squared_error: 2.3583 - val_loss: 11.4172 - val_loss_1: 0.1082 - val_root_mean_squared_error: 2.3881\n",
      "Epoch 171/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 10.8427 - loss_1: 0.1081 - root_mean_squared_error: 2.3642 - val_loss: 11.0241 - val_loss_1: 0.1099 - val_root_mean_squared_error: 2.3684\n",
      "Epoch 172/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 10.8234 - loss_1: 0.1093 - root_mean_squared_error: 2.3645 - val_loss: 11.0324 - val_loss_1: 0.1080 - val_root_mean_squared_error: 2.3704\n",
      "Epoch 173/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.8153 - loss_1: 0.1091 - root_mean_squared_error: 2.3549 - val_loss: 11.1638 - val_loss_1: 0.1109 - val_root_mean_squared_error: 2.3513\n",
      "Epoch 174/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 10.5906 - loss_1: 0.1093 - root_mean_squared_error: 2.3256 - val_loss: 10.9006 - val_loss_1: 0.1079 - val_root_mean_squared_error: 2.3179\n",
      "Epoch 175/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.8525 - loss_1: 0.1082 - root_mean_squared_error: 2.3645 - val_loss: 11.2369 - val_loss_1: 0.1086 - val_root_mean_squared_error: 2.3611\n",
      "Epoch 176/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 10.6346 - loss_1: 0.1095 - root_mean_squared_error: 2.3326 - val_loss: 10.8593 - val_loss_1: 0.1083 - val_root_mean_squared_error: 2.3208\n",
      "Epoch 177/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 10.6110 - loss_1: 0.1094 - root_mean_squared_error: 2.3410 - val_loss: 10.6690 - val_loss_1: 0.1090 - val_root_mean_squared_error: 2.2884\n",
      "Epoch 178/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.6775 - loss_1: 0.1085 - root_mean_squared_error: 2.3398 - val_loss: 10.9547 - val_loss_1: 0.1092 - val_root_mean_squared_error: 2.3303\n",
      "Epoch 179/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.7260 - loss_1: 0.1096 - root_mean_squared_error: 2.3515 - val_loss: 11.0635 - val_loss_1: 0.1088 - val_root_mean_squared_error: 2.3532\n",
      "Epoch 180/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.6304 - loss_1: 0.1080 - root_mean_squared_error: 2.3325 - val_loss: 10.2955 - val_loss_1: 0.1082 - val_root_mean_squared_error: 2.2516\n",
      "Epoch 181/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.4774 - loss_1: 0.1095 - root_mean_squared_error: 2.3252 - val_loss: 11.3027 - val_loss_1: 0.1100 - val_root_mean_squared_error: 2.3626\n",
      "Epoch 182/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 10.4261 - loss_1: 0.1088 - root_mean_squared_error: 2.3155 - val_loss: 10.8168 - val_loss_1: 0.1081 - val_root_mean_squared_error: 2.3094\n",
      "Epoch 183/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.4548 - loss_1: 0.1081 - root_mean_squared_error: 2.3229 - val_loss: 11.3908 - val_loss_1: 0.1103 - val_root_mean_squared_error: 2.3776\n",
      "Epoch 184/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.2702 - loss_1: 0.1096 - root_mean_squared_error: 2.3047 - val_loss: 10.6136 - val_loss_1: 0.1080 - val_root_mean_squared_error: 2.2868\n",
      "Epoch 185/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 10.6735 - loss_1: 0.1089 - root_mean_squared_error: 2.3248 - val_loss: 10.7145 - val_loss_1: 0.1112 - val_root_mean_squared_error: 2.2950\n",
      "Epoch 186/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.5622 - loss_1: 0.1093 - root_mean_squared_error: 2.3221 - val_loss: 11.2058 - val_loss_1: 0.1056 - val_root_mean_squared_error: 2.3335\n",
      "Epoch 187/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.0865 - loss_1: 0.1082 - root_mean_squared_error: 2.2727 - val_loss: 10.7425 - val_loss_1: 0.1111 - val_root_mean_squared_error: 2.2955\n",
      "Epoch 188/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.3261 - loss_1: 0.1093 - root_mean_squared_error: 2.3026 - val_loss: 10.7211 - val_loss_1: 0.1072 - val_root_mean_squared_error: 2.3089\n",
      "Epoch 189/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.3881 - loss_1: 0.1078 - root_mean_squared_error: 2.2845 - val_loss: 10.7259 - val_loss_1: 0.1094 - val_root_mean_squared_error: 2.2989\n",
      "Epoch 190/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.1201 - loss_1: 0.1086 - root_mean_squared_error: 2.2821 - val_loss: 11.0057 - val_loss_1: 0.1074 - val_root_mean_squared_error: 2.3258\n",
      "Epoch 191/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.2359 - loss_1: 0.1081 - root_mean_squared_error: 2.2925 - val_loss: 11.0138 - val_loss_1: 0.1100 - val_root_mean_squared_error: 2.2957\n",
      "Epoch 192/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.3089 - loss_1: 0.1089 - root_mean_squared_error: 2.2881 - val_loss: 10.5441 - val_loss_1: 0.1087 - val_root_mean_squared_error: 2.2702\n",
      "Epoch 193/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 10.3517 - loss_1: 0.1086 - root_mean_squared_error: 2.3010 - val_loss: 10.2314 - val_loss_1: 0.1076 - val_root_mean_squared_error: 2.2252\n",
      "Epoch 194/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.3056 - loss_1: 0.1070 - root_mean_squared_error: 2.2888 - val_loss: 10.6477 - val_loss_1: 0.1096 - val_root_mean_squared_error: 2.2826\n",
      "Epoch 195/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.5852 - loss_1: 0.1083 - root_mean_squared_error: 2.3317 - val_loss: 10.6637 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.2614\n",
      "Epoch 196/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.1085 - loss_1: 0.1083 - root_mean_squared_error: 2.2672 - val_loss: 10.5847 - val_loss_1: 0.1079 - val_root_mean_squared_error: 2.2795\n",
      "Epoch 197/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 10.2686 - loss_1: 0.1070 - root_mean_squared_error: 2.2849 - val_loss: 10.4370 - val_loss_1: 0.1075 - val_root_mean_squared_error: 2.2790\n",
      "Epoch 198/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.0942 - loss_1: 0.1080 - root_mean_squared_error: 2.2814 - val_loss: 10.1252 - val_loss_1: 0.1092 - val_root_mean_squared_error: 2.2264\n",
      "Epoch 199/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 10.2274 - loss_1: 0.1074 - root_mean_squared_error: 2.2891 - val_loss: 10.3613 - val_loss_1: 0.1069 - val_root_mean_squared_error: 2.2413\n",
      "Epoch 200/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.8451 - loss_1: 0.1081 - root_mean_squared_error: 2.2392 - val_loss: 10.6626 - val_loss_1: 0.1086 - val_root_mean_squared_error: 2.2943\n",
      "Epoch 201/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 10.2953 - loss_1: 0.1076 - root_mean_squared_error: 2.2874 - val_loss: 10.9375 - val_loss_1: 0.1075 - val_root_mean_squared_error: 2.2974\n",
      "Epoch 202/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 10.2720 - loss_1: 0.1081 - root_mean_squared_error: 2.2770 - val_loss: 10.7465 - val_loss_1: 0.1081 - val_root_mean_squared_error: 2.2786\n",
      "Epoch 203/1000\n",
      "9600/9600 [==============================] - 1s 98us/step - loss: 10.0955 - loss_1: 0.1067 - root_mean_squared_error: 2.2661 - val_loss: 10.2088 - val_loss_1: 0.1067 - val_root_mean_squared_error: 2.2266\n",
      "Epoch 204/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 10.2354 - loss_1: 0.1078 - root_mean_squared_error: 2.2674 - val_loss: 10.6611 - val_loss_1: 0.1070 - val_root_mean_squared_error: 2.2858\n",
      "Epoch 205/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.0468 - loss_1: 0.1063 - root_mean_squared_error: 2.2536 - val_loss: 10.3385 - val_loss_1: 0.1087 - val_root_mean_squared_error: 2.2603\n",
      "Epoch 206/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.9404 - loss_1: 0.1078 - root_mean_squared_error: 2.2429 - val_loss: 10.1965 - val_loss_1: 0.1081 - val_root_mean_squared_error: 2.2489\n",
      "Epoch 207/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.9381 - loss_1: 0.1082 - root_mean_squared_error: 2.2403 - val_loss: 10.0657 - val_loss_1: 0.1069 - val_root_mean_squared_error: 2.2124\n",
      "Epoch 208/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.2561 - loss_1: 0.1078 - root_mean_squared_error: 2.2716 - val_loss: 10.2591 - val_loss_1: 0.1083 - val_root_mean_squared_error: 2.2673\n",
      "Epoch 209/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.9508 - loss_1: 0.1074 - root_mean_squared_error: 2.2466 - val_loss: 10.2571 - val_loss_1: 0.1084 - val_root_mean_squared_error: 2.2528\n",
      "Epoch 210/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.0140 - loss_1: 0.1078 - root_mean_squared_error: 2.2559 - val_loss: 10.3205 - val_loss_1: 0.1087 - val_root_mean_squared_error: 2.2249\n",
      "Epoch 211/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.9037 - loss_1: 0.1088 - root_mean_squared_error: 2.2388 - val_loss: 10.4812 - val_loss_1: 0.1073 - val_root_mean_squared_error: 2.2722\n",
      "Epoch 212/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 10.0333 - loss_1: 0.1069 - root_mean_squared_error: 2.2528 - val_loss: 10.3632 - val_loss_1: 0.1075 - val_root_mean_squared_error: 2.2425\n",
      "Epoch 213/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.8715 - loss_1: 0.1084 - root_mean_squared_error: 2.2397 - val_loss: 9.6612 - val_loss_1: 0.1075 - val_root_mean_squared_error: 2.2023\n",
      "Epoch 214/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.9223 - loss_1: 0.1082 - root_mean_squared_error: 2.2432 - val_loss: 10.2027 - val_loss_1: 0.1101 - val_root_mean_squared_error: 2.2020\n",
      "Epoch 215/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 10.2353 - loss_1: 0.1092 - root_mean_squared_error: 2.2682 - val_loss: 10.4788 - val_loss_1: 0.1071 - val_root_mean_squared_error: 2.2397\n",
      "Epoch 216/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.4704 - loss_1: 0.1079 - root_mean_squared_error: 2.1813 - val_loss: 10.0567 - val_loss_1: 0.1087 - val_root_mean_squared_error: 2.2230\n",
      "Epoch 217/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.6259 - loss_1: 0.1073 - root_mean_squared_error: 2.2044 - val_loss: 9.9196 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.1648\n",
      "Epoch 218/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 10.0196 - loss_1: 0.1084 - root_mean_squared_error: 2.2607 - val_loss: 9.9630 - val_loss_1: 0.1076 - val_root_mean_squared_error: 2.1975\n",
      "Epoch 219/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 10.0635 - loss_1: 0.1070 - root_mean_squared_error: 2.2709 - val_loss: 9.9395 - val_loss_1: 0.1079 - val_root_mean_squared_error: 2.2008\n",
      "Epoch 220/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.8168 - loss_1: 0.1066 - root_mean_squared_error: 2.2262 - val_loss: 10.1782 - val_loss_1: 0.1057 - val_root_mean_squared_error: 2.1986\n",
      "Epoch 221/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.9055 - loss_1: 0.1079 - root_mean_squared_error: 2.2395 - val_loss: 10.0094 - val_loss_1: 0.1094 - val_root_mean_squared_error: 2.1839\n",
      "Epoch 222/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.5336 - loss_1: 0.1080 - root_mean_squared_error: 2.1974 - val_loss: 10.0791 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.1981\n",
      "Epoch 223/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.8132 - loss_1: 0.1077 - root_mean_squared_error: 2.2332 - val_loss: 10.0760 - val_loss_1: 0.1081 - val_root_mean_squared_error: 2.1732\n",
      "Epoch 224/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.7279 - loss_1: 0.1070 - root_mean_squared_error: 2.2129 - val_loss: 9.2604 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.1131\n",
      "Epoch 225/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.6693 - loss_1: 0.1083 - root_mean_squared_error: 2.2064 - val_loss: 10.1786 - val_loss_1: 0.1082 - val_root_mean_squared_error: 2.2121\n",
      "Epoch 226/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.6992 - loss_1: 0.1059 - root_mean_squared_error: 2.1986 - val_loss: 10.0356 - val_loss_1: 0.1064 - val_root_mean_squared_error: 2.2122\n",
      "Epoch 227/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.8206 - loss_1: 0.1081 - root_mean_squared_error: 2.2296 - val_loss: 10.2653 - val_loss_1: 0.1076 - val_root_mean_squared_error: 2.2120\n",
      "Epoch 228/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 9.7023 - loss_1: 0.1054 - root_mean_squared_error: 2.2169 - val_loss: 10.1017 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.2330\n",
      "Epoch 229/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.7533 - loss_1: 0.1068 - root_mean_squared_error: 2.2226 - val_loss: 10.0364 - val_loss_1: 0.1072 - val_root_mean_squared_error: 2.2213\n",
      "Epoch 230/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 9.8325 - loss_1: 0.1068 - root_mean_squared_error: 2.2272 - val_loss: 9.8765 - val_loss_1: 0.1078 - val_root_mean_squared_error: 2.1920\n",
      "Epoch 231/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 9.9058 - loss_1: 0.1060 - root_mean_squared_error: 2.2373 - val_loss: 9.9333 - val_loss_1: 0.1067 - val_root_mean_squared_error: 2.2100\n",
      "Epoch 232/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 9.7145 - loss_1: 0.1074 - root_mean_squared_error: 2.2076 - val_loss: 10.0565 - val_loss_1: 0.1071 - val_root_mean_squared_error: 2.2111\n",
      "Epoch 233/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.7899 - loss_1: 0.1076 - root_mean_squared_error: 2.2157 - val_loss: 10.1050 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.2104\n",
      "Epoch 234/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 9.5313 - loss_1: 0.1061 - root_mean_squared_error: 2.2020 - val_loss: 9.6780 - val_loss_1: 0.1076 - val_root_mean_squared_error: 2.1786\n",
      "Epoch 235/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.6022 - loss_1: 0.1078 - root_mean_squared_error: 2.2027 - val_loss: 9.8460 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.1946\n",
      "Epoch 236/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 10.0232 - loss_1: 0.1066 - root_mean_squared_error: 2.2394 - val_loss: 9.9210 - val_loss_1: 0.1077 - val_root_mean_squared_error: 2.1659\n",
      "Epoch 237/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.4729 - loss_1: 0.1074 - root_mean_squared_error: 2.1885 - val_loss: 9.6461 - val_loss_1: 0.1064 - val_root_mean_squared_error: 2.1565\n",
      "Epoch 238/1000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 9.7715 - loss_1: 0.1066 - root_mean_squared_error: 2.2035 - val_loss: 9.8970 - val_loss_1: 0.1069 - val_root_mean_squared_error: 2.2041\n",
      "Epoch 239/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 9.8431 - loss_1: 0.1063 - root_mean_squared_error: 2.2194 - val_loss: 10.2153 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.2102\n",
      "Epoch 240/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 9.6101 - loss_1: 0.1058 - root_mean_squared_error: 2.2102 - val_loss: 9.8693 - val_loss_1: 0.1061 - val_root_mean_squared_error: 2.2054\n",
      "Epoch 241/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.8456 - loss_1: 0.1070 - root_mean_squared_error: 2.2275 - val_loss: 9.7430 - val_loss_1: 0.1069 - val_root_mean_squared_error: 2.1626\n",
      "Epoch 242/1000\n",
      "9600/9600 [==============================] - 1s 105us/step - loss: 9.5153 - loss_1: 0.1061 - root_mean_squared_error: 2.2048 - val_loss: 9.4685 - val_loss_1: 0.1055 - val_root_mean_squared_error: 2.1591\n",
      "Epoch 243/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.6907 - loss_1: 0.1053 - root_mean_squared_error: 2.1939 - val_loss: 9.6443 - val_loss_1: 0.1065 - val_root_mean_squared_error: 2.1636\n",
      "Epoch 244/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.5665 - loss_1: 0.1064 - root_mean_squared_error: 2.2007 - val_loss: 9.2853 - val_loss_1: 0.1058 - val_root_mean_squared_error: 2.1372\n",
      "Epoch 245/1000\n",
      "9600/9600 [==============================] - 1s 105us/step - loss: 9.4227 - loss_1: 0.1058 - root_mean_squared_error: 2.1751 - val_loss: 9.6788 - val_loss_1: 0.1067 - val_root_mean_squared_error: 2.1639\n",
      "Epoch 246/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 9.6977 - loss_1: 0.1062 - root_mean_squared_error: 2.2002 - val_loss: 9.8817 - val_loss_1: 0.1060 - val_root_mean_squared_error: 2.1810\n",
      "Epoch 247/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.6431 - loss_1: 0.1049 - root_mean_squared_error: 2.2077 - val_loss: 9.5813 - val_loss_1: 0.1050 - val_root_mean_squared_error: 2.1460\n",
      "Epoch 248/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.5666 - loss_1: 0.1047 - root_mean_squared_error: 2.1981 - val_loss: 9.2572 - val_loss_1: 0.1063 - val_root_mean_squared_error: 2.1446\n",
      "Epoch 249/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.4588 - loss_1: 0.1069 - root_mean_squared_error: 2.1825 - val_loss: 9.1753 - val_loss_1: 0.1050 - val_root_mean_squared_error: 2.0965\n",
      "Epoch 250/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.4864 - loss_1: 0.1058 - root_mean_squared_error: 2.1857 - val_loss: 9.7485 - val_loss_1: 0.1071 - val_root_mean_squared_error: 2.1907\n",
      "Epoch 251/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.4403 - loss_1: 0.1054 - root_mean_squared_error: 2.1856 - val_loss: 9.0260 - val_loss_1: 0.1045 - val_root_mean_squared_error: 2.1081\n",
      "Epoch 252/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.7007 - loss_1: 0.1063 - root_mean_squared_error: 2.2067 - val_loss: 10.4412 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.2379\n",
      "Epoch 253/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 9.3814 - loss_1: 0.1047 - root_mean_squared_error: 2.1668 - val_loss: 9.3428 - val_loss_1: 0.1055 - val_root_mean_squared_error: 2.1166\n",
      "Epoch 254/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1762 - loss_1: 0.1067 - root_mean_squared_error: 2.1521 - val_loss: 9.6440 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.1701\n",
      "Epoch 255/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 9.4074 - loss_1: 0.1055 - root_mean_squared_error: 2.1734 - val_loss: 9.0166 - val_loss_1: 0.1058 - val_root_mean_squared_error: 2.0926\n",
      "Epoch 256/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.3140 - loss_1: 0.1059 - root_mean_squared_error: 2.1636 - val_loss: 10.1956 - val_loss_1: 0.1042 - val_root_mean_squared_error: 2.2211\n",
      "Epoch 257/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.6440 - loss_1: 0.1049 - root_mean_squared_error: 2.1914 - val_loss: 10.0191 - val_loss_1: 0.1051 - val_root_mean_squared_error: 2.1760\n",
      "Epoch 258/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 9.2795 - loss_1: 0.1044 - root_mean_squared_error: 2.1618 - val_loss: 9.7647 - val_loss_1: 0.1043 - val_root_mean_squared_error: 2.1801\n",
      "Epoch 259/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.5197 - loss_1: 0.1052 - root_mean_squared_error: 2.1952 - val_loss: 9.2704 - val_loss_1: 0.1056 - val_root_mean_squared_error: 2.1014\n",
      "Epoch 260/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.5583 - loss_1: 0.1060 - root_mean_squared_error: 2.1955 - val_loss: 9.5983 - val_loss_1: 0.1049 - val_root_mean_squared_error: 2.1721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.2582 - loss_1: 0.1048 - root_mean_squared_error: 2.1637 - val_loss: 9.2714 - val_loss_1: 0.1041 - val_root_mean_squared_error: 2.1159\n",
      "Epoch 262/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 9.4415 - loss_1: 0.1039 - root_mean_squared_error: 2.1778 - val_loss: 9.3508 - val_loss_1: 0.1032 - val_root_mean_squared_error: 2.1168\n",
      "Epoch 263/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.3143 - loss_1: 0.1046 - root_mean_squared_error: 2.1539 - val_loss: 9.5469 - val_loss_1: 0.1037 - val_root_mean_squared_error: 2.1520\n",
      "Epoch 264/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.1843 - loss_1: 0.1048 - root_mean_squared_error: 2.1525 - val_loss: 9.3195 - val_loss_1: 0.1051 - val_root_mean_squared_error: 2.1063\n",
      "Epoch 265/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.0739 - loss_1: 0.1046 - root_mean_squared_error: 2.1476 - val_loss: 9.1955 - val_loss_1: 0.1036 - val_root_mean_squared_error: 2.1072\n",
      "Epoch 266/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.4160 - loss_1: 0.1046 - root_mean_squared_error: 2.1854 - val_loss: 9.8722 - val_loss_1: 0.1065 - val_root_mean_squared_error: 2.2151\n",
      "Epoch 267/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.4855 - loss_1: 0.1053 - root_mean_squared_error: 2.1877 - val_loss: 9.5803 - val_loss_1: 0.1034 - val_root_mean_squared_error: 2.1387\n",
      "Epoch 268/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.2781 - loss_1: 0.1039 - root_mean_squared_error: 2.1652 - val_loss: 9.1401 - val_loss_1: 0.1066 - val_root_mean_squared_error: 2.0981\n",
      "Epoch 269/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.2681 - loss_1: 0.1050 - root_mean_squared_error: 2.1543 - val_loss: 9.6552 - val_loss_1: 0.1027 - val_root_mean_squared_error: 2.1947\n",
      "Epoch 270/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.3423 - loss_1: 0.1051 - root_mean_squared_error: 2.1674 - val_loss: 9.5792 - val_loss_1: 0.1076 - val_root_mean_squared_error: 2.1635\n",
      "Epoch 271/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.3691 - loss_1: 0.1050 - root_mean_squared_error: 2.1573 - val_loss: 9.6316 - val_loss_1: 0.1027 - val_root_mean_squared_error: 2.1233\n",
      "Epoch 272/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.2518 - loss_1: 0.1038 - root_mean_squared_error: 2.1599 - val_loss: 9.2138 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.1144\n",
      "Epoch 273/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.3240 - loss_1: 0.1029 - root_mean_squared_error: 2.1660 - val_loss: 9.1871 - val_loss_1: 0.1007 - val_root_mean_squared_error: 2.1181\n",
      "Epoch 274/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.4078 - loss_1: 0.1038 - root_mean_squared_error: 2.1631 - val_loss: 9.1780 - val_loss_1: 0.1065 - val_root_mean_squared_error: 2.1154\n",
      "Epoch 275/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.3986 - loss_1: 0.1036 - root_mean_squared_error: 2.1789 - val_loss: 9.0162 - val_loss_1: 0.1023 - val_root_mean_squared_error: 2.0916\n",
      "Epoch 276/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.1453 - loss_1: 0.1033 - root_mean_squared_error: 2.1538 - val_loss: 9.0418 - val_loss_1: 0.1055 - val_root_mean_squared_error: 2.0929\n",
      "Epoch 277/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.2608 - loss_1: 0.1048 - root_mean_squared_error: 2.1622 - val_loss: 9.4452 - val_loss_1: 0.1042 - val_root_mean_squared_error: 2.1239\n",
      "Epoch 278/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.2376 - loss_1: 0.1038 - root_mean_squared_error: 2.1412 - val_loss: 9.7583 - val_loss_1: 0.1035 - val_root_mean_squared_error: 2.1700\n",
      "Epoch 279/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.2586 - loss_1: 0.1041 - root_mean_squared_error: 2.1509 - val_loss: 9.4981 - val_loss_1: 0.1032 - val_root_mean_squared_error: 2.1493\n",
      "Epoch 280/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.2082 - loss_1: 0.1033 - root_mean_squared_error: 2.1460 - val_loss: 8.9358 - val_loss_1: 0.1045 - val_root_mean_squared_error: 2.1036\n",
      "Epoch 281/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.2795 - loss_1: 0.1044 - root_mean_squared_error: 2.1584 - val_loss: 9.1983 - val_loss_1: 0.1050 - val_root_mean_squared_error: 2.1252\n",
      "Epoch 282/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.4530 - loss_1: 0.1046 - root_mean_squared_error: 2.1761 - val_loss: 9.3107 - val_loss_1: 0.1024 - val_root_mean_squared_error: 2.1350\n",
      "Epoch 283/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.3351 - loss_1: 0.1029 - root_mean_squared_error: 2.1638 - val_loss: 8.9677 - val_loss_1: 0.1055 - val_root_mean_squared_error: 2.0840\n",
      "Epoch 284/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.3514 - loss_1: 0.1044 - root_mean_squared_error: 2.1822 - val_loss: 9.2811 - val_loss_1: 0.1024 - val_root_mean_squared_error: 2.1088\n",
      "Epoch 285/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.2499 - loss_1: 0.1035 - root_mean_squared_error: 2.1575 - val_loss: 8.6949 - val_loss_1: 0.1041 - val_root_mean_squared_error: 2.0386\n",
      "Epoch 286/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.0685 - loss_1: 0.1035 - root_mean_squared_error: 2.1429 - val_loss: 9.6358 - val_loss_1: 0.1038 - val_root_mean_squared_error: 2.1533\n",
      "Epoch 287/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.9385 - loss_1: 0.1036 - root_mean_squared_error: 2.1228 - val_loss: 9.0950 - val_loss_1: 0.1024 - val_root_mean_squared_error: 2.0976\n",
      "Epoch 288/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.4634 - loss_1: 0.1034 - root_mean_squared_error: 2.1913 - val_loss: 9.1469 - val_loss_1: 0.1057 - val_root_mean_squared_error: 2.1142\n",
      "Epoch 289/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.5254 - loss_1: 0.1037 - root_mean_squared_error: 2.1795 - val_loss: 9.5344 - val_loss_1: 0.1022 - val_root_mean_squared_error: 2.1484\n",
      "Epoch 290/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1600 - loss_1: 0.1039 - root_mean_squared_error: 2.1277 - val_loss: 9.4261 - val_loss_1: 0.1047 - val_root_mean_squared_error: 2.1279\n",
      "Epoch 291/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.1702 - loss_1: 0.1028 - root_mean_squared_error: 2.1485 - val_loss: 9.4133 - val_loss_1: 0.1033 - val_root_mean_squared_error: 2.1261\n",
      "Epoch 292/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.2317 - loss_1: 0.1038 - root_mean_squared_error: 2.1572 - val_loss: 9.3630 - val_loss_1: 0.1042 - val_root_mean_squared_error: 2.1152\n",
      "Epoch 293/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.1029 - loss_1: 0.1035 - root_mean_squared_error: 2.1498 - val_loss: 8.8342 - val_loss_1: 0.1029 - val_root_mean_squared_error: 2.0663\n",
      "Epoch 294/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.1298 - loss_1: 0.1031 - root_mean_squared_error: 2.1468 - val_loss: 9.2960 - val_loss_1: 0.1038 - val_root_mean_squared_error: 2.1388\n",
      "Epoch 295/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1950 - loss_1: 0.1039 - root_mean_squared_error: 2.1617 - val_loss: 9.0851 - val_loss_1: 0.1034 - val_root_mean_squared_error: 2.1333\n",
      "Epoch 296/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 9.1298 - loss_1: 0.1037 - root_mean_squared_error: 2.1331 - val_loss: 9.1172 - val_loss_1: 0.1024 - val_root_mean_squared_error: 2.1012\n",
      "Epoch 297/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.9854 - loss_1: 0.1033 - root_mean_squared_error: 2.1296 - val_loss: 9.5451 - val_loss_1: 0.1040 - val_root_mean_squared_error: 2.1327\n",
      "Epoch 298/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.9748 - loss_1: 0.1030 - root_mean_squared_error: 2.1235 - val_loss: 9.1760 - val_loss_1: 0.1036 - val_root_mean_squared_error: 2.1211\n",
      "Epoch 299/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.9397 - loss_1: 0.1033 - root_mean_squared_error: 2.1125 - val_loss: 8.9927 - val_loss_1: 0.1020 - val_root_mean_squared_error: 2.0952\n",
      "Epoch 300/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.0978 - loss_1: 0.1016 - root_mean_squared_error: 2.1415 - val_loss: 9.0695 - val_loss_1: 0.1014 - val_root_mean_squared_error: 2.1114\n",
      "Epoch 301/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.9946 - loss_1: 0.1028 - root_mean_squared_error: 2.1307 - val_loss: 9.1419 - val_loss_1: 0.1034 - val_root_mean_squared_error: 2.1045\n",
      "Epoch 302/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.2200 - loss_1: 0.1020 - root_mean_squared_error: 2.1565 - val_loss: 8.9043 - val_loss_1: 0.1031 - val_root_mean_squared_error: 2.0567\n",
      "Epoch 303/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.1170 - loss_1: 0.1037 - root_mean_squared_error: 2.1429 - val_loss: 8.5132 - val_loss_1: 0.1038 - val_root_mean_squared_error: 2.0324\n",
      "Epoch 304/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1277 - loss_1: 0.1022 - root_mean_squared_error: 2.1351 - val_loss: 8.5588 - val_loss_1: 0.1003 - val_root_mean_squared_error: 2.0435\n",
      "Epoch 305/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.9932 - loss_1: 0.1017 - root_mean_squared_error: 2.1244 - val_loss: 9.0807 - val_loss_1: 0.1017 - val_root_mean_squared_error: 2.1080\n",
      "Epoch 306/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 8.8776 - loss_1: 0.1024 - root_mean_squared_error: 2.1157 - val_loss: 8.8181 - val_loss_1: 0.1027 - val_root_mean_squared_error: 2.1034\n",
      "Epoch 307/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.8678 - loss_1: 0.1033 - root_mean_squared_error: 2.1030 - val_loss: 9.2755 - val_loss_1: 0.1018 - val_root_mean_squared_error: 2.1089\n",
      "Epoch 308/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1207 - loss_1: 0.1018 - root_mean_squared_error: 2.1293 - val_loss: 9.0963 - val_loss_1: 0.1035 - val_root_mean_squared_error: 2.0865\n",
      "Epoch 309/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.1023 - loss_1: 0.1021 - root_mean_squared_error: 2.1335 - val_loss: 9.1411 - val_loss_1: 0.1026 - val_root_mean_squared_error: 2.0821\n",
      "Epoch 310/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.2081 - loss_1: 0.1021 - root_mean_squared_error: 2.1425 - val_loss: 8.4165 - val_loss_1: 0.1026 - val_root_mean_squared_error: 2.0152\n",
      "Epoch 311/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.0989 - loss_1: 0.1032 - root_mean_squared_error: 2.1457 - val_loss: 9.5336 - val_loss_1: 0.1019 - val_root_mean_squared_error: 2.1352\n",
      "Epoch 312/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.0143 - loss_1: 0.1014 - root_mean_squared_error: 2.1263 - val_loss: 8.5986 - val_loss_1: 0.1035 - val_root_mean_squared_error: 2.0320\n",
      "Epoch 313/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 9.0344 - loss_1: 0.1027 - root_mean_squared_error: 2.1211 - val_loss: 9.4079 - val_loss_1: 0.0995 - val_root_mean_squared_error: 2.1087\n",
      "Epoch 314/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.8421 - loss_1: 0.1009 - root_mean_squared_error: 2.1010 - val_loss: 8.7139 - val_loss_1: 0.1027 - val_root_mean_squared_error: 2.0469\n",
      "Epoch 315/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.9865 - loss_1: 0.1022 - root_mean_squared_error: 2.1252 - val_loss: 8.4529 - val_loss_1: 0.1018 - val_root_mean_squared_error: 2.0390\n",
      "Epoch 316/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 8.8918 - loss_1: 0.1007 - root_mean_squared_error: 2.1056 - val_loss: 9.0587 - val_loss_1: 0.1021 - val_root_mean_squared_error: 2.0938\n",
      "Epoch 317/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1172 - loss_1: 0.1029 - root_mean_squared_error: 2.1339 - val_loss: 8.8774 - val_loss_1: 0.1018 - val_root_mean_squared_error: 2.0680\n",
      "Epoch 318/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1329 - loss_1: 0.1012 - root_mean_squared_error: 2.1386 - val_loss: 9.1518 - val_loss_1: 0.1027 - val_root_mean_squared_error: 2.0909\n",
      "Epoch 319/1000\n",
      "9600/9600 [==============================] - 1s 107us/step - loss: 8.8279 - loss_1: 0.1027 - root_mean_squared_error: 2.0939 - val_loss: 8.7588 - val_loss_1: 0.1020 - val_root_mean_squared_error: 2.0380\n",
      "Epoch 320/1000\n",
      "9600/9600 [==============================] - 1s 106us/step - loss: 9.0930 - loss_1: 0.1020 - root_mean_squared_error: 2.1211 - val_loss: 8.9367 - val_loss_1: 0.1003 - val_root_mean_squared_error: 2.0904\n",
      "Epoch 321/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 9.1877 - loss_1: 0.1004 - root_mean_squared_error: 2.1311 - val_loss: 9.0027 - val_loss_1: 0.1021 - val_root_mean_squared_error: 2.0755\n",
      "Epoch 322/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.9637 - loss_1: 0.1021 - root_mean_squared_error: 2.1176 - val_loss: 9.1337 - val_loss_1: 0.1021 - val_root_mean_squared_error: 2.1138\n",
      "Epoch 323/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.9650 - loss_1: 0.1026 - root_mean_squared_error: 2.1154 - val_loss: 9.0618 - val_loss_1: 0.1028 - val_root_mean_squared_error: 2.0942\n",
      "Epoch 324/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.8313 - loss_1: 0.1011 - root_mean_squared_error: 2.0937 - val_loss: 9.0309 - val_loss_1: 0.1013 - val_root_mean_squared_error: 2.0396\n",
      "Epoch 325/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.9334 - loss_1: 0.1019 - root_mean_squared_error: 2.1103 - val_loss: 9.2460 - val_loss_1: 0.1009 - val_root_mean_squared_error: 2.1135\n",
      "Epoch 326/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.7930 - loss_1: 0.1009 - root_mean_squared_error: 2.1118 - val_loss: 8.8899 - val_loss_1: 0.1015 - val_root_mean_squared_error: 2.0774\n",
      "Epoch 327/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.9231 - loss_1: 0.1015 - root_mean_squared_error: 2.1156 - val_loss: 8.8291 - val_loss_1: 0.1017 - val_root_mean_squared_error: 2.0589\n",
      "Epoch 328/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6812 - loss_1: 0.1022 - root_mean_squared_error: 2.0957 - val_loss: 9.0258 - val_loss_1: 0.1014 - val_root_mean_squared_error: 2.0704\n",
      "Epoch 329/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.6231 - loss_1: 0.1008 - root_mean_squared_error: 2.0680 - val_loss: 8.6605 - val_loss_1: 0.1015 - val_root_mean_squared_error: 2.0502\n",
      "Epoch 330/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.8294 - loss_1: 0.1018 - root_mean_squared_error: 2.1108 - val_loss: 8.9355 - val_loss_1: 0.1038 - val_root_mean_squared_error: 2.0487\n",
      "Epoch 331/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.7180 - loss_1: 0.1026 - root_mean_squared_error: 2.0788 - val_loss: 9.3168 - val_loss_1: 0.1004 - val_root_mean_squared_error: 2.0898\n",
      "Epoch 332/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.8954 - loss_1: 0.1013 - root_mean_squared_error: 2.0992 - val_loss: 8.1955 - val_loss_1: 0.1020 - val_root_mean_squared_error: 1.9848\n",
      "Epoch 333/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.7103 - loss_1: 0.1014 - root_mean_squared_error: 2.0948 - val_loss: 8.9894 - val_loss_1: 0.1007 - val_root_mean_squared_error: 2.0742\n",
      "Epoch 334/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.5977 - loss_1: 0.1008 - root_mean_squared_error: 2.0706 - val_loss: 8.5793 - val_loss_1: 0.1009 - val_root_mean_squared_error: 2.0145\n",
      "Epoch 335/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.8726 - loss_1: 0.1015 - root_mean_squared_error: 2.1051 - val_loss: 8.6854 - val_loss_1: 0.1007 - val_root_mean_squared_error: 2.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.7086 - loss_1: 0.1011 - root_mean_squared_error: 2.0856 - val_loss: 8.6964 - val_loss_1: 0.1006 - val_root_mean_squared_error: 2.0418\n",
      "Epoch 337/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.6860 - loss_1: 0.1014 - root_mean_squared_error: 2.0677 - val_loss: 8.8113 - val_loss_1: 0.1017 - val_root_mean_squared_error: 2.0467\n",
      "Epoch 338/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6959 - loss_1: 0.1005 - root_mean_squared_error: 2.0826 - val_loss: 8.5040 - val_loss_1: 0.0994 - val_root_mean_squared_error: 1.9955\n",
      "Epoch 339/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.8913 - loss_1: 0.1009 - root_mean_squared_error: 2.1146 - val_loss: 8.4422 - val_loss_1: 0.1013 - val_root_mean_squared_error: 2.0255\n",
      "Epoch 340/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.6160 - loss_1: 0.1004 - root_mean_squared_error: 2.0761 - val_loss: 8.6972 - val_loss_1: 0.0989 - val_root_mean_squared_error: 2.0114\n",
      "Epoch 341/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.7078 - loss_1: 0.1005 - root_mean_squared_error: 2.0776 - val_loss: 8.4787 - val_loss_1: 0.1016 - val_root_mean_squared_error: 2.0137\n",
      "Epoch 342/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.9566 - loss_1: 0.1002 - root_mean_squared_error: 2.1039 - val_loss: 8.4388 - val_loss_1: 0.0991 - val_root_mean_squared_error: 2.0022\n",
      "Epoch 343/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6921 - loss_1: 0.1001 - root_mean_squared_error: 2.0874 - val_loss: 8.6974 - val_loss_1: 0.1013 - val_root_mean_squared_error: 2.0333\n",
      "Epoch 344/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.7211 - loss_1: 0.1002 - root_mean_squared_error: 2.0979 - val_loss: 9.0650 - val_loss_1: 0.0998 - val_root_mean_squared_error: 2.0599\n",
      "Epoch 345/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.8167 - loss_1: 0.1006 - root_mean_squared_error: 2.0978 - val_loss: 8.7047 - val_loss_1: 0.1005 - val_root_mean_squared_error: 2.0601\n",
      "Epoch 346/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6867 - loss_1: 0.1010 - root_mean_squared_error: 2.0917 - val_loss: 8.3409 - val_loss_1: 0.1006 - val_root_mean_squared_error: 2.0157\n",
      "Epoch 347/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.8017 - loss_1: 0.0995 - root_mean_squared_error: 2.0988 - val_loss: 8.2453 - val_loss_1: 0.1014 - val_root_mean_squared_error: 1.9860\n",
      "Epoch 348/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.7440 - loss_1: 0.1009 - root_mean_squared_error: 2.0866 - val_loss: 9.2220 - val_loss_1: 0.0990 - val_root_mean_squared_error: 2.1015\n",
      "Epoch 349/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.9926 - loss_1: 0.0995 - root_mean_squared_error: 2.0995 - val_loss: 9.2945 - val_loss_1: 0.1004 - val_root_mean_squared_error: 2.0646\n",
      "Epoch 350/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5443 - loss_1: 0.1000 - root_mean_squared_error: 2.0730 - val_loss: 8.4347 - val_loss_1: 0.0996 - val_root_mean_squared_error: 2.0197\n",
      "Epoch 351/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.4991 - loss_1: 0.1000 - root_mean_squared_error: 2.0652 - val_loss: 8.2957 - val_loss_1: 0.0997 - val_root_mean_squared_error: 1.9853\n",
      "Epoch 352/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 9.0516 - loss_1: 0.0999 - root_mean_squared_error: 2.1185 - val_loss: 8.8707 - val_loss_1: 0.0992 - val_root_mean_squared_error: 2.0521\n",
      "Epoch 353/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6232 - loss_1: 0.1001 - root_mean_squared_error: 2.0771 - val_loss: 8.8291 - val_loss_1: 0.1008 - val_root_mean_squared_error: 2.0393\n",
      "Epoch 354/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.7231 - loss_1: 0.0997 - root_mean_squared_error: 2.0731 - val_loss: 8.6396 - val_loss_1: 0.1003 - val_root_mean_squared_error: 2.0129\n",
      "Epoch 355/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 9.0479 - loss_1: 0.1008 - root_mean_squared_error: 2.1297 - val_loss: 8.6591 - val_loss_1: 0.1004 - val_root_mean_squared_error: 2.0358\n",
      "Epoch 356/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 8.5213 - loss_1: 0.1004 - root_mean_squared_error: 2.0637 - val_loss: 8.7400 - val_loss_1: 0.0995 - val_root_mean_squared_error: 2.0507\n",
      "Epoch 357/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.6396 - loss_1: 0.0996 - root_mean_squared_error: 2.0641 - val_loss: 8.9066 - val_loss_1: 0.0994 - val_root_mean_squared_error: 2.0535\n",
      "Epoch 358/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.4513 - loss_1: 0.1003 - root_mean_squared_error: 2.0404 - val_loss: 8.3815 - val_loss_1: 0.1006 - val_root_mean_squared_error: 2.0272\n",
      "Epoch 359/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5675 - loss_1: 0.0998 - root_mean_squared_error: 2.0592 - val_loss: 8.6284 - val_loss_1: 0.1000 - val_root_mean_squared_error: 2.0151\n",
      "Epoch 360/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6174 - loss_1: 0.1003 - root_mean_squared_error: 2.0779 - val_loss: 8.4276 - val_loss_1: 0.1006 - val_root_mean_squared_error: 2.0147\n",
      "Epoch 361/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.8614 - loss_1: 0.1001 - root_mean_squared_error: 2.0772 - val_loss: 8.5121 - val_loss_1: 0.0995 - val_root_mean_squared_error: 2.0163\n",
      "Epoch 362/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.5504 - loss_1: 0.1001 - root_mean_squared_error: 2.0607 - val_loss: 8.5231 - val_loss_1: 0.1003 - val_root_mean_squared_error: 2.0213\n",
      "Epoch 363/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6046 - loss_1: 0.1000 - root_mean_squared_error: 2.0600 - val_loss: 7.6785 - val_loss_1: 0.0988 - val_root_mean_squared_error: 1.9165\n",
      "Epoch 364/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.6317 - loss_1: 0.0990 - root_mean_squared_error: 2.0784 - val_loss: 8.6687 - val_loss_1: 0.1001 - val_root_mean_squared_error: 2.0268\n",
      "Epoch 365/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.7116 - loss_1: 0.0996 - root_mean_squared_error: 2.0911 - val_loss: 8.1747 - val_loss_1: 0.0984 - val_root_mean_squared_error: 1.9722\n",
      "Epoch 366/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.5049 - loss_1: 0.0992 - root_mean_squared_error: 2.0449 - val_loss: 8.7488 - val_loss_1: 0.0993 - val_root_mean_squared_error: 2.0172\n",
      "Epoch 367/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.4156 - loss_1: 0.0985 - root_mean_squared_error: 2.0545 - val_loss: 8.6104 - val_loss_1: 0.0993 - val_root_mean_squared_error: 2.0269\n",
      "Epoch 368/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.7530 - loss_1: 0.0997 - root_mean_squared_error: 2.0788 - val_loss: 8.3765 - val_loss_1: 0.0991 - val_root_mean_squared_error: 1.9981\n",
      "Epoch 369/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.4907 - loss_1: 0.0991 - root_mean_squared_error: 2.0461 - val_loss: 8.5869 - val_loss_1: 0.1002 - val_root_mean_squared_error: 2.0264\n",
      "Epoch 370/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.5539 - loss_1: 0.0998 - root_mean_squared_error: 2.0584 - val_loss: 8.3203 - val_loss_1: 0.0989 - val_root_mean_squared_error: 1.9960\n",
      "Epoch 371/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5922 - loss_1: 0.0988 - root_mean_squared_error: 2.0740 - val_loss: 8.0277 - val_loss_1: 0.1009 - val_root_mean_squared_error: 1.9347\n",
      "Epoch 372/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.4885 - loss_1: 0.0996 - root_mean_squared_error: 2.0598 - val_loss: 8.2144 - val_loss_1: 0.0980 - val_root_mean_squared_error: 1.9855\n",
      "Epoch 373/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.4320 - loss_1: 0.0986 - root_mean_squared_error: 2.0498 - val_loss: 8.5207 - val_loss_1: 0.0990 - val_root_mean_squared_error: 2.0336\n",
      "Epoch 374/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.6069 - loss_1: 0.0990 - root_mean_squared_error: 2.0694 - val_loss: 8.4500 - val_loss_1: 0.0981 - val_root_mean_squared_error: 2.0156\n",
      "Epoch 375/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.4165 - loss_1: 0.0977 - root_mean_squared_error: 2.0520 - val_loss: 8.5878 - val_loss_1: 0.0993 - val_root_mean_squared_error: 2.0137\n",
      "Epoch 376/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.5782 - loss_1: 0.0990 - root_mean_squared_error: 2.0688 - val_loss: 8.0308 - val_loss_1: 0.0982 - val_root_mean_squared_error: 1.9589\n",
      "Epoch 377/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.4685 - loss_1: 0.0981 - root_mean_squared_error: 2.0372 - val_loss: 8.1068 - val_loss_1: 0.0991 - val_root_mean_squared_error: 1.9543\n",
      "Epoch 378/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.4313 - loss_1: 0.0992 - root_mean_squared_error: 2.0542 - val_loss: 8.5819 - val_loss_1: 0.0983 - val_root_mean_squared_error: 2.0169\n",
      "Epoch 379/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.4844 - loss_1: 0.0984 - root_mean_squared_error: 2.0376 - val_loss: 8.4374 - val_loss_1: 0.0992 - val_root_mean_squared_error: 2.0074\n",
      "Epoch 380/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5927 - loss_1: 0.0987 - root_mean_squared_error: 2.0621 - val_loss: 8.2213 - val_loss_1: 0.0993 - val_root_mean_squared_error: 1.9684\n",
      "Epoch 381/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.5867 - loss_1: 0.0983 - root_mean_squared_error: 2.0585 - val_loss: 8.1744 - val_loss_1: 0.0994 - val_root_mean_squared_error: 2.0079\n",
      "Epoch 382/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.3986 - loss_1: 0.0990 - root_mean_squared_error: 2.0445 - val_loss: 8.3260 - val_loss_1: 0.0982 - val_root_mean_squared_error: 1.9901\n",
      "Epoch 383/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.5175 - loss_1: 0.0979 - root_mean_squared_error: 2.0546 - val_loss: 8.1588 - val_loss_1: 0.0983 - val_root_mean_squared_error: 1.9720\n",
      "Epoch 384/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5632 - loss_1: 0.0983 - root_mean_squared_error: 2.0685 - val_loss: 8.5374 - val_loss_1: 0.0980 - val_root_mean_squared_error: 2.0152\n",
      "Epoch 385/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.4071 - loss_1: 0.0986 - root_mean_squared_error: 2.0466 - val_loss: 7.9756 - val_loss_1: 0.0996 - val_root_mean_squared_error: 1.9754\n",
      "Epoch 386/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.4266 - loss_1: 0.0983 - root_mean_squared_error: 2.0437 - val_loss: 8.6686 - val_loss_1: 0.0988 - val_root_mean_squared_error: 1.9908\n",
      "Epoch 387/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5982 - loss_1: 0.0987 - root_mean_squared_error: 2.0574 - val_loss: 8.4436 - val_loss_1: 0.0978 - val_root_mean_squared_error: 2.0103\n",
      "Epoch 388/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.2884 - loss_1: 0.0974 - root_mean_squared_error: 2.0298 - val_loss: 8.0705 - val_loss_1: 0.0973 - val_root_mean_squared_error: 1.9493\n",
      "Epoch 389/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.5827 - loss_1: 0.0976 - root_mean_squared_error: 2.0638 - val_loss: 8.5956 - val_loss_1: 0.0973 - val_root_mean_squared_error: 1.9980\n",
      "Epoch 390/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.3856 - loss_1: 0.0989 - root_mean_squared_error: 2.0381 - val_loss: 8.2010 - val_loss_1: 0.0991 - val_root_mean_squared_error: 1.9612\n",
      "Epoch 391/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.3437 - loss_1: 0.0978 - root_mean_squared_error: 2.0413 - val_loss: 8.2207 - val_loss_1: 0.0966 - val_root_mean_squared_error: 2.0024\n",
      "Epoch 392/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.6106 - loss_1: 0.0975 - root_mean_squared_error: 2.0668 - val_loss: 8.3189 - val_loss_1: 0.0982 - val_root_mean_squared_error: 1.9928\n",
      "Epoch 393/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.5486 - loss_1: 0.0982 - root_mean_squared_error: 2.0611 - val_loss: 8.3396 - val_loss_1: 0.0969 - val_root_mean_squared_error: 2.0122\n",
      "Epoch 394/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.4752 - loss_1: 0.0975 - root_mean_squared_error: 2.0450 - val_loss: 8.0326 - val_loss_1: 0.0979 - val_root_mean_squared_error: 1.9556\n",
      "Epoch 395/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.3375 - loss_1: 0.0978 - root_mean_squared_error: 2.0287 - val_loss: 8.4397 - val_loss_1: 0.0972 - val_root_mean_squared_error: 2.0122\n",
      "Epoch 396/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.3785 - loss_1: 0.0975 - root_mean_squared_error: 2.0419 - val_loss: 8.4789 - val_loss_1: 0.0986 - val_root_mean_squared_error: 1.9795\n",
      "Epoch 397/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.3983 - loss_1: 0.0980 - root_mean_squared_error: 2.0471 - val_loss: 8.3252 - val_loss_1: 0.0976 - val_root_mean_squared_error: 1.9940\n",
      "Epoch 398/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.3456 - loss_1: 0.0976 - root_mean_squared_error: 2.0326 - val_loss: 8.0790 - val_loss_1: 0.0990 - val_root_mean_squared_error: 1.9700\n",
      "Epoch 399/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.4055 - loss_1: 0.0979 - root_mean_squared_error: 2.0433 - val_loss: 8.3375 - val_loss_1: 0.0974 - val_root_mean_squared_error: 1.9948\n",
      "Epoch 400/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2225 - loss_1: 0.0980 - root_mean_squared_error: 2.0246 - val_loss: 8.4576 - val_loss_1: 0.0979 - val_root_mean_squared_error: 1.9595\n",
      "Epoch 401/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.2111 - loss_1: 0.0967 - root_mean_squared_error: 2.0289 - val_loss: 8.5469 - val_loss_1: 0.0958 - val_root_mean_squared_error: 2.0333\n",
      "Epoch 402/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.3013 - loss_1: 0.0975 - root_mean_squared_error: 2.0366 - val_loss: 8.2207 - val_loss_1: 0.0980 - val_root_mean_squared_error: 1.9840\n",
      "Epoch 403/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.2674 - loss_1: 0.0978 - root_mean_squared_error: 2.0313 - val_loss: 8.2673 - val_loss_1: 0.0982 - val_root_mean_squared_error: 1.9870\n",
      "Epoch 404/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5274 - loss_1: 0.0968 - root_mean_squared_error: 2.0500 - val_loss: 8.4739 - val_loss_1: 0.0968 - val_root_mean_squared_error: 2.0198\n",
      "Epoch 405/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2204 - loss_1: 0.0985 - root_mean_squared_error: 2.0219 - val_loss: 8.0186 - val_loss_1: 0.0985 - val_root_mean_squared_error: 1.9234\n",
      "Epoch 406/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.5458 - loss_1: 0.0975 - root_mean_squared_error: 2.0493 - val_loss: 8.5316 - val_loss_1: 0.0973 - val_root_mean_squared_error: 2.0336\n",
      "Epoch 407/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.1096 - loss_1: 0.0970 - root_mean_squared_error: 2.0094 - val_loss: 7.9041 - val_loss_1: 0.0966 - val_root_mean_squared_error: 1.9301\n",
      "Epoch 408/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2104 - loss_1: 0.0968 - root_mean_squared_error: 2.0175 - val_loss: 8.3996 - val_loss_1: 0.0972 - val_root_mean_squared_error: 2.0094\n",
      "Epoch 409/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.3224 - loss_1: 0.0971 - root_mean_squared_error: 2.0281 - val_loss: 7.8876 - val_loss_1: 0.0973 - val_root_mean_squared_error: 1.9564\n",
      "Epoch 410/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.1311 - loss_1: 0.0973 - root_mean_squared_error: 2.0129 - val_loss: 8.3981 - val_loss_1: 0.0977 - val_root_mean_squared_error: 2.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.2275 - loss_1: 0.0964 - root_mean_squared_error: 2.0180 - val_loss: 8.2129 - val_loss_1: 0.0956 - val_root_mean_squared_error: 1.9965\n",
      "Epoch 412/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.1927 - loss_1: 0.0968 - root_mean_squared_error: 2.0087 - val_loss: 8.2452 - val_loss_1: 0.0963 - val_root_mean_squared_error: 1.9700\n",
      "Epoch 413/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.9245 - loss_1: 0.0958 - root_mean_squared_error: 1.9905 - val_loss: 8.4667 - val_loss_1: 0.0965 - val_root_mean_squared_error: 2.0045\n",
      "Epoch 414/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2408 - loss_1: 0.0964 - root_mean_squared_error: 2.0302 - val_loss: 8.0856 - val_loss_1: 0.0979 - val_root_mean_squared_error: 1.9425\n",
      "Epoch 415/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.1645 - loss_1: 0.0965 - root_mean_squared_error: 2.0038 - val_loss: 7.9159 - val_loss_1: 0.0957 - val_root_mean_squared_error: 1.9520\n",
      "Epoch 416/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.3958 - loss_1: 0.0969 - root_mean_squared_error: 2.0297 - val_loss: 7.8644 - val_loss_1: 0.0960 - val_root_mean_squared_error: 1.9181\n",
      "Epoch 417/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.1815 - loss_1: 0.0960 - root_mean_squared_error: 2.0196 - val_loss: 8.3842 - val_loss_1: 0.0962 - val_root_mean_squared_error: 1.9843\n",
      "Epoch 418/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.1925 - loss_1: 0.0975 - root_mean_squared_error: 2.0186 - val_loss: 8.4803 - val_loss_1: 0.0967 - val_root_mean_squared_error: 2.0106\n",
      "Epoch 419/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2602 - loss_1: 0.0972 - root_mean_squared_error: 2.0349 - val_loss: 8.2339 - val_loss_1: 0.0983 - val_root_mean_squared_error: 1.9935\n",
      "Epoch 420/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.2432 - loss_1: 0.0974 - root_mean_squared_error: 2.0122 - val_loss: 8.1503 - val_loss_1: 0.0955 - val_root_mean_squared_error: 1.9769\n",
      "Epoch 421/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2243 - loss_1: 0.0961 - root_mean_squared_error: 2.0133 - val_loss: 7.7937 - val_loss_1: 0.0973 - val_root_mean_squared_error: 1.9216\n",
      "Epoch 422/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2897 - loss_1: 0.0967 - root_mean_squared_error: 2.0296 - val_loss: 8.1413 - val_loss_1: 0.0954 - val_root_mean_squared_error: 1.9657\n",
      "Epoch 423/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.1305 - loss_1: 0.0956 - root_mean_squared_error: 2.0143 - val_loss: 7.5502 - val_loss_1: 0.0956 - val_root_mean_squared_error: 1.9228\n",
      "Epoch 424/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 8.1875 - loss_1: 0.0959 - root_mean_squared_error: 2.0039 - val_loss: 8.3376 - val_loss_1: 0.0974 - val_root_mean_squared_error: 2.0044\n",
      "Epoch 425/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0334 - loss_1: 0.0970 - root_mean_squared_error: 2.0011 - val_loss: 7.8600 - val_loss_1: 0.0956 - val_root_mean_squared_error: 1.9468\n",
      "Epoch 426/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.1063 - loss_1: 0.0963 - root_mean_squared_error: 1.9997 - val_loss: 7.8316 - val_loss_1: 0.0968 - val_root_mean_squared_error: 1.9211\n",
      "Epoch 427/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.2857 - loss_1: 0.0964 - root_mean_squared_error: 2.0329 - val_loss: 8.3369 - val_loss_1: 0.0949 - val_root_mean_squared_error: 1.9976\n",
      "Epoch 428/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.1140 - loss_1: 0.0957 - root_mean_squared_error: 2.0078 - val_loss: 8.5341 - val_loss_1: 0.0968 - val_root_mean_squared_error: 1.9797\n",
      "Epoch 429/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.1104 - loss_1: 0.0960 - root_mean_squared_error: 2.0159 - val_loss: 7.7234 - val_loss_1: 0.0941 - val_root_mean_squared_error: 1.9321\n",
      "Epoch 430/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0479 - loss_1: 0.0962 - root_mean_squared_error: 1.9960 - val_loss: 8.0288 - val_loss_1: 0.0971 - val_root_mean_squared_error: 1.9523\n",
      "Epoch 431/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2068 - loss_1: 0.0964 - root_mean_squared_error: 2.0157 - val_loss: 8.1704 - val_loss_1: 0.0956 - val_root_mean_squared_error: 1.9909\n",
      "Epoch 432/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.1091 - loss_1: 0.0969 - root_mean_squared_error: 2.0141 - val_loss: 7.7132 - val_loss_1: 0.0957 - val_root_mean_squared_error: 1.9239\n",
      "Epoch 433/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0877 - loss_1: 0.0959 - root_mean_squared_error: 2.0031 - val_loss: 7.5102 - val_loss_1: 0.0961 - val_root_mean_squared_error: 1.8877\n",
      "Epoch 434/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2025 - loss_1: 0.0961 - root_mean_squared_error: 2.0182 - val_loss: 8.2255 - val_loss_1: 0.0954 - val_root_mean_squared_error: 1.9809\n",
      "Epoch 435/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.2717 - loss_1: 0.0961 - root_mean_squared_error: 2.0245 - val_loss: 8.5391 - val_loss_1: 0.0958 - val_root_mean_squared_error: 2.0048\n",
      "Epoch 436/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.1491 - loss_1: 0.0947 - root_mean_squared_error: 2.0128 - val_loss: 8.5631 - val_loss_1: 0.0962 - val_root_mean_squared_error: 1.9979\n",
      "Epoch 437/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.1651 - loss_1: 0.0960 - root_mean_squared_error: 2.0216 - val_loss: 8.5056 - val_loss_1: 0.0963 - val_root_mean_squared_error: 2.0099\n",
      "Epoch 438/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0020 - loss_1: 0.0957 - root_mean_squared_error: 1.9974 - val_loss: 8.1025 - val_loss_1: 0.0963 - val_root_mean_squared_error: 1.9495\n",
      "Epoch 439/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2189 - loss_1: 0.0955 - root_mean_squared_error: 2.0114 - val_loss: 7.8733 - val_loss_1: 0.0940 - val_root_mean_squared_error: 1.9164\n",
      "Epoch 440/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.0894 - loss_1: 0.0952 - root_mean_squared_error: 2.0124 - val_loss: 8.0608 - val_loss_1: 0.0958 - val_root_mean_squared_error: 1.9455\n",
      "Epoch 441/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.9581 - loss_1: 0.0951 - root_mean_squared_error: 1.9939 - val_loss: 8.2229 - val_loss_1: 0.0948 - val_root_mean_squared_error: 1.9885\n",
      "Epoch 442/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.2739 - loss_1: 0.0950 - root_mean_squared_error: 2.0222 - val_loss: 7.8593 - val_loss_1: 0.0958 - val_root_mean_squared_error: 1.9332\n",
      "Epoch 443/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2167 - loss_1: 0.0957 - root_mean_squared_error: 2.0258 - val_loss: 8.6628 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.0321\n",
      "Epoch 444/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 7.9508 - loss_1: 0.0953 - root_mean_squared_error: 1.9743 - val_loss: 8.1518 - val_loss_1: 0.0954 - val_root_mean_squared_error: 1.9701\n",
      "Epoch 445/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.2428 - loss_1: 0.0960 - root_mean_squared_error: 2.0138 - val_loss: 7.8678 - val_loss_1: 0.0944 - val_root_mean_squared_error: 1.9628\n",
      "Epoch 446/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.6805 - loss_1: 0.0945 - root_mean_squared_error: 1.9471 - val_loss: 8.0628 - val_loss_1: 0.0953 - val_root_mean_squared_error: 1.9580\n",
      "Epoch 447/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2242 - loss_1: 0.0947 - root_mean_squared_error: 2.0152 - val_loss: 7.9571 - val_loss_1: 0.0952 - val_root_mean_squared_error: 1.9687\n",
      "Epoch 448/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.0977 - loss_1: 0.0952 - root_mean_squared_error: 1.9997 - val_loss: 7.9901 - val_loss_1: 0.0949 - val_root_mean_squared_error: 1.9590\n",
      "Epoch 449/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.9649 - loss_1: 0.0939 - root_mean_squared_error: 1.9911 - val_loss: 8.2234 - val_loss_1: 0.0942 - val_root_mean_squared_error: 1.9604\n",
      "Epoch 450/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.0365 - loss_1: 0.0951 - root_mean_squared_error: 1.9957 - val_loss: 8.5430 - val_loss_1: 0.0947 - val_root_mean_squared_error: 2.0253\n",
      "Epoch 451/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.8961 - loss_1: 0.0942 - root_mean_squared_error: 1.9742 - val_loss: 8.1356 - val_loss_1: 0.0954 - val_root_mean_squared_error: 1.9653\n",
      "Epoch 452/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.0684 - loss_1: 0.0950 - root_mean_squared_error: 1.9997 - val_loss: 7.9805 - val_loss_1: 0.0944 - val_root_mean_squared_error: 1.9611\n",
      "Epoch 453/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0277 - loss_1: 0.0944 - root_mean_squared_error: 1.9929 - val_loss: 8.0640 - val_loss_1: 0.0948 - val_root_mean_squared_error: 1.9408\n",
      "Epoch 454/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.1823 - loss_1: 0.0946 - root_mean_squared_error: 2.0053 - val_loss: 7.8506 - val_loss_1: 0.0936 - val_root_mean_squared_error: 1.9465\n",
      "Epoch 455/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.2049 - loss_1: 0.0940 - root_mean_squared_error: 2.0048 - val_loss: 8.2918 - val_loss_1: 0.0938 - val_root_mean_squared_error: 1.9600\n",
      "Epoch 456/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.1580 - loss_1: 0.0946 - root_mean_squared_error: 2.0225 - val_loss: 7.8350 - val_loss_1: 0.0947 - val_root_mean_squared_error: 1.9180\n",
      "Epoch 457/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.1325 - loss_1: 0.0952 - root_mean_squared_error: 1.9865 - val_loss: 7.7230 - val_loss_1: 0.0951 - val_root_mean_squared_error: 1.8992\n",
      "Epoch 458/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.0321 - loss_1: 0.0945 - root_mean_squared_error: 1.9996 - val_loss: 7.6944 - val_loss_1: 0.0949 - val_root_mean_squared_error: 1.9278\n",
      "Epoch 459/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.9368 - loss_1: 0.0948 - root_mean_squared_error: 1.9763 - val_loss: 7.5990 - val_loss_1: 0.0951 - val_root_mean_squared_error: 1.8749\n",
      "Epoch 460/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.0044 - loss_1: 0.0941 - root_mean_squared_error: 1.9770 - val_loss: 7.7976 - val_loss_1: 0.0936 - val_root_mean_squared_error: 1.9485\n",
      "Epoch 461/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8525 - loss_1: 0.0947 - root_mean_squared_error: 1.9789 - val_loss: 7.6156 - val_loss_1: 0.0955 - val_root_mean_squared_error: 1.8926\n",
      "Epoch 462/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.1252 - loss_1: 0.0952 - root_mean_squared_error: 2.0112 - val_loss: 7.7258 - val_loss_1: 0.0935 - val_root_mean_squared_error: 1.9163\n",
      "Epoch 463/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.1599 - loss_1: 0.0937 - root_mean_squared_error: 2.0185 - val_loss: 7.8178 - val_loss_1: 0.0944 - val_root_mean_squared_error: 1.9389\n",
      "Epoch 464/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.9936 - loss_1: 0.0952 - root_mean_squared_error: 2.0033 - val_loss: 8.1014 - val_loss_1: 0.0950 - val_root_mean_squared_error: 1.9760\n",
      "Epoch 465/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 8.0011 - loss_1: 0.0934 - root_mean_squared_error: 1.9851 - val_loss: 8.0158 - val_loss_1: 0.0939 - val_root_mean_squared_error: 1.9608\n",
      "Epoch 466/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.0481 - loss_1: 0.0950 - root_mean_squared_error: 1.9869 - val_loss: 7.7959 - val_loss_1: 0.0942 - val_root_mean_squared_error: 1.9537\n",
      "Epoch 467/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0255 - loss_1: 0.0939 - root_mean_squared_error: 1.9949 - val_loss: 8.2088 - val_loss_1: 0.0950 - val_root_mean_squared_error: 1.9452\n",
      "Epoch 468/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.9850 - loss_1: 0.0950 - root_mean_squared_error: 1.9798 - val_loss: 8.4114 - val_loss_1: 0.0942 - val_root_mean_squared_error: 2.0006\n",
      "Epoch 469/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.8964 - loss_1: 0.0944 - root_mean_squared_error: 1.9616 - val_loss: 7.8330 - val_loss_1: 0.0945 - val_root_mean_squared_error: 1.9464\n",
      "Epoch 470/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8372 - loss_1: 0.0945 - root_mean_squared_error: 1.9699 - val_loss: 8.4615 - val_loss_1: 0.0948 - val_root_mean_squared_error: 1.9936\n",
      "Epoch 471/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 8.0349 - loss_1: 0.0944 - root_mean_squared_error: 1.9955 - val_loss: 7.7935 - val_loss_1: 0.0946 - val_root_mean_squared_error: 1.9057\n",
      "Epoch 472/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0366 - loss_1: 0.0939 - root_mean_squared_error: 1.9949 - val_loss: 7.7836 - val_loss_1: 0.0933 - val_root_mean_squared_error: 1.9499\n",
      "Epoch 473/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7491 - loss_1: 0.0946 - root_mean_squared_error: 1.9546 - val_loss: 8.3642 - val_loss_1: 0.0951 - val_root_mean_squared_error: 1.9929\n",
      "Epoch 474/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8766 - loss_1: 0.0938 - root_mean_squared_error: 1.9766 - val_loss: 7.9023 - val_loss_1: 0.0946 - val_root_mean_squared_error: 1.9669\n",
      "Epoch 475/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.0442 - loss_1: 0.0941 - root_mean_squared_error: 1.9797 - val_loss: 7.8620 - val_loss_1: 0.0939 - val_root_mean_squared_error: 1.9266\n",
      "Epoch 476/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.9947 - loss_1: 0.0946 - root_mean_squared_error: 1.9870 - val_loss: 8.4859 - val_loss_1: 0.0940 - val_root_mean_squared_error: 1.9855\n",
      "Epoch 477/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.0239 - loss_1: 0.0936 - root_mean_squared_error: 1.9967 - val_loss: 7.7290 - val_loss_1: 0.0943 - val_root_mean_squared_error: 1.9257\n",
      "Epoch 478/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.0909 - loss_1: 0.0938 - root_mean_squared_error: 1.9959 - val_loss: 7.3602 - val_loss_1: 0.0930 - val_root_mean_squared_error: 1.8752\n",
      "Epoch 479/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.8625 - loss_1: 0.0932 - root_mean_squared_error: 1.9797 - val_loss: 7.6833 - val_loss_1: 0.0940 - val_root_mean_squared_error: 1.9066\n",
      "Epoch 480/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.1244 - loss_1: 0.0943 - root_mean_squared_error: 1.9909 - val_loss: 7.5517 - val_loss_1: 0.0930 - val_root_mean_squared_error: 1.8932\n",
      "Epoch 481/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8949 - loss_1: 0.0927 - root_mean_squared_error: 1.9708 - val_loss: 7.7387 - val_loss_1: 0.0938 - val_root_mean_squared_error: 1.9458\n",
      "Epoch 482/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8194 - loss_1: 0.0942 - root_mean_squared_error: 1.9725 - val_loss: 7.6723 - val_loss_1: 0.0932 - val_root_mean_squared_error: 1.9428\n",
      "Epoch 483/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.9560 - loss_1: 0.0933 - root_mean_squared_error: 1.9836 - val_loss: 7.9412 - val_loss_1: 0.0952 - val_root_mean_squared_error: 1.9363\n",
      "Epoch 484/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7953 - loss_1: 0.0943 - root_mean_squared_error: 1.9773 - val_loss: 7.7106 - val_loss_1: 0.0926 - val_root_mean_squared_error: 1.9405\n",
      "Epoch 485/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 8.0787 - loss_1: 0.0928 - root_mean_squared_error: 1.9991 - val_loss: 7.5471 - val_loss_1: 0.0942 - val_root_mean_squared_error: 1.8925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.8925 - loss_1: 0.0941 - root_mean_squared_error: 1.9732 - val_loss: 7.9540 - val_loss_1: 0.0931 - val_root_mean_squared_error: 1.9413\n",
      "Epoch 487/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8976 - loss_1: 0.0929 - root_mean_squared_error: 1.9862 - val_loss: 7.0412 - val_loss_1: 0.0943 - val_root_mean_squared_error: 1.8550\n",
      "Epoch 488/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0144 - loss_1: 0.0938 - root_mean_squared_error: 1.9898 - val_loss: 7.6704 - val_loss_1: 0.0927 - val_root_mean_squared_error: 1.8882\n",
      "Epoch 489/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.9255 - loss_1: 0.0932 - root_mean_squared_error: 1.9810 - val_loss: 7.8342 - val_loss_1: 0.0943 - val_root_mean_squared_error: 1.9242\n",
      "Epoch 490/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8834 - loss_1: 0.0939 - root_mean_squared_error: 1.9834 - val_loss: 7.7169 - val_loss_1: 0.0941 - val_root_mean_squared_error: 1.9145\n",
      "Epoch 491/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.9964 - loss_1: 0.0940 - root_mean_squared_error: 1.9890 - val_loss: 7.3192 - val_loss_1: 0.0934 - val_root_mean_squared_error: 1.8761\n",
      "Epoch 492/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8056 - loss_1: 0.0938 - root_mean_squared_error: 1.9685 - val_loss: 7.7844 - val_loss_1: 0.0945 - val_root_mean_squared_error: 1.9368\n",
      "Epoch 493/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8466 - loss_1: 0.0938 - root_mean_squared_error: 1.9629 - val_loss: 7.9612 - val_loss_1: 0.0930 - val_root_mean_squared_error: 1.9352\n",
      "Epoch 494/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8660 - loss_1: 0.0928 - root_mean_squared_error: 1.9708 - val_loss: 7.7622 - val_loss_1: 0.0925 - val_root_mean_squared_error: 1.9172\n",
      "Epoch 495/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.8401 - loss_1: 0.0936 - root_mean_squared_error: 1.9723 - val_loss: 7.6135 - val_loss_1: 0.0937 - val_root_mean_squared_error: 1.8973\n",
      "Epoch 496/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8283 - loss_1: 0.0921 - root_mean_squared_error: 1.9576 - val_loss: 7.7295 - val_loss_1: 0.0922 - val_root_mean_squared_error: 1.8968\n",
      "Epoch 497/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 7.9370 - loss_1: 0.0921 - root_mean_squared_error: 1.9744 - val_loss: 8.2381 - val_loss_1: 0.0919 - val_root_mean_squared_error: 1.9566\n",
      "Epoch 498/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 8.0220 - loss_1: 0.0927 - root_mean_squared_error: 1.9798 - val_loss: 7.9029 - val_loss_1: 0.0947 - val_root_mean_squared_error: 1.9400\n",
      "Epoch 499/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.6953 - loss_1: 0.0944 - root_mean_squared_error: 1.9524 - val_loss: 7.7254 - val_loss_1: 0.0921 - val_root_mean_squared_error: 1.9297\n",
      "Epoch 500/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6931 - loss_1: 0.0922 - root_mean_squared_error: 1.9445 - val_loss: 8.2409 - val_loss_1: 0.0941 - val_root_mean_squared_error: 1.9532\n",
      "Epoch 501/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6815 - loss_1: 0.0941 - root_mean_squared_error: 1.9545 - val_loss: 7.5007 - val_loss_1: 0.0932 - val_root_mean_squared_error: 1.8739\n",
      "Epoch 502/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.6507 - loss_1: 0.0931 - root_mean_squared_error: 1.9531 - val_loss: 7.9089 - val_loss_1: 0.0939 - val_root_mean_squared_error: 1.9287\n",
      "Epoch 503/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7846 - loss_1: 0.0925 - root_mean_squared_error: 1.9526 - val_loss: 7.5481 - val_loss_1: 0.0921 - val_root_mean_squared_error: 1.9100\n",
      "Epoch 504/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.9204 - loss_1: 0.0933 - root_mean_squared_error: 1.9921 - val_loss: 8.2673 - val_loss_1: 0.0933 - val_root_mean_squared_error: 1.9965\n",
      "Epoch 505/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.6865 - loss_1: 0.0925 - root_mean_squared_error: 1.9541 - val_loss: 7.8675 - val_loss_1: 0.0923 - val_root_mean_squared_error: 1.9291\n",
      "Epoch 506/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8455 - loss_1: 0.0935 - root_mean_squared_error: 1.9712 - val_loss: 7.6796 - val_loss_1: 0.0946 - val_root_mean_squared_error: 1.8821\n",
      "Epoch 507/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8169 - loss_1: 0.0928 - root_mean_squared_error: 1.9586 - val_loss: 7.7250 - val_loss_1: 0.0918 - val_root_mean_squared_error: 1.9245\n",
      "Epoch 508/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 8.1527 - loss_1: 0.0928 - root_mean_squared_error: 2.0008 - val_loss: 7.5903 - val_loss_1: 0.0938 - val_root_mean_squared_error: 1.9103\n",
      "Epoch 509/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.7547 - loss_1: 0.0930 - root_mean_squared_error: 1.9667 - val_loss: 7.7665 - val_loss_1: 0.0922 - val_root_mean_squared_error: 1.9144\n",
      "Epoch 510/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8545 - loss_1: 0.0932 - root_mean_squared_error: 1.9672 - val_loss: 7.6696 - val_loss_1: 0.0927 - val_root_mean_squared_error: 1.9002\n",
      "Epoch 511/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4253 - loss_1: 0.0927 - root_mean_squared_error: 1.9112 - val_loss: 7.9115 - val_loss_1: 0.0918 - val_root_mean_squared_error: 1.9402\n",
      "Epoch 512/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.8910 - loss_1: 0.0924 - root_mean_squared_error: 1.9730 - val_loss: 7.9358 - val_loss_1: 0.0928 - val_root_mean_squared_error: 1.9257\n",
      "Epoch 513/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6203 - loss_1: 0.0925 - root_mean_squared_error: 1.9395 - val_loss: 7.9510 - val_loss_1: 0.0929 - val_root_mean_squared_error: 1.9441\n",
      "Epoch 514/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7020 - loss_1: 0.0936 - root_mean_squared_error: 1.9433 - val_loss: 7.8956 - val_loss_1: 0.0923 - val_root_mean_squared_error: 1.9354\n",
      "Epoch 515/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7194 - loss_1: 0.0921 - root_mean_squared_error: 1.9528 - val_loss: 7.5154 - val_loss_1: 0.0924 - val_root_mean_squared_error: 1.8852\n",
      "Epoch 516/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7176 - loss_1: 0.0930 - root_mean_squared_error: 1.9629 - val_loss: 7.5927 - val_loss_1: 0.0928 - val_root_mean_squared_error: 1.8880\n",
      "Epoch 517/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6659 - loss_1: 0.0925 - root_mean_squared_error: 1.9521 - val_loss: 7.1855 - val_loss_1: 0.0921 - val_root_mean_squared_error: 1.8425\n",
      "Epoch 518/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8135 - loss_1: 0.0931 - root_mean_squared_error: 1.9533 - val_loss: 7.2922 - val_loss_1: 0.0933 - val_root_mean_squared_error: 1.8770\n",
      "Epoch 519/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8122 - loss_1: 0.0928 - root_mean_squared_error: 1.9596 - val_loss: 7.8444 - val_loss_1: 0.0922 - val_root_mean_squared_error: 1.9336\n",
      "Epoch 520/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.5647 - loss_1: 0.0921 - root_mean_squared_error: 1.9448 - val_loss: 7.2737 - val_loss_1: 0.0918 - val_root_mean_squared_error: 1.8702\n",
      "Epoch 521/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.9036 - loss_1: 0.0926 - root_mean_squared_error: 1.9628 - val_loss: 8.3386 - val_loss_1: 0.0943 - val_root_mean_squared_error: 1.9482\n",
      "Epoch 522/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7305 - loss_1: 0.0927 - root_mean_squared_error: 1.9513 - val_loss: 7.9390 - val_loss_1: 0.0906 - val_root_mean_squared_error: 1.9320\n",
      "Epoch 523/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7998 - loss_1: 0.0924 - root_mean_squared_error: 1.9596 - val_loss: 7.6007 - val_loss_1: 0.0935 - val_root_mean_squared_error: 1.9076\n",
      "Epoch 524/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7361 - loss_1: 0.0926 - root_mean_squared_error: 1.9403 - val_loss: 7.6595 - val_loss_1: 0.0924 - val_root_mean_squared_error: 1.9111\n",
      "Epoch 525/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6013 - loss_1: 0.0928 - root_mean_squared_error: 1.9368 - val_loss: 7.6635 - val_loss_1: 0.0931 - val_root_mean_squared_error: 1.9252\n",
      "Epoch 526/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.7364 - loss_1: 0.0918 - root_mean_squared_error: 1.9538 - val_loss: 7.4702 - val_loss_1: 0.0921 - val_root_mean_squared_error: 1.8890\n",
      "Epoch 527/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.8379 - loss_1: 0.0921 - root_mean_squared_error: 1.9579 - val_loss: 7.6840 - val_loss_1: 0.0907 - val_root_mean_squared_error: 1.9392\n",
      "Epoch 528/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.7755 - loss_1: 0.0914 - root_mean_squared_error: 1.9680 - val_loss: 7.5681 - val_loss_1: 0.0923 - val_root_mean_squared_error: 1.8926\n",
      "Epoch 529/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.4362 - loss_1: 0.0922 - root_mean_squared_error: 1.9162 - val_loss: 7.0971 - val_loss_1: 0.0908 - val_root_mean_squared_error: 1.8468\n",
      "Epoch 530/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 7.6557 - loss_1: 0.0916 - root_mean_squared_error: 1.9368 - val_loss: 8.1317 - val_loss_1: 0.0915 - val_root_mean_squared_error: 1.9412\n",
      "Epoch 531/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.7560 - loss_1: 0.0918 - root_mean_squared_error: 1.9601 - val_loss: 7.4152 - val_loss_1: 0.0907 - val_root_mean_squared_error: 1.9105\n",
      "Epoch 532/1000\n",
      "9600/9600 [==============================] - 1s 100us/step - loss: 7.7021 - loss_1: 0.0913 - root_mean_squared_error: 1.9450 - val_loss: 7.6598 - val_loss_1: 0.0928 - val_root_mean_squared_error: 1.9263\n",
      "Epoch 533/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4680 - loss_1: 0.0924 - root_mean_squared_error: 1.9354 - val_loss: 7.7782 - val_loss_1: 0.0916 - val_root_mean_squared_error: 1.9358\n",
      "Epoch 534/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.6024 - loss_1: 0.0906 - root_mean_squared_error: 1.9390 - val_loss: 7.4908 - val_loss_1: 0.0907 - val_root_mean_squared_error: 1.8862\n",
      "Epoch 535/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.5906 - loss_1: 0.0920 - root_mean_squared_error: 1.9424 - val_loss: 7.7812 - val_loss_1: 0.0924 - val_root_mean_squared_error: 1.9310\n",
      "Epoch 536/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.6386 - loss_1: 0.0917 - root_mean_squared_error: 1.9438 - val_loss: 7.7285 - val_loss_1: 0.0920 - val_root_mean_squared_error: 1.9137\n",
      "Epoch 537/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5911 - loss_1: 0.0917 - root_mean_squared_error: 1.9436 - val_loss: 7.7559 - val_loss_1: 0.0909 - val_root_mean_squared_error: 1.9257\n",
      "Epoch 538/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.4372 - loss_1: 0.0912 - root_mean_squared_error: 1.9306 - val_loss: 7.5773 - val_loss_1: 0.0921 - val_root_mean_squared_error: 1.8956\n",
      "Epoch 539/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.6193 - loss_1: 0.0911 - root_mean_squared_error: 1.9343 - val_loss: 7.6324 - val_loss_1: 0.0914 - val_root_mean_squared_error: 1.8957\n",
      "Epoch 540/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.5373 - loss_1: 0.0912 - root_mean_squared_error: 1.9250 - val_loss: 7.1313 - val_loss_1: 0.0916 - val_root_mean_squared_error: 1.8572\n",
      "Epoch 541/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6075 - loss_1: 0.0918 - root_mean_squared_error: 1.9310 - val_loss: 7.4152 - val_loss_1: 0.0917 - val_root_mean_squared_error: 1.8883\n",
      "Epoch 542/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.8024 - loss_1: 0.0919 - root_mean_squared_error: 1.9670 - val_loss: 7.4256 - val_loss_1: 0.0917 - val_root_mean_squared_error: 1.8785\n",
      "Epoch 543/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.6573 - loss_1: 0.0915 - root_mean_squared_error: 1.9455 - val_loss: 7.8353 - val_loss_1: 0.0917 - val_root_mean_squared_error: 1.9426\n",
      "Epoch 544/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5336 - loss_1: 0.0905 - root_mean_squared_error: 1.9386 - val_loss: 7.3592 - val_loss_1: 0.0920 - val_root_mean_squared_error: 1.8752\n",
      "Epoch 545/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.3632 - loss_1: 0.0917 - root_mean_squared_error: 1.9140 - val_loss: 7.9258 - val_loss_1: 0.0911 - val_root_mean_squared_error: 1.9099\n",
      "Epoch 546/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.6567 - loss_1: 0.0904 - root_mean_squared_error: 1.9486 - val_loss: 7.1246 - val_loss_1: 0.0902 - val_root_mean_squared_error: 1.8390\n",
      "Epoch 547/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.5893 - loss_1: 0.0909 - root_mean_squared_error: 1.9286 - val_loss: 7.5939 - val_loss_1: 0.0915 - val_root_mean_squared_error: 1.9010\n",
      "Epoch 548/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6539 - loss_1: 0.0916 - root_mean_squared_error: 1.9425 - val_loss: 7.6272 - val_loss_1: 0.0909 - val_root_mean_squared_error: 1.9015\n",
      "Epoch 549/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.3303 - loss_1: 0.0908 - root_mean_squared_error: 1.9015 - val_loss: 7.5612 - val_loss_1: 0.0918 - val_root_mean_squared_error: 1.8777\n",
      "Epoch 550/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5498 - loss_1: 0.0911 - root_mean_squared_error: 1.9361 - val_loss: 7.5142 - val_loss_1: 0.0909 - val_root_mean_squared_error: 1.8690\n",
      "Epoch 551/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.6547 - loss_1: 0.0906 - root_mean_squared_error: 1.9444 - val_loss: 7.5405 - val_loss_1: 0.0924 - val_root_mean_squared_error: 1.8995\n",
      "Epoch 552/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.6003 - loss_1: 0.0911 - root_mean_squared_error: 1.9301 - val_loss: 7.6290 - val_loss_1: 0.0901 - val_root_mean_squared_error: 1.9061\n",
      "Epoch 553/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5008 - loss_1: 0.0907 - root_mean_squared_error: 1.9320 - val_loss: 7.7166 - val_loss_1: 0.0918 - val_root_mean_squared_error: 1.9168\n",
      "Epoch 554/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.5175 - loss_1: 0.0909 - root_mean_squared_error: 1.9383 - val_loss: 7.4607 - val_loss_1: 0.0902 - val_root_mean_squared_error: 1.9191\n",
      "Epoch 555/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.4476 - loss_1: 0.0902 - root_mean_squared_error: 1.9180 - val_loss: 7.2290 - val_loss_1: 0.0915 - val_root_mean_squared_error: 1.8694\n",
      "Epoch 556/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5494 - loss_1: 0.0905 - root_mean_squared_error: 1.9358 - val_loss: 7.2106 - val_loss_1: 0.0898 - val_root_mean_squared_error: 1.8539\n",
      "Epoch 557/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4161 - loss_1: 0.0903 - root_mean_squared_error: 1.9201 - val_loss: 7.3545 - val_loss_1: 0.0916 - val_root_mean_squared_error: 1.8588\n",
      "Epoch 558/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.6094 - loss_1: 0.0918 - root_mean_squared_error: 1.9371 - val_loss: 7.7802 - val_loss_1: 0.0903 - val_root_mean_squared_error: 1.9317\n",
      "Epoch 559/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5305 - loss_1: 0.0898 - root_mean_squared_error: 1.9368 - val_loss: 7.9754 - val_loss_1: 0.0897 - val_root_mean_squared_error: 1.9212\n",
      "Epoch 560/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4529 - loss_1: 0.0905 - root_mean_squared_error: 1.9135 - val_loss: 7.7400 - val_loss_1: 0.0911 - val_root_mean_squared_error: 1.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.6438 - loss_1: 0.0908 - root_mean_squared_error: 1.9447 - val_loss: 7.6362 - val_loss_1: 0.0917 - val_root_mean_squared_error: 1.9072\n",
      "Epoch 562/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.3784 - loss_1: 0.0910 - root_mean_squared_error: 1.9262 - val_loss: 7.1415 - val_loss_1: 0.0894 - val_root_mean_squared_error: 1.8654\n",
      "Epoch 563/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4384 - loss_1: 0.0904 - root_mean_squared_error: 1.9095 - val_loss: 7.5170 - val_loss_1: 0.0913 - val_root_mean_squared_error: 1.8995\n",
      "Epoch 564/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.5244 - loss_1: 0.0901 - root_mean_squared_error: 1.9269 - val_loss: 7.2161 - val_loss_1: 0.0893 - val_root_mean_squared_error: 1.8826\n",
      "Epoch 565/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4594 - loss_1: 0.0898 - root_mean_squared_error: 1.9276 - val_loss: 7.3632 - val_loss_1: 0.0907 - val_root_mean_squared_error: 1.8870\n",
      "Epoch 566/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 7.6021 - loss_1: 0.0908 - root_mean_squared_error: 1.9479 - val_loss: 7.5108 - val_loss_1: 0.0906 - val_root_mean_squared_error: 1.9032\n",
      "Epoch 567/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.5104 - loss_1: 0.0901 - root_mean_squared_error: 1.9308 - val_loss: 7.2867 - val_loss_1: 0.0912 - val_root_mean_squared_error: 1.8567\n",
      "Epoch 568/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.4948 - loss_1: 0.0905 - root_mean_squared_error: 1.9224 - val_loss: 7.8022 - val_loss_1: 0.0903 - val_root_mean_squared_error: 1.8907\n",
      "Epoch 569/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5024 - loss_1: 0.0903 - root_mean_squared_error: 1.9189 - val_loss: 7.3411 - val_loss_1: 0.0885 - val_root_mean_squared_error: 1.8531\n",
      "Epoch 570/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.4482 - loss_1: 0.0887 - root_mean_squared_error: 1.9158 - val_loss: 7.4089 - val_loss_1: 0.0894 - val_root_mean_squared_error: 1.8596\n",
      "Epoch 571/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4500 - loss_1: 0.0896 - root_mean_squared_error: 1.9241 - val_loss: 7.8263 - val_loss_1: 0.0904 - val_root_mean_squared_error: 1.8938\n",
      "Epoch 572/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.4543 - loss_1: 0.0903 - root_mean_squared_error: 1.9105 - val_loss: 7.3590 - val_loss_1: 0.0892 - val_root_mean_squared_error: 1.8754\n",
      "Epoch 573/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.3826 - loss_1: 0.0899 - root_mean_squared_error: 1.9051 - val_loss: 7.4002 - val_loss_1: 0.0906 - val_root_mean_squared_error: 1.8850\n",
      "Epoch 574/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.3791 - loss_1: 0.0899 - root_mean_squared_error: 1.9178 - val_loss: 7.5219 - val_loss_1: 0.0898 - val_root_mean_squared_error: 1.9074\n",
      "Epoch 575/1000\n",
      "9600/9600 [==============================] - 1s 105us/step - loss: 7.4751 - loss_1: 0.0906 - root_mean_squared_error: 1.9192 - val_loss: 7.1423 - val_loss_1: 0.0913 - val_root_mean_squared_error: 1.8421\n",
      "Epoch 576/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.5414 - loss_1: 0.0898 - root_mean_squared_error: 1.9298 - val_loss: 7.3351 - val_loss_1: 0.0898 - val_root_mean_squared_error: 1.8849\n",
      "Epoch 577/1000\n",
      "9600/9600 [==============================] - 1s 104us/step - loss: 7.4958 - loss_1: 0.0902 - root_mean_squared_error: 1.9248 - val_loss: 7.7210 - val_loss_1: 0.0901 - val_root_mean_squared_error: 1.9460\n",
      "Epoch 578/1000\n",
      "9600/9600 [==============================] - 1s 107us/step - loss: 7.5267 - loss_1: 0.0893 - root_mean_squared_error: 1.9276 - val_loss: 7.3272 - val_loss_1: 0.0906 - val_root_mean_squared_error: 1.8789\n",
      "Epoch 579/1000\n",
      "9600/9600 [==============================] - 1s 107us/step - loss: 7.4732 - loss_1: 0.0898 - root_mean_squared_error: 1.9148 - val_loss: 7.6615 - val_loss_1: 0.0882 - val_root_mean_squared_error: 1.9119\n",
      "Epoch 580/1000\n",
      "9600/9600 [==============================] - 1s 107us/step - loss: 7.6334 - loss_1: 0.0885 - root_mean_squared_error: 1.9331 - val_loss: 7.2856 - val_loss_1: 0.0899 - val_root_mean_squared_error: 1.8734\n",
      "Epoch 581/1000\n",
      "9600/9600 [==============================] - 1s 101us/step - loss: 7.4041 - loss_1: 0.0900 - root_mean_squared_error: 1.9132 - val_loss: 7.9364 - val_loss_1: 0.0900 - val_root_mean_squared_error: 1.9659\n",
      "Epoch 582/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.5434 - loss_1: 0.0898 - root_mean_squared_error: 1.9347 - val_loss: 7.5442 - val_loss_1: 0.0896 - val_root_mean_squared_error: 1.9022\n",
      "Epoch 583/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.2639 - loss_1: 0.0886 - root_mean_squared_error: 1.9026 - val_loss: 7.2751 - val_loss_1: 0.0879 - val_root_mean_squared_error: 1.8658\n",
      "Epoch 584/1000\n",
      "9600/9600 [==============================] - 1s 105us/step - loss: 7.4273 - loss_1: 0.0894 - root_mean_squared_error: 1.9190 - val_loss: 7.2288 - val_loss_1: 0.0901 - val_root_mean_squared_error: 1.8641\n",
      "Epoch 585/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.3238 - loss_1: 0.0897 - root_mean_squared_error: 1.9115 - val_loss: 7.5945 - val_loss_1: 0.0895 - val_root_mean_squared_error: 1.8843\n",
      "Epoch 586/1000\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 7.4788 - loss_1: 0.0890 - root_mean_squared_error: 1.9318 - val_loss: 7.3802 - val_loss_1: 0.0888 - val_root_mean_squared_error: 1.8934\n",
      "Epoch 587/1000\n",
      "9600/9600 [==============================] - 1s 102us/step - loss: 7.4325 - loss_1: 0.0897 - root_mean_squared_error: 1.9062 - val_loss: 7.6139 - val_loss_1: 0.0903 - val_root_mean_squared_error: 1.8980\n",
      "Epoch 00587: early stopping\n",
      "1500/1500 [==============================] - 3s 2ms/step\n",
      "[7.882981836954753, 0.09017156809568405, 2.0440170764923096]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9980169606208802"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses=[]\n",
    "std_rmses=[]\n",
    "for ii in ([12000]):\n",
    "    test_rmse, history = pass_arg(50, ii, 0.1)\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    mean_rmses.append(mean_rmse)\n",
    "    std_rmses.append(std_rmse)\n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize dataset with MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import scipy.io as spio\n",
    "scaler = preprocessing.StandardScaler()\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = '../../data/'\n",
    "filename = 'mendota' + '.mat'\n",
    "mat = spio.loadmat(data_dir + filename, squeeze_me=True,\n",
    "variable_names=['Y','Xc_doy','Modeled_temp'])\n",
    "Xc = mat['Xc_doy']\n",
    "Y = mat['Y']\n",
    "\n",
    "        \n",
    "# Loading unsupervised data\n",
    "unsup_filename = 'mendota' + '_sampled.mat'\n",
    "unsup_mat = spio.loadmat(data_dir+unsup_filename, squeeze_me=True,\n",
    "variable_names=['Xc_doy1','Xc_doy2'])\n",
    "\n",
    "uX1 = unsup_mat['Xc_doy1'] # Xc at depth i for every pair of consecutive depth values\n",
    "uX2 = unsup_mat['Xc_doy2'] # Xc at depth i + 1 for every pair of consecutive depth values\n",
    "# uX1 = uX1[:40000,:]\n",
    "# uX2 = uX2[:40000,:]\n",
    "\n",
    "if 0 == 0:\n",
    "    # Removing the last column from uX (corresponding to Y_PHY)\n",
    "    uX1 = uX1[:,:-1]\n",
    "    uX2 = uX2[:,:-1]\n",
    "\n",
    "Xcs = scaler.fit_transform(Xc)\n",
    "uX11 = scaler.fit_transform(uX1)\n",
    "uX22 = scaler.fit_transform(uX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "genb=pd.DataFrame(scaler.fit_transform(np.random.uniform(0,1,(100,100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_in_column_Xc = np.max(Xc,axis=0)\n",
    "min_in_column_Xc = np.min(Xc,axis=0)\n",
    "asd=pd.DataFrame(np.random.uniform(0,1,(100,12))*(max_in_column_Xc-min_in_column_Xc) + min_in_column_Xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.382983\n",
       "1      2.571669\n",
       "2      1.850680\n",
       "3      1.552988\n",
       "4      1.979500\n",
       "5      1.947942\n",
       "6      3.657069\n",
       "7      2.034485\n",
       "8      3.894908\n",
       "9      6.689927\n",
       "10    23.546963\n",
       "11     2.902570\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -2.595319\n",
       "1    -1.959459\n",
       "2    -1.628505\n",
       "3    -2.368447\n",
       "4    -3.772943\n",
       "5    -4.637236\n",
       "6    -0.180324\n",
       "7    -3.666775\n",
       "8    -1.922708\n",
       "9    -0.305745\n",
       "10    0.176982\n",
       "11   -2.014623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.452313\n",
       "1      2.705936\n",
       "2      1.902933\n",
       "3      1.555987\n",
       "4      1.983242\n",
       "5      2.053915\n",
       "6      3.732374\n",
       "7      2.067658\n",
       "8      3.904492\n",
       "9      6.796041\n",
       "10    23.702346\n",
       "11     2.992860\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -2.599583\n",
       "1    -1.977433\n",
       "2    -1.633660\n",
       "3    -2.422871\n",
       "4    -3.797224\n",
       "5    -4.679816\n",
       "6    -0.267906\n",
       "7    -3.767017\n",
       "8    -1.946658\n",
       "9    -0.443125\n",
       "10   -0.097724\n",
       "11   -2.055992\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.595319</td>\n",
       "      <td>2.490163</td>\n",
       "      <td>-0.495785</td>\n",
       "      <td>-1.845365</td>\n",
       "      <td>1.658861</td>\n",
       "      <td>-1.538898</td>\n",
       "      <td>0.673073</td>\n",
       "      <td>-1.159785</td>\n",
       "      <td>-1.922708</td>\n",
       "      <td>3.632165</td>\n",
       "      <td>0.256699</td>\n",
       "      <td>-1.798057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.361988</td>\n",
       "      <td>-1.395345</td>\n",
       "      <td>0.855030</td>\n",
       "      <td>0.768461</td>\n",
       "      <td>-3.595006</td>\n",
       "      <td>-0.363725</td>\n",
       "      <td>2.195049</td>\n",
       "      <td>-2.530082</td>\n",
       "      <td>1.398101</td>\n",
       "      <td>5.618262</td>\n",
       "      <td>19.806999</td>\n",
       "      <td>1.881862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.542936</td>\n",
       "      <td>1.375275</td>\n",
       "      <td>-0.485648</td>\n",
       "      <td>-0.783981</td>\n",
       "      <td>-1.194112</td>\n",
       "      <td>-1.093703</td>\n",
       "      <td>3.232184</td>\n",
       "      <td>1.554529</td>\n",
       "      <td>2.822350</td>\n",
       "      <td>0.414012</td>\n",
       "      <td>6.641671</td>\n",
       "      <td>-0.139058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.325065</td>\n",
       "      <td>2.188083</td>\n",
       "      <td>-0.776960</td>\n",
       "      <td>0.729151</td>\n",
       "      <td>-3.094985</td>\n",
       "      <td>1.746585</td>\n",
       "      <td>1.608009</td>\n",
       "      <td>0.326520</td>\n",
       "      <td>0.447410</td>\n",
       "      <td>5.912117</td>\n",
       "      <td>16.201288</td>\n",
       "      <td>1.092997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.240157</td>\n",
       "      <td>2.567790</td>\n",
       "      <td>1.775089</td>\n",
       "      <td>-1.941235</td>\n",
       "      <td>0.155195</td>\n",
       "      <td>-4.390828</td>\n",
       "      <td>3.476064</td>\n",
       "      <td>-2.130897</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>1.536694</td>\n",
       "      <td>23.546963</td>\n",
       "      <td>-0.918070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.110447</td>\n",
       "      <td>-0.744382</td>\n",
       "      <td>1.426823</td>\n",
       "      <td>-0.277793</td>\n",
       "      <td>-1.405439</td>\n",
       "      <td>-0.354579</td>\n",
       "      <td>2.322633</td>\n",
       "      <td>1.066359</td>\n",
       "      <td>1.075761</td>\n",
       "      <td>3.686185</td>\n",
       "      <td>2.531620</td>\n",
       "      <td>2.902570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-2.021685</td>\n",
       "      <td>-0.939713</td>\n",
       "      <td>-0.479704</td>\n",
       "      <td>-1.521879</td>\n",
       "      <td>-1.476246</td>\n",
       "      <td>-3.654209</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>-1.625596</td>\n",
       "      <td>2.984203</td>\n",
       "      <td>5.577036</td>\n",
       "      <td>18.630975</td>\n",
       "      <td>-0.110815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.616647</td>\n",
       "      <td>-0.532543</td>\n",
       "      <td>-1.077482</td>\n",
       "      <td>0.659035</td>\n",
       "      <td>-2.685852</td>\n",
       "      <td>-2.768420</td>\n",
       "      <td>1.033667</td>\n",
       "      <td>-0.266177</td>\n",
       "      <td>2.941924</td>\n",
       "      <td>0.981523</td>\n",
       "      <td>17.964134</td>\n",
       "      <td>2.811943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.025190</td>\n",
       "      <td>-0.778952</td>\n",
       "      <td>-0.985119</td>\n",
       "      <td>-0.748396</td>\n",
       "      <td>-1.430662</td>\n",
       "      <td>1.780907</td>\n",
       "      <td>2.033628</td>\n",
       "      <td>-1.337718</td>\n",
       "      <td>0.066515</td>\n",
       "      <td>2.838620</td>\n",
       "      <td>5.056179</td>\n",
       "      <td>1.809698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.135265</td>\n",
       "      <td>0.911309</td>\n",
       "      <td>-0.318148</td>\n",
       "      <td>0.229111</td>\n",
       "      <td>-2.141239</td>\n",
       "      <td>-0.601600</td>\n",
       "      <td>3.193667</td>\n",
       "      <td>-1.204311</td>\n",
       "      <td>1.193903</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>2.438290</td>\n",
       "      <td>-0.652496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -2.595319  2.490163 -0.495785 -1.845365  1.658861 -1.538898  0.673073   \n",
       "1  -1.361988 -1.395345  0.855030  0.768461 -3.595006 -0.363725  2.195049   \n",
       "2  -1.542936  1.375275 -0.485648 -0.783981 -1.194112 -1.093703  3.232184   \n",
       "3   2.325065  2.188083 -0.776960  0.729151 -3.094985  1.746585  1.608009   \n",
       "4   2.240157  2.567790  1.775089 -1.941235  0.155195 -4.390828  3.476064   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  1.110447 -0.744382  1.426823 -0.277793 -1.405439 -0.354579  2.322633   \n",
       "96 -2.021685 -0.939713 -0.479704 -1.521879 -1.476246 -3.654209  0.006435   \n",
       "97 -0.616647 -0.532543 -1.077482  0.659035 -2.685852 -2.768420  1.033667   \n",
       "98  0.025190 -0.778952 -0.985119 -0.748396 -1.430662  1.780907  2.033628   \n",
       "99  0.135265  0.911309 -0.318148  0.229111 -2.141239 -0.601600  3.193667   \n",
       "\n",
       "           7         8         9         10        11  \n",
       "0  -1.159785 -1.922708  3.632165   0.256699 -1.798057  \n",
       "1  -2.530082  1.398101  5.618262  19.806999  1.881862  \n",
       "2   1.554529  2.822350  0.414012   6.641671 -0.139058  \n",
       "3   0.326520  0.447410  5.912117  16.201288  1.092997  \n",
       "4  -2.130897  0.855491  1.536694  23.546963 -0.918070  \n",
       "..       ...       ...       ...        ...       ...  \n",
       "95  1.066359  1.075761  3.686185   2.531620  2.902570  \n",
       "96 -1.625596  2.984203  5.577036  18.630975 -0.110815  \n",
       "97 -0.266177  2.941924  0.981523  17.964134  2.811943  \n",
       "98 -1.337718  0.066515  2.838620   5.056179  1.809698  \n",
       "99 -1.204311  1.193903  0.167445   2.438290 -0.652496  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.005032</td>\n",
       "      <td>0.483933</td>\n",
       "      <td>-1.633660</td>\n",
       "      <td>-0.402863</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445772</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.515147</td>\n",
       "      <td>0.964921</td>\n",
       "      <td>-0.333229</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.651967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.005032</td>\n",
       "      <td>0.483933</td>\n",
       "      <td>-0.931955</td>\n",
       "      <td>-0.402863</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445772</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.515147</td>\n",
       "      <td>0.964921</td>\n",
       "      <td>-0.333229</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.651967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.005032</td>\n",
       "      <td>0.483933</td>\n",
       "      <td>-0.230250</td>\n",
       "      <td>-0.402863</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445772</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.515147</td>\n",
       "      <td>0.964921</td>\n",
       "      <td>-0.333229</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.656723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.005032</td>\n",
       "      <td>0.483933</td>\n",
       "      <td>0.471455</td>\n",
       "      <td>-0.402863</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445772</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.515147</td>\n",
       "      <td>0.964921</td>\n",
       "      <td>-0.333229</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.666941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.005032</td>\n",
       "      <td>0.483933</td>\n",
       "      <td>1.173160</td>\n",
       "      <td>-0.402863</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445772</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.515147</td>\n",
       "      <td>0.964921</td>\n",
       "      <td>-0.333229</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.669756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13538</th>\n",
       "      <td>1.751902</td>\n",
       "      <td>2.705936</td>\n",
       "      <td>1.313501</td>\n",
       "      <td>-2.376567</td>\n",
       "      <td>-0.201790</td>\n",
       "      <td>-0.841133</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.567412</td>\n",
       "      <td>0.592054</td>\n",
       "      <td>1.003907</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.338104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>1.751902</td>\n",
       "      <td>2.705936</td>\n",
       "      <td>1.453842</td>\n",
       "      <td>-2.376567</td>\n",
       "      <td>-0.201790</td>\n",
       "      <td>-0.841133</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.567412</td>\n",
       "      <td>0.592054</td>\n",
       "      <td>1.003907</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.347063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13540</th>\n",
       "      <td>1.751902</td>\n",
       "      <td>2.705936</td>\n",
       "      <td>1.594183</td>\n",
       "      <td>-2.376567</td>\n",
       "      <td>-0.201790</td>\n",
       "      <td>-0.841133</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.567412</td>\n",
       "      <td>0.592054</td>\n",
       "      <td>1.003907</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.359658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13541</th>\n",
       "      <td>1.751902</td>\n",
       "      <td>2.705936</td>\n",
       "      <td>1.734524</td>\n",
       "      <td>-2.376567</td>\n",
       "      <td>-0.201790</td>\n",
       "      <td>-0.841133</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.567412</td>\n",
       "      <td>0.592054</td>\n",
       "      <td>1.003907</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.364733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13542</th>\n",
       "      <td>1.751902</td>\n",
       "      <td>2.705936</td>\n",
       "      <td>1.790660</td>\n",
       "      <td>-2.376567</td>\n",
       "      <td>-0.201790</td>\n",
       "      <td>-0.841133</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.567412</td>\n",
       "      <td>0.592054</td>\n",
       "      <td>1.003907</td>\n",
       "      <td>-0.097724</td>\n",
       "      <td>-0.364733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13543 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -1.005032  0.483933 -1.633660 -0.402863 -0.022585 -0.445772 -0.267906   \n",
       "1     -1.005032  0.483933 -0.931955 -0.402863 -0.022585 -0.445772 -0.267906   \n",
       "2     -1.005032  0.483933 -0.230250 -0.402863 -0.022585 -0.445772 -0.267906   \n",
       "3     -1.005032  0.483933  0.471455 -0.402863 -0.022585 -0.445772 -0.267906   \n",
       "4     -1.005032  0.483933  1.173160 -0.402863 -0.022585 -0.445772 -0.267906   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13538  1.751902  2.705936  1.313501 -2.376567 -0.201790 -0.841133 -0.267906   \n",
       "13539  1.751902  2.705936  1.453842 -2.376567 -0.201790 -0.841133 -0.267906   \n",
       "13540  1.751902  2.705936  1.594183 -2.376567 -0.201790 -0.841133 -0.267906   \n",
       "13541  1.751902  2.705936  1.734524 -2.376567 -0.201790 -0.841133 -0.267906   \n",
       "13542  1.751902  2.705936  1.790660 -2.376567 -0.201790 -0.841133 -0.267906   \n",
       "\n",
       "              7         8         9        10        11  \n",
       "0     -0.515147  0.964921 -0.333229 -0.097724 -0.651967  \n",
       "1     -0.515147  0.964921 -0.333229 -0.097724 -0.651967  \n",
       "2     -0.515147  0.964921 -0.333229 -0.097724 -0.656723  \n",
       "3     -0.515147  0.964921 -0.333229 -0.097724 -0.666941  \n",
       "4     -0.515147  0.964921 -0.333229 -0.097724 -0.669756  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "13538  1.567412  0.592054  1.003907 -0.097724 -0.338104  \n",
       "13539  1.567412  0.592054  1.003907 -0.097724 -0.347063  \n",
       "13540  1.567412  0.592054  1.003907 -0.097724 -0.359658  \n",
       "13541  1.567412  0.592054  1.003907 -0.097724 -0.364733  \n",
       "13542  1.567412  0.592054  1.003907 -0.097724 -0.364733  \n",
       "\n",
       "[13543 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.DataFrame(Xc)\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.005069</td>\n",
       "      <td>0.483950</td>\n",
       "      <td>-1.633721</td>\n",
       "      <td>-0.402878</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445788</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>-0.515166</td>\n",
       "      <td>0.964957</td>\n",
       "      <td>-0.333241</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.651991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.005069</td>\n",
       "      <td>0.483950</td>\n",
       "      <td>-0.931990</td>\n",
       "      <td>-0.402878</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445788</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>-0.515166</td>\n",
       "      <td>0.964957</td>\n",
       "      <td>-0.333241</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.651991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.005069</td>\n",
       "      <td>0.483950</td>\n",
       "      <td>-0.230259</td>\n",
       "      <td>-0.402878</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445788</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>-0.515166</td>\n",
       "      <td>0.964957</td>\n",
       "      <td>-0.333241</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.656747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.005069</td>\n",
       "      <td>0.483950</td>\n",
       "      <td>0.471472</td>\n",
       "      <td>-0.402878</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445788</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>-0.515166</td>\n",
       "      <td>0.964957</td>\n",
       "      <td>-0.333241</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.666965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.005069</td>\n",
       "      <td>0.483950</td>\n",
       "      <td>1.173203</td>\n",
       "      <td>-0.402878</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.445788</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>-0.515166</td>\n",
       "      <td>0.964957</td>\n",
       "      <td>-0.333241</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.669781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13538</th>\n",
       "      <td>1.751967</td>\n",
       "      <td>2.706036</td>\n",
       "      <td>1.313549</td>\n",
       "      <td>-2.376655</td>\n",
       "      <td>-0.201797</td>\n",
       "      <td>-0.841164</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>1.567470</td>\n",
       "      <td>0.592076</td>\n",
       "      <td>1.003945</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.338116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>1.751967</td>\n",
       "      <td>2.706036</td>\n",
       "      <td>1.453896</td>\n",
       "      <td>-2.376655</td>\n",
       "      <td>-0.201797</td>\n",
       "      <td>-0.841164</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>1.567470</td>\n",
       "      <td>0.592076</td>\n",
       "      <td>1.003945</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.347075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13540</th>\n",
       "      <td>1.751967</td>\n",
       "      <td>2.706036</td>\n",
       "      <td>1.594242</td>\n",
       "      <td>-2.376655</td>\n",
       "      <td>-0.201797</td>\n",
       "      <td>-0.841164</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>1.567470</td>\n",
       "      <td>0.592076</td>\n",
       "      <td>1.003945</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.359671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13541</th>\n",
       "      <td>1.751967</td>\n",
       "      <td>2.706036</td>\n",
       "      <td>1.734588</td>\n",
       "      <td>-2.376655</td>\n",
       "      <td>-0.201797</td>\n",
       "      <td>-0.841164</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>1.567470</td>\n",
       "      <td>0.592076</td>\n",
       "      <td>1.003945</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.364746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13542</th>\n",
       "      <td>1.751967</td>\n",
       "      <td>2.706036</td>\n",
       "      <td>1.790726</td>\n",
       "      <td>-2.376655</td>\n",
       "      <td>-0.201797</td>\n",
       "      <td>-0.841164</td>\n",
       "      <td>-0.267916</td>\n",
       "      <td>1.567470</td>\n",
       "      <td>0.592076</td>\n",
       "      <td>1.003945</td>\n",
       "      <td>-0.097727</td>\n",
       "      <td>-0.364746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13543 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -1.005069  0.483950 -1.633721 -0.402878 -0.022585 -0.445788 -0.267916   \n",
       "1     -1.005069  0.483950 -0.931990 -0.402878 -0.022585 -0.445788 -0.267916   \n",
       "2     -1.005069  0.483950 -0.230259 -0.402878 -0.022585 -0.445788 -0.267916   \n",
       "3     -1.005069  0.483950  0.471472 -0.402878 -0.022585 -0.445788 -0.267916   \n",
       "4     -1.005069  0.483950  1.173203 -0.402878 -0.022585 -0.445788 -0.267916   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13538  1.751967  2.706036  1.313549 -2.376655 -0.201797 -0.841164 -0.267916   \n",
       "13539  1.751967  2.706036  1.453896 -2.376655 -0.201797 -0.841164 -0.267916   \n",
       "13540  1.751967  2.706036  1.594242 -2.376655 -0.201797 -0.841164 -0.267916   \n",
       "13541  1.751967  2.706036  1.734588 -2.376655 -0.201797 -0.841164 -0.267916   \n",
       "13542  1.751967  2.706036  1.790726 -2.376655 -0.201797 -0.841164 -0.267916   \n",
       "\n",
       "              7         8         9        10        11  \n",
       "0     -0.515166  0.964957 -0.333241 -0.097727 -0.651991  \n",
       "1     -0.515166  0.964957 -0.333241 -0.097727 -0.651991  \n",
       "2     -0.515166  0.964957 -0.333241 -0.097727 -0.656747  \n",
       "3     -0.515166  0.964957 -0.333241 -0.097727 -0.666965  \n",
       "4     -0.515166  0.964957 -0.333241 -0.097727 -0.669781  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "13538  1.567470  0.592076  1.003945 -0.097727 -0.338116  \n",
       "13539  1.567470  0.592076  1.003945 -0.097727 -0.347075  \n",
       "13540  1.567470  0.592076  1.003945 -0.097727 -0.359671  \n",
       "13541  1.567470  0.592076  1.003945 -0.097727 -0.364746  \n",
       "13542  1.567470  0.592076  1.003945 -0.097727 -0.364746  \n",
       "\n",
       "[13543 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff2 = pd.DataFrame(Xcs)\n",
    "dff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.633660</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.563490</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.493319</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.423149</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.352978</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649718</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>1.524012</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649719</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>1.594183</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649720</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>1.664353</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649721</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>1.734524</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649722</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>1.804694</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649723 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -1.422298 -1.168365 -1.633660  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "1      -1.422298 -1.168365 -1.563490  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "2      -1.422298 -1.168365 -1.493319  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "3      -1.422298 -1.168365 -1.423149  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "4      -1.422298 -1.168365 -1.352978  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "649718 -2.793314 -6.487178  1.524012 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "649719 -2.793314 -6.487178  1.594183 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "649720 -2.793314 -6.487178  1.664353 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "649721 -2.793314 -6.487178  1.734524 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "649722 -2.793314 -6.487178  1.804694 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "\n",
       "               7         8         9        10  \n",
       "0      -1.085630  0.606806 -0.430212 -0.097724  \n",
       "1      -1.085630  0.606806 -0.430212 -0.097724  \n",
       "2      -1.085630  0.606806 -0.430212 -0.097724  \n",
       "3      -1.085630  0.606806 -0.430212 -0.097724  \n",
       "4      -1.085630  0.606806 -0.430212 -0.097724  \n",
       "...          ...       ...       ...       ...  \n",
       "649718  2.092482 -1.018537 -0.443125 -0.097724  \n",
       "649719  2.092482 -1.018537 -0.443125 -0.097724  \n",
       "649720  2.092482 -1.018537 -0.443125 -0.097724  \n",
       "649721  2.092482 -1.018537 -0.443125 -0.097724  \n",
       "649722  2.092482 -1.018537 -0.443125 -0.097724  \n",
       "\n",
       "[649723 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfff2 = pd.DataFrame(uX1)\n",
    "dfff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.646043\n",
       "1      -1.168365\n",
       "2       1.804694\n",
       "3       1.647084\n",
       "4       2.247056\n",
       "5       2.247018\n",
       "6       3.732374\n",
       "7       2.573417\n",
       "8       4.460306\n",
       "9      14.318928\n",
       "10    199.502851\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dfff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -2.793314\n",
       "1    -6.487178\n",
       "2    -1.633660\n",
       "3    -2.747030\n",
       "4    -4.217377\n",
       "5    -5.239464\n",
       "6    -0.267906\n",
       "7    -4.810238\n",
       "8    -2.268161\n",
       "9    -0.443125\n",
       "10   -0.097724\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dfff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.697334</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.627715</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.558096</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.488476</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.418857</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649718</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.435536</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649719</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.505155</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649720</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.574775</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649721</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.644394</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649722</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.714013</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649723 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1         2         3         4         5         6  \\\n",
       "0      -0.871578   3.440158 -1.697334  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "1      -0.871578   3.440158 -1.627715  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "2      -0.871578   3.440158 -1.558096  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "3      -0.871578   3.440158 -1.488476  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "4      -0.871578   3.440158 -1.418857  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "649718 -1.747829 -10.790532  1.435536 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649719 -1.747829 -10.790532  1.505155 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649720 -1.747829 -10.790532  1.574775 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649721 -1.747829 -10.790532  1.644394 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649722 -1.747829 -10.790532  1.714013 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "\n",
       "               7         8         9        10  \n",
       "0      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "1      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "2      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "3      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "4      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "...          ...       ...       ...       ...  \n",
       "649718  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649719  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649720  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649721  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649722  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "\n",
       "[649723 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfff2 = pd.DataFrame(uX11)\n",
    "dfff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.697334</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.627715</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.558096</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.488476</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.871578</td>\n",
       "      <td>3.440158</td>\n",
       "      <td>-1.418857</td>\n",
       "      <td>0.845762</td>\n",
       "      <td>-0.526656</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>-0.629909</td>\n",
       "      <td>-1.039069</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>-0.343343</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649718</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.435536</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649719</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.505155</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649720</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.574775</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649721</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.644394</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649722</th>\n",
       "      <td>-1.747829</td>\n",
       "      <td>-10.790532</td>\n",
       "      <td>1.714013</td>\n",
       "      <td>-2.036474</td>\n",
       "      <td>-0.262260</td>\n",
       "      <td>-0.957121</td>\n",
       "      <td>1.587531</td>\n",
       "      <td>1.629183</td>\n",
       "      <td>-1.137184</td>\n",
       "      <td>-0.359058</td>\n",
       "      <td>-0.168382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649723 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1         2         3         4         5         6  \\\n",
       "0      -0.871578   3.440158 -1.697334  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "1      -0.871578   3.440158 -1.627715  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "2      -0.871578   3.440158 -1.558096  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "3      -0.871578   3.440158 -1.488476  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "4      -0.871578   3.440158 -1.418857  0.845762 -0.526656 -0.388357 -0.629909   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "649718 -1.747829 -10.790532  1.435536 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649719 -1.747829 -10.790532  1.505155 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649720 -1.747829 -10.790532  1.574775 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649721 -1.747829 -10.790532  1.644394 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "649722 -1.747829 -10.790532  1.714013 -2.036474 -0.262260 -0.957121  1.587531   \n",
       "\n",
       "               7         8         9        10  \n",
       "0      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "1      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "2      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "3      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "4      -1.039069  0.539348 -0.343343 -0.168382  \n",
       "...          ...       ...       ...       ...  \n",
       "649718  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649719  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649720  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649721  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "649722  1.629183 -1.137184 -0.359058 -0.168382  \n",
       "\n",
       "[649723 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfff2 = pd.DataFrame(uX22)\n",
    "dfff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.633660</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.407395</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.563490</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>-1.735839</td>\n",
       "      <td>-1.242555</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.258821</td>\n",
       "      <td>-0.598777</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.392493</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.493319</td>\n",
       "      <td>0.300787</td>\n",
       "      <td>-0.787525</td>\n",
       "      <td>-0.913333</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.239056</td>\n",
       "      <td>-0.500905</td>\n",
       "      <td>-0.288125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.377591</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.423149</td>\n",
       "      <td>-1.357741</td>\n",
       "      <td>-0.579140</td>\n",
       "      <td>-1.161290</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.870932</td>\n",
       "      <td>0.697632</td>\n",
       "      <td>1.138781</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.362688</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.352978</td>\n",
       "      <td>-0.225113</td>\n",
       "      <td>-0.914887</td>\n",
       "      <td>-1.259344</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.546666</td>\n",
       "      <td>1.221574</td>\n",
       "      <td>-0.333985</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12735</th>\n",
       "      <td>2.586434</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>-0.791614</td>\n",
       "      <td>-2.229446</td>\n",
       "      <td>-1.080380</td>\n",
       "      <td>-1.631719</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.011055</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>-0.142539</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12736</th>\n",
       "      <td>2.601336</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>-0.721444</td>\n",
       "      <td>-1.706303</td>\n",
       "      <td>-1.434994</td>\n",
       "      <td>-1.592682</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.153522</td>\n",
       "      <td>1.207722</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12737</th>\n",
       "      <td>2.616238</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>-0.651273</td>\n",
       "      <td>-2.292746</td>\n",
       "      <td>-1.607716</td>\n",
       "      <td>-1.981337</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>2.784608</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>99.769617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12738</th>\n",
       "      <td>2.631141</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>-0.581103</td>\n",
       "      <td>-2.208536</td>\n",
       "      <td>-0.863699</td>\n",
       "      <td>-1.951551</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>1.784827</td>\n",
       "      <td>1.718058</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>40.112582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12739</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12740 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -1.422298 -1.168365 -1.633660  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "1     -1.407395 -1.168365 -1.563490  0.010444 -1.735839 -1.242555 -0.267906   \n",
       "2     -1.392493 -1.168365 -1.493319  0.300787 -0.787525 -0.913333 -0.267906   \n",
       "3     -1.377591 -1.168365 -1.423149 -1.357741 -0.579140 -1.161290 -0.267906   \n",
       "4     -1.362688 -1.168365 -1.352978 -0.225113 -0.914887 -1.259344 -0.267906   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12735  2.586434 -2.150821 -0.791614 -2.229446 -1.080380 -1.631719 -0.267906   \n",
       "12736  2.601336 -2.150821 -0.721444 -1.706303 -1.434994 -1.592682 -0.267906   \n",
       "12737  2.616238 -2.150821 -0.651273 -2.292746 -1.607716 -1.981337  3.732374   \n",
       "12738  2.631141 -2.150821 -0.581103 -2.208536 -0.863699 -1.951551  3.732374   \n",
       "12739 -2.793314 -6.487178 -0.510932 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "\n",
       "              7         8         9         10  \n",
       "0     -1.085630  0.606806 -0.430212  -0.097724  \n",
       "1     -1.258821 -0.598777 -0.443125  -0.097724  \n",
       "2     -0.239056 -0.500905 -0.288125  -0.097724  \n",
       "3      0.870932  0.697632  1.138781  -0.097724  \n",
       "4      0.546666  1.221574 -0.333985  -0.097724  \n",
       "...         ...       ...       ...        ...  \n",
       "12735  1.011055  0.998416 -0.142539  -0.097724  \n",
       "12736  1.153522  1.207722 -0.443125  -0.097724  \n",
       "12737  0.763889  2.784608 -0.443125  99.769617  \n",
       "12738  1.784827  1.718058 -0.443125  40.112582  \n",
       "12739  2.092482 -1.018537 -0.443125  -0.097724  \n",
       "\n",
       "[12740 rows x 11 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uX1.shape\n",
    "aa = uX1[range(0,649723,51),:]\n",
    "aaa=pd.DataFrame(aa)\n",
    "aaa\n",
    "\n",
    "\n",
    "# # uX1.shape\n",
    "# aa = uX1[range(0,286738,25),:]\n",
    "# aaa=pd.DataFrame(aa)\n",
    "# aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.633660</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>0.962648</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.407395</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>0.050432</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>-1.735839</td>\n",
       "      <td>-1.242555</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.258821</td>\n",
       "      <td>-0.598777</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.392493</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-0.861785</td>\n",
       "      <td>0.300787</td>\n",
       "      <td>-0.787525</td>\n",
       "      <td>-0.913333</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.239056</td>\n",
       "      <td>-0.500905</td>\n",
       "      <td>-0.288125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.392493</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>1.734524</td>\n",
       "      <td>0.300787</td>\n",
       "      <td>-0.787525</td>\n",
       "      <td>-0.913333</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.239056</td>\n",
       "      <td>-0.500905</td>\n",
       "      <td>-0.288125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17556</th>\n",
       "      <td>2.601336</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>1.804694</td>\n",
       "      <td>-1.706303</td>\n",
       "      <td>-1.434994</td>\n",
       "      <td>-1.592682</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.153522</td>\n",
       "      <td>1.207722</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17557</th>\n",
       "      <td>2.616238</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>0.892478</td>\n",
       "      <td>-2.292746</td>\n",
       "      <td>-1.607716</td>\n",
       "      <td>-1.981337</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>2.784608</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>99.769617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>2.631141</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>-0.019739</td>\n",
       "      <td>-2.208536</td>\n",
       "      <td>-0.863699</td>\n",
       "      <td>-1.951551</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>1.784827</td>\n",
       "      <td>1.718058</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>40.112582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>-0.931955</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17560</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>1.664353</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17561 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -1.422298 -1.168365 -1.633660  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "1     -1.422298 -1.168365  0.962648  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "2     -1.407395 -1.168365  0.050432  0.010444 -1.735839 -1.242555 -0.267906   \n",
       "3     -1.392493 -1.168365 -0.861785  0.300787 -0.787525 -0.913333 -0.267906   \n",
       "4     -1.392493 -1.168365  1.734524  0.300787 -0.787525 -0.913333 -0.267906   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "17556  2.601336 -2.150821  1.804694 -1.706303 -1.434994 -1.592682 -0.267906   \n",
       "17557  2.616238 -2.150821  0.892478 -2.292746 -1.607716 -1.981337  3.732374   \n",
       "17558  2.631141 -2.150821 -0.019739 -2.208536 -0.863699 -1.951551  3.732374   \n",
       "17559 -2.793314 -6.487178 -0.931955 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "17560 -2.793314 -6.487178  1.664353 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "\n",
       "              7         8         9         10  \n",
       "0     -1.085630  0.606806 -0.430212  -0.097724  \n",
       "1     -1.085630  0.606806 -0.430212  -0.097724  \n",
       "2     -1.258821 -0.598777 -0.443125  -0.097724  \n",
       "3     -0.239056 -0.500905 -0.288125  -0.097724  \n",
       "4     -0.239056 -0.500905 -0.288125  -0.097724  \n",
       "...         ...       ...       ...        ...  \n",
       "17556  1.153522  1.207722 -0.443125  -0.097724  \n",
       "17557  0.763889  2.784608 -0.443125  99.769617  \n",
       "17558  1.784827  1.718058 -0.443125  40.112582  \n",
       "17559  2.092482 -1.018537 -0.443125  -0.097724  \n",
       "17560  2.092482 -1.018537 -0.443125  -0.097724  \n",
       "\n",
       "[17561 rows x 11 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uX1.shape\n",
    "aa = uX1[range(0,649723,37),:]\n",
    "aaa=pd.DataFrame(aa)\n",
    "aaa\n",
    "\n",
    "\n",
    "# # uX1.shape\n",
    "# aa = uX1[range(0,286738,25),:]\n",
    "# aaa=pd.DataFrame(aa)\n",
    "# aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.563490</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>-1.330248</td>\n",
       "      <td>-1.278122</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-1.085630</td>\n",
       "      <td>0.606806</td>\n",
       "      <td>-0.430212</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.392493</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.563490</td>\n",
       "      <td>0.300787</td>\n",
       "      <td>-0.787525</td>\n",
       "      <td>-0.913333</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.239056</td>\n",
       "      <td>-0.500905</td>\n",
       "      <td>-0.288125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.362688</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.563490</td>\n",
       "      <td>-0.225113</td>\n",
       "      <td>-0.914887</td>\n",
       "      <td>-1.259344</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.546666</td>\n",
       "      <td>1.221574</td>\n",
       "      <td>-0.333985</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.332884</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.563490</td>\n",
       "      <td>-1.413953</td>\n",
       "      <td>-0.102336</td>\n",
       "      <td>-0.711767</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>-0.136157</td>\n",
       "      <td>0.398808</td>\n",
       "      <td>-0.195120</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.303079</td>\n",
       "      <td>-1.168365</td>\n",
       "      <td>-1.563490</td>\n",
       "      <td>-1.633378</td>\n",
       "      <td>-0.291926</td>\n",
       "      <td>-0.745022</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.224254</td>\n",
       "      <td>-0.800594</td>\n",
       "      <td>2.007367</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>2.526824</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>0.331114</td>\n",
       "      <td>-1.747946</td>\n",
       "      <td>-1.279327</td>\n",
       "      <td>-1.408322</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.551718</td>\n",
       "      <td>-0.915049</td>\n",
       "      <td>-0.409609</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>2.556629</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>0.331114</td>\n",
       "      <td>-2.100857</td>\n",
       "      <td>-1.530174</td>\n",
       "      <td>-1.364845</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>0.262921</td>\n",
       "      <td>1.825708</td>\n",
       "      <td>-0.225375</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>2.586434</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>0.331114</td>\n",
       "      <td>-2.229446</td>\n",
       "      <td>-1.080380</td>\n",
       "      <td>-1.631719</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>1.011055</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>-0.142539</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>2.616238</td>\n",
       "      <td>-2.150821</td>\n",
       "      <td>0.331114</td>\n",
       "      <td>-2.292746</td>\n",
       "      <td>-1.607716</td>\n",
       "      <td>-1.981337</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>2.784608</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>99.769617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>-2.793314</td>\n",
       "      <td>-6.487178</td>\n",
       "      <td>0.331114</td>\n",
       "      <td>-2.747030</td>\n",
       "      <td>-1.010196</td>\n",
       "      <td>-2.028422</td>\n",
       "      <td>3.732374</td>\n",
       "      <td>2.092482</td>\n",
       "      <td>-1.018537</td>\n",
       "      <td>-0.443125</td>\n",
       "      <td>-0.097724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6498 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -1.422298 -1.168365 -1.563490  0.340643 -1.330248 -1.278122 -0.267906   \n",
       "1    -1.392493 -1.168365 -1.563490  0.300787 -0.787525 -0.913333 -0.267906   \n",
       "2    -1.362688 -1.168365 -1.563490 -0.225113 -0.914887 -1.259344 -0.267906   \n",
       "3    -1.332884 -1.168365 -1.563490 -1.413953 -0.102336 -0.711767 -0.267906   \n",
       "4    -1.303079 -1.168365 -1.563490 -1.633378 -0.291926 -0.745022 -0.267906   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6493  2.526824 -2.150821  0.331114 -1.747946 -1.279327 -1.408322 -0.267906   \n",
       "6494  2.556629 -2.150821  0.331114 -2.100857 -1.530174 -1.364845 -0.267906   \n",
       "6495  2.586434 -2.150821  0.331114 -2.229446 -1.080380 -1.631719 -0.267906   \n",
       "6496  2.616238 -2.150821  0.331114 -2.292746 -1.607716 -1.981337  3.732374   \n",
       "6497 -2.793314 -6.487178  0.331114 -2.747030 -1.010196 -2.028422  3.732374   \n",
       "\n",
       "             7         8         9         10  \n",
       "0    -1.085630  0.606806 -0.430212  -0.097724  \n",
       "1    -0.239056 -0.500905 -0.288125  -0.097724  \n",
       "2     0.546666  1.221574 -0.333985  -0.097724  \n",
       "3    -0.136157  0.398808 -0.195120  -0.097724  \n",
       "4     1.224254 -0.800594  2.007367  -0.097724  \n",
       "...        ...       ...       ...        ...  \n",
       "6493  1.551718 -0.915049 -0.409609  -0.097724  \n",
       "6494  0.262921  1.825708 -0.225375  -0.097724  \n",
       "6495  1.011055  0.998416 -0.142539  -0.097724  \n",
       "6496  0.763889  2.784608 -0.443125  99.769617  \n",
       "6497  2.092482 -1.018537 -0.443125  -0.097724  \n",
       "\n",
       "[6498 rows x 11 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uX1.shape\n",
    "aa2 = uX2[range(0,649723,100),:]\n",
    "aaa2=pd.DataFrame(aa2)\n",
    "aaa2\n",
    "\n",
    "# # uX1.shape\n",
    "# aa2 = uX2[range(0,286738,51),:]\n",
    "# aaa2=pd.DataFrame(aa2)\n",
    "# aaa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(uX1)[:,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.79331375, -2.7784114 , -2.76350905, -2.74860671, -2.73370436,\n",
       "       -2.71880201, -2.70389966, -2.68899732, -2.67409497, -2.65919262,\n",
       "       -2.64429027, -2.62938792, -2.61448558, -2.59958323, -2.58468088,\n",
       "       -2.56977853, -2.55487619, -2.53997384, -2.52507149, -2.51016914,\n",
       "       -2.49526679, -2.48036445, -2.4654621 , -2.45055975, -2.4356574 ,\n",
       "       -2.42075506, -2.40585271, -2.39095036, -2.37604801, -2.36114567,\n",
       "       -2.34624332, -2.33134097, -2.31643862, -2.30153627, -2.28663393,\n",
       "       -2.27173158, -2.25682923, -2.24192688, -2.22702454, -2.21212219,\n",
       "       -2.19721984, -2.18231749, -2.16741515, -2.1525128 , -2.13761045,\n",
       "       -2.1227081 , -2.10780575, -2.09290341, -2.07800106, -2.06309871,\n",
       "       -2.04819636, -2.03329402, -2.01839167, -2.00348932, -1.98858697,\n",
       "       -1.97368462, -1.95878228, -1.94387993, -1.92897758, -1.91407523,\n",
       "       -1.89917289, -1.88427054, -1.86936819, -1.85446584, -1.8395635 ,\n",
       "       -1.82466115, -1.8097588 , -1.79485645, -1.7799541 , -1.76505176,\n",
       "       -1.75014941, -1.73524706, -1.72034471, -1.70544237, -1.69054002,\n",
       "       -1.67563767, -1.66073532, -1.64583298, -1.63093063, -1.61602828,\n",
       "       -1.60112593, -1.58622358, -1.57132124, -1.55641889, -1.54151654,\n",
       "       -1.52661419, -1.51171185, -1.4968095 , -1.48190715, -1.4670048 ,\n",
       "       -1.45210246, -1.43720011, -1.42229776, -1.40739541, -1.39249306,\n",
       "       -1.37759072, -1.36268837, -1.34778602, -1.33288367, -1.31798133,\n",
       "       -1.30307898, -1.28817663, -1.27327428, -1.25837193, -1.24346959,\n",
       "       -1.22856724, -1.21366489, -1.19876254, -1.1838602 , -1.16895785,\n",
       "       -1.1540555 , -1.13915315, -1.12425081, -1.10934846, -1.09444611,\n",
       "       -1.07954376, -1.06464141, -1.04973907, -1.03483672, -1.01993437,\n",
       "       -1.00503202, -0.99012968, -0.97522733, -0.96032498, -0.94542263,\n",
       "       -0.93052029, -0.91561794, -0.90071559, -0.88581324, -0.87091089,\n",
       "       -0.85600855, -0.8411062 , -0.82620385, -0.8113015 , -0.79639916,\n",
       "       -0.78149681, -0.76659446, -0.75169211, -0.73678976, -0.72188742,\n",
       "       -0.70698507, -0.69208272, -0.67718037, -0.66227803, -0.64737568,\n",
       "       -0.63247333, -0.61757098, -0.60266864, -0.58776629, -0.57286394,\n",
       "       -0.55796159, -0.54305924, -0.5281569 , -0.51325455, -0.4983522 ,\n",
       "       -0.48344985, -0.46854751, -0.45364516, -0.43874281, -0.42384046,\n",
       "       -0.40893812, -0.39403577, -0.37913342, -0.36423107, -0.34932872,\n",
       "       -0.33442638, -0.31952403, -0.30462168, -0.28971933, -0.27481699,\n",
       "       -0.25991464, -0.24501229, -0.23010994, -0.21520759, -0.20030525,\n",
       "       -0.1854029 , -0.17050055, -0.1555982 , -0.14069586, -0.12579351,\n",
       "       -0.11089116, -0.09598881, -0.08108647, -0.06618412, -0.05128177,\n",
       "       -0.03637942, -0.02147707, -0.00657473,  0.00832762,  0.02322997,\n",
       "        0.03813232,  0.05303466,  0.06793701,  0.08283936,  0.09774171,\n",
       "        0.11264405,  0.1275464 ,  0.14244875,  0.1573511 ,  0.17225345,\n",
       "        0.18715579,  0.20205814,  0.21696049,  0.23186284,  0.24676518,\n",
       "        0.26166753,  0.27656988,  0.29147223,  0.30637457,  0.32127692,\n",
       "        0.33617927,  0.35108162,  0.36598397,  0.38088631,  0.39578866,\n",
       "        0.41069101,  0.42559336,  0.4404957 ,  0.45539805,  0.4703004 ,\n",
       "        0.48520275,  0.5001051 ,  0.51500744,  0.52990979,  0.54481214,\n",
       "        0.55971449,  0.57461683,  0.58951918,  0.60442153,  0.61932388,\n",
       "        0.63422622,  0.64912857,  0.66403092,  0.67893327,  0.69383562,\n",
       "        0.70873796,  0.72364031,  0.73854266,  0.75344501,  0.76834735,\n",
       "        0.7832497 ,  0.79815205,  0.8130544 ,  0.82795674,  0.84285909,\n",
       "        0.85776144,  0.87266379,  0.88756614,  0.90246848,  0.91737083,\n",
       "        0.93227318,  0.94717553,  0.96207787,  0.97698022,  0.99188257,\n",
       "        1.00678492,  1.02168727,  1.03658961,  1.05149196,  1.06639431,\n",
       "        1.08129666,  1.096199  ,  1.11110135,  1.1260037 ,  1.14090605,\n",
       "        1.15580839,  1.17071074,  1.18561309,  1.20051544,  1.21541779,\n",
       "        1.23032013,  1.24522248,  1.26012483,  1.27502718,  1.28992952,\n",
       "        1.30483187,  1.31973422,  1.33463657,  1.34953891,  1.36444126,\n",
       "        1.37934361,  1.39424596,  1.40914831,  1.42405065,  1.438953  ,\n",
       "        1.45385535,  1.4687577 ,  1.48366004,  1.49856239,  1.51346474,\n",
       "        1.52836709,  1.54326944,  1.55817178,  1.57307413,  1.58797648,\n",
       "        1.60287883,  1.61778117,  1.63268352,  1.64758587,  1.66248822,\n",
       "        1.67739056,  1.69229291,  1.70719526,  1.72209761,  1.73699996,\n",
       "        1.7519023 ,  1.76680465,  1.781707  ,  1.79660935,  1.81151169,\n",
       "        1.82641404,  1.84131639,  1.85621874,  1.87112108,  1.88602343,\n",
       "        1.90092578,  1.91582813,  1.93073048,  1.94563282,  1.96053517,\n",
       "        1.97543752,  1.99033987,  2.00524221,  2.02014456,  2.03504691,\n",
       "        2.04994926,  2.06485161,  2.07975395,  2.0946563 ,  2.10955865,\n",
       "        2.124461  ,  2.13936334,  2.15426569,  2.16916804,  2.18407039,\n",
       "        2.19897273,  2.21387508,  2.22877743,  2.24367978,  2.25858213,\n",
       "        2.27348447,  2.28838682,  2.30328917,  2.31819152,  2.33309386,\n",
       "        2.34799621,  2.36289856,  2.37780091,  2.39270325,  2.4076056 ,\n",
       "        2.42250795,  2.4374103 ,  2.45231265,  2.46721499,  2.48211734,\n",
       "        2.49701969,  2.51192204,  2.52682438,  2.54172673,  2.55662908,\n",
       "        2.57153143,  2.58643377,  2.60133612,  2.61623847,  2.63114082,\n",
       "        2.64604317])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(uX1)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.39357137, -1.13044031, -0.86730925, -0.60417819, -0.34104712,\n",
       "       -0.07791606,  0.185215  ,  0.44834606,  0.71147713,  0.97460819,\n",
       "        1.23773925,  1.50087032,  1.76400138,  2.02713244,  2.2902635 ,\n",
       "        2.55339457,  2.81652563,  3.07965669,  3.34278775,  3.60591882,\n",
       "        3.86904988,  4.13218094,  4.395312  ,  4.65844307])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(aaa)[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.56348975, -1.49331924, -1.42314874, -1.35297824, -1.28280773,\n",
       "       -1.21263723, -1.14246672, -1.07229622, -1.00212572, -0.93195521,\n",
       "       -0.86178471, -0.7916142 , -0.7214437 , -0.65127319, -0.58110269,\n",
       "       -0.51093219, -0.44076168, -0.37059118, -0.30042067, -0.23025017,\n",
       "       -0.16007967, -0.08990916, -0.01973866,  0.05043185,  0.12060235,\n",
       "        0.19077285,  0.26094336,  0.33111386,  0.40128437,  0.47145487,\n",
       "        0.54162537,  0.61179588,  0.68196638,  0.75213689,  0.82230739,\n",
       "        0.89247789,  0.9626484 ,  1.0328189 ,  1.10298941,  1.17315991,\n",
       "        1.24333041,  1.31350092,  1.38367142,  1.45384193,  1.52401243,\n",
       "        1.59418293,  1.66435344,  1.73452394,  1.80469445,  1.87486495])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(aaa2)[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # max and min value in each column \n",
    "# max_in_column_Xc = np.max(Xc,axis=0)\n",
    "# max_in_column_uX1 = np.max(uX1,axis=0)\n",
    "# max_in_column_uX2 = np.max(uX2,axis=0)\n",
    "# min_in_column_Xc = np.min(Xc,axis=0)\n",
    "# min_in_column_uX1 = np.min(uX1,axis=0)\n",
    "# min_in_column_uX2 = np.min(uX2,axis=0)\n",
    "# Xc_scaled = (Xc-min_in_column_Xc)/(max_in_column_Xc-min_in_column_Xc)\n",
    "# Xc_org = Xc_scaled*(max_in_column_Xc-min_in_column_Xc) + min_in_column_Xc\n",
    "# pd.DataFrame(Xc_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 13450\n",
      "Train on 10760 samples, validate on 2690 samples\n",
      "Epoch 1/1000\n",
      "10760/10760 [==============================] - 1s 92us/step - loss: 225.2867 - loss_1: 0.0155 - root_mean_squared_error: 13.8408 - val_loss: 210.1478 - val_loss_1: 0.0147 - val_root_mean_squared_error: 12.9198\n",
      "Epoch 2/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 218.6843 - loss_1: 0.0140 - root_mean_squared_error: 13.6074 - val_loss: 204.0727 - val_loss_1: 0.0134 - val_root_mean_squared_error: 12.6994\n",
      "Epoch 3/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 212.3532 - loss_1: 0.0133 - root_mean_squared_error: 13.3779 - val_loss: 197.9947 - val_loss_1: 0.0128 - val_root_mean_squared_error: 12.4698\n",
      "Epoch 4/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 205.9619 - loss_1: 0.0129 - root_mean_squared_error: 13.1421 - val_loss: 192.0446 - val_loss_1: 0.0128 - val_root_mean_squared_error: 12.2411\n",
      "Epoch 5/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 199.1416 - loss_1: 0.0128 - root_mean_squared_error: 12.8855 - val_loss: 185.5602 - val_loss_1: 0.0128 - val_root_mean_squared_error: 11.9930\n",
      "Epoch 6/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 191.9535 - loss_1: 0.0127 - root_mean_squared_error: 12.6124 - val_loss: 178.9606 - val_loss_1: 0.0124 - val_root_mean_squared_error: 11.7352\n",
      "Epoch 7/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 184.0344 - loss_1: 0.0123 - root_mean_squared_error: 12.3095 - val_loss: 170.9528 - val_loss_1: 0.0119 - val_root_mean_squared_error: 11.4577\n",
      "Epoch 8/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 175.7036 - loss_1: 0.0116 - root_mean_squared_error: 11.9867 - val_loss: 163.0505 - val_loss_1: 0.0112 - val_root_mean_squared_error: 11.1500\n",
      "Epoch 9/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 166.8616 - loss_1: 0.0108 - root_mean_squared_error: 11.6410 - val_loss: 154.4338 - val_loss_1: 0.0105 - val_root_mean_squared_error: 10.8199\n",
      "Epoch 10/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 157.6078 - loss_1: 0.0104 - root_mean_squared_error: 11.2743 - val_loss: 146.3334 - val_loss_1: 0.0106 - val_root_mean_squared_error: 10.5015\n",
      "Epoch 11/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 148.4739 - loss_1: 0.0108 - root_mean_squared_error: 10.8994 - val_loss: 137.7280 - val_loss_1: 0.0115 - val_root_mean_squared_error: 10.1538\n",
      "Epoch 12/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 138.4299 - loss_1: 0.0126 - root_mean_squared_error: 10.4806 - val_loss: 127.9455 - val_loss_1: 0.0142 - val_root_mean_squared_error: 9.7631\n",
      "Epoch 13/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 129.5177 - loss_1: 0.0158 - root_mean_squared_error: 10.0809 - val_loss: 118.1334 - val_loss_1: 0.0181 - val_root_mean_squared_error: 9.3467\n",
      "Epoch 14/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 118.7459 - loss_1: 0.0206 - root_mean_squared_error: 9.6008 - val_loss: 108.8783 - val_loss_1: 0.0238 - val_root_mean_squared_error: 8.9174\n",
      "Epoch 15/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 109.0403 - loss_1: 0.0271 - root_mean_squared_error: 9.1302 - val_loss: 98.6218 - val_loss_1: 0.0312 - val_root_mean_squared_error: 8.4233\n",
      "Epoch 16/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 98.0812 - loss_1: 0.0355 - root_mean_squared_error: 8.5919 - val_loss: 88.4262 - val_loss_1: 0.0404 - val_root_mean_squared_error: 7.9246\n",
      "Epoch 17/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 87.6396 - loss_1: 0.0454 - root_mean_squared_error: 8.0722 - val_loss: 78.3461 - val_loss_1: 0.0515 - val_root_mean_squared_error: 7.3710\n",
      "Epoch 18/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 78.1961 - loss_1: 0.0570 - root_mean_squared_error: 7.5413 - val_loss: 69.0616 - val_loss_1: 0.0639 - val_root_mean_squared_error: 6.8450\n",
      "Epoch 19/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 67.9764 - loss_1: 0.0700 - root_mean_squared_error: 6.9580 - val_loss: 59.3251 - val_loss_1: 0.0780 - val_root_mean_squared_error: 6.2715\n",
      "Epoch 20/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 59.2778 - loss_1: 0.0850 - root_mean_squared_error: 6.4244 - val_loss: 49.8749 - val_loss_1: 0.0941 - val_root_mean_squared_error: 5.6797\n",
      "Epoch 21/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 50.5458 - loss_1: 0.1008 - root_mean_squared_error: 5.8600 - val_loss: 42.4792 - val_loss_1: 0.1092 - val_root_mean_squared_error: 5.1625\n",
      "Epoch 22/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 43.1621 - loss_1: 0.1177 - root_mean_squared_error: 5.3254 - val_loss: 35.1304 - val_loss_1: 0.1267 - val_root_mean_squared_error: 4.5793\n",
      "Epoch 23/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 36.9420 - loss_1: 0.1348 - root_mean_squared_error: 4.8426 - val_loss: 29.4230 - val_loss_1: 0.1439 - val_root_mean_squared_error: 4.1056\n",
      "Epoch 24/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 31.5468 - loss_1: 0.1501 - root_mean_squared_error: 4.4283 - val_loss: 24.3352 - val_loss_1: 0.1588 - val_root_mean_squared_error: 3.6661\n",
      "Epoch 25/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 28.0616 - loss_1: 0.1626 - root_mean_squared_error: 4.1134 - val_loss: 21.4620 - val_loss_1: 0.1668 - val_root_mean_squared_error: 3.4016\n",
      "Epoch 26/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 25.0257 - loss_1: 0.1682 - root_mean_squared_error: 3.8512 - val_loss: 20.6694 - val_loss_1: 0.1666 - val_root_mean_squared_error: 3.3460\n",
      "Epoch 27/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 23.3273 - loss_1: 0.1596 - root_mean_squared_error: 3.6888 - val_loss: 19.3693 - val_loss_1: 0.1511 - val_root_mean_squared_error: 3.2691\n",
      "Epoch 28/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 22.4587 - loss_1: 0.1457 - root_mean_squared_error: 3.6374 - val_loss: 19.4566 - val_loss_1: 0.1400 - val_root_mean_squared_error: 3.3050\n",
      "Epoch 29/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 21.2927 - loss_1: 0.1378 - root_mean_squared_error: 3.5150 - val_loss: 18.5537 - val_loss_1: 0.1369 - val_root_mean_squared_error: 3.2414\n",
      "Epoch 30/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 20.6323 - loss_1: 0.1361 - root_mean_squared_error: 3.4554 - val_loss: 19.5573 - val_loss_1: 0.1334 - val_root_mean_squared_error: 3.3636\n",
      "Epoch 31/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 20.1524 - loss_1: 0.1310 - root_mean_squared_error: 3.4013 - val_loss: 18.5396 - val_loss_1: 0.1299 - val_root_mean_squared_error: 3.2772\n",
      "Epoch 32/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 18.9721 - loss_1: 0.1283 - root_mean_squared_error: 3.3026 - val_loss: 18.8287 - val_loss_1: 0.1275 - val_root_mean_squared_error: 3.2802\n",
      "Epoch 33/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 18.7751 - loss_1: 0.1251 - root_mean_squared_error: 3.2805 - val_loss: 18.5967 - val_loss_1: 0.1230 - val_root_mean_squared_error: 3.2717\n",
      "Epoch 34/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 18.5317 - loss_1: 0.1216 - root_mean_squared_error: 3.2567 - val_loss: 18.5297 - val_loss_1: 0.1213 - val_root_mean_squared_error: 3.2775\n",
      "Epoch 35/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 18.0845 - loss_1: 0.1204 - root_mean_squared_error: 3.1978 - val_loss: 17.1971 - val_loss_1: 0.1194 - val_root_mean_squared_error: 3.1701\n",
      "Epoch 36/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 17.6293 - loss_1: 0.1189 - root_mean_squared_error: 3.1518 - val_loss: 17.4598 - val_loss_1: 0.1167 - val_root_mean_squared_error: 3.1905\n",
      "Epoch 37/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 17.6963 - loss_1: 0.1153 - root_mean_squared_error: 3.1604 - val_loss: 17.0176 - val_loss_1: 0.1152 - val_root_mean_squared_error: 3.1633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 17.2941 - loss_1: 0.1145 - root_mean_squared_error: 3.1130 - val_loss: 17.1922 - val_loss_1: 0.1135 - val_root_mean_squared_error: 3.1304\n",
      "Epoch 39/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 17.3338 - loss_1: 0.1129 - root_mean_squared_error: 3.1345 - val_loss: 17.1045 - val_loss_1: 0.1114 - val_root_mean_squared_error: 3.1335\n",
      "Epoch 40/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 16.6573 - loss_1: 0.1107 - root_mean_squared_error: 3.043 - 1s 76us/step - loss: 16.7945 - loss_1: 0.1108 - root_mean_squared_error: 3.0579 - val_loss: 17.2528 - val_loss_1: 0.1101 - val_root_mean_squared_error: 3.1554\n",
      "Epoch 41/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.7080 - loss_1: 0.1112 - root_mean_squared_error: 3.0523 - val_loss: 16.5252 - val_loss_1: 0.1105 - val_root_mean_squared_error: 3.0626\n",
      "Epoch 42/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 16.4847 - loss_1: 0.1091 - root_mean_squared_error: 3.0410 - val_loss: 15.8272 - val_loss_1: 0.1069 - val_root_mean_squared_error: 3.0005\n",
      "Epoch 43/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 16.2417 - loss_1: 0.1069 - root_mean_squared_error: 3.0037 - val_loss: 15.7787 - val_loss_1: 0.1070 - val_root_mean_squared_error: 3.0001\n",
      "Epoch 44/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.0695 - loss_1: 0.1070 - root_mean_squared_error: 2.9928 - val_loss: 16.6085 - val_loss_1: 0.1053 - val_root_mean_squared_error: 3.0629\n",
      "Epoch 45/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.3170 - loss_1: 0.1048 - root_mean_squared_error: 3.0147 - val_loss: 15.6241 - val_loss_1: 0.1038 - val_root_mean_squared_error: 3.0000\n",
      "Epoch 46/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 16.1327 - loss_1: 0.1017 - root_mean_squared_error: 2.9979 - val_loss: 15.0635 - val_loss_1: 0.1023 - val_root_mean_squared_error: 2.9133\n",
      "Epoch 47/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.9156 - loss_1: 0.1021 - root_mean_squared_error: 2.9647 - val_loss: 16.0240 - val_loss_1: 0.1024 - val_root_mean_squared_error: 3.0095\n",
      "Epoch 48/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 15.8976 - loss_1: 0.1033 - root_mean_squared_error: 2.9508 - val_loss: 15.5006 - val_loss_1: 0.1020 - val_root_mean_squared_error: 2.9747\n",
      "Epoch 49/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 15.5956 - loss_1: 0.1006 - root_mean_squared_error: 2.9428 - val_loss: 15.4001 - val_loss_1: 0.1007 - val_root_mean_squared_error: 2.9600\n",
      "Epoch 50/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.4618 - loss_1: 0.1002 - root_mean_squared_error: 2.9178 - val_loss: 15.7431 - val_loss_1: 0.1009 - val_root_mean_squared_error: 2.9932\n",
      "Epoch 51/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 15.4370 - loss_1: 0.1010 - root_mean_squared_error: 2.9234 - val_loss: 15.0926 - val_loss_1: 0.0999 - val_root_mean_squared_error: 2.9158\n",
      "Epoch 52/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.3113 - loss_1: 0.0998 - root_mean_squared_error: 2.9131 - val_loss: 14.9290 - val_loss_1: 0.0989 - val_root_mean_squared_error: 2.8994\n",
      "Epoch 53/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 14.8607 - loss_1: 0.0972 - root_mean_squared_error: 2.8520 - val_loss: 15.0474 - val_loss_1: 0.0961 - val_root_mean_squared_error: 2.9096\n",
      "Epoch 54/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.1213 - loss_1: 0.0968 - root_mean_squared_error: 2.8972 - val_loss: 14.8035 - val_loss_1: 0.0967 - val_root_mean_squared_error: 2.8946\n",
      "Epoch 55/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 15.1385 - loss_1: 0.0957 - root_mean_squared_error: 2.8869 - val_loss: 15.3279 - val_loss_1: 0.0973 - val_root_mean_squared_error: 2.9102\n",
      "Epoch 56/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.5696 - loss_1: 0.0976 - root_mean_squared_error: 2.8254 - val_loss: 14.7369 - val_loss_1: 0.0973 - val_root_mean_squared_error: 2.8522\n",
      "Epoch 57/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 14.8161 - loss_1: 0.0966 - root_mean_squared_error: 2.8510 - val_loss: 15.0123 - val_loss_1: 0.0976 - val_root_mean_squared_error: 2.9049\n",
      "Epoch 58/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 14.6701 - loss_1: 0.0974 - root_mean_squared_error: 2.8453 - val_loss: 14.8404 - val_loss_1: 0.0975 - val_root_mean_squared_error: 2.8460\n",
      "Epoch 59/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.8159 - loss_1: 0.0973 - root_mean_squared_error: 2.8441 - val_loss: 13.9901 - val_loss_1: 0.0973 - val_root_mean_squared_error: 2.7409\n",
      "Epoch 60/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 14.5167 - loss_1: 0.0959 - root_mean_squared_error: 2.8179 - val_loss: 14.1856 - val_loss_1: 0.0943 - val_root_mean_squared_error: 2.7867\n",
      "Epoch 61/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 14.3220 - loss_1: 0.0951 - root_mean_squared_error: 2.7773 - val_loss: 14.8021 - val_loss_1: 0.0956 - val_root_mean_squared_error: 2.8403\n",
      "Epoch 62/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.4357 - loss_1: 0.0944 - root_mean_squared_error: 2.8063 - val_loss: 13.8988 - val_loss_1: 0.0943 - val_root_mean_squared_error: 2.7517\n",
      "Epoch 63/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.2588 - loss_1: 0.0942 - root_mean_squared_error: 2.7876 - val_loss: 14.0941 - val_loss_1: 0.0938 - val_root_mean_squared_error: 2.7855\n",
      "Epoch 64/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 14.1892 - loss_1: 0.0934 - root_mean_squared_error: 2.7963 - val_loss: 13.9584 - val_loss_1: 0.0923 - val_root_mean_squared_error: 2.7591\n",
      "Epoch 65/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 13.9404 - loss_1: 0.0927 - root_mean_squared_error: 2.7403 - val_loss: 13.6076 - val_loss_1: 0.0932 - val_root_mean_squared_error: 2.7087\n",
      "Epoch 66/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 14.0591 - loss_1: 0.0933 - root_mean_squared_error: 2.7584 - val_loss: 13.8027 - val_loss_1: 0.0939 - val_root_mean_squared_error: 2.7461\n",
      "Epoch 67/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.8474 - loss_1: 0.0920 - root_mean_squared_error: 2.7367 - val_loss: 13.3323 - val_loss_1: 0.0914 - val_root_mean_squared_error: 2.6933\n",
      "Epoch 68/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.6408 - loss_1: 0.0914 - root_mean_squared_error: 2.7145 - val_loss: 12.9232 - val_loss_1: 0.0910 - val_root_mean_squared_error: 2.6213\n",
      "Epoch 69/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.6967 - loss_1: 0.0906 - root_mean_squared_error: 2.7007 - val_loss: 13.3457 - val_loss_1: 0.0899 - val_root_mean_squared_error: 2.6832\n",
      "Epoch 70/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 13.1982 - loss_1: 0.0905 - root_mean_squared_error: 2.6686 - val_loss: 12.8000 - val_loss_1: 0.0897 - val_root_mean_squared_error: 2.6425\n",
      "Epoch 71/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 13.3825 - loss_1: 0.0904 - root_mean_squared_error: 2.6846 - val_loss: 13.2479 - val_loss_1: 0.0907 - val_root_mean_squared_error: 2.6367\n",
      "Epoch 72/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.4300 - loss_1: 0.0893 - root_mean_squared_error: 2.6804 - val_loss: 13.4614 - val_loss_1: 0.0883 - val_root_mean_squared_error: 2.6884\n",
      "Epoch 73/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.1870 - loss_1: 0.0891 - root_mean_squared_error: 2.6668 - val_loss: 13.4119 - val_loss_1: 0.0907 - val_root_mean_squared_error: 2.6712\n",
      "Epoch 74/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.2604 - loss_1: 0.0897 - root_mean_squared_error: 2.6501 - val_loss: 13.0787 - val_loss_1: 0.0883 - val_root_mean_squared_error: 2.6766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 12.9618 - loss_1: 0.0884 - root_mean_squared_error: 2.6326 - val_loss: 12.5705 - val_loss_1: 0.0876 - val_root_mean_squared_error: 2.5956\n",
      "Epoch 76/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.9497 - loss_1: 0.0879 - root_mean_squared_error: 2.6228 - val_loss: 12.7482 - val_loss_1: 0.0876 - val_root_mean_squared_error: 2.5886\n",
      "Epoch 77/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.9336 - loss_1: 0.0876 - root_mean_squared_error: 2.6449 - val_loss: 12.1416 - val_loss_1: 0.0870 - val_root_mean_squared_error: 2.5527\n",
      "Epoch 78/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.7278 - loss_1: 0.0874 - root_mean_squared_error: 2.6198 - val_loss: 12.8014 - val_loss_1: 0.0881 - val_root_mean_squared_error: 2.6112\n",
      "Epoch 79/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.1045 - loss_1: 0.0878 - root_mean_squared_error: 2.6531 - val_loss: 12.4353 - val_loss_1: 0.0884 - val_root_mean_squared_error: 2.5584\n",
      "Epoch 80/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.8088 - loss_1: 0.0879 - root_mean_squared_error: 2.6192 - val_loss: 12.5050 - val_loss_1: 0.0868 - val_root_mean_squared_error: 2.5421\n",
      "Epoch 81/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 12.4651 - loss_1: 0.0877 - root_mean_squared_error: 2.5810 - val_loss: 12.3903 - val_loss_1: 0.0876 - val_root_mean_squared_error: 2.5832\n",
      "Epoch 82/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.5645 - loss_1: 0.0882 - root_mean_squared_error: 2.5902 - val_loss: 12.5125 - val_loss_1: 0.0865 - val_root_mean_squared_error: 2.5601\n",
      "Epoch 83/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.6361 - loss_1: 0.0858 - root_mean_squared_error: 2.5919 - val_loss: 12.3385 - val_loss_1: 0.0852 - val_root_mean_squared_error: 2.5667\n",
      "Epoch 84/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.9261 - loss_1: 0.0868 - root_mean_squared_error: 2.6292 - val_loss: 11.7737 - val_loss_1: 0.0878 - val_root_mean_squared_error: 2.4863\n",
      "Epoch 85/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.7510 - loss_1: 0.0876 - root_mean_squared_error: 2.5894 - val_loss: 12.0437 - val_loss_1: 0.0866 - val_root_mean_squared_error: 2.5120\n",
      "Epoch 86/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.2270 - loss_1: 0.0855 - root_mean_squared_error: 2.5513 - val_loss: 11.4024 - val_loss_1: 0.0874 - val_root_mean_squared_error: 2.4406\n",
      "Epoch 87/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.5446 - loss_1: 0.0887 - root_mean_squared_error: 2.5929 - val_loss: 12.6006 - val_loss_1: 0.0883 - val_root_mean_squared_error: 2.5844\n",
      "Epoch 88/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.4711 - loss_1: 0.0864 - root_mean_squared_error: 2.5789 - val_loss: 11.8234 - val_loss_1: 0.0862 - val_root_mean_squared_error: 2.5121\n",
      "Epoch 89/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.0366 - loss_1: 0.0868 - root_mean_squared_error: 2.5282 - val_loss: 12.1052 - val_loss_1: 0.0874 - val_root_mean_squared_error: 2.5237\n",
      "Epoch 90/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.9789 - loss_1: 0.0873 - root_mean_squared_error: 2.5088 - val_loss: 12.2622 - val_loss_1: 0.0855 - val_root_mean_squared_error: 2.5360\n",
      "Epoch 91/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.9858 - loss_1: 0.0850 - root_mean_squared_error: 2.5396 - val_loss: 12.0134 - val_loss_1: 0.0862 - val_root_mean_squared_error: 2.5180\n",
      "Epoch 92/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.4195 - loss_1: 0.0859 - root_mean_squared_error: 2.5706 - val_loss: 12.2159 - val_loss_1: 0.0869 - val_root_mean_squared_error: 2.5333\n",
      "Epoch 93/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.1538 - loss_1: 0.0863 - root_mean_squared_error: 2.5553 - val_loss: 11.9738 - val_loss_1: 0.0861 - val_root_mean_squared_error: 2.5025\n",
      "Epoch 94/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 12.1263 - loss_1: 0.0864 - root_mean_squared_error: 2.5323 - val_loss: 11.8610 - val_loss_1: 0.0841 - val_root_mean_squared_error: 2.5139\n",
      "Epoch 95/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 12.1412 - loss_1: 0.0852 - root_mean_squared_error: 2.5399 - val_loss: 12.2363 - val_loss_1: 0.0850 - val_root_mean_squared_error: 2.5417\n",
      "Epoch 96/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 11.8538 - loss_1: 0.0850 - root_mean_squared_error: 2.5347 - val_loss: 12.2681 - val_loss_1: 0.0837 - val_root_mean_squared_error: 2.5678\n",
      "Epoch 97/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.1999 - loss_1: 0.0838 - root_mean_squared_error: 2.5432 - val_loss: 11.7919 - val_loss_1: 0.0840 - val_root_mean_squared_error: 2.5047\n",
      "Epoch 98/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.8516 - loss_1: 0.0849 - root_mean_squared_error: 2.5197 - val_loss: 11.7572 - val_loss_1: 0.0852 - val_root_mean_squared_error: 2.4944\n",
      "Epoch 99/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.7350 - loss_1: 0.0850 - root_mean_squared_error: 2.4910 - val_loss: 12.0982 - val_loss_1: 0.0849 - val_root_mean_squared_error: 2.5148\n",
      "Epoch 100/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.9090 - loss_1: 0.0853 - root_mean_squared_error: 2.5350 - val_loss: 12.3665 - val_loss_1: 0.0859 - val_root_mean_squared_error: 2.5547\n",
      "Epoch 101/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 11.9362 - loss_1: 0.0854 - root_mean_squared_error: 2.5233 - val_loss: 11.8110 - val_loss_1: 0.0853 - val_root_mean_squared_error: 2.5025\n",
      "Epoch 102/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.8867 - loss_1: 0.0843 - root_mean_squared_error: 2.5116 - val_loss: 11.6913 - val_loss_1: 0.0847 - val_root_mean_squared_error: 2.4831\n",
      "Epoch 103/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.9280 - loss_1: 0.0849 - root_mean_squared_error: 2.5202 - val_loss: 12.1171 - val_loss_1: 0.0849 - val_root_mean_squared_error: 2.5296\n",
      "Epoch 104/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.6622 - loss_1: 0.0844 - root_mean_squared_error: 2.4803 - val_loss: 11.9864 - val_loss_1: 0.0840 - val_root_mean_squared_error: 2.5335\n",
      "Epoch 105/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.5836 - loss_1: 0.0839 - root_mean_squared_error: 2.4818 - val_loss: 11.6568 - val_loss_1: 0.0829 - val_root_mean_squared_error: 2.4755\n",
      "Epoch 106/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.8294 - loss_1: 0.0829 - root_mean_squared_error: 2.5139 - val_loss: 12.0854 - val_loss_1: 0.0831 - val_root_mean_squared_error: 2.5603\n",
      "Epoch 107/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.5771 - loss_1: 0.0831 - root_mean_squared_error: 2.4870 - val_loss: 11.7714 - val_loss_1: 0.0824 - val_root_mean_squared_error: 2.5199\n",
      "Epoch 108/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.6857 - loss_1: 0.0832 - root_mean_squared_error: 2.4867 - val_loss: 12.0970 - val_loss_1: 0.0835 - val_root_mean_squared_error: 2.5219\n",
      "Epoch 109/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.8578 - loss_1: 0.0835 - root_mean_squared_error: 2.4989 - val_loss: 11.7295 - val_loss_1: 0.0848 - val_root_mean_squared_error: 2.4818\n",
      "Epoch 110/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.7068 - loss_1: 0.0837 - root_mean_squared_error: 2.4825 - val_loss: 11.7804 - val_loss_1: 0.0819 - val_root_mean_squared_error: 2.4942\n",
      "Epoch 111/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.5798 - loss_1: 0.0823 - root_mean_squared_error: 2.4840 - val_loss: 11.4251 - val_loss_1: 0.0830 - val_root_mean_squared_error: 2.4561\n",
      "Epoch 112/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.5104 - loss_1: 0.0842 - root_mean_squared_error: 2.4732 - val_loss: 12.1696 - val_loss_1: 0.0844 - val_root_mean_squared_error: 2.5007\n",
      "Epoch 113/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.1702 - loss_1: 0.0827 - root_mean_squared_error: 2.4477 - val_loss: 11.3167 - val_loss_1: 0.0824 - val_root_mean_squared_error: 2.4587\n",
      "Epoch 114/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.6255 - loss_1: 0.0829 - root_mean_squared_error: 2.4877 - val_loss: 11.6635 - val_loss_1: 0.0827 - val_root_mean_squared_error: 2.4844\n",
      "Epoch 115/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.5738 - loss_1: 0.0817 - root_mean_squared_error: 2.4796 - val_loss: 11.9227 - val_loss_1: 0.0825 - val_root_mean_squared_error: 2.5107\n",
      "Epoch 116/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.4554 - loss_1: 0.0822 - root_mean_squared_error: 2.4706 - val_loss: 11.0341 - val_loss_1: 0.0813 - val_root_mean_squared_error: 2.4129\n",
      "Epoch 117/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.3588 - loss_1: 0.0809 - root_mean_squared_error: 2.4499 - val_loss: 11.3329 - val_loss_1: 0.0804 - val_root_mean_squared_error: 2.4511\n",
      "Epoch 118/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.3174 - loss_1: 0.0815 - root_mean_squared_error: 2.4464 - val_loss: 11.9809 - val_loss_1: 0.0826 - val_root_mean_squared_error: 2.5245\n",
      "Epoch 119/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.2031 - loss_1: 0.0818 - root_mean_squared_error: 2.4500 - val_loss: 11.8943 - val_loss_1: 0.0809 - val_root_mean_squared_error: 2.5202\n",
      "Epoch 120/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.4328 - loss_1: 0.0819 - root_mean_squared_error: 2.4704 - val_loss: 11.2292 - val_loss_1: 0.0826 - val_root_mean_squared_error: 2.4198\n",
      "Epoch 121/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.9615 - loss_1: 0.0814 - root_mean_squared_error: 2.4098 - val_loss: 11.3335 - val_loss_1: 0.0804 - val_root_mean_squared_error: 2.4385\n",
      "Epoch 122/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.1538 - loss_1: 0.0804 - root_mean_squared_error: 2.4243 - val_loss: 11.1767 - val_loss_1: 0.0807 - val_root_mean_squared_error: 2.4337\n",
      "Epoch 123/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.5154 - loss_1: 0.0801 - root_mean_squared_error: 2.4613 - val_loss: 11.4118 - val_loss_1: 0.0803 - val_root_mean_squared_error: 2.4610\n",
      "Epoch 124/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.4040 - loss_1: 0.0812 - root_mean_squared_error: 2.4445 - val_loss: 11.7167 - val_loss_1: 0.0814 - val_root_mean_squared_error: 2.4733\n",
      "Epoch 125/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 11.4153 - loss_1: 0.0806 - root_mean_squared_error: 2.4555 - val_loss: 11.1368 - val_loss_1: 0.0795 - val_root_mean_squared_error: 2.4375\n",
      "Epoch 126/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.2491 - loss_1: 0.0805 - root_mean_squared_error: 2.4429 - val_loss: 11.6369 - val_loss_1: 0.0810 - val_root_mean_squared_error: 2.4803\n",
      "Epoch 127/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.2100 - loss_1: 0.0820 - root_mean_squared_error: 2.4303 - val_loss: 11.5258 - val_loss_1: 0.0815 - val_root_mean_squared_error: 2.4772\n",
      "Epoch 128/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 11.6354 - loss_1: 0.0812 - root_mean_squared_error: 2.466 - 1s 75us/step - loss: 11.6027 - loss_1: 0.0811 - root_mean_squared_error: 2.4616 - val_loss: 10.8365 - val_loss_1: 0.0816 - val_root_mean_squared_error: 2.3789\n",
      "Epoch 129/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.9799 - loss_1: 0.0816 - root_mean_squared_error: 2.4294 - val_loss: 12.2832 - val_loss_1: 0.0813 - val_root_mean_squared_error: 2.5684\n",
      "Epoch 130/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.2857 - loss_1: 0.0801 - root_mean_squared_error: 2.4447 - val_loss: 10.9399 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.4374\n",
      "Epoch 131/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.2039 - loss_1: 0.0785 - root_mean_squared_error: 2.4342 - val_loss: 11.7753 - val_loss_1: 0.0808 - val_root_mean_squared_error: 2.5047\n",
      "Epoch 132/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.2015 - loss_1: 0.0794 - root_mean_squared_error: 2.4324 - val_loss: 10.8696 - val_loss_1: 0.0797 - val_root_mean_squared_error: 2.4014\n",
      "Epoch 133/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.2990 - loss_1: 0.0793 - root_mean_squared_error: 2.4444 - val_loss: 11.2191 - val_loss_1: 0.0791 - val_root_mean_squared_error: 2.4418\n",
      "Epoch 134/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.0518 - loss_1: 0.0788 - root_mean_squared_error: 2.4045 - val_loss: 11.4241 - val_loss_1: 0.0787 - val_root_mean_squared_error: 2.4703\n",
      "Epoch 135/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.9501 - loss_1: 0.0802 - root_mean_squared_error: 2.4115 - val_loss: 10.9642 - val_loss_1: 0.0791 - val_root_mean_squared_error: 2.4125\n",
      "Epoch 136/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.9803 - loss_1: 0.0793 - root_mean_squared_error: 2.4062 - val_loss: 11.7823 - val_loss_1: 0.0802 - val_root_mean_squared_error: 2.5076\n",
      "Epoch 137/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.9543 - loss_1: 0.0805 - root_mean_squared_error: 2.4107 - val_loss: 11.1236 - val_loss_1: 0.0800 - val_root_mean_squared_error: 2.4299\n",
      "Epoch 138/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.0096 - loss_1: 0.0801 - root_mean_squared_error: 2.4233 - val_loss: 10.9469 - val_loss_1: 0.0794 - val_root_mean_squared_error: 2.4200\n",
      "Epoch 139/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.0942 - loss_1: 0.0788 - root_mean_squared_error: 2.4209 - val_loss: 10.4944 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.3725\n",
      "Epoch 140/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.9813 - loss_1: 0.0787 - root_mean_squared_error: 2.4093 - val_loss: 10.5576 - val_loss_1: 0.0793 - val_root_mean_squared_error: 2.3739\n",
      "Epoch 141/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.8199 - loss_1: 0.0786 - root_mean_squared_error: 2.3919 - val_loss: 11.6869 - val_loss_1: 0.0782 - val_root_mean_squared_error: 2.4834\n",
      "Epoch 142/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 11.1634 - loss_1: 0.0782 - root_mean_squared_error: 2.4252 - val_loss: 10.6127 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.3813\n",
      "Epoch 143/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.6971 - loss_1: 0.0789 - root_mean_squared_error: 2.3653 - val_loss: 10.8214 - val_loss_1: 0.0784 - val_root_mean_squared_error: 2.4000\n",
      "Epoch 144/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.1955 - loss_1: 0.0785 - root_mean_squared_error: 2.4380 - val_loss: 10.9030 - val_loss_1: 0.0791 - val_root_mean_squared_error: 2.4283\n",
      "Epoch 145/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.0359 - loss_1: 0.0783 - root_mean_squared_error: 2.4003 - val_loss: 10.4773 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.3548\n",
      "Epoch 146/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.9638 - loss_1: 0.0781 - root_mean_squared_error: 2.3879 - val_loss: 11.4246 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.4530\n",
      "Epoch 147/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.8726 - loss_1: 0.0774 - root_mean_squared_error: 2.3990 - val_loss: 11.3267 - val_loss_1: 0.0764 - val_root_mean_squared_error: 2.4564\n",
      "Epoch 148/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.8094 - loss_1: 0.0767 - root_mean_squared_error: 2.3882 - val_loss: 11.1495 - val_loss_1: 0.0784 - val_root_mean_squared_error: 2.4358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.7627 - loss_1: 0.0784 - root_mean_squared_error: 2.3709 - val_loss: 10.6282 - val_loss_1: 0.0787 - val_root_mean_squared_error: 2.3669\n",
      "Epoch 150/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.1397 - loss_1: 0.0787 - root_mean_squared_error: 2.4166 - val_loss: 11.1773 - val_loss_1: 0.0784 - val_root_mean_squared_error: 2.4279\n",
      "Epoch 151/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 10.7879 - loss_1: 0.0776 - root_mean_squared_error: 2.391 - 1s 76us/step - loss: 10.7911 - loss_1: 0.0776 - root_mean_squared_error: 2.3918 - val_loss: 11.3244 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.4608\n",
      "Epoch 152/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.7056 - loss_1: 0.0781 - root_mean_squared_error: 2.3837 - val_loss: 10.6034 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.3888\n",
      "Epoch 153/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.9329 - loss_1: 0.0780 - root_mean_squared_error: 2.3839 - val_loss: 11.0541 - val_loss_1: 0.0799 - val_root_mean_squared_error: 2.4259\n",
      "Epoch 154/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.8285 - loss_1: 0.0791 - root_mean_squared_error: 2.3932 - val_loss: 10.7948 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.3719\n",
      "Epoch 155/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.8069 - loss_1: 0.0777 - root_mean_squared_error: 2.3925 - val_loss: 10.6867 - val_loss_1: 0.0784 - val_root_mean_squared_error: 2.3715\n",
      "Epoch 156/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.8630 - loss_1: 0.0789 - root_mean_squared_error: 2.4026 - val_loss: 11.0823 - val_loss_1: 0.0788 - val_root_mean_squared_error: 2.4058\n",
      "Epoch 157/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.1248 - loss_1: 0.0785 - root_mean_squared_error: 2.4240 - val_loss: 10.8038 - val_loss_1: 0.0786 - val_root_mean_squared_error: 2.3922\n",
      "Epoch 158/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.7137 - loss_1: 0.0781 - root_mean_squared_error: 2.3912 - val_loss: 10.6981 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.3523\n",
      "Epoch 159/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.7881 - loss_1: 0.0778 - root_mean_squared_error: 2.3886 - val_loss: 10.8203 - val_loss_1: 0.0782 - val_root_mean_squared_error: 2.4108\n",
      "Epoch 160/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.5207 - loss_1: 0.0780 - root_mean_squared_error: 2.3473 - val_loss: 10.5284 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.3398\n",
      "Epoch 161/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.6149 - loss_1: 0.0779 - root_mean_squared_error: 2.3579 - val_loss: 11.0128 - val_loss_1: 0.0781 - val_root_mean_squared_error: 2.4007\n",
      "Epoch 162/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.0250 - loss_1: 0.0767 - root_mean_squared_error: 2.4074 - val_loss: 10.8325 - val_loss_1: 0.0781 - val_root_mean_squared_error: 2.3803\n",
      "Epoch 163/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 10.6599 - loss_1: 0.0790 - root_mean_squared_error: 2.3746 - val_loss: 10.8221 - val_loss_1: 0.0796 - val_root_mean_squared_error: 2.3627\n",
      "Epoch 164/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 10.6785 - loss_1: 0.0772 - root_mean_squared_error: 2.3802 - val_loss: 11.2619 - val_loss_1: 0.0759 - val_root_mean_squared_error: 2.4416\n",
      "Epoch 165/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.6118 - loss_1: 0.0762 - root_mean_squared_error: 2.3594 - val_loss: 10.8612 - val_loss_1: 0.0764 - val_root_mean_squared_error: 2.4094\n",
      "Epoch 166/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.8475 - loss_1: 0.0767 - root_mean_squared_error: 2.3896 - val_loss: 10.9123 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.3800\n",
      "Epoch 167/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.6680 - loss_1: 0.0776 - root_mean_squared_error: 2.3840 - val_loss: 11.1069 - val_loss_1: 0.0766 - val_root_mean_squared_error: 2.4272\n",
      "Epoch 168/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.6744 - loss_1: 0.0764 - root_mean_squared_error: 2.3766 - val_loss: 11.2230 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.4363\n",
      "Epoch 169/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.7408 - loss_1: 0.0771 - root_mean_squared_error: 2.3705 - val_loss: 10.7842 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.4018\n",
      "Epoch 170/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.8029 - loss_1: 0.0765 - root_mean_squared_error: 2.3775 - val_loss: 10.5214 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.3754\n",
      "Epoch 171/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.5906 - loss_1: 0.0788 - root_mean_squared_error: 2.3627 - val_loss: 11.0495 - val_loss_1: 0.0773 - val_root_mean_squared_error: 2.4113\n",
      "Epoch 172/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.6226 - loss_1: 0.0774 - root_mean_squared_error: 2.3532 - val_loss: 11.0373 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.4025\n",
      "Epoch 173/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.6218 - loss_1: 0.0778 - root_mean_squared_error: 2.3739 - val_loss: 10.6591 - val_loss_1: 0.0778 - val_root_mean_squared_error: 2.3776\n",
      "Epoch 174/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.8234 - loss_1: 0.0772 - root_mean_squared_error: 2.3792 - val_loss: 11.0019 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.3831\n",
      "Epoch 175/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.4709 - loss_1: 0.0775 - root_mean_squared_error: 2.3473 - val_loss: 10.8766 - val_loss_1: 0.0786 - val_root_mean_squared_error: 2.3935\n",
      "Epoch 176/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.7572 - loss_1: 0.0778 - root_mean_squared_error: 2.3845 - val_loss: 10.7721 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.3777\n",
      "Epoch 177/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.5384 - loss_1: 0.0773 - root_mean_squared_error: 2.3509 - val_loss: 10.4185 - val_loss_1: 0.0766 - val_root_mean_squared_error: 2.3461\n",
      "Epoch 178/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 10.4433 - loss_1: 0.0773 - root_mean_squared_error: 2.3500 - val_loss: 10.7793 - val_loss_1: 0.0790 - val_root_mean_squared_error: 2.3850\n",
      "Epoch 179/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.1754 - loss_1: 0.0783 - root_mean_squared_error: 2.3171 - val_loss: 11.0067 - val_loss_1: 0.0768 - val_root_mean_squared_error: 2.4267\n",
      "Epoch 180/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.5447 - loss_1: 0.0766 - root_mean_squared_error: 2.3485 - val_loss: 11.1886 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.4007\n",
      "Epoch 181/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.3354 - loss_1: 0.0776 - root_mean_squared_error: 2.3318 - val_loss: 10.3082 - val_loss_1: 0.0767 - val_root_mean_squared_error: 2.3148\n",
      "Epoch 182/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.3895 - loss_1: 0.0764 - root_mean_squared_error: 2.3460 - val_loss: 10.5411 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.3641\n",
      "Epoch 183/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.3251 - loss_1: 0.0768 - root_mean_squared_error: 2.3280 - val_loss: 10.4746 - val_loss_1: 0.0767 - val_root_mean_squared_error: 2.3467\n",
      "Epoch 184/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.4594 - loss_1: 0.0774 - root_mean_squared_error: 2.3399 - val_loss: 10.2060 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.3481\n",
      "Epoch 185/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.3161 - loss_1: 0.0774 - root_mean_squared_error: 2.3219 - val_loss: 10.1009 - val_loss_1: 0.0778 - val_root_mean_squared_error: 2.3240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 10.4635 - loss_1: 0.0770 - root_mean_squared_error: 2.3483 - val_loss: 10.8663 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.3912\n",
      "Epoch 187/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2852 - loss_1: 0.0768 - root_mean_squared_error: 2.3398 - val_loss: 10.2402 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.3178\n",
      "Epoch 188/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.2104 - loss_1: 0.0766 - root_mean_squared_error: 2.3240 - val_loss: 10.9538 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.4119\n",
      "Epoch 189/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.3405 - loss_1: 0.0768 - root_mean_squared_error: 2.3296 - val_loss: 10.4808 - val_loss_1: 0.0752 - val_root_mean_squared_error: 2.3735\n",
      "Epoch 190/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2161 - loss_1: 0.0753 - root_mean_squared_error: 2.3299 - val_loss: 10.5716 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.3515\n",
      "Epoch 191/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2954 - loss_1: 0.0759 - root_mean_squared_error: 2.3242 - val_loss: 10.2920 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.3327\n",
      "Epoch 192/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2344 - loss_1: 0.0761 - root_mean_squared_error: 2.3224 - val_loss: 10.4708 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.3310\n",
      "Epoch 193/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 10.3947 - loss_1: 0.0772 - root_mean_squared_error: 2.3438 - val_loss: 10.1479 - val_loss_1: 0.0753 - val_root_mean_squared_error: 2.3309\n",
      "Epoch 194/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.3714 - loss_1: 0.0762 - root_mean_squared_error: 2.3305 - val_loss: 10.3880 - val_loss_1: 0.0774 - val_root_mean_squared_error: 2.3497\n",
      "Epoch 195/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.4370 - loss_1: 0.0764 - root_mean_squared_error: 2.3595 - val_loss: 10.1465 - val_loss_1: 0.0761 - val_root_mean_squared_error: 2.3233ss: 10.4348 - loss_1: 0.0764 - root_mean_squared_error: 2.362\n",
      "Epoch 196/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2578 - loss_1: 0.0769 - root_mean_squared_error: 2.3197 - val_loss: 10.7301 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.3887\n",
      "Epoch 197/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.0496 - loss_1: 0.0757 - root_mean_squared_error: 2.2963 - val_loss: 10.0877 - val_loss_1: 0.0759 - val_root_mean_squared_error: 2.3169\n",
      "Epoch 198/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.3488 - loss_1: 0.0769 - root_mean_squared_error: 2.3350 - val_loss: 10.6311 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.3523\n",
      "Epoch 199/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2471 - loss_1: 0.0764 - root_mean_squared_error: 2.3244 - val_loss: 10.5199 - val_loss_1: 0.0754 - val_root_mean_squared_error: 2.3784\n",
      "Epoch 200/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.4692 - loss_1: 0.0758 - root_mean_squared_error: 2.3282 - val_loss: 10.7686 - val_loss_1: 0.0767 - val_root_mean_squared_error: 2.3803\n",
      "Epoch 201/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.7148 - loss_1: 0.0769 - root_mean_squared_error: 2.2551 - val_loss: 10.6565 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.3905\n",
      "Epoch 202/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2621 - loss_1: 0.0772 - root_mean_squared_error: 2.3157 - val_loss: 10.3972 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.3624\n",
      "Epoch 203/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.9081 - loss_1: 0.0781 - root_mean_squared_error: 2.3005 - val_loss: 10.4487 - val_loss_1: 0.0775 - val_root_mean_squared_error: 2.3487\n",
      "Epoch 204/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2119 - loss_1: 0.0769 - root_mean_squared_error: 2.3046 - val_loss: 10.2790 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.3348\n",
      "Epoch 205/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.1204 - loss_1: 0.0769 - root_mean_squared_error: 2.3084 - val_loss: 9.7745 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.2621\n",
      "Epoch 206/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.1582 - loss_1: 0.0776 - root_mean_squared_error: 2.2992 - val_loss: 10.4586 - val_loss_1: 0.0773 - val_root_mean_squared_error: 2.3284\n",
      "Epoch 207/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.1037 - loss_1: 0.0774 - root_mean_squared_error: 2.3048 - val_loss: 10.4028 - val_loss_1: 0.0774 - val_root_mean_squared_error: 2.3365\n",
      "Epoch 208/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.8846 - loss_1: 0.0775 - root_mean_squared_error: 2.2742 - val_loss: 10.5079 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.3559\n",
      "Epoch 209/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.8091 - loss_1: 0.0768 - root_mean_squared_error: 2.2802 - val_loss: 10.1126 - val_loss_1: 0.0781 - val_root_mean_squared_error: 2.2922\n",
      "Epoch 210/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.1274 - loss_1: 0.0790 - root_mean_squared_error: 2.3088 - val_loss: 10.2870 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.3335\n",
      "Epoch 211/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.9615 - loss_1: 0.0775 - root_mean_squared_error: 2.2823 - val_loss: 9.8291 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.2734\n",
      "Epoch 212/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.0207 - loss_1: 0.0776 - root_mean_squared_error: 2.2784 - val_loss: 10.3813 - val_loss_1: 0.0797 - val_root_mean_squared_error: 2.3500\n",
      "Epoch 213/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.8700 - loss_1: 0.0776 - root_mean_squared_error: 2.2773 - val_loss: 10.0314 - val_loss_1: 0.0774 - val_root_mean_squared_error: 2.3108\n",
      "Epoch 214/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.8114 - loss_1: 0.0782 - root_mean_squared_error: 2.2653 - val_loss: 10.2529 - val_loss_1: 0.0782 - val_root_mean_squared_error: 2.3120\n",
      "Epoch 215/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.7670 - loss_1: 0.0778 - root_mean_squared_error: 2.2648 - val_loss: 10.1050 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.2872\n",
      "Epoch 216/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.9539 - loss_1: 0.0780 - root_mean_squared_error: 2.2682 - val_loss: 9.8407 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.2694\n",
      "Epoch 217/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.4421 - loss_1: 0.0777 - root_mean_squared_error: 2.2110 - val_loss: 10.3394 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.3113\n",
      "Epoch 218/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.7282 - loss_1: 0.0781 - root_mean_squared_error: 2.2475 - val_loss: 10.1956 - val_loss_1: 0.0785 - val_root_mean_squared_error: 2.2850\n",
      "Epoch 219/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.5901 - loss_1: 0.0782 - root_mean_squared_error: 2.2481 - val_loss: 9.5515 - val_loss_1: 0.0780 - val_root_mean_squared_error: 2.2084\n",
      "Epoch 220/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6001 - loss_1: 0.0782 - root_mean_squared_error: 2.2424 - val_loss: 10.1654 - val_loss_1: 0.0789 - val_root_mean_squared_error: 2.3102\n",
      "Epoch 221/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.4577 - loss_1: 0.0784 - root_mean_squared_error: 2.2137 - val_loss: 9.9301 - val_loss_1: 0.0786 - val_root_mean_squared_error: 2.2748\n",
      "Epoch 222/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.5750 - loss_1: 0.0790 - root_mean_squared_error: 2.2327 - val_loss: 9.9320 - val_loss_1: 0.0790 - val_root_mean_squared_error: 2.2718\n",
      "Epoch 223/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.8446 - loss_1: 0.0787 - root_mean_squared_error: 2.2470 - val_loss: 10.5350 - val_loss_1: 0.0796 - val_root_mean_squared_error: 2.3116\n",
      "Epoch 224/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.3842 - loss_1: 0.0794 - root_mean_squared_error: 2.2125 - val_loss: 10.1475 - val_loss_1: 0.0786 - val_root_mean_squared_error: 2.3005\n",
      "Epoch 225/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.7712 - loss_1: 0.0773 - root_mean_squared_error: 2.2584 - val_loss: 9.4486 - val_loss_1: 0.0767 - val_root_mean_squared_error: 2.2094\n",
      "Epoch 226/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.7637 - loss_1: 0.0783 - root_mean_squared_error: 2.2569 - val_loss: 10.0715 - val_loss_1: 0.0781 - val_root_mean_squared_error: 2.3133\n",
      "Epoch 227/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6376 - loss_1: 0.0775 - root_mean_squared_error: 2.2466 - val_loss: 10.0113 - val_loss_1: 0.0772 - val_root_mean_squared_error: 2.3094\n",
      "Epoch 228/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.4711 - loss_1: 0.0775 - root_mean_squared_error: 2.2157 - val_loss: 9.8639 - val_loss_1: 0.0778 - val_root_mean_squared_error: 2.2534\n",
      "Epoch 229/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.8423 - loss_1: 0.0787 - root_mean_squared_error: 2.2508 - val_loss: 9.6017 - val_loss_1: 0.0785 - val_root_mean_squared_error: 2.2461\n",
      "Epoch 230/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.7210 - loss_1: 0.0775 - root_mean_squared_error: 2.2470 - val_loss: 9.9708 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.2835\n",
      "Epoch 231/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.5727 - loss_1: 0.0788 - root_mean_squared_error: 2.2218 - val_loss: 10.3519 - val_loss_1: 0.0798 - val_root_mean_squared_error: 2.2966\n",
      "Epoch 232/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.3943 - loss_1: 0.0785 - root_mean_squared_error: 2.2119 - val_loss: 10.2354 - val_loss_1: 0.0788 - val_root_mean_squared_error: 2.2882\n",
      "Epoch 233/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.3475 - loss_1: 0.0796 - root_mean_squared_error: 2.1944 - val_loss: 9.9223 - val_loss_1: 0.0799 - val_root_mean_squared_error: 2.2663\n",
      "Epoch 234/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.5871 - loss_1: 0.0788 - root_mean_squared_error: 2.2249 - val_loss: 10.1893 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.3211\n",
      "Epoch 235/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.5208 - loss_1: 0.0785 - root_mean_squared_error: 2.2244 - val_loss: 10.5140 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.3002\n",
      "Epoch 236/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.5109 - loss_1: 0.0776 - root_mean_squared_error: 2.2282 - val_loss: 9.6578 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.2630\n",
      "Epoch 237/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.4494 - loss_1: 0.0794 - root_mean_squared_error: 2.2009 - val_loss: 9.7355 - val_loss_1: 0.0786 - val_root_mean_squared_error: 2.2431\n",
      "Epoch 238/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.4652 - loss_1: 0.0777 - root_mean_squared_error: 2.2092 - val_loss: 10.1924 - val_loss_1: 0.0786 - val_root_mean_squared_error: 2.3322\n",
      "Epoch 239/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.4719 - loss_1: 0.0787 - root_mean_squared_error: 2.2006 - val_loss: 10.0671 - val_loss_1: 0.0780 - val_root_mean_squared_error: 2.3020\n",
      "Epoch 240/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.4621 - loss_1: 0.0780 - root_mean_squared_error: 2.2114 - val_loss: 9.6099 - val_loss_1: 0.0781 - val_root_mean_squared_error: 2.2499\n",
      "Epoch 241/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6070 - loss_1: 0.0780 - root_mean_squared_error: 2.2234 - val_loss: 10.3961 - val_loss_1: 0.0790 - val_root_mean_squared_error: 2.3615\n",
      "Epoch 242/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.2061 - loss_1: 0.0788 - root_mean_squared_error: 2.1622 - val_loss: 10.3859 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.3030\n",
      "Epoch 243/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.4689 - loss_1: 0.0784 - root_mean_squared_error: 2.2229 - val_loss: 10.3113 - val_loss_1: 0.0780 - val_root_mean_squared_error: 2.3181\n",
      "Epoch 244/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.0418 - loss_1: 0.0777 - root_mean_squared_error: 2.1575 - val_loss: 9.9460 - val_loss_1: 0.0784 - val_root_mean_squared_error: 2.2709\n",
      "Epoch 245/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.4599 - loss_1: 0.0782 - root_mean_squared_error: 2.1976 - val_loss: 10.3111 - val_loss_1: 0.0774 - val_root_mean_squared_error: 2.3046\n",
      "Epoch 246/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.1102 - loss_1: 0.0778 - root_mean_squared_error: 2.1596 - val_loss: 10.2037 - val_loss_1: 0.0784 - val_root_mean_squared_error: 2.3449\n",
      "Epoch 247/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.3951 - loss_1: 0.0775 - root_mean_squared_error: 2.1921 - val_loss: 9.7302 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.2299\n",
      "Epoch 248/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.9759 - loss_1: 0.0773 - root_mean_squared_error: 2.1396 - val_loss: 10.1512 - val_loss_1: 0.0780 - val_root_mean_squared_error: 2.2937\n",
      "Epoch 249/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.1553 - loss_1: 0.0777 - root_mean_squared_error: 2.1707 - val_loss: 10.3229 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.3159\n",
      "Epoch 250/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.2998 - loss_1: 0.0771 - root_mean_squared_error: 2.1933 - val_loss: 10.1311 - val_loss_1: 0.0783 - val_root_mean_squared_error: 2.2742\n",
      "Epoch 251/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.1367 - loss_1: 0.0778 - root_mean_squared_error: 2.1724 - val_loss: 10.2236 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.2951\n",
      "Epoch 252/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0785 - loss_1: 0.0779 - root_mean_squared_error: 2.1540 - val_loss: 10.3591 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.3156\n",
      "Epoch 253/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0434 - loss_1: 0.0776 - root_mean_squared_error: 2.1489 - val_loss: 9.9491 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.2741\n",
      "Epoch 254/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 9.2973 - loss_1: 0.0774 - root_mean_squared_error: 2.1748 ETA: 0s - loss: 9.2299 - loss_1: 0.0773 - root_mean_squared_err - 1s 76us/step - loss: 9.2649 - loss_1: 0.0775 - root_mean_squared_error: 2.1722 - val_loss: 9.8939 - val_loss_1: 0.0785 - val_root_mean_squared_error: 2.2760\n",
      "Epoch 255/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.1654 - loss_1: 0.0779 - root_mean_squared_error: 2.1702 - val_loss: 10.0010 - val_loss_1: 0.0782 - val_root_mean_squared_error: 2.2894\n",
      "Epoch 256/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0641 - loss_1: 0.0780 - root_mean_squared_error: 2.1530 - val_loss: 9.8190 - val_loss_1: 0.0775 - val_root_mean_squared_error: 2.2662\n",
      "Epoch 257/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 9.0354 - loss_1: 0.0767 - root_mean_squared_error: 2.15 - 1s 76us/step - loss: 9.0738 - loss_1: 0.0768 - root_mean_squared_error: 2.1666 - val_loss: 10.0223 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.3056\n",
      "Epoch 258/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.9208 - loss_1: 0.0782 - root_mean_squared_error: 2.1236 - val_loss: 9.7829 - val_loss_1: 0.0768 - val_root_mean_squared_error: 2.2777\n",
      "Epoch 259/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.1119 - loss_1: 0.0759 - root_mean_squared_error: 2.1604 - val_loss: 9.8505 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.2726\n",
      "Epoch 260/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.0006 - loss_1: 0.0775 - root_mean_squared_error: 2.1422 - val_loss: 9.9346 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.2713\n",
      "Epoch 261/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.1203 - loss_1: 0.0779 - root_mean_squared_error: 2.1482 - val_loss: 9.6810 - val_loss_1: 0.0784 - val_root_mean_squared_error: 2.2242\n",
      "Epoch 262/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.0814 - loss_1: 0.0782 - root_mean_squared_error: 2.1371 - val_loss: 9.9368 - val_loss_1: 0.0780 - val_root_mean_squared_error: 2.2568\n",
      "Epoch 263/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.9917 - loss_1: 0.0781 - root_mean_squared_error: 2.1301 - val_loss: 9.9310 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.2428\n",
      "Epoch 264/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.8040 - loss_1: 0.0777 - root_mean_squared_error: 2.1213 - val_loss: 10.0786 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.2840\n",
      "Epoch 265/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.9318 - loss_1: 0.0772 - root_mean_squared_error: 2.1351 - val_loss: 9.9777 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.2682\n",
      "Epoch 266/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.0473 - loss_1: 0.0783 - root_mean_squared_error: 2.1563 - val_loss: 9.2103 - val_loss_1: 0.0774 - val_root_mean_squared_error: 2.1799\n",
      "Epoch 267/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8853 - loss_1: 0.0766 - root_mean_squared_error: 2.1288 - val_loss: 9.6595 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.2475\n",
      "Epoch 268/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.0569 - loss_1: 0.0771 - root_mean_squared_error: 2.1491 - val_loss: 10.1161 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.2814\n",
      "Epoch 269/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.9551 - loss_1: 0.0771 - root_mean_squared_error: 2.1328 - val_loss: 9.2756 - val_loss_1: 0.0773 - val_root_mean_squared_error: 2.1702\n",
      "Epoch 270/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8342 - loss_1: 0.0769 - root_mean_squared_error: 2.1284 - val_loss: 10.2222 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.2986\n",
      "Epoch 271/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.8226 - loss_1: 0.0790 - root_mean_squared_error: 2.1253 - val_loss: 10.2816 - val_loss_1: 0.0787 - val_root_mean_squared_error: 2.2890\n",
      "Epoch 272/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.7452 - loss_1: 0.0787 - root_mean_squared_error: 2.1104 - val_loss: 9.5416 - val_loss_1: 0.0781 - val_root_mean_squared_error: 2.2001\n",
      "Epoch 273/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8647 - loss_1: 0.0778 - root_mean_squared_error: 2.1268 - val_loss: 9.7119 - val_loss_1: 0.0782 - val_root_mean_squared_error: 2.2331\n",
      "Epoch 274/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.8512 - loss_1: 0.0779 - root_mean_squared_error: 2.1197 - val_loss: 9.5850 - val_loss_1: 0.0781 - val_root_mean_squared_error: 2.2070\n",
      "Epoch 275/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.7669 - loss_1: 0.0782 - root_mean_squared_error: 2.1161 - val_loss: 10.1048 - val_loss_1: 0.0773 - val_root_mean_squared_error: 2.2961\n",
      "Epoch 276/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.9444 - loss_1: 0.0777 - root_mean_squared_error: 2.1281 - val_loss: 9.9151 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.2806\n",
      "Epoch 277/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.9669 - loss_1: 0.0779 - root_mean_squared_error: 2.1315 - val_loss: 9.8543 - val_loss_1: 0.0774 - val_root_mean_squared_error: 2.2409\n",
      "Epoch 278/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.9804 - loss_1: 0.0773 - root_mean_squared_error: 2.1311 - val_loss: 9.8119 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.2510\n",
      "Epoch 279/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.8007 - loss_1: 0.0770 - root_mean_squared_error: 2.1188 - val_loss: 9.5630 - val_loss_1: 0.0764 - val_root_mean_squared_error: 2.2207\n",
      "Epoch 280/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.7752 - loss_1: 0.0769 - root_mean_squared_error: 2.1089 - val_loss: 10.0527 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.2673\n",
      "Epoch 281/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5032 - loss_1: 0.0771 - root_mean_squared_error: 2.0843 - val_loss: 9.4024 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.1949\n",
      "Epoch 282/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8185 - loss_1: 0.0764 - root_mean_squared_error: 2.1140 - val_loss: 9.7222 - val_loss_1: 0.0773 - val_root_mean_squared_error: 2.2060\n",
      "Epoch 283/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.7788 - loss_1: 0.0776 - root_mean_squared_error: 2.1073 - val_loss: 9.6933 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.2406\n",
      "Epoch 284/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.6278 - loss_1: 0.0765 - root_mean_squared_error: 2.0907 - val_loss: 10.0119 - val_loss_1: 0.0780 - val_root_mean_squared_error: 2.2782\n",
      "Epoch 285/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.6219 - loss_1: 0.0763 - root_mean_squared_error: 2.0964 - val_loss: 10.0246 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.2684\n",
      "Epoch 286/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.8982 - loss_1: 0.0767 - root_mean_squared_error: 2.1341 - val_loss: 9.6853 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.2393\n",
      "Epoch 287/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5144 - loss_1: 0.0757 - root_mean_squared_error: 2.0874 - val_loss: 9.7763 - val_loss_1: 0.0764 - val_root_mean_squared_error: 2.2240\n",
      "Epoch 288/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5609 - loss_1: 0.0775 - root_mean_squared_error: 2.0905 - val_loss: 9.2305 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.1814\n",
      "Epoch 289/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5638 - loss_1: 0.0760 - root_mean_squared_error: 2.0879 - val_loss: 9.8206 - val_loss_1: 0.0766 - val_root_mean_squared_error: 2.2479\n",
      "Epoch 290/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.5990 - loss_1: 0.0774 - root_mean_squared_error: 2.0946 - val_loss: 9.7608 - val_loss_1: 0.0778 - val_root_mean_squared_error: 2.2413\n",
      "Epoch 291/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.8536 - loss_1: 0.0766 - root_mean_squared_error: 2.1136 - val_loss: 10.1373 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.2535\n",
      "Epoch 292/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.7978 - loss_1: 0.0775 - root_mean_squared_error: 2.1119 - val_loss: 9.9230 - val_loss_1: 0.0776 - val_root_mean_squared_error: 2.2720\n",
      "Epoch 293/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.5618 - loss_1: 0.0768 - root_mean_squared_error: 2.0871 - val_loss: 9.7007 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.2172\n",
      "Epoch 294/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.4236 - loss_1: 0.0774 - root_mean_squared_error: 2.0640 - val_loss: 9.6310 - val_loss_1: 0.0767 - val_root_mean_squared_error: 2.2169\n",
      "Epoch 295/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.4012 - loss_1: 0.0766 - root_mean_squared_error: 2.0639 - val_loss: 9.3750 - val_loss_1: 0.0755 - val_root_mean_squared_error: 2.2037\n",
      "Epoch 296/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5941 - loss_1: 0.0759 - root_mean_squared_error: 2.0802 - val_loss: 9.6377 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.2503\n",
      "Epoch 297/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.6761 - loss_1: 0.0779 - root_mean_squared_error: 2.1033 - val_loss: 9.4674 - val_loss_1: 0.0772 - val_root_mean_squared_error: 2.2099\n",
      "Epoch 298/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.7175 - loss_1: 0.0765 - root_mean_squared_error: 2.1052 - val_loss: 9.4223 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.1898\n",
      "Epoch 299/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.6413 - loss_1: 0.0771 - root_mean_squared_error: 2.0818 - val_loss: 9.4067 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.2016\n",
      "Epoch 300/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.6363 - loss_1: 0.0775 - root_mean_squared_error: 2.0913 - val_loss: 9.5229 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.1932\n",
      "Epoch 301/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5495 - loss_1: 0.0772 - root_mean_squared_error: 2.0869 - val_loss: 9.6596 - val_loss_1: 0.0777 - val_root_mean_squared_error: 2.2109\n",
      "Epoch 302/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.6402 - loss_1: 0.0774 - root_mean_squared_error: 2.0901 - val_loss: 10.2412 - val_loss_1: 0.0768 - val_root_mean_squared_error: 2.2842\n",
      "Epoch 303/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.3698 - loss_1: 0.0760 - root_mean_squared_error: 2.0530 - val_loss: 10.3230 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.2665\n",
      "Epoch 304/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.7094 - loss_1: 0.0773 - root_mean_squared_error: 2.1144 - val_loss: 9.6179 - val_loss_1: 0.0768 - val_root_mean_squared_error: 2.2136\n",
      "Epoch 305/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.4538 - loss_1: 0.0765 - root_mean_squared_error: 2.0814 - val_loss: 9.8226 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.2206\n",
      "Epoch 306/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.7835 - loss_1: 0.0765 - root_mean_squared_error: 2.0928 - val_loss: 9.8275 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.2366\n",
      "Epoch 307/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.5445 - loss_1: 0.0775 - root_mean_squared_error: 2.0889 - val_loss: 9.7371 - val_loss_1: 0.0766 - val_root_mean_squared_error: 2.2046\n",
      "Epoch 308/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.5194 - loss_1: 0.0765 - root_mean_squared_error: 2.0744 - val_loss: 9.0321 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.1536\n",
      "Epoch 309/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.3924 - loss_1: 0.0773 - root_mean_squared_error: 2.0646 - val_loss: 9.8174 - val_loss_1: 0.0779 - val_root_mean_squared_error: 2.2177\n",
      "Epoch 310/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3581 - loss_1: 0.0765 - root_mean_squared_error: 2.0512 - val_loss: 9.4533 - val_loss_1: 0.0766 - val_root_mean_squared_error: 2.1962\n",
      "Epoch 311/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5587 - loss_1: 0.0764 - root_mean_squared_error: 2.0727 - val_loss: 9.9786 - val_loss_1: 0.0769 - val_root_mean_squared_error: 2.2365\n",
      "Epoch 312/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.3133 - loss_1: 0.0764 - root_mean_squared_error: 2.0568 - val_loss: 9.4662 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.2169\n",
      "Epoch 313/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2321 - loss_1: 0.0758 - root_mean_squared_error: 2.0387 - val_loss: 9.8479 - val_loss_1: 0.0768 - val_root_mean_squared_error: 2.2408\n",
      "Epoch 314/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.7494 - loss_1: 0.0765 - root_mean_squared_error: 2.0943 - val_loss: 9.2856 - val_loss_1: 0.0766 - val_root_mean_squared_error: 2.1982\n",
      "Epoch 315/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3657 - loss_1: 0.0768 - root_mean_squared_error: 2.0660 - val_loss: 9.6729 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.2232\n",
      "Epoch 316/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.5220 - loss_1: 0.0770 - root_mean_squared_error: 2.0837 - val_loss: 9.7749 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.2176\n",
      "Epoch 317/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3278 - loss_1: 0.0768 - root_mean_squared_error: 2.0527 - val_loss: 9.6159 - val_loss_1: 0.0761 - val_root_mean_squared_error: 2.2191\n",
      "Epoch 318/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.6010 - loss_1: 0.0759 - root_mean_squared_error: 2.0729 - val_loss: 9.5115 - val_loss_1: 0.0772 - val_root_mean_squared_error: 2.2161\n",
      "Epoch 319/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.4931 - loss_1: 0.0764 - root_mean_squared_error: 2.0724 - val_loss: 9.7510 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.2199\n",
      "Epoch 320/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.4766 - loss_1: 0.0763 - root_mean_squared_error: 2.0837 - val_loss: 9.0110 - val_loss_1: 0.0752 - val_root_mean_squared_error: 2.1286\n",
      "Epoch 321/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3042 - loss_1: 0.0756 - root_mean_squared_error: 2.0507 - val_loss: 9.4733 - val_loss_1: 0.0768 - val_root_mean_squared_error: 2.2061\n",
      "Epoch 322/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3000 - loss_1: 0.0768 - root_mean_squared_error: 2.0591 - val_loss: 9.2190 - val_loss_1: 0.0773 - val_root_mean_squared_error: 2.1570\n",
      "Epoch 323/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.4047 - loss_1: 0.0766 - root_mean_squared_error: 2.0666 - val_loss: 9.2477 - val_loss_1: 0.0757 - val_root_mean_squared_error: 2.1586\n",
      "Epoch 324/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.4823 - loss_1: 0.0760 - root_mean_squared_error: 2.0659 - val_loss: 9.4918 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.2138\n",
      "Epoch 325/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2976 - loss_1: 0.0759 - root_mean_squared_error: 2.0552 - val_loss: 9.3990 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.1967\n",
      "Epoch 326/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.4411 - loss_1: 0.0754 - root_mean_squared_error: 2.0498 - val_loss: 9.2509 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.1867\n",
      "Epoch 327/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.3835 - loss_1: 0.0766 - root_mean_squared_error: 2.0541 - val_loss: 9.6135 - val_loss_1: 0.0764 - val_root_mean_squared_error: 2.2053\n",
      "Epoch 328/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.3589 - loss_1: 0.0760 - root_mean_squared_error: 2.0524 - val_loss: 9.6626 - val_loss_1: 0.0756 - val_root_mean_squared_error: 2.2100\n",
      "Epoch 329/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.4982 - loss_1: 0.0757 - root_mean_squared_error: 2.0862 - val_loss: 9.3519 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.1794\n",
      "Epoch 330/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.2985 - loss_1: 0.0769 - root_mean_squared_error: 2.0544 - val_loss: 9.4278 - val_loss_1: 0.0757 - val_root_mean_squared_error: 2.1548\n",
      "Epoch 331/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2533 - loss_1: 0.0756 - root_mean_squared_error: 2.0431 - val_loss: 9.6671 - val_loss_1: 0.0757 - val_root_mean_squared_error: 2.2051\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.6902 - loss_1: 0.0757 - root_mean_squared_error: 2.0923 - val_loss: 9.2709 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.1792\n",
      "Epoch 333/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.2630 - loss_1: 0.0755 - root_mean_squared_error: 2.0373 - val_loss: 9.4963 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.2017\n",
      "Epoch 334/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2929 - loss_1: 0.0756 - root_mean_squared_error: 2.0591 - val_loss: 9.1506 - val_loss_1: 0.0753 - val_root_mean_squared_error: 2.1520\n",
      "Epoch 335/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.3352 - loss_1: 0.0759 - root_mean_squared_error: 2.0617 - val_loss: 9.4468 - val_loss_1: 0.0753 - val_root_mean_squared_error: 2.1968\n",
      "Epoch 336/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3037 - loss_1: 0.0762 - root_mean_squared_error: 2.0484 - val_loss: 9.7337 - val_loss_1: 0.0761 - val_root_mean_squared_error: 2.2097\n",
      "Epoch 337/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.2048 - loss_1: 0.0765 - root_mean_squared_error: 2.0443 - val_loss: 9.6030 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.2196\n",
      "Epoch 338/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.1029 - loss_1: 0.0760 - root_mean_squared_error: 2.0247 - val_loss: 9.6007 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.2114\n",
      "Epoch 339/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1635 - loss_1: 0.0758 - root_mean_squared_error: 2.0368 - val_loss: 9.2392 - val_loss_1: 0.0757 - val_root_mean_squared_error: 2.1814\n",
      "Epoch 340/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.3841 - loss_1: 0.0755 - root_mean_squared_error: 2.0616 - val_loss: 9.7248 - val_loss_1: 0.0759 - val_root_mean_squared_error: 2.2489\n",
      "Epoch 341/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.2306 - loss_1: 0.0761 - root_mean_squared_error: 2.0460 - val_loss: 9.6339 - val_loss_1: 0.0761 - val_root_mean_squared_error: 2.2154\n",
      "Epoch 342/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0444 - loss_1: 0.0759 - root_mean_squared_error: 2.0249 - val_loss: 8.9277 - val_loss_1: 0.0752 - val_root_mean_squared_error: 2.1359\n",
      "Epoch 343/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1543 - loss_1: 0.0757 - root_mean_squared_error: 2.0386 - val_loss: 9.5571 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.2062\n",
      "Epoch 344/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0612 - loss_1: 0.0758 - root_mean_squared_error: 2.0218 - val_loss: 9.9520 - val_loss_1: 0.0764 - val_root_mean_squared_error: 2.2302\n",
      "Epoch 345/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.3552 - loss_1: 0.0765 - root_mean_squared_error: 2.0501 - val_loss: 9.0541 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.1607\n",
      "Epoch 346/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1975 - loss_1: 0.0755 - root_mean_squared_error: 2.0327 - val_loss: 9.1326 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.1560\n",
      "Epoch 347/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.3140 - loss_1: 0.0758 - root_mean_squared_error: 2.0547 - val_loss: 9.0881 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.1654\n",
      "Epoch 348/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.2024 - loss_1: 0.0754 - root_mean_squared_error: 2.0398 - val_loss: 9.8649 - val_loss_1: 0.0748 - val_root_mean_squared_error: 2.2192\n",
      "Epoch 349/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2232 - loss_1: 0.0763 - root_mean_squared_error: 2.0492 - val_loss: 9.1853 - val_loss_1: 0.0767 - val_root_mean_squared_error: 2.1383\n",
      "Epoch 350/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3678 - loss_1: 0.0754 - root_mean_squared_error: 2.0550 - val_loss: 9.4474 - val_loss_1: 0.0751 - val_root_mean_squared_error: 2.1676\n",
      "Epoch 351/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.4067 - loss_1: 0.0754 - root_mean_squared_error: 2.0559 - val_loss: 9.3648 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.1781\n",
      "Epoch 352/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.1246 - loss_1: 0.0756 - root_mean_squared_error: 2.0222 - val_loss: 8.8940 - val_loss_1: 0.0745 - val_root_mean_squared_error: 2.1408\n",
      "Epoch 353/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0620 - loss_1: 0.0747 - root_mean_squared_error: 2.0157 - val_loss: 9.0827 - val_loss_1: 0.0765 - val_root_mean_squared_error: 2.1686\n",
      "Epoch 354/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3233 - loss_1: 0.0763 - root_mean_squared_error: 2.0471 - val_loss: 9.2600 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.1867\n",
      "Epoch 355/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.4671 - loss_1: 0.0768 - root_mean_squared_error: 2.0539 - val_loss: 9.4419 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.2178\n",
      "Epoch 356/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3218 - loss_1: 0.0761 - root_mean_squared_error: 2.0536 - val_loss: 9.0448 - val_loss_1: 0.0755 - val_root_mean_squared_error: 2.1350\n",
      "Epoch 357/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9723 - loss_1: 0.0757 - root_mean_squared_error: 2.0064 - val_loss: 9.4379 - val_loss_1: 0.0761 - val_root_mean_squared_error: 2.2145\n",
      "Epoch 358/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.0326 - loss_1: 0.0756 - root_mean_squared_error: 2.0112 - val_loss: 9.3323 - val_loss_1: 0.0754 - val_root_mean_squared_error: 2.1841\n",
      "Epoch 359/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0120 - loss_1: 0.0756 - root_mean_squared_error: 2.0125 - val_loss: 8.7156 - val_loss_1: 0.0755 - val_root_mean_squared_error: 2.0846\n",
      "Epoch 360/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.0952 - loss_1: 0.0751 - root_mean_squared_error: 2.0314 - val_loss: 9.0008 - val_loss_1: 0.0749 - val_root_mean_squared_error: 2.1526\n",
      "Epoch 361/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0039 - loss_1: 0.0754 - root_mean_squared_error: 2.0035 - val_loss: 9.0047 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.1377\n",
      "Epoch 362/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.1258 - loss_1: 0.0756 - root_mean_squared_error: 2.0187 - val_loss: 9.4384 - val_loss_1: 0.0747 - val_root_mean_squared_error: 2.1889\n",
      "Epoch 363/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1607 - loss_1: 0.0750 - root_mean_squared_error: 2.0336 - val_loss: 9.3833 - val_loss_1: 0.0756 - val_root_mean_squared_error: 2.1803\n",
      "Epoch 364/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1333 - loss_1: 0.0747 - root_mean_squared_error: 2.0203 - val_loss: 9.2800 - val_loss_1: 0.0746 - val_root_mean_squared_error: 2.1788\n",
      "Epoch 365/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0591 - loss_1: 0.0747 - root_mean_squared_error: 2.0301 - val_loss: 9.3223 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.1894\n",
      "Epoch 366/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2501 - loss_1: 0.0755 - root_mean_squared_error: 2.0421 - val_loss: 9.4143 - val_loss_1: 0.0755 - val_root_mean_squared_error: 2.1931\n",
      "Epoch 367/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9129 - loss_1: 0.0754 - root_mean_squared_error: 1.9947 - val_loss: 9.4428 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.1872\n",
      "Epoch 368/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2013 - loss_1: 0.0762 - root_mean_squared_error: 2.0318 - val_loss: 9.2521 - val_loss_1: 0.0748 - val_root_mean_squared_error: 2.1555\n",
      "Epoch 369/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0421 - loss_1: 0.0749 - root_mean_squared_error: 2.0114 - val_loss: 9.3615 - val_loss_1: 0.0763 - val_root_mean_squared_error: 2.1681\n",
      "Epoch 370/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.1015 - loss_1: 0.0758 - root_mean_squared_error: 2.0225 - val_loss: 9.9917 - val_loss_1: 0.0757 - val_root_mean_squared_error: 2.2496\n",
      "Epoch 371/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1319 - loss_1: 0.0755 - root_mean_squared_error: 2.0239 - val_loss: 9.7617 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.2224\n",
      "Epoch 372/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0916 - loss_1: 0.0749 - root_mean_squared_error: 2.0209 - val_loss: 9.5763 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.2104\n",
      "Epoch 373/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.1707 - loss_1: 0.0753 - root_mean_squared_error: 2.0183 - val_loss: 9.3698 - val_loss_1: 0.0753 - val_root_mean_squared_error: 2.1890\n",
      "Epoch 374/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.0176 - loss_1: 0.0745 - root_mean_squared_error: 2.0116 - val_loss: 8.9574 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.1360\n",
      "Epoch 375/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8583 - loss_1: 0.0755 - root_mean_squared_error: 2.0049 - val_loss: 9.1400 - val_loss_1: 0.0761 - val_root_mean_squared_error: 2.1741\n",
      "Epoch 376/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.1264 - loss_1: 0.0753 - root_mean_squared_error: 2.0179 - val_loss: 9.4560 - val_loss_1: 0.0743 - val_root_mean_squared_error: 2.1640\n",
      "Epoch 377/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9869 - loss_1: 0.0749 - root_mean_squared_error: 2.0038 - val_loss: 9.3493 - val_loss_1: 0.0756 - val_root_mean_squared_error: 2.1953\n",
      "Epoch 378/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.1287 - loss_1: 0.0766 - root_mean_squared_error: 2.0267 - val_loss: 9.5118 - val_loss_1: 0.0766 - val_root_mean_squared_error: 2.1885\n",
      "Epoch 379/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9562 - loss_1: 0.0751 - root_mean_squared_error: 1.9985 - val_loss: 9.0759 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.1294\n",
      "Epoch 380/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9350 - loss_1: 0.0762 - root_mean_squared_error: 2.0118 - val_loss: 9.4722 - val_loss_1: 0.0771 - val_root_mean_squared_error: 2.1884loss: 7.9058 - loss_1: 0.0759 - root_mean_squared_error: 2.\n",
      "Epoch 381/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0557 - loss_1: 0.0754 - root_mean_squared_error: 2.0181 - val_loss: 8.7941 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.1229\n",
      "Epoch 382/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8696 - loss_1: 0.0750 - root_mean_squared_error: 1.9896 - val_loss: 9.2157 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.1817\n",
      "Epoch 383/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9893 - loss_1: 0.0742 - root_mean_squared_error: 2.0046 - val_loss: 9.4354 - val_loss_1: 0.0733 - val_root_mean_squared_error: 2.1933\n",
      "Epoch 384/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9072 - loss_1: 0.0745 - root_mean_squared_error: 1.9993 - val_loss: 9.0307 - val_loss_1: 0.0749 - val_root_mean_squared_error: 2.1527\n",
      "Epoch 385/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8779 - loss_1: 0.0741 - root_mean_squared_error: 1.9911 - val_loss: 8.8402 - val_loss_1: 0.0739 - val_root_mean_squared_error: 2.1198\n",
      "Epoch 386/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.8018 - loss_1: 0.0757 - root_mean_squared_error: 1.9887 - val_loss: 9.4892 - val_loss_1: 0.0770 - val_root_mean_squared_error: 2.1892\n",
      "Epoch 387/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9420 - loss_1: 0.0754 - root_mean_squared_error: 2.0049 - val_loss: 9.5178 - val_loss_1: 0.0743 - val_root_mean_squared_error: 2.1839\n",
      "Epoch 388/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.9279 - loss_1: 0.0744 - root_mean_squared_error: 2.01 - 1s 75us/step - loss: 7.9059 - loss_1: 0.0745 - root_mean_squared_error: 2.0094 - val_loss: 9.6929 - val_loss_1: 0.0761 - val_root_mean_squared_error: 2.2267\n",
      "Epoch 389/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9504 - loss_1: 0.0758 - root_mean_squared_error: 2.0150 - val_loss: 9.0837 - val_loss_1: 0.0752 - val_root_mean_squared_error: 2.1440\n",
      "Epoch 390/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.8019 - loss_1: 0.0750 - root_mean_squared_error: 1.9951 - val_loss: 8.6959 - val_loss_1: 0.0747 - val_root_mean_squared_error: 2.0855\n",
      "Epoch 391/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8485 - loss_1: 0.0747 - root_mean_squared_error: 2.0047 - val_loss: 9.3909 - val_loss_1: 0.0751 - val_root_mean_squared_error: 2.1769\n",
      "Epoch 392/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6962 - loss_1: 0.0748 - root_mean_squared_error: 1.9800 - val_loss: 9.2568 - val_loss_1: 0.0745 - val_root_mean_squared_error: 2.1395\n",
      "Epoch 393/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.1547 - loss_1: 0.0742 - root_mean_squared_error: 2.0323 - val_loss: 9.1431 - val_loss_1: 0.0753 - val_root_mean_squared_error: 2.1734\n",
      "Epoch 394/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9089 - loss_1: 0.0745 - root_mean_squared_error: 1.9894 - val_loss: 8.6484 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.0965\n",
      "Epoch 395/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.8912 - loss_1: 0.0764 - root_mean_squared_error: 1.9949 - val_loss: 9.3427 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.1977\n",
      "Epoch 396/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.7663 - loss_1: 0.0749 - root_mean_squared_error: 1.9778 - val_loss: 9.1397 - val_loss_1: 0.0744 - val_root_mean_squared_error: 2.1580\n",
      "Epoch 397/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8847 - loss_1: 0.0747 - root_mean_squared_error: 2.0061 - val_loss: 8.9924 - val_loss_1: 0.0745 - val_root_mean_squared_error: 2.1695\n",
      "Epoch 398/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8132 - loss_1: 0.0747 - root_mean_squared_error: 1.9853 - val_loss: 9.1718 - val_loss_1: 0.0747 - val_root_mean_squared_error: 2.1672\n",
      "Epoch 399/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.7665 - loss_1: 0.0748 - root_mean_squared_error: 1.9840 - val_loss: 9.1593 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1685\n",
      "Epoch 400/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8057 - loss_1: 0.0744 - root_mean_squared_error: 1.9888 - val_loss: 9.2918 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.1860\n",
      "Epoch 401/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8363 - loss_1: 0.0754 - root_mean_squared_error: 1.9963 - val_loss: 9.0543 - val_loss_1: 0.0745 - val_root_mean_squared_error: 2.1552\n",
      "Epoch 402/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.7507 - loss_1: 0.0747 - root_mean_squared_error: 1.9788 - val_loss: 9.1914 - val_loss_1: 0.0748 - val_root_mean_squared_error: 2.1571\n",
      "Epoch 403/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6715 - loss_1: 0.0750 - root_mean_squared_error: 1.9727 - val_loss: 9.3051 - val_loss_1: 0.0751 - val_root_mean_squared_error: 2.1731\n",
      "Epoch 404/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8062 - loss_1: 0.0759 - root_mean_squared_error: 1.9961 - val_loss: 9.1142 - val_loss_1: 0.0760 - val_root_mean_squared_error: 2.1624\n",
      "Epoch 405/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0521 - loss_1: 0.0756 - root_mean_squared_error: 2.0003 - val_loss: 8.8844 - val_loss_1: 0.0748 - val_root_mean_squared_error: 2.1212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1125 - loss_1: 0.0746 - root_mean_squared_error: 2.0160 - val_loss: 8.9769 - val_loss_1: 0.0753 - val_root_mean_squared_error: 2.1565\n",
      "Epoch 407/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9145 - loss_1: 0.0758 - root_mean_squared_error: 2.0015 - val_loss: 9.3391 - val_loss_1: 0.0755 - val_root_mean_squared_error: 2.1792\n",
      "Epoch 408/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9453 - loss_1: 0.0741 - root_mean_squared_error: 1.9918 - val_loss: 9.0084 - val_loss_1: 0.0739 - val_root_mean_squared_error: 2.1291\n",
      "Epoch 409/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9143 - loss_1: 0.0747 - root_mean_squared_error: 2.0131 - val_loss: 9.2582 - val_loss_1: 0.0750 - val_root_mean_squared_error: 2.1782\n",
      "Epoch 410/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 7.5759 - loss_1: 0.0742 - root_mean_squared_error: 1.9576 - val_loss: 8.9456 - val_loss_1: 0.0735 - val_root_mean_squared_error: 2.1233\n",
      "Epoch 411/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6132 - loss_1: 0.0742 - root_mean_squared_error: 1.9591 - val_loss: 8.8251 - val_loss_1: 0.0744 - val_root_mean_squared_error: 2.1283\n",
      "Epoch 412/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7869 - loss_1: 0.0737 - root_mean_squared_error: 1.9699 - val_loss: 9.3240 - val_loss_1: 0.0741 - val_root_mean_squared_error: 2.1544\n",
      "Epoch 413/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.8440 - loss_1: 0.0747 - root_mean_squared_error: 1.9935 - val_loss: 8.8065 - val_loss_1: 0.0743 - val_root_mean_squared_error: 2.1195\n",
      "Epoch 414/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7139 - loss_1: 0.0741 - root_mean_squared_error: 1.9711 - val_loss: 8.9555 - val_loss_1: 0.0745 - val_root_mean_squared_error: 2.1135\n",
      "Epoch 415/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.7988 - loss_1: 0.0743 - root_mean_squared_error: 1.9817 - val_loss: 9.2315 - val_loss_1: 0.0758 - val_root_mean_squared_error: 2.1555\n",
      "Epoch 416/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 7.6825 - loss_1: 0.0759 - root_mean_squared_error: 1.9783 - val_loss: 9.3609 - val_loss_1: 0.0752 - val_root_mean_squared_error: 2.1619\n",
      "Epoch 417/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5028 - loss_1: 0.0741 - root_mean_squared_error: 1.9513 - val_loss: 8.9138 - val_loss_1: 0.0741 - val_root_mean_squared_error: 2.1406\n",
      "Epoch 418/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9442 - loss_1: 0.0750 - root_mean_squared_error: 2.0033 - val_loss: 9.1295 - val_loss_1: 0.0762 - val_root_mean_squared_error: 2.1465\n",
      "Epoch 419/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.8466 - loss_1: 0.0752 - root_mean_squared_error: 1.9935 - val_loss: 8.6273 - val_loss_1: 0.0746 - val_root_mean_squared_error: 2.0863\n",
      "Epoch 420/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7651 - loss_1: 0.0745 - root_mean_squared_error: 1.9720 - val_loss: 8.7775 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1043\n",
      "Epoch 421/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6470 - loss_1: 0.0747 - root_mean_squared_error: 1.9647 - val_loss: 9.3261 - val_loss_1: 0.0735 - val_root_mean_squared_error: 2.1736\n",
      "Epoch 422/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7295 - loss_1: 0.0739 - root_mean_squared_error: 1.9782 - val_loss: 9.4406 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1933\n",
      "Epoch 423/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.6774 - loss_1: 0.0744 - root_mean_squared_error: 1.9746 - val_loss: 8.8306 - val_loss_1: 0.0740 - val_root_mean_squared_error: 2.1141\n",
      "Epoch 424/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.6727 - loss_1: 0.0741 - root_mean_squared_error: 1.9785 - val_loss: 8.8023 - val_loss_1: 0.0753 - val_root_mean_squared_error: 2.1017\n",
      "Epoch 425/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4802 - loss_1: 0.0747 - root_mean_squared_error: 1.9347 - val_loss: 8.9047 - val_loss_1: 0.0752 - val_root_mean_squared_error: 2.1303\n",
      "Epoch 426/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.6352 - loss_1: 0.0741 - root_mean_squared_error: 1.9644 - val_loss: 9.3470 - val_loss_1: 0.0746 - val_root_mean_squared_error: 2.1652\n",
      "Epoch 427/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6158 - loss_1: 0.0745 - root_mean_squared_error: 1.9696 - val_loss: 8.9730 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1206\n",
      "Epoch 428/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8204 - loss_1: 0.0738 - root_mean_squared_error: 1.9888 - val_loss: 9.0578 - val_loss_1: 0.0737 - val_root_mean_squared_error: 2.1312\n",
      "Epoch 429/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5682 - loss_1: 0.0743 - root_mean_squared_error: 1.9574 - val_loss: 8.8245 - val_loss_1: 0.0741 - val_root_mean_squared_error: 2.1284\n",
      "Epoch 430/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5115 - loss_1: 0.0741 - root_mean_squared_error: 1.9441 - val_loss: 8.6645 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1014\n",
      "Epoch 431/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6435 - loss_1: 0.0737 - root_mean_squared_error: 1.9687 - val_loss: 9.2337 - val_loss_1: 0.0734 - val_root_mean_squared_error: 2.1567\n",
      "Epoch 432/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5535 - loss_1: 0.0731 - root_mean_squared_error: 1.9562 - val_loss: 9.0946 - val_loss_1: 0.0728 - val_root_mean_squared_error: 2.1274\n",
      "Epoch 433/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5393 - loss_1: 0.0738 - root_mean_squared_error: 1.9476 - val_loss: 9.0008 - val_loss_1: 0.0743 - val_root_mean_squared_error: 2.1341\n",
      "Epoch 434/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7245 - loss_1: 0.0737 - root_mean_squared_error: 1.9809 - val_loss: 8.4037 - val_loss_1: 0.0729 - val_root_mean_squared_error: 2.0454\n",
      "Epoch 435/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5869 - loss_1: 0.0733 - root_mean_squared_error: 1.9628 - val_loss: 8.9490 - val_loss_1: 0.0740 - val_root_mean_squared_error: 2.1242\n",
      "Epoch 436/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8626 - loss_1: 0.0742 - root_mean_squared_error: 1.9803 - val_loss: 9.2713 - val_loss_1: 0.0741 - val_root_mean_squared_error: 2.1833\n",
      "Epoch 437/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5117 - loss_1: 0.0737 - root_mean_squared_error: 1.9525 - val_loss: 9.0671 - val_loss_1: 0.0732 - val_root_mean_squared_error: 2.1262\n",
      "Epoch 438/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5752 - loss_1: 0.0734 - root_mean_squared_error: 1.9483 - val_loss: 8.9831 - val_loss_1: 0.0732 - val_root_mean_squared_error: 2.1497\n",
      "Epoch 439/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5965 - loss_1: 0.0740 - root_mean_squared_error: 1.9771 - val_loss: 8.6027 - val_loss_1: 0.0740 - val_root_mean_squared_error: 2.0809\n",
      "Epoch 440/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5078 - loss_1: 0.0737 - root_mean_squared_error: 1.9459 - val_loss: 8.5791 - val_loss_1: 0.0734 - val_root_mean_squared_error: 2.0797\n",
      "Epoch 441/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5381 - loss_1: 0.0739 - root_mean_squared_error: 1.9466 - val_loss: 8.7876 - val_loss_1: 0.0737 - val_root_mean_squared_error: 2.1060\n",
      "Epoch 442/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5841 - loss_1: 0.0734 - root_mean_squared_error: 1.9641 - val_loss: 8.6583 - val_loss_1: 0.0729 - val_root_mean_squared_error: 2.1140\n",
      "Epoch 443/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 7.5000 - loss_1: 0.0730 - root_mean_squared_error: 1.9530 - val_loss: 8.7082 - val_loss_1: 0.0735 - val_root_mean_squared_error: 2.0990\n",
      "Epoch 444/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5054 - loss_1: 0.0742 - root_mean_squared_error: 1.9398 - val_loss: 9.0510 - val_loss_1: 0.0738 - val_root_mean_squared_error: 2.1590\n",
      "Epoch 445/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5507 - loss_1: 0.0727 - root_mean_squared_error: 1.9620 - val_loss: 8.4292 - val_loss_1: 0.0731 - val_root_mean_squared_error: 2.0981\n",
      "Epoch 446/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 7.4550 - loss_1: 0.0738 - root_mean_squared_error: 1.9270 - val_loss: 9.0956 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1322\n",
      "Epoch 447/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 7.3139 - loss_1: 0.0738 - root_mean_squared_error: 1.9177 - val_loss: 8.5077 - val_loss_1: 0.0730 - val_root_mean_squared_error: 2.0791\n",
      "Epoch 448/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 7.4556 - loss_1: 0.0739 - root_mean_squared_error: 1.9408 - val_loss: 8.7661 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1119\n",
      "Epoch 449/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7369 - loss_1: 0.0732 - root_mean_squared_error: 1.9662 - val_loss: 8.5339 - val_loss_1: 0.0730 - val_root_mean_squared_error: 2.0774\n",
      "Epoch 450/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4483 - loss_1: 0.0728 - root_mean_squared_error: 1.9452 - val_loss: 9.1343 - val_loss_1: 0.0726 - val_root_mean_squared_error: 2.1571\n",
      "Epoch 451/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4281 - loss_1: 0.0730 - root_mean_squared_error: 1.9351 - val_loss: 8.8073 - val_loss_1: 0.0728 - val_root_mean_squared_error: 2.1220\n",
      "Epoch 452/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4325 - loss_1: 0.0725 - root_mean_squared_error: 1.9379 - val_loss: 8.4556 - val_loss_1: 0.0727 - val_root_mean_squared_error: 2.0599\n",
      "Epoch 453/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3827 - loss_1: 0.0731 - root_mean_squared_error: 1.9199 - val_loss: 8.8404 - val_loss_1: 0.0732 - val_root_mean_squared_error: 2.0913\n",
      "Epoch 454/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5527 - loss_1: 0.0736 - root_mean_squared_error: 1.9570 - val_loss: 8.6125 - val_loss_1: 0.0741 - val_root_mean_squared_error: 2.0873\n",
      "Epoch 455/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7231 - loss_1: 0.0735 - root_mean_squared_error: 1.9743 - val_loss: 8.8642 - val_loss_1: 0.0742 - val_root_mean_squared_error: 2.1079\n",
      "Epoch 456/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5802 - loss_1: 0.0739 - root_mean_squared_error: 1.9566 - val_loss: 8.5756 - val_loss_1: 0.0743 - val_root_mean_squared_error: 2.09467.6341 - loss_1: 0.0741 - root_mean_squared_error: \n",
      "Epoch 457/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5076 - loss_1: 0.0731 - root_mean_squared_error: 1.9462 - val_loss: 8.5932 - val_loss_1: 0.0722 - val_root_mean_squared_error: 2.0915\n",
      "Epoch 458/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3929 - loss_1: 0.0733 - root_mean_squared_error: 1.9330 - val_loss: 8.7436 - val_loss_1: 0.0738 - val_root_mean_squared_error: 2.1060\n",
      "Epoch 459/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4965 - loss_1: 0.0736 - root_mean_squared_error: 1.9539 - val_loss: 9.0676 - val_loss_1: 0.0725 - val_root_mean_squared_error: 2.1493\n",
      "Epoch 460/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5948 - loss_1: 0.0735 - root_mean_squared_error: 1.9608 - val_loss: 8.9978 - val_loss_1: 0.0738 - val_root_mean_squared_error: 2.1319\n",
      "Epoch 461/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5221 - loss_1: 0.0731 - root_mean_squared_error: 1.9527 - val_loss: 9.0211 - val_loss_1: 0.0727 - val_root_mean_squared_error: 2.1210\n",
      "Epoch 462/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5093 - loss_1: 0.0729 - root_mean_squared_error: 1.9554 - val_loss: 8.5759 - val_loss_1: 0.0732 - val_root_mean_squared_error: 2.0938\n",
      "Epoch 463/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3428 - loss_1: 0.0737 - root_mean_squared_error: 1.9301 - val_loss: 8.5801 - val_loss_1: 0.0737 - val_root_mean_squared_error: 2.0893\n",
      "Epoch 464/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.4281 - loss_1: 0.0738 - root_mean_squared_error: 1.9447 - val_loss: 8.8463 - val_loss_1: 0.0739 - val_root_mean_squared_error: 2.1164\n",
      "Epoch 465/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3092 - loss_1: 0.0731 - root_mean_squared_error: 1.9216 - val_loss: 8.8452 - val_loss_1: 0.0728 - val_root_mean_squared_error: 2.1129\n",
      "Epoch 466/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3958 - loss_1: 0.0730 - root_mean_squared_error: 1.9346 - val_loss: 8.9951 - val_loss_1: 0.0734 - val_root_mean_squared_error: 2.1415\n",
      "Epoch 467/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1961 - loss_1: 0.0725 - root_mean_squared_error: 1.9010 - val_loss: 8.2486 - val_loss_1: 0.0729 - val_root_mean_squared_error: 2.0360\n",
      "Epoch 468/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3302 - loss_1: 0.0731 - root_mean_squared_error: 1.9278 - val_loss: 8.2117 - val_loss_1: 0.0730 - val_root_mean_squared_error: 2.0299\n",
      "Epoch 469/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6360 - loss_1: 0.0720 - root_mean_squared_error: 1.9639 - val_loss: 8.7921 - val_loss_1: 0.0732 - val_root_mean_squared_error: 2.0960\n",
      "Epoch 470/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4103 - loss_1: 0.0729 - root_mean_squared_error: 1.9341 - val_loss: 8.2704 - val_loss_1: 0.0731 - val_root_mean_squared_error: 2.0327\n",
      "Epoch 471/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2232 - loss_1: 0.0724 - root_mean_squared_error: 1.9061 - val_loss: 8.7110 - val_loss_1: 0.0734 - val_root_mean_squared_error: 2.1019\n",
      "Epoch 472/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4242 - loss_1: 0.0725 - root_mean_squared_error: 1.9344 - val_loss: 8.3336 - val_loss_1: 0.0719 - val_root_mean_squared_error: 2.0383\n",
      "Epoch 473/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5284 - loss_1: 0.0725 - root_mean_squared_error: 1.9483 - val_loss: 8.2179 - val_loss_1: 0.0727 - val_root_mean_squared_error: 2.0431\n",
      "Epoch 474/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6066 - loss_1: 0.0730 - root_mean_squared_error: 1.9516 - val_loss: 9.0678 - val_loss_1: 0.0733 - val_root_mean_squared_error: 2.1246\n",
      "Epoch 475/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2763 - loss_1: 0.0727 - root_mean_squared_error: 1.9163 - val_loss: 8.4454 - val_loss_1: 0.0728 - val_root_mean_squared_error: 2.0737\n",
      "Epoch 476/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4448 - loss_1: 0.0716 - root_mean_squared_error: 1.9380 - val_loss: 8.7317 - val_loss_1: 0.0720 - val_root_mean_squared_error: 2.1184\n",
      "Epoch 477/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1973 - loss_1: 0.0721 - root_mean_squared_error: 1.9123 - val_loss: 8.8927 - val_loss_1: 0.0712 - val_root_mean_squared_error: 2.0992\n",
      "Epoch 478/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2178 - loss_1: 0.0715 - root_mean_squared_error: 1.9138 - val_loss: 8.9325 - val_loss_1: 0.0721 - val_root_mean_squared_error: 2.1167\n",
      "Epoch 479/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2977 - loss_1: 0.0723 - root_mean_squared_error: 1.9151 - val_loss: 8.6766 - val_loss_1: 0.0721 - val_root_mean_squared_error: 2.1007\n",
      "Epoch 480/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3116 - loss_1: 0.0721 - root_mean_squared_error: 1.9125 - val_loss: 8.7869 - val_loss_1: 0.0730 - val_root_mean_squared_error: 2.0935\n",
      "Epoch 481/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4089 - loss_1: 0.0727 - root_mean_squared_error: 1.9425 - val_loss: 8.3621 - val_loss_1: 0.0725 - val_root_mean_squared_error: 2.0703\n",
      "Epoch 482/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2826 - loss_1: 0.0724 - root_mean_squared_error: 1.9136 - val_loss: 8.5037 - val_loss_1: 0.0716 - val_root_mean_squared_error: 2.0818\n",
      "Epoch 483/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.2819 - loss_1: 0.0721 - root_mean_squared_error: 1.91 - 1s 76us/step - loss: 7.3618 - loss_1: 0.0722 - root_mean_squared_error: 1.9271 - val_loss: 8.8734 - val_loss_1: 0.0726 - val_root_mean_squared_error: 2.0830\n",
      "Epoch 484/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3425 - loss_1: 0.0717 - root_mean_squared_error: 1.9286 - val_loss: 8.4333 - val_loss_1: 0.0710 - val_root_mean_squared_error: 2.0364\n",
      "Epoch 485/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2624 - loss_1: 0.0717 - root_mean_squared_error: 1.9117 - val_loss: 8.7011 - val_loss_1: 0.0718 - val_root_mean_squared_error: 2.0848\n",
      "Epoch 486/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3991 - loss_1: 0.0714 - root_mean_squared_error: 1.9250 - val_loss: 9.0781 - val_loss_1: 0.0713 - val_root_mean_squared_error: 2.1349\n",
      "Epoch 487/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3630 - loss_1: 0.0718 - root_mean_squared_error: 1.9284 - val_loss: 8.0513 - val_loss_1: 0.0724 - val_root_mean_squared_error: 2.0159\n",
      "Epoch 488/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3803 - loss_1: 0.0718 - root_mean_squared_error: 1.9167 - val_loss: 8.8813 - val_loss_1: 0.0719 - val_root_mean_squared_error: 2.1265\n",
      "Epoch 489/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.2353 - loss_1: 0.0715 - root_mean_squared_error: 1.9102 - val_loss: 8.4139 - val_loss_1: 0.0713 - val_root_mean_squared_error: 2.0753\n",
      "Epoch 490/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3134 - loss_1: 0.0726 - root_mean_squared_error: 1.9261 - val_loss: 8.3994 - val_loss_1: 0.0718 - val_root_mean_squared_error: 2.0926\n",
      "Epoch 491/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2066 - loss_1: 0.0719 - root_mean_squared_error: 1.9078 - val_loss: 8.1041 - val_loss_1: 0.0720 - val_root_mean_squared_error: 2.0107\n",
      "Epoch 492/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3302 - loss_1: 0.0723 - root_mean_squared_error: 1.9142 - val_loss: 8.0668 - val_loss_1: 0.0718 - val_root_mean_squared_error: 2.0347\n",
      "Epoch 493/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2387 - loss_1: 0.0718 - root_mean_squared_error: 1.9046 - val_loss: 8.6971 - val_loss_1: 0.0711 - val_root_mean_squared_error: 2.0784\n",
      "Epoch 494/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3937 - loss_1: 0.0722 - root_mean_squared_error: 1.9228 - val_loss: 8.8176 - val_loss_1: 0.0723 - val_root_mean_squared_error: 2.1023\n",
      "Epoch 495/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3429 - loss_1: 0.0725 - root_mean_squared_error: 1.9246 - val_loss: 8.9258 - val_loss_1: 0.0728 - val_root_mean_squared_error: 2.1074\n",
      "Epoch 496/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5115 - loss_1: 0.0725 - root_mean_squared_error: 1.9471 - val_loss: 8.8652 - val_loss_1: 0.0729 - val_root_mean_squared_error: 2.1010\n",
      "Epoch 497/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3036 - loss_1: 0.0723 - root_mean_squared_error: 1.9231 - val_loss: 8.3612 - val_loss_1: 0.0719 - val_root_mean_squared_error: 2.0658\n",
      "Epoch 498/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1331 - loss_1: 0.0719 - root_mean_squared_error: 1.8999 - val_loss: 8.8048 - val_loss_1: 0.0726 - val_root_mean_squared_error: 2.0877\n",
      "Epoch 499/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1638 - loss_1: 0.0725 - root_mean_squared_error: 1.8972 - val_loss: 8.6898 - val_loss_1: 0.0720 - val_root_mean_squared_error: 2.0987\n",
      "Epoch 500/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1721 - loss_1: 0.0719 - root_mean_squared_error: 1.9120 - val_loss: 8.8049 - val_loss_1: 0.0720 - val_root_mean_squared_error: 2.1165\n",
      "Epoch 501/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1561 - loss_1: 0.0718 - root_mean_squared_error: 1.8968 - val_loss: 8.7756 - val_loss_1: 0.0713 - val_root_mean_squared_error: 2.1051\n",
      "Epoch 502/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4879 - loss_1: 0.0722 - root_mean_squared_error: 1.9249 - val_loss: 8.5758 - val_loss_1: 0.0729 - val_root_mean_squared_error: 2.0682\n",
      "Epoch 503/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1424 - loss_1: 0.0718 - root_mean_squared_error: 1.9013 - val_loss: 8.0769 - val_loss_1: 0.0714 - val_root_mean_squared_error: 2.0154\n",
      "Epoch 504/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3147 - loss_1: 0.0714 - root_mean_squared_error: 1.9247 - val_loss: 8.7355 - val_loss_1: 0.0727 - val_root_mean_squared_error: 2.1051\n",
      "Epoch 505/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3726 - loss_1: 0.0734 - root_mean_squared_error: 1.9233 - val_loss: 8.5353 - val_loss_1: 0.0721 - val_root_mean_squared_error: 2.0773\n",
      "Epoch 506/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1714 - loss_1: 0.0715 - root_mean_squared_error: 1.9076 - val_loss: 8.3815 - val_loss_1: 0.0715 - val_root_mean_squared_error: 2.0768\n",
      "Epoch 507/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2604 - loss_1: 0.0719 - root_mean_squared_error: 1.9125 - val_loss: 8.1785 - val_loss_1: 0.0731 - val_root_mean_squared_error: 2.0362\n",
      "Epoch 508/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2717 - loss_1: 0.0719 - root_mean_squared_error: 1.9190 - val_loss: 8.5358 - val_loss_1: 0.0718 - val_root_mean_squared_error: 2.0610\n",
      "Epoch 509/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1896 - loss_1: 0.0725 - root_mean_squared_error: 1.9061 - val_loss: 8.7244 - val_loss_1: 0.0724 - val_root_mean_squared_error: 2.1071\n",
      "Epoch 510/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2228 - loss_1: 0.0717 - root_mean_squared_error: 1.9069 - val_loss: 8.7751 - val_loss_1: 0.0707 - val_root_mean_squared_error: 2.1187\n",
      "Epoch 511/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1938 - loss_1: 0.0713 - root_mean_squared_error: 1.9045 - val_loss: 8.3758 - val_loss_1: 0.0713 - val_root_mean_squared_error: 2.0191\n",
      "Epoch 512/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3266 - loss_1: 0.0719 - root_mean_squared_error: 1.9199 - val_loss: 8.3789 - val_loss_1: 0.0727 - val_root_mean_squared_error: 2.0439\n",
      "Epoch 513/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.2144 - loss_1: 0.0721 - root_mean_squared_error: 1.8967 - val_loss: 8.3007 - val_loss_1: 0.0724 - val_root_mean_squared_error: 2.0285\n",
      "Epoch 514/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1910 - loss_1: 0.0711 - root_mean_squared_error: 1.8947 - val_loss: 8.6917 - val_loss_1: 0.0716 - val_root_mean_squared_error: 2.0927\n",
      "Epoch 515/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.0667 - loss_1: 0.0718 - root_mean_squared_error: 1.8926 - val_loss: 8.5633 - val_loss_1: 0.0722 - val_root_mean_squared_error: 2.0974\n",
      "Epoch 516/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3054 - loss_1: 0.0719 - root_mean_squared_error: 1.9065 - val_loss: 8.6605 - val_loss_1: 0.0718 - val_root_mean_squared_error: 2.0893\n",
      "Epoch 517/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.0673 - loss_1: 0.0720 - root_mean_squared_error: 1.8994 - val_loss: 8.4030 - val_loss_1: 0.0709 - val_root_mean_squared_error: 2.0486\n",
      "Epoch 518/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.2896 - loss_1: 0.0708 - root_mean_squared_error: 1.9174 - val_loss: 8.6791 - val_loss_1: 0.0714 - val_root_mean_squared_error: 2.1105\n",
      "Epoch 519/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0830 - loss_1: 0.0714 - root_mean_squared_error: 1.8887 - val_loss: 8.1582 - val_loss_1: 0.0716 - val_root_mean_squared_error: 2.0052\n",
      "Epoch 520/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9809 - loss_1: 0.0717 - root_mean_squared_error: 1.8750 - val_loss: 8.2532 - val_loss_1: 0.0718 - val_root_mean_squared_error: 2.0464\n",
      "Epoch 521/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1222 - loss_1: 0.0714 - root_mean_squared_error: 1.8974 - val_loss: 8.3454 - val_loss_1: 0.0724 - val_root_mean_squared_error: 2.0347\n",
      "Epoch 522/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0662 - loss_1: 0.0713 - root_mean_squared_error: 1.8935 - val_loss: 8.6514 - val_loss_1: 0.0716 - val_root_mean_squared_error: 2.0741\n",
      "Epoch 523/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1369 - loss_1: 0.0719 - root_mean_squared_error: 1.9089 - val_loss: 8.1373 - val_loss_1: 0.0711 - val_root_mean_squared_error: 2.0249\n",
      "Epoch 524/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2051 - loss_1: 0.0715 - root_mean_squared_error: 1.8999 - val_loss: 8.7008 - val_loss_1: 0.0712 - val_root_mean_squared_error: 2.0818\n",
      "Epoch 525/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3064 - loss_1: 0.0712 - root_mean_squared_error: 1.9156 - val_loss: 8.5187 - val_loss_1: 0.0707 - val_root_mean_squared_error: 2.0645\n",
      "Epoch 526/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2009 - loss_1: 0.0703 - root_mean_squared_error: 1.9093 - val_loss: 8.1799 - val_loss_1: 0.0708 - val_root_mean_squared_error: 2.0299\n",
      "Epoch 527/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1142 - loss_1: 0.0713 - root_mean_squared_error: 1.9015 - val_loss: 8.3645 - val_loss_1: 0.0708 - val_root_mean_squared_error: 2.0521\n",
      "Epoch 528/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.2510 - loss_1: 0.0710 - root_mean_squared_error: 1.9118 - val_loss: 8.2922 - val_loss_1: 0.0715 - val_root_mean_squared_error: 2.0348\n",
      "Epoch 529/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9488 - loss_1: 0.0711 - root_mean_squared_error: 1.8784 - val_loss: 8.3124 - val_loss_1: 0.0700 - val_root_mean_squared_error: 2.0269\n",
      "Epoch 530/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0356 - loss_1: 0.0701 - root_mean_squared_error: 1.8845 - val_loss: 8.0784 - val_loss_1: 0.0719 - val_root_mean_squared_error: 1.9980\n",
      "Epoch 531/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2244 - loss_1: 0.0715 - root_mean_squared_error: 1.9089 - val_loss: 8.5014 - val_loss_1: 0.0704 - val_root_mean_squared_error: 2.0465\n",
      "Epoch 532/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9984 - loss_1: 0.0699 - root_mean_squared_error: 1.8845 - val_loss: 8.5713 - val_loss_1: 0.0705 - val_root_mean_squared_error: 2.0640\n",
      "Epoch 533/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1300 - loss_1: 0.0710 - root_mean_squared_error: 1.8844 - val_loss: 8.3187 - val_loss_1: 0.0716 - val_root_mean_squared_error: 2.0313\n",
      "Epoch 534/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9222 - loss_1: 0.0708 - root_mean_squared_error: 1.8740 - val_loss: 8.5311 - val_loss_1: 0.0710 - val_root_mean_squared_error: 2.0742\n",
      "Epoch 535/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.8839 - loss_1: 0.0710 - root_mean_squared_error: 1.8703 - val_loss: 8.4483 - val_loss_1: 0.0707 - val_root_mean_squared_error: 2.0672\n",
      "Epoch 536/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2969 - loss_1: 0.0705 - root_mean_squared_error: 1.9170 - val_loss: 8.2621 - val_loss_1: 0.0717 - val_root_mean_squared_error: 2.0391\n",
      "Epoch 537/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1704 - loss_1: 0.0711 - root_mean_squared_error: 1.9064 - val_loss: 7.8606 - val_loss_1: 0.0707 - val_root_mean_squared_error: 1.9959\n",
      "Epoch 538/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9959 - loss_1: 0.0699 - root_mean_squared_error: 1.8755 - val_loss: 8.4924 - val_loss_1: 0.0700 - val_root_mean_squared_error: 2.0663\n",
      "Epoch 539/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3525 - loss_1: 0.0702 - root_mean_squared_error: 1.9116 - val_loss: 8.3748 - val_loss_1: 0.0706 - val_root_mean_squared_error: 2.0438\n",
      "Epoch 540/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7522 - loss_1: 0.0705 - root_mean_squared_error: 1.8508 - val_loss: 7.9780 - val_loss_1: 0.0696 - val_root_mean_squared_error: 1.9849\n",
      "Epoch 541/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2106 - loss_1: 0.0695 - root_mean_squared_error: 1.9041 - val_loss: 8.2816 - val_loss_1: 0.0692 - val_root_mean_squared_error: 2.0386\n",
      "Epoch 542/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1703 - loss_1: 0.0703 - root_mean_squared_error: 1.8833 - val_loss: 8.2726 - val_loss_1: 0.0710 - val_root_mean_squared_error: 2.0335\n",
      "Epoch 543/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8747 - loss_1: 0.0701 - root_mean_squared_error: 1.8682 - val_loss: 8.0549 - val_loss_1: 0.0697 - val_root_mean_squared_error: 2.0230\n",
      "Epoch 544/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1715 - loss_1: 0.0699 - root_mean_squared_error: 1.9057 - val_loss: 8.7097 - val_loss_1: 0.0709 - val_root_mean_squared_error: 2.1095\n",
      "Epoch 545/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1319 - loss_1: 0.0701 - root_mean_squared_error: 1.8916 - val_loss: 7.8149 - val_loss_1: 0.0701 - val_root_mean_squared_error: 1.9687\n",
      "Epoch 546/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.8252 - loss_1: 0.0708 - root_mean_squared_error: 1.8473 - val_loss: 8.0494 - val_loss_1: 0.0704 - val_root_mean_squared_error: 2.0123\n",
      "Epoch 547/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9576 - loss_1: 0.0708 - root_mean_squared_error: 1.8766 - val_loss: 8.1867 - val_loss_1: 0.0711 - val_root_mean_squared_error: 2.0180\n",
      "Epoch 548/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8176 - loss_1: 0.0704 - root_mean_squared_error: 1.8617 - val_loss: 7.9816 - val_loss_1: 0.0703 - val_root_mean_squared_error: 2.0025\n",
      "Epoch 549/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8685 - loss_1: 0.0708 - root_mean_squared_error: 1.8709 - val_loss: 8.4642 - val_loss_1: 0.0708 - val_root_mean_squared_error: 2.0185\n",
      "Epoch 550/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0799 - loss_1: 0.0710 - root_mean_squared_error: 1.8877 - val_loss: 8.3573 - val_loss_1: 0.0696 - val_root_mean_squared_error: 2.0512\n",
      "Epoch 551/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9985 - loss_1: 0.0698 - root_mean_squared_error: 1.8801 - val_loss: 8.2091 - val_loss_1: 0.0703 - val_root_mean_squared_error: 2.0364\n",
      "Epoch 552/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9534 - loss_1: 0.0701 - root_mean_squared_error: 1.8738 - val_loss: 8.5199 - val_loss_1: 0.0692 - val_root_mean_squared_error: 2.0515\n",
      "Epoch 553/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7460 - loss_1: 0.0694 - root_mean_squared_error: 1.8407 - val_loss: 8.7594 - val_loss_1: 0.0701 - val_root_mean_squared_error: 2.0834\n",
      "Epoch 554/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0465 - loss_1: 0.0708 - root_mean_squared_error: 1.8865 - val_loss: 8.4086 - val_loss_1: 0.0703 - val_root_mean_squared_error: 2.0459\n",
      "Epoch 555/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.8479 - loss_1: 0.0704 - root_mean_squared_error: 1.85 - 1s 76us/step - loss: 6.8627 - loss_1: 0.0705 - root_mean_squared_error: 1.8553 - val_loss: 7.9168 - val_loss_1: 0.0707 - val_root_mean_squared_error: 1.9852\n",
      "Epoch 556/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9165 - loss_1: 0.0700 - root_mean_squared_error: 1.8693 - val_loss: 7.7998 - val_loss_1: 0.0700 - val_root_mean_squared_error: 1.9793\n",
      "Epoch 557/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8368 - loss_1: 0.0692 - root_mean_squared_error: 1.8607 - val_loss: 7.9637 - val_loss_1: 0.0698 - val_root_mean_squared_error: 1.9977\n",
      "Epoch 558/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9728 - loss_1: 0.0710 - root_mean_squared_error: 1.8809 - val_loss: 8.1549 - val_loss_1: 0.0717 - val_root_mean_squared_error: 2.0283\n",
      "Epoch 559/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8806 - loss_1: 0.0710 - root_mean_squared_error: 1.8578 - val_loss: 8.0385 - val_loss_1: 0.0699 - val_root_mean_squared_error: 1.9947\n",
      "Epoch 560/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8146 - loss_1: 0.0707 - root_mean_squared_error: 1.8476 - val_loss: 8.3021 - val_loss_1: 0.0702 - val_root_mean_squared_error: 2.0258\n",
      "Epoch 561/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0556 - loss_1: 0.0701 - root_mean_squared_error: 1.8789 - val_loss: 8.0043 - val_loss_1: 0.0699 - val_root_mean_squared_error: 2.0007\n",
      "Epoch 562/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8995 - loss_1: 0.0704 - root_mean_squared_error: 1.8563 - val_loss: 8.3344 - val_loss_1: 0.0702 - val_root_mean_squared_error: 2.0646\n",
      "Epoch 563/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9574 - loss_1: 0.0699 - root_mean_squared_error: 1.8676 - val_loss: 7.8096 - val_loss_1: 0.0691 - val_root_mean_squared_error: 1.9609\n",
      "Epoch 564/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9817 - loss_1: 0.0696 - root_mean_squared_error: 1.8727 - val_loss: 7.9943 - val_loss_1: 0.0701 - val_root_mean_squared_error: 1.9596\n",
      "Epoch 565/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9351 - loss_1: 0.0699 - root_mean_squared_error: 1.8662 - val_loss: 7.8817 - val_loss_1: 0.0691 - val_root_mean_squared_error: 1.9999\n",
      "Epoch 566/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9054 - loss_1: 0.0690 - root_mean_squared_error: 1.8555 - val_loss: 8.1505 - val_loss_1: 0.0692 - val_root_mean_squared_error: 2.0425\n",
      "Epoch 567/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.7087 - loss_1: 0.0693 - root_mean_squared_error: 1.8439 - val_loss: 7.9522 - val_loss_1: 0.0699 - val_root_mean_squared_error: 1.9897\n",
      "Epoch 568/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.0083 - loss_1: 0.0701 - root_mean_squared_error: 1.8682 - val_loss: 7.8299 - val_loss_1: 0.0697 - val_root_mean_squared_error: 1.9867\n",
      "Epoch 569/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8051 - loss_1: 0.0700 - root_mean_squared_error: 1.8526 - val_loss: 7.5153 - val_loss_1: 0.0698 - val_root_mean_squared_error: 1.93387762 - loss_1: 0.0700 - root_mean_squared_error: 1.\n",
      "Epoch 570/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.8372 - loss_1: 0.0697 - root_mean_squared_error: 1.8540 - val_loss: 8.1481 - val_loss_1: 0.0690 - val_root_mean_squared_error: 2.0108\n",
      "Epoch 571/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9879 - loss_1: 0.0690 - root_mean_squared_error: 1.8603 - val_loss: 7.8912 - val_loss_1: 0.0695 - val_root_mean_squared_error: 1.9662\n",
      "Epoch 572/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9286 - loss_1: 0.0703 - root_mean_squared_error: 1.8696 - val_loss: 7.8679 - val_loss_1: 0.0707 - val_root_mean_squared_error: 1.9882\n",
      "Epoch 573/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9321 - loss_1: 0.0697 - root_mean_squared_error: 1.8682 - val_loss: 8.1092 - val_loss_1: 0.0708 - val_root_mean_squared_error: 1.9858\n",
      "Epoch 574/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8997 - loss_1: 0.0706 - root_mean_squared_error: 1.8678 - val_loss: 7.9671 - val_loss_1: 0.0700 - val_root_mean_squared_error: 1.9972\n",
      "Epoch 575/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0431 - loss_1: 0.0702 - root_mean_squared_error: 1.8811 - val_loss: 7.8183 - val_loss_1: 0.0709 - val_root_mean_squared_error: 1.9817\n",
      "Epoch 576/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9151 - loss_1: 0.0704 - root_mean_squared_error: 1.8677 - val_loss: 7.8966 - val_loss_1: 0.0700 - val_root_mean_squared_error: 1.9881\n",
      "Epoch 577/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7446 - loss_1: 0.0697 - root_mean_squared_error: 1.8362 - val_loss: 8.0379 - val_loss_1: 0.0691 - val_root_mean_squared_error: 1.9869\n",
      "Epoch 578/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.8887 - loss_1: 0.0692 - root_mean_squared_error: 1.8523 - val_loss: 8.3114 - val_loss_1: 0.0700 - val_root_mean_squared_error: 2.0240\n",
      "Epoch 579/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8683 - loss_1: 0.0700 - root_mean_squared_error: 1.8587 - val_loss: 8.1098 - val_loss_1: 0.0695 - val_root_mean_squared_error: 1.9933\n",
      "Epoch 580/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.8103 - loss_1: 0.0695 - root_mean_squared_error: 1.8419 - val_loss: 7.7892 - val_loss_1: 0.0698 - val_root_mean_squared_error: 1.9659\n",
      "Epoch 581/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8439 - loss_1: 0.0696 - root_mean_squared_error: 1.8586 - val_loss: 8.0678 - val_loss_1: 0.0698 - val_root_mean_squared_error: 2.0032\n",
      "Epoch 582/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7920 - loss_1: 0.0693 - root_mean_squared_error: 1.8608 - val_loss: 8.0824 - val_loss_1: 0.0687 - val_root_mean_squared_error: 2.0121\n",
      "Epoch 583/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7720 - loss_1: 0.0691 - root_mean_squared_error: 1.8351 - val_loss: 8.2104 - val_loss_1: 0.0695 - val_root_mean_squared_error: 2.0119\n",
      "Epoch 584/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7308 - loss_1: 0.0692 - root_mean_squared_error: 1.8415 - val_loss: 8.1265 - val_loss_1: 0.0688 - val_root_mean_squared_error: 2.0103\n",
      "Epoch 585/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.6430 - loss_1: 0.0694 - root_mean_squared_error: 1.8184 - val_loss: 8.2489 - val_loss_1: 0.0701 - val_root_mean_squared_error: 2.0410\n",
      "Epoch 586/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7179 - loss_1: 0.0699 - root_mean_squared_error: 1.8434 - val_loss: 8.3433 - val_loss_1: 0.0700 - val_root_mean_squared_error: 2.0061\n",
      "Epoch 587/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7021 - loss_1: 0.0695 - root_mean_squared_error: 1.8410 - val_loss: 8.1856 - val_loss_1: 0.0693 - val_root_mean_squared_error: 2.0183\n",
      "Epoch 588/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7553 - loss_1: 0.0693 - root_mean_squared_error: 1.8383 - val_loss: 8.0600 - val_loss_1: 0.0692 - val_root_mean_squared_error: 2.0173\n",
      "Epoch 589/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8005 - loss_1: 0.0687 - root_mean_squared_error: 1.8502 - val_loss: 8.1105 - val_loss_1: 0.0690 - val_root_mean_squared_error: 2.0174\n",
      "Epoch 590/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7749 - loss_1: 0.0698 - root_mean_squared_error: 1.8464 - val_loss: 8.2535 - val_loss_1: 0.0696 - val_root_mean_squared_error: 2.0157\n",
      "Epoch 591/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6992 - loss_1: 0.0690 - root_mean_squared_error: 1.8489 - val_loss: 8.0281 - val_loss_1: 0.0686 - val_root_mean_squared_error: 1.9744\n",
      "Epoch 592/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8551 - loss_1: 0.0693 - root_mean_squared_error: 1.8461 - val_loss: 7.4490 - val_loss_1: 0.0697 - val_root_mean_squared_error: 1.9257\n",
      "Epoch 593/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8148 - loss_1: 0.0697 - root_mean_squared_error: 1.8452 - val_loss: 7.7201 - val_loss_1: 0.0688 - val_root_mean_squared_error: 1.9585\n",
      "Epoch 594/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9543 - loss_1: 0.0690 - root_mean_squared_error: 1.8572 - val_loss: 8.0923 - val_loss_1: 0.0685 - val_root_mean_squared_error: 2.0027\n",
      "Epoch 595/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7227 - loss_1: 0.0692 - root_mean_squared_error: 1.8506 - val_loss: 7.9708 - val_loss_1: 0.0686 - val_root_mean_squared_error: 1.9822\n",
      "Epoch 596/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6781 - loss_1: 0.0693 - root_mean_squared_error: 1.8323 - val_loss: 7.9005 - val_loss_1: 0.0691 - val_root_mean_squared_error: 1.9509\n",
      "Epoch 597/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4915 - loss_1: 0.0687 - root_mean_squared_error: 1.8140 - val_loss: 7.8514 - val_loss_1: 0.0685 - val_root_mean_squared_error: 1.9603\n",
      "Epoch 598/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7983 - loss_1: 0.0690 - root_mean_squared_error: 1.8433 - val_loss: 7.9680 - val_loss_1: 0.0689 - val_root_mean_squared_error: 1.9807\n",
      "Epoch 599/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7952 - loss_1: 0.0686 - root_mean_squared_error: 1.8495 - val_loss: 7.8943 - val_loss_1: 0.0684 - val_root_mean_squared_error: 1.9795\n",
      "Epoch 600/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7028 - loss_1: 0.0681 - root_mean_squared_error: 1.8320 - val_loss: 7.6003 - val_loss_1: 0.0680 - val_root_mean_squared_error: 1.9515\n",
      "Epoch 601/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9004 - loss_1: 0.0695 - root_mean_squared_error: 1.8660 - val_loss: 7.6486 - val_loss_1: 0.0696 - val_root_mean_squared_error: 1.9552\n",
      "Epoch 602/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.7536 - loss_1: 0.0692 - root_mean_squared_error: 1.8365 - val_loss: 7.8215 - val_loss_1: 0.0696 - val_root_mean_squared_error: 1.9647\n",
      "Epoch 603/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6189 - loss_1: 0.0696 - root_mean_squared_error: 1.8177 - val_loss: 7.7579 - val_loss_1: 0.0690 - val_root_mean_squared_error: 1.9623\n",
      "Epoch 604/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8778 - loss_1: 0.0686 - root_mean_squared_error: 1.8511 - val_loss: 7.6059 - val_loss_1: 0.0689 - val_root_mean_squared_error: 1.9046\n",
      "Epoch 605/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7011 - loss_1: 0.0686 - root_mean_squared_error: 1.8374 - val_loss: 7.9007 - val_loss_1: 0.0679 - val_root_mean_squared_error: 2.0042\n",
      "Epoch 606/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8517 - loss_1: 0.0685 - root_mean_squared_error: 1.8602 - val_loss: 8.0606 - val_loss_1: 0.0691 - val_root_mean_squared_error: 1.9940\n",
      "Epoch 607/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.9101 - loss_1: 0.0685 - root_mean_squared_error: 1.8629 - val_loss: 7.7807 - val_loss_1: 0.0684 - val_root_mean_squared_error: 1.9583\n",
      "Epoch 608/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7449 - loss_1: 0.0679 - root_mean_squared_error: 1.8358 - val_loss: 8.2226 - val_loss_1: 0.0669 - val_root_mean_squared_error: 2.0176\n",
      "Epoch 609/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8366 - loss_1: 0.0678 - root_mean_squared_error: 1.8494 - val_loss: 7.7846 - val_loss_1: 0.0677 - val_root_mean_squared_error: 1.9751\n",
      "Epoch 610/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7506 - loss_1: 0.0678 - root_mean_squared_error: 1.8386 - val_loss: 7.5985 - val_loss_1: 0.0683 - val_root_mean_squared_error: 1.9401\n",
      "Epoch 611/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5742 - loss_1: 0.0682 - root_mean_squared_error: 1.8264 - val_loss: 7.8721 - val_loss_1: 0.0677 - val_root_mean_squared_error: 1.9795\n",
      "Epoch 612/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5386 - loss_1: 0.0679 - root_mean_squared_error: 1.8061 - val_loss: 7.7890 - val_loss_1: 0.0697 - val_root_mean_squared_error: 1.9671\n",
      "Epoch 613/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7309 - loss_1: 0.0689 - root_mean_squared_error: 1.8410 - val_loss: 7.7463 - val_loss_1: 0.0680 - val_root_mean_squared_error: 1.9500\n",
      "Epoch 614/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7662 - loss_1: 0.0681 - root_mean_squared_error: 1.8396 - val_loss: 7.6164 - val_loss_1: 0.0683 - val_root_mean_squared_error: 1.9385\n",
      "Epoch 615/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7198 - loss_1: 0.0686 - root_mean_squared_error: 1.8301 - val_loss: 7.8374 - val_loss_1: 0.0687 - val_root_mean_squared_error: 1.9842\n",
      "Epoch 616/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5568 - loss_1: 0.0687 - root_mean_squared_error: 1.8132 - val_loss: 7.9456 - val_loss_1: 0.0676 - val_root_mean_squared_error: 1.9923\n",
      "Epoch 617/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.7230 - loss_1: 0.0685 - root_mean_squared_error: 1.8316 - val_loss: 7.8622 - val_loss_1: 0.0687 - val_root_mean_squared_error: 1.9725\n",
      "Epoch 618/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6267 - loss_1: 0.0683 - root_mean_squared_error: 1.8213 - val_loss: 7.1164 - val_loss_1: 0.0675 - val_root_mean_squared_error: 1.8680\n",
      "Epoch 619/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.6514 - loss_1: 0.0685 - root_mean_squared_error: 1.8200 - val_loss: 7.7501 - val_loss_1: 0.0686 - val_root_mean_squared_error: 1.9521\n",
      "Epoch 620/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6959 - loss_1: 0.0685 - root_mean_squared_error: 1.8207 - val_loss: 7.4189 - val_loss_1: 0.0677 - val_root_mean_squared_error: 1.9132\n",
      "Epoch 621/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7014 - loss_1: 0.0680 - root_mean_squared_error: 1.8273 - val_loss: 7.9782 - val_loss_1: 0.0679 - val_root_mean_squared_error: 1.9827\n",
      "Epoch 622/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.7466 - loss_1: 0.0687 - root_mean_squared_error: 1.8375 - val_loss: 7.6514 - val_loss_1: 0.0685 - val_root_mean_squared_error: 1.9434\n",
      "Epoch 623/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6751 - loss_1: 0.0681 - root_mean_squared_error: 1.8281 - val_loss: 7.7909 - val_loss_1: 0.0680 - val_root_mean_squared_error: 1.9636\n",
      "Epoch 624/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6430 - loss_1: 0.0676 - root_mean_squared_error: 1.8224 - val_loss: 7.5961 - val_loss_1: 0.0673 - val_root_mean_squared_error: 1.9551\n",
      "Epoch 625/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8014 - loss_1: 0.0675 - root_mean_squared_error: 1.8457 - val_loss: 8.1326 - val_loss_1: 0.0673 - val_root_mean_squared_error: 2.0082\n",
      "Epoch 626/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7843 - loss_1: 0.0676 - root_mean_squared_error: 1.8444 - val_loss: 7.7552 - val_loss_1: 0.0676 - val_root_mean_squared_error: 1.9687\n",
      "Epoch 627/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7240 - loss_1: 0.0672 - root_mean_squared_error: 1.8431 - val_loss: 7.5489 - val_loss_1: 0.0676 - val_root_mean_squared_error: 1.9439\n",
      "Epoch 628/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7360 - loss_1: 0.0680 - root_mean_squared_error: 1.8244 - val_loss: 7.7285 - val_loss_1: 0.0681 - val_root_mean_squared_error: 1.9492\n",
      "Epoch 629/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5598 - loss_1: 0.0682 - root_mean_squared_error: 1.8189 - val_loss: 7.9257 - val_loss_1: 0.0674 - val_root_mean_squared_error: 1.9894\n",
      "Epoch 630/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4989 - loss_1: 0.0674 - root_mean_squared_error: 1.8116 - val_loss: 7.7501 - val_loss_1: 0.0677 - val_root_mean_squared_error: 1.9537\n",
      "Epoch 631/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3741 - loss_1: 0.0676 - root_mean_squared_error: 1.7871 - val_loss: 7.2752 - val_loss_1: 0.0673 - val_root_mean_squared_error: 1.9258\n",
      "Epoch 632/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.6197 - loss_1: 0.0679 - root_mean_squared_error: 1.8090 - val_loss: 7.6753 - val_loss_1: 0.0685 - val_root_mean_squared_error: 1.9521\n",
      "Epoch 633/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6430 - loss_1: 0.0684 - root_mean_squared_error: 1.8244 - val_loss: 7.7487 - val_loss_1: 0.0671 - val_root_mean_squared_error: 1.9609\n",
      "Epoch 634/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5893 - loss_1: 0.0669 - root_mean_squared_error: 1.8248 - val_loss: 7.9355 - val_loss_1: 0.0678 - val_root_mean_squared_error: 1.9696\n",
      "Epoch 635/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6017 - loss_1: 0.0676 - root_mean_squared_error: 1.8163 - val_loss: 7.8162 - val_loss_1: 0.0677 - val_root_mean_squared_error: 1.9500\n",
      "Epoch 636/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5582 - loss_1: 0.0676 - root_mean_squared_error: 1.8092 - val_loss: 7.9259 - val_loss_1: 0.0682 - val_root_mean_squared_error: 1.9799\n",
      "Epoch 637/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5813 - loss_1: 0.0670 - root_mean_squared_error: 1.8109 - val_loss: 7.4987 - val_loss_1: 0.0669 - val_root_mean_squared_error: 1.9327\n",
      "Epoch 638/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5162 - loss_1: 0.0672 - root_mean_squared_error: 1.8139 - val_loss: 7.7563 - val_loss_1: 0.0666 - val_root_mean_squared_error: 1.9550- loss: 6.5394 - loss_1: 0.0671 - root_mean_squared_error: 1.\n",
      "Epoch 639/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5974 - loss_1: 0.0671 - root_mean_squared_error: 1.8134 - val_loss: 7.7623 - val_loss_1: 0.0676 - val_root_mean_squared_error: 1.9629\n",
      "Epoch 640/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5692 - loss_1: 0.0679 - root_mean_squared_error: 1.8142 - val_loss: 7.6874 - val_loss_1: 0.0677 - val_root_mean_squared_error: 1.9508\n",
      "Epoch 641/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4564 - loss_1: 0.0673 - root_mean_squared_error: 1.8002 - val_loss: 7.4476 - val_loss_1: 0.0665 - val_root_mean_squared_error: 1.9245\n",
      "Epoch 642/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6785 - loss_1: 0.0677 - root_mean_squared_error: 1.8375 - val_loss: 7.7007 - val_loss_1: 0.0672 - val_root_mean_squared_error: 1.9436\n",
      "Epoch 643/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8957 - loss_1: 0.0672 - root_mean_squared_error: 1.8496 - val_loss: 7.4795 - val_loss_1: 0.0678 - val_root_mean_squared_error: 1.9520\n",
      "Epoch 644/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.4800 - loss_1: 0.0677 - root_mean_squared_error: 1.7971 - val_loss: 7.6878 - val_loss_1: 0.0679 - val_root_mean_squared_error: 1.9429\n",
      "Epoch 645/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4406 - loss_1: 0.0666 - root_mean_squared_error: 1.7948 - val_loss: 7.8093 - val_loss_1: 0.0661 - val_root_mean_squared_error: 1.9562\n",
      "Epoch 646/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5301 - loss_1: 0.0673 - root_mean_squared_error: 1.8092 - val_loss: 8.3317 - val_loss_1: 0.0672 - val_root_mean_squared_error: 2.0139\n",
      "Epoch 647/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5675 - loss_1: 0.0668 - root_mean_squared_error: 1.8138 - val_loss: 7.5851 - val_loss_1: 0.0672 - val_root_mean_squared_error: 1.9349\n",
      "Epoch 648/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5576 - loss_1: 0.0672 - root_mean_squared_error: 1.8104 - val_loss: 7.4790 - val_loss_1: 0.0674 - val_root_mean_squared_error: 1.9122\n",
      "Epoch 649/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5520 - loss_1: 0.0670 - root_mean_squared_error: 1.8024 - val_loss: 7.5121 - val_loss_1: 0.0672 - val_root_mean_squared_error: 1.9205\n",
      "Epoch 650/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5758 - loss_1: 0.0674 - root_mean_squared_error: 1.8090 - val_loss: 7.4356 - val_loss_1: 0.0669 - val_root_mean_squared_error: 1.9419\n",
      "Epoch 651/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6153 - loss_1: 0.0665 - root_mean_squared_error: 1.8235 - val_loss: 7.2380 - val_loss_1: 0.0663 - val_root_mean_squared_error: 1.8896\n",
      "Epoch 652/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5697 - loss_1: 0.0668 - root_mean_squared_error: 1.8104 - val_loss: 8.2518 - val_loss_1: 0.0662 - val_root_mean_squared_error: 2.0279\n",
      "Epoch 653/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4830 - loss_1: 0.0662 - root_mean_squared_error: 1.7968 - val_loss: 7.5723 - val_loss_1: 0.0669 - val_root_mean_squared_error: 1.9303\n",
      "Epoch 654/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4311 - loss_1: 0.0666 - root_mean_squared_error: 1.8022 - val_loss: 7.1574 - val_loss_1: 0.0667 - val_root_mean_squared_error: 1.8790\n",
      "Epoch 655/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5409 - loss_1: 0.0669 - root_mean_squared_error: 1.7925 - val_loss: 7.5405 - val_loss_1: 0.0670 - val_root_mean_squared_error: 1.9203\n",
      "Epoch 656/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3843 - loss_1: 0.0674 - root_mean_squared_error: 1.7873 - val_loss: 7.6624 - val_loss_1: 0.0669 - val_root_mean_squared_error: 1.9259\n",
      "Epoch 657/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6046 - loss_1: 0.0664 - root_mean_squared_error: 1.8157 - val_loss: 7.8642 - val_loss_1: 0.0670 - val_root_mean_squared_error: 1.9581\n",
      "Epoch 658/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.4114 - loss_1: 0.0677 - root_mean_squared_error: 1.7964 - val_loss: 7.4705 - val_loss_1: 0.0669 - val_root_mean_squared_error: 1.9244\n",
      "Epoch 659/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3765 - loss_1: 0.0663 - root_mean_squared_error: 1.7788 - val_loss: 7.3718 - val_loss_1: 0.0664 - val_root_mean_squared_error: 1.8984\n",
      "Epoch 660/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4845 - loss_1: 0.0668 - root_mean_squared_error: 1.8113 - val_loss: 7.6660 - val_loss_1: 0.0666 - val_root_mean_squared_error: 1.9656\n",
      "Epoch 661/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2949 - loss_1: 0.0663 - root_mean_squared_error: 1.7730 - val_loss: 7.4686 - val_loss_1: 0.0667 - val_root_mean_squared_error: 1.9142\n",
      "Epoch 662/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3477 - loss_1: 0.0675 - root_mean_squared_error: 1.7851 - val_loss: 7.8679 - val_loss_1: 0.0676 - val_root_mean_squared_error: 1.9467\n",
      "Epoch 663/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4038 - loss_1: 0.0662 - root_mean_squared_error: 1.7962 - val_loss: 7.6550 - val_loss_1: 0.0666 - val_root_mean_squared_error: 1.9501\n",
      "Epoch 664/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4098 - loss_1: 0.0669 - root_mean_squared_error: 1.7954 - val_loss: 7.1615 - val_loss_1: 0.0662 - val_root_mean_squared_error: 1.8862\n",
      "Epoch 665/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3330 - loss_1: 0.0656 - root_mean_squared_error: 1.7841 - val_loss: 7.8478 - val_loss_1: 0.0664 - val_root_mean_squared_error: 1.9653\n",
      "Epoch 666/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4025 - loss_1: 0.0669 - root_mean_squared_error: 1.7918 - val_loss: 7.5396 - val_loss_1: 0.0671 - val_root_mean_squared_error: 1.9361\n",
      "Epoch 667/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5174 - loss_1: 0.0665 - root_mean_squared_error: 1.8040 - val_loss: 7.3928 - val_loss_1: 0.0661 - val_root_mean_squared_error: 1.9231\n",
      "Epoch 668/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4225 - loss_1: 0.0661 - root_mean_squared_error: 1.7983 - val_loss: 7.6383 - val_loss_1: 0.0662 - val_root_mean_squared_error: 1.9187\n",
      "Epoch 669/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2934 - loss_1: 0.0668 - root_mean_squared_error: 1.7705 - val_loss: 7.6500 - val_loss_1: 0.0664 - val_root_mean_squared_error: 1.9532\n",
      "Epoch 670/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4877 - loss_1: 0.0650 - root_mean_squared_error: 1.7972 - val_loss: 7.4909 - val_loss_1: 0.0649 - val_root_mean_squared_error: 1.9459\n",
      "Epoch 671/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5152 - loss_1: 0.0662 - root_mean_squared_error: 1.8067 - val_loss: 7.2655 - val_loss_1: 0.0658 - val_root_mean_squared_error: 1.8861\n",
      "Epoch 672/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2912 - loss_1: 0.0657 - root_mean_squared_error: 1.7674 - val_loss: 7.7333 - val_loss_1: 0.0661 - val_root_mean_squared_error: 1.9787\n",
      "Epoch 673/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3256 - loss_1: 0.0664 - root_mean_squared_error: 1.7737 - val_loss: 7.5654 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.9435\n",
      "Epoch 674/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4987 - loss_1: 0.0655 - root_mean_squared_error: 1.8008 - val_loss: 7.4313 - val_loss_1: 0.0657 - val_root_mean_squared_error: 1.8959\n",
      "Epoch 675/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2713 - loss_1: 0.0660 - root_mean_squared_error: 1.7820 - val_loss: 7.0478 - val_loss_1: 0.0656 - val_root_mean_squared_error: 1.8660\n",
      "Epoch 676/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3841 - loss_1: 0.0660 - root_mean_squared_error: 1.7763 - val_loss: 7.8882 - val_loss_1: 0.0656 - val_root_mean_squared_error: 1.9667\n",
      "Epoch 677/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3462 - loss_1: 0.0661 - root_mean_squared_error: 1.7793 - val_loss: 7.7229 - val_loss_1: 0.0668 - val_root_mean_squared_error: 1.9452\n",
      "Epoch 678/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2007 - loss_1: 0.0656 - root_mean_squared_error: 1.7633 - val_loss: 7.3591 - val_loss_1: 0.0665 - val_root_mean_squared_error: 1.9054\n",
      "Epoch 679/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4947 - loss_1: 0.0662 - root_mean_squared_error: 1.7930 - val_loss: 7.3383 - val_loss_1: 0.0665 - val_root_mean_squared_error: 1.9211\n",
      "Epoch 680/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5251 - loss_1: 0.0663 - root_mean_squared_error: 1.7926 - val_loss: 7.2735 - val_loss_1: 0.0661 - val_root_mean_squared_error: 1.9007\n",
      "Epoch 681/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3585 - loss_1: 0.0667 - root_mean_squared_error: 1.7808 - val_loss: 7.3376 - val_loss_1: 0.0668 - val_root_mean_squared_error: 1.8863\n",
      "Epoch 682/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3195 - loss_1: 0.0661 - root_mean_squared_error: 1.7807 - val_loss: 7.3781 - val_loss_1: 0.0658 - val_root_mean_squared_error: 1.9104\n",
      "Epoch 683/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3415 - loss_1: 0.0664 - root_mean_squared_error: 1.7750 - val_loss: 7.2181 - val_loss_1: 0.0655 - val_root_mean_squared_error: 1.8870\n",
      "Epoch 684/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2411 - loss_1: 0.0658 - root_mean_squared_error: 1.7712 - val_loss: 7.2263 - val_loss_1: 0.0655 - val_root_mean_squared_error: 1.8981\n",
      "Epoch 685/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3977 - loss_1: 0.0663 - root_mean_squared_error: 1.7948 - val_loss: 7.1987 - val_loss_1: 0.0662 - val_root_mean_squared_error: 1.8931\n",
      "Epoch 686/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.4389 - loss_1: 0.0662 - root_mean_squared_error: 1.79 - 1s 75us/step - loss: 6.4351 - loss_1: 0.0662 - root_mean_squared_error: 1.7939 - val_loss: 7.2627 - val_loss_1: 0.0660 - val_root_mean_squared_error: 1.9011\n",
      "Epoch 687/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3086 - loss_1: 0.0661 - root_mean_squared_error: 1.7723 - val_loss: 7.8103 - val_loss_1: 0.0658 - val_root_mean_squared_error: 1.9591\n",
      "Epoch 688/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2049 - loss_1: 0.0655 - root_mean_squared_error: 1.7559 - val_loss: 7.3369 - val_loss_1: 0.0666 - val_root_mean_squared_error: 1.9196\n",
      "Epoch 689/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3635 - loss_1: 0.0661 - root_mean_squared_error: 1.7756 - val_loss: 7.4334 - val_loss_1: 0.0657 - val_root_mean_squared_error: 1.8887\n",
      "Epoch 690/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2708 - loss_1: 0.0662 - root_mean_squared_error: 1.7745 - val_loss: 7.0133 - val_loss_1: 0.0658 - val_root_mean_squared_error: 1.8877\n",
      "Epoch 691/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3164 - loss_1: 0.0659 - root_mean_squared_error: 1.7756 - val_loss: 7.1506 - val_loss_1: 0.0654 - val_root_mean_squared_error: 1.8937\n",
      "Epoch 692/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1740 - loss_1: 0.0653 - root_mean_squared_error: 1.7483 - val_loss: 7.5501 - val_loss_1: 0.0660 - val_root_mean_squared_error: 1.9286\n",
      "Epoch 693/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.4269 - loss_1: 0.0655 - root_mean_squared_error: 1.7818 - val_loss: 7.1179 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.8874\n",
      "Epoch 694/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2875 - loss_1: 0.0652 - root_mean_squared_error: 1.7642 - val_loss: 7.1333 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.8896\n",
      "Epoch 695/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3423 - loss_1: 0.0649 - root_mean_squared_error: 1.7753 - val_loss: 7.4495 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.9176\n",
      "Epoch 696/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2101 - loss_1: 0.0661 - root_mean_squared_error: 1.7563 - val_loss: 7.6988 - val_loss_1: 0.0669 - val_root_mean_squared_error: 1.9580\n",
      "Epoch 697/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1140 - loss_1: 0.0664 - root_mean_squared_error: 1.7529 - val_loss: 7.3161 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.8943\n",
      "Epoch 698/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2357 - loss_1: 0.0655 - root_mean_squared_error: 1.7664 - val_loss: 7.2948 - val_loss_1: 0.0654 - val_root_mean_squared_error: 1.8930\n",
      "Epoch 699/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2377 - loss_1: 0.0656 - root_mean_squared_error: 1.7712 - val_loss: 7.1920 - val_loss_1: 0.0649 - val_root_mean_squared_error: 1.8926\n",
      "Epoch 700/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2282 - loss_1: 0.0656 - root_mean_squared_error: 1.7576 - val_loss: 7.3318 - val_loss_1: 0.0663 - val_root_mean_squared_error: 1.8993\n",
      "Epoch 701/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1652 - loss_1: 0.0663 - root_mean_squared_error: 1.7574 - val_loss: 7.4145 - val_loss_1: 0.0657 - val_root_mean_squared_error: 1.9149\n",
      "Epoch 702/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2313 - loss_1: 0.0660 - root_mean_squared_error: 1.7715 - val_loss: 7.2844 - val_loss_1: 0.0659 - val_root_mean_squared_error: 1.9115\n",
      "Epoch 703/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.2428 - loss_1: 0.0660 - root_mean_squared_error: 1.7577 - val_loss: 7.3592 - val_loss_1: 0.0658 - val_root_mean_squared_error: 1.9143\n",
      "Epoch 704/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2499 - loss_1: 0.0660 - root_mean_squared_error: 1.7553 - val_loss: 7.2174 - val_loss_1: 0.0661 - val_root_mean_squared_error: 1.8971\n",
      "Epoch 705/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2364 - loss_1: 0.0659 - root_mean_squared_error: 1.7672 - val_loss: 7.0561 - val_loss_1: 0.0664 - val_root_mean_squared_error: 1.8651\n",
      "Epoch 706/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1728 - loss_1: 0.0661 - root_mean_squared_error: 1.7572 - val_loss: 6.8060 - val_loss_1: 0.0664 - val_root_mean_squared_error: 1.8445\n",
      "Epoch 707/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0186 - loss_1: 0.0657 - root_mean_squared_error: 1.7434 - val_loss: 7.6752 - val_loss_1: 0.0660 - val_root_mean_squared_error: 1.9340\n",
      "Epoch 708/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3134 - loss_1: 0.0658 - root_mean_squared_error: 1.7760 - val_loss: 7.5718 - val_loss_1: 0.0658 - val_root_mean_squared_error: 1.9364\n",
      "Epoch 709/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2728 - loss_1: 0.0658 - root_mean_squared_error: 1.7735 - val_loss: 7.3632 - val_loss_1: 0.0657 - val_root_mean_squared_error: 1.8948\n",
      "Epoch 710/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1400 - loss_1: 0.0655 - root_mean_squared_error: 1.7460 - val_loss: 7.2124 - val_loss_1: 0.0660 - val_root_mean_squared_error: 1.8642\n",
      "Epoch 711/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1882 - loss_1: 0.0656 - root_mean_squared_error: 1.7640 - val_loss: 7.2515 - val_loss_1: 0.0659 - val_root_mean_squared_error: 1.8795\n",
      "Epoch 712/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3187 - loss_1: 0.0659 - root_mean_squared_error: 1.7698 - val_loss: 6.8557 - val_loss_1: 0.0663 - val_root_mean_squared_error: 1.8415\n",
      "Epoch 713/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.2551 - loss_1: 0.0648 - root_mean_squared_error: 1.7696 - val_loss: 7.5424 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.9199\n",
      "Epoch 714/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0845 - loss_1: 0.0653 - root_mean_squared_error: 1.7399 - val_loss: 7.1050 - val_loss_1: 0.0654 - val_root_mean_squared_error: 1.8885\n",
      "Epoch 715/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3293 - loss_1: 0.0658 - root_mean_squared_error: 1.7734 - val_loss: 7.3943 - val_loss_1: 0.0657 - val_root_mean_squared_error: 1.9026\n",
      "Epoch 716/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1057 - loss_1: 0.0649 - root_mean_squared_error: 1.7504 - val_loss: 7.2165 - val_loss_1: 0.0656 - val_root_mean_squared_error: 1.8861\n",
      "Epoch 717/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1211 - loss_1: 0.0654 - root_mean_squared_error: 1.7467 - val_loss: 7.0201 - val_loss_1: 0.0659 - val_root_mean_squared_error: 1.8640\n",
      "Epoch 718/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1522 - loss_1: 0.0654 - root_mean_squared_error: 1.7559 - val_loss: 7.3224 - val_loss_1: 0.0657 - val_root_mean_squared_error: 1.9082\n",
      "Epoch 719/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3055 - loss_1: 0.0653 - root_mean_squared_error: 1.7595 - val_loss: 7.3513 - val_loss_1: 0.0650 - val_root_mean_squared_error: 1.8823\n",
      "Epoch 720/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2404 - loss_1: 0.0649 - root_mean_squared_error: 1.7564 - val_loss: 7.3660 - val_loss_1: 0.0644 - val_root_mean_squared_error: 1.8885\n",
      "Epoch 721/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1840 - loss_1: 0.0653 - root_mean_squared_error: 1.7558 - val_loss: 7.2617 - val_loss_1: 0.0657 - val_root_mean_squared_error: 1.8906\n",
      "Epoch 722/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1248 - loss_1: 0.0655 - root_mean_squared_error: 1.7531 - val_loss: 6.8310 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.8521\n",
      "Epoch 723/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0136 - loss_1: 0.0648 - root_mean_squared_error: 1.7293 - val_loss: 7.6347 - val_loss_1: 0.0643 - val_root_mean_squared_error: 1.9267\n",
      "Epoch 724/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1721 - loss_1: 0.0650 - root_mean_squared_error: 1.7631 - val_loss: 6.8839 - val_loss_1: 0.0651 - val_root_mean_squared_error: 1.8405\n",
      "Epoch 725/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1972 - loss_1: 0.0652 - root_mean_squared_error: 1.7593 - val_loss: 6.7401 - val_loss_1: 0.0652 - val_root_mean_squared_error: 1.8378\n",
      "Epoch 726/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1964 - loss_1: 0.0654 - root_mean_squared_error: 1.7558 - val_loss: 7.2393 - val_loss_1: 0.0656 - val_root_mean_squared_error: 1.9115\n",
      "Epoch 727/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0742 - loss_1: 0.0653 - root_mean_squared_error: 1.7372 - val_loss: 7.6736 - val_loss_1: 0.0653 - val_root_mean_squared_error: 1.9531\n",
      "Epoch 728/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1124 - loss_1: 0.0647 - root_mean_squared_error: 1.7446 - val_loss: 7.1794 - val_loss_1: 0.0643 - val_root_mean_squared_error: 1.8793\n",
      "Epoch 729/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1797 - loss_1: 0.0641 - root_mean_squared_error: 1.7473 - val_loss: 6.8891 - val_loss_1: 0.0646 - val_root_mean_squared_error: 1.8507\n",
      "Epoch 730/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1792 - loss_1: 0.0651 - root_mean_squared_error: 1.7458 - val_loss: 7.0771 - val_loss_1: 0.0647 - val_root_mean_squared_error: 1.8699\n",
      "Epoch 731/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1343 - loss_1: 0.0639 - root_mean_squared_error: 1.7500 - val_loss: 7.3433 - val_loss_1: 0.0643 - val_root_mean_squared_error: 1.9136\n",
      "Epoch 732/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1037 - loss_1: 0.0646 - root_mean_squared_error: 1.7455 - val_loss: 7.2448 - val_loss_1: 0.0639 - val_root_mean_squared_error: 1.8818\n",
      "Epoch 733/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0041 - loss_1: 0.0641 - root_mean_squared_error: 1.7334 - val_loss: 7.3309 - val_loss_1: 0.0641 - val_root_mean_squared_error: 1.9092\n",
      "Epoch 734/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0578 - loss_1: 0.0640 - root_mean_squared_error: 1.7211 - val_loss: 7.5397 - val_loss_1: 0.0649 - val_root_mean_squared_error: 1.9252\n",
      "Epoch 735/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0031 - loss_1: 0.0644 - root_mean_squared_error: 1.7275 - val_loss: 7.1951 - val_loss_1: 0.0643 - val_root_mean_squared_error: 1.9014\n",
      "Epoch 736/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9875 - loss_1: 0.0636 - root_mean_squared_error: 1.7285 - val_loss: 7.1893 - val_loss_1: 0.0642 - val_root_mean_squared_error: 1.9018\n",
      "Epoch 737/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0300 - loss_1: 0.0645 - root_mean_squared_error: 1.7345 - val_loss: 7.0304 - val_loss_1: 0.0641 - val_root_mean_squared_error: 1.8833\n",
      "Epoch 738/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1038 - loss_1: 0.0638 - root_mean_squared_error: 1.7488 - val_loss: 7.0682 - val_loss_1: 0.0634 - val_root_mean_squared_error: 1.8809\n",
      "Epoch 739/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0520 - loss_1: 0.0643 - root_mean_squared_error: 1.7353 - val_loss: 7.0762 - val_loss_1: 0.0643 - val_root_mean_squared_error: 1.8849\n",
      "Epoch 740/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0941 - loss_1: 0.0638 - root_mean_squared_error: 1.7332 - val_loss: 7.2598 - val_loss_1: 0.0639 - val_root_mean_squared_error: 1.9064\n",
      "Epoch 741/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0343 - loss_1: 0.0642 - root_mean_squared_error: 1.7372 - val_loss: 6.9670 - val_loss_1: 0.0647 - val_root_mean_squared_error: 1.8480\n",
      "Epoch 742/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0909 - loss_1: 0.0640 - root_mean_squared_error: 1.7471 - val_loss: 7.2868 - val_loss_1: 0.0639 - val_root_mean_squared_error: 1.8879\n",
      "Epoch 743/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1151 - loss_1: 0.0633 - root_mean_squared_error: 1.7500 - val_loss: 6.8825 - val_loss_1: 0.0633 - val_root_mean_squared_error: 1.8542\n",
      "Epoch 744/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.9319 - loss_1: 0.0631 - root_mean_squared_error: 1.7192 - val_loss: 7.6243 - val_loss_1: 0.0633 - val_root_mean_squared_error: 1.9497\n",
      "Epoch 745/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0131 - loss_1: 0.0632 - root_mean_squared_error: 1.7314 - val_loss: 7.0891 - val_loss_1: 0.0636 - val_root_mean_squared_error: 1.8814\n",
      "Epoch 746/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9598 - loss_1: 0.0639 - root_mean_squared_error: 1.7292 - val_loss: 6.9159 - val_loss_1: 0.0626 - val_root_mean_squared_error: 1.8337\n",
      "Epoch 747/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0911 - loss_1: 0.0630 - root_mean_squared_error: 1.7422 - val_loss: 6.8512 - val_loss_1: 0.0631 - val_root_mean_squared_error: 1.8512\n",
      "Epoch 748/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9774 - loss_1: 0.0637 - root_mean_squared_error: 1.7173 - val_loss: 7.0906 - val_loss_1: 0.0638 - val_root_mean_squared_error: 1.8598\n",
      "Epoch 749/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0397 - loss_1: 0.0632 - root_mean_squared_error: 1.7425 - val_loss: 7.1418 - val_loss_1: 0.0637 - val_root_mean_squared_error: 1.8648\n",
      "Epoch 750/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1369 - loss_1: 0.0645 - root_mean_squared_error: 1.7544 - val_loss: 7.0398 - val_loss_1: 0.0644 - val_root_mean_squared_error: 1.8784\n",
      "Epoch 751/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0181 - loss_1: 0.0633 - root_mean_squared_error: 1.7252 - val_loss: 7.0453 - val_loss_1: 0.0629 - val_root_mean_squared_error: 1.8728\n",
      "Epoch 752/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0530 - loss_1: 0.0632 - root_mean_squared_error: 1.7283 - val_loss: 7.3955 - val_loss_1: 0.0641 - val_root_mean_squared_error: 1.9318\n",
      "Epoch 753/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0053 - loss_1: 0.0639 - root_mean_squared_error: 1.7246 - val_loss: 7.3758 - val_loss_1: 0.0641 - val_root_mean_squared_error: 1.9078\n",
      "Epoch 754/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.9528 - loss_1: 0.0633 - root_mean_squared_error: 1.7272 - val_loss: 7.2723 - val_loss_1: 0.0624 - val_root_mean_squared_error: 1.9000\n",
      "Epoch 755/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9881 - loss_1: 0.0631 - root_mean_squared_error: 1.7288 - val_loss: 7.3003 - val_loss_1: 0.0638 - val_root_mean_squared_error: 1.9105\n",
      "Epoch 756/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 5.9185 - loss_1: 0.0639 - root_mean_squared_error: 1.7254 ETA: 0s - loss: 5.8651 - loss_1: 0.0641 - root_mean_squared_e - 1s 75us/step - loss: 5.8763 - loss_1: 0.0638 - root_mean_squared_error: 1.7182 - val_loss: 7.2559 - val_loss_1: 0.0624 - val_root_mean_squared_error: 1.8754\n",
      "Epoch 757/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0154 - loss_1: 0.0619 - root_mean_squared_error: 1.7287 - val_loss: 7.3034 - val_loss_1: 0.0628 - val_root_mean_squared_error: 1.9112\n",
      "Epoch 758/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2347 - loss_1: 0.0630 - root_mean_squared_error: 1.7648 - val_loss: 7.1243 - val_loss_1: 0.0620 - val_root_mean_squared_error: 1.8812\n",
      "Epoch 759/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0146 - loss_1: 0.0619 - root_mean_squared_error: 1.7377 - val_loss: 7.2685 - val_loss_1: 0.0618 - val_root_mean_squared_error: 1.8894\n",
      "Epoch 760/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0510 - loss_1: 0.0628 - root_mean_squared_error: 1.7392 - val_loss: 7.0560 - val_loss_1: 0.0635 - val_root_mean_squared_error: 1.8697\n",
      "Epoch 761/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9360 - loss_1: 0.0629 - root_mean_squared_error: 1.7110 - val_loss: 6.9940 - val_loss_1: 0.0626 - val_root_mean_squared_error: 1.8730\n",
      "Epoch 762/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9620 - loss_1: 0.0626 - root_mean_squared_error: 1.7274 - val_loss: 7.1762 - val_loss_1: 0.0626 - val_root_mean_squared_error: 1.8990\n",
      "Epoch 763/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9381 - loss_1: 0.0625 - root_mean_squared_error: 1.7327 - val_loss: 6.9103 - val_loss_1: 0.0631 - val_root_mean_squared_error: 1.8482\n",
      "Epoch 764/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8254 - loss_1: 0.0622 - root_mean_squared_error: 1.7226 - val_loss: 6.7629 - val_loss_1: 0.0619 - val_root_mean_squared_error: 1.8320\n",
      "Epoch 765/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.8798 - loss_1: 0.0625 - root_mean_squared_error: 1.7188 - val_loss: 7.2317 - val_loss_1: 0.0624 - val_root_mean_squared_error: 1.9091\n",
      "Epoch 766/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0385 - loss_1: 0.0628 - root_mean_squared_error: 1.7318 - val_loss: 7.0913 - val_loss_1: 0.0625 - val_root_mean_squared_error: 1.8722\n",
      "Epoch 767/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0243 - loss_1: 0.0618 - root_mean_squared_error: 1.7326 - val_loss: 7.1132 - val_loss_1: 0.0624 - val_root_mean_squared_error: 1.8711\n",
      "Epoch 768/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8285 - loss_1: 0.0630 - root_mean_squared_error: 1.7050 - val_loss: 6.8073 - val_loss_1: 0.0628 - val_root_mean_squared_error: 1.8432\n",
      "Epoch 769/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.9946 - loss_1: 0.0619 - root_mean_squared_error: 1.7233 - val_loss: 7.0601 - val_loss_1: 0.0617 - val_root_mean_squared_error: 1.8464\n",
      "Epoch 770/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.9495 - loss_1: 0.0626 - root_mean_squared_error: 1.7176 - val_loss: 7.2477 - val_loss_1: 0.0622 - val_root_mean_squared_error: 1.8975\n",
      "Epoch 771/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.7939 - loss_1: 0.0616 - root_mean_squared_error: 1.6966 - val_loss: 7.0854 - val_loss_1: 0.0613 - val_root_mean_squared_error: 1.8828\n",
      "Epoch 772/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8055 - loss_1: 0.0624 - root_mean_squared_error: 1.7068 - val_loss: 6.7154 - val_loss_1: 0.0628 - val_root_mean_squared_error: 1.8381\n",
      "Epoch 773/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.9196 - loss_1: 0.0619 - root_mean_squared_error: 1.6995 - val_loss: 6.8844 - val_loss_1: 0.0614 - val_root_mean_squared_error: 1.8506\n",
      "Epoch 774/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.8508 - loss_1: 0.0628 - root_mean_squared_error: 1.7066 - val_loss: 7.2159 - val_loss_1: 0.0634 - val_root_mean_squared_error: 1.9017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.9384 - loss_1: 0.0626 - root_mean_squared_error: 1.7232 - val_loss: 6.4957 - val_loss_1: 0.0622 - val_root_mean_squared_error: 1.8114\n",
      "Epoch 776/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.8646 - loss_1: 0.0620 - root_mean_squared_error: 1.7020 - val_loss: 6.8252 - val_loss_1: 0.0622 - val_root_mean_squared_error: 1.8544\n",
      "Epoch 777/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.7841 - loss_1: 0.0623 - root_mean_squared_error: 1.7014 - val_loss: 6.8188 - val_loss_1: 0.0623 - val_root_mean_squared_error: 1.8579\n",
      "Epoch 778/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0102 - loss_1: 0.0616 - root_mean_squared_error: 1.7174 - val_loss: 6.8778 - val_loss_1: 0.0617 - val_root_mean_squared_error: 1.8505\n",
      "Epoch 779/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.9122 - loss_1: 0.0619 - root_mean_squared_error: 1.7100 - val_loss: 6.6880 - val_loss_1: 0.0613 - val_root_mean_squared_error: 1.8214\n",
      "Epoch 780/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.7416 - loss_1: 0.0616 - root_mean_squared_error: 1.6897 - val_loss: 6.9807 - val_loss_1: 0.0619 - val_root_mean_squared_error: 1.8664\n",
      "Epoch 781/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.8759 - loss_1: 0.0617 - root_mean_squared_error: 1.7110 - val_loss: 7.1811 - val_loss_1: 0.0608 - val_root_mean_squared_error: 1.8932\n",
      "Epoch 782/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9147 - loss_1: 0.0612 - root_mean_squared_error: 1.7130 - val_loss: 6.8343 - val_loss_1: 0.0614 - val_root_mean_squared_error: 1.8375\n",
      "Epoch 783/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 5.8309 - loss_1: 0.0611 - root_mean_squared_error: 1.6961 - val_loss: 6.8102 - val_loss_1: 0.0617 - val_root_mean_squared_error: 1.8600\n",
      "Epoch 784/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.8525 - loss_1: 0.0622 - root_mean_squared_error: 1.7014 - val_loss: 6.8589 - val_loss_1: 0.0621 - val_root_mean_squared_error: 1.8348\n",
      "Epoch 785/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8311 - loss_1: 0.0614 - root_mean_squared_error: 1.7019 - val_loss: 6.8915 - val_loss_1: 0.0619 - val_root_mean_squared_error: 1.8715\n",
      "Epoch 786/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8099 - loss_1: 0.0620 - root_mean_squared_error: 1.7058 - val_loss: 6.4906 - val_loss_1: 0.0617 - val_root_mean_squared_error: 1.8322\n",
      "Epoch 787/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.6276 - loss_1: 0.0619 - root_mean_squared_error: 1.6745 - val_loss: 7.4881 - val_loss_1: 0.0617 - val_root_mean_squared_error: 1.9086\n",
      "Epoch 788/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.7832 - loss_1: 0.0613 - root_mean_squared_error: 1.6972 - val_loss: 6.8162 - val_loss_1: 0.0606 - val_root_mean_squared_error: 1.8470\n",
      "Epoch 789/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8624 - loss_1: 0.0616 - root_mean_squared_error: 1.7142 - val_loss: 7.0621 - val_loss_1: 0.0603 - val_root_mean_squared_error: 1.8703\n",
      "Epoch 790/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.6709 - loss_1: 0.0607 - root_mean_squared_error: 1.6893 - val_loss: 6.9506 - val_loss_1: 0.0616 - val_root_mean_squared_error: 1.8709\n",
      "Epoch 791/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 5.8853 - loss_1: 0.0619 - root_mean_squared_error: 1.7045 - val_loss: 6.8551 - val_loss_1: 0.0620 - val_root_mean_squared_error: 1.8682\n",
      "Epoch 792/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 5.7851 - loss_1: 0.0606 - root_mean_squared_error: 1.7014 ETA: 0s - loss: 5.7644 - loss_1: 0.0606 - root_mean_squared_error:  - 1s 75us/step - loss: 5.8021 - loss_1: 0.0606 - root_mean_squared_error: 1.7051 - val_loss: 7.2087 - val_loss_1: 0.0615 - val_root_mean_squared_error: 1.8951\n",
      "Epoch 793/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9285 - loss_1: 0.0614 - root_mean_squared_error: 1.7187 - val_loss: 6.9199 - val_loss_1: 0.0613 - val_root_mean_squared_error: 1.8423\n",
      "Epoch 794/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8228 - loss_1: 0.0617 - root_mean_squared_error: 1.6979 - val_loss: 6.9023 - val_loss_1: 0.0616 - val_root_mean_squared_error: 1.8457\n",
      "Epoch 795/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.7770 - loss_1: 0.0619 - root_mean_squared_error: 1.6912 - val_loss: 6.7737 - val_loss_1: 0.0618 - val_root_mean_squared_error: 1.8569\n",
      "Epoch 796/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8319 - loss_1: 0.0622 - root_mean_squared_error: 1.7055 - val_loss: 7.2350 - val_loss_1: 0.0615 - val_root_mean_squared_error: 1.9011\n",
      "Epoch 797/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8471 - loss_1: 0.0612 - root_mean_squared_error: 1.7069 - val_loss: 6.5531 - val_loss_1: 0.0611 - val_root_mean_squared_error: 1.8206\n",
      "Epoch 798/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.7829 - loss_1: 0.0613 - root_mean_squared_error: 1.7057 - val_loss: 6.9279 - val_loss_1: 0.0618 - val_root_mean_squared_error: 1.8646\n",
      "Epoch 799/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.8000 - loss_1: 0.0609 - root_mean_squared_error: 1.6992 - val_loss: 6.7631 - val_loss_1: 0.0607 - val_root_mean_squared_error: 1.8239\n",
      "Epoch 800/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.7512 - loss_1: 0.0608 - root_mean_squared_error: 1.6931 - val_loss: 7.2989 - val_loss_1: 0.0613 - val_root_mean_squared_error: 1.9055\n",
      "Epoch 801/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.8200 - loss_1: 0.0604 - root_mean_squared_error: 1.7121 - val_loss: 6.7841 - val_loss_1: 0.0596 - val_root_mean_squared_error: 1.8369\n",
      "Epoch 802/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.7286 - loss_1: 0.0596 - root_mean_squared_error: 1.6854 - val_loss: 6.8367 - val_loss_1: 0.0605 - val_root_mean_squared_error: 1.8525\n",
      "Epoch 803/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.8070 - loss_1: 0.0605 - root_mean_squared_error: 1.7014 - val_loss: 6.9633 - val_loss_1: 0.0598 - val_root_mean_squared_error: 1.8678\n",
      "Epoch 804/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 5.8910 - loss_1: 0.0598 - root_mean_squared_error: 1.71 - 1s 75us/step - loss: 5.8853 - loss_1: 0.0599 - root_mean_squared_error: 1.7146 - val_loss: 6.9270 - val_loss_1: 0.0599 - val_root_mean_squared_error: 1.8530\n",
      "Epoch 805/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.7561 - loss_1: 0.0601 - root_mean_squared_error: 1.7008 - val_loss: 7.0489 - val_loss_1: 0.0599 - val_root_mean_squared_error: 1.8836\n",
      "Epoch 806/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.7400 - loss_1: 0.0592 - root_mean_squared_error: 1.6944 - val_loss: 6.5944 - val_loss_1: 0.0595 - val_root_mean_squared_error: 1.8413\n",
      "Epoch 807/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.7373 - loss_1: 0.0593 - root_mean_squared_error: 1.7006 - val_loss: 6.8281 - val_loss_1: 0.0588 - val_root_mean_squared_error: 1.8581\n",
      "Epoch 808/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.6497 - loss_1: 0.0586 - root_mean_squared_error: 1.6811 - val_loss: 7.1274 - val_loss_1: 0.0587 - val_root_mean_squared_error: 1.8701\n",
      "Epoch 809/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.7464 - loss_1: 0.0590 - root_mean_squared_error: 1.7047 - val_loss: 7.0482 - val_loss_1: 0.0588 - val_root_mean_squared_error: 1.8875\n",
      "Epoch 810/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.8051 - loss_1: 0.0588 - root_mean_squared_error: 1.6963 - val_loss: 6.6359 - val_loss_1: 0.0592 - val_root_mean_squared_error: 1.8438\n",
      "Epoch 811/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.5660 - loss_1: 0.0593 - root_mean_squared_error: 1.6693 - val_loss: 6.5463 - val_loss_1: 0.0591 - val_root_mean_squared_error: 1.8134\n",
      "Epoch 812/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.6629 - loss_1: 0.0592 - root_mean_squared_error: 1.6751 - val_loss: 6.9438 - val_loss_1: 0.0591 - val_root_mean_squared_error: 1.8785\n",
      "Epoch 813/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.5723 - loss_1: 0.0588 - root_mean_squared_error: 1.6758 - val_loss: 6.3548 - val_loss_1: 0.0584 - val_root_mean_squared_error: 1.7971\n",
      "Epoch 814/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.5068 - loss_1: 0.0581 - root_mean_squared_error: 1.6581 - val_loss: 6.8210 - val_loss_1: 0.0585 - val_root_mean_squared_error: 1.8603\n",
      "Epoch 815/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.5003 - loss_1: 0.0590 - root_mean_squared_error: 1.6596 - val_loss: 7.0871 - val_loss_1: 0.0597 - val_root_mean_squared_error: 1.8965\n",
      "Epoch 816/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.6528 - loss_1: 0.0587 - root_mean_squared_error: 1.6790 - val_loss: 6.7128 - val_loss_1: 0.0579 - val_root_mean_squared_error: 1.8351\n",
      "Epoch 817/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.5617 - loss_1: 0.0584 - root_mean_squared_error: 1.6655 - val_loss: 6.8311 - val_loss_1: 0.0591 - val_root_mean_squared_error: 1.8547\n",
      "Epoch 818/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 5.5847 - loss_1: 0.0584 - root_mean_squared_error: 1.6713 - val_loss: 6.6023 - val_loss_1: 0.0572 - val_root_mean_squared_error: 1.8355\n",
      "Epoch 819/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.6331 - loss_1: 0.0575 - root_mean_squared_error: 1.6663 - val_loss: 6.4075 - val_loss_1: 0.0578 - val_root_mean_squared_error: 1.7746\n",
      "Epoch 820/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.5113 - loss_1: 0.0582 - root_mean_squared_error: 1.6682 - val_loss: 6.4928 - val_loss_1: 0.0578 - val_root_mean_squared_error: 1.8085\n",
      "Epoch 821/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.5854 - loss_1: 0.0569 - root_mean_squared_error: 1.6645 - val_loss: 6.6896 - val_loss_1: 0.0576 - val_root_mean_squared_error: 1.8209\n",
      "Epoch 822/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.5391 - loss_1: 0.0580 - root_mean_squared_error: 1.6607 - val_loss: 6.6221 - val_loss_1: 0.0584 - val_root_mean_squared_error: 1.8291\n",
      "Epoch 823/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.4213 - loss_1: 0.0580 - root_mean_squared_error: 1.6450 - val_loss: 6.6511 - val_loss_1: 0.0572 - val_root_mean_squared_error: 1.8185\n",
      "Epoch 824/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.6157 - loss_1: 0.0577 - root_mean_squared_error: 1.6810 - val_loss: 6.7588 - val_loss_1: 0.0584 - val_root_mean_squared_error: 1.8378\n",
      "Epoch 825/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.5447 - loss_1: 0.0578 - root_mean_squared_error: 1.6522 - val_loss: 6.6912 - val_loss_1: 0.0571 - val_root_mean_squared_error: 1.8379\n",
      "Epoch 826/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.5142 - loss_1: 0.0574 - root_mean_squared_error: 1.6636 - val_loss: 6.3744 - val_loss_1: 0.0584 - val_root_mean_squared_error: 1.7906\n",
      "Epoch 827/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.4248 - loss_1: 0.0582 - root_mean_squared_error: 1.6372 - val_loss: 6.4028 - val_loss_1: 0.0577 - val_root_mean_squared_error: 1.7950\n",
      "Epoch 828/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.5358 - loss_1: 0.0573 - root_mean_squared_error: 1.6555 - val_loss: 6.8977 - val_loss_1: 0.0576 - val_root_mean_squared_error: 1.8455\n",
      "Epoch 829/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2336 - loss_1: 0.0574 - root_mean_squared_error: 1.6242 - val_loss: 6.6745 - val_loss_1: 0.0573 - val_root_mean_squared_error: 1.8196\n",
      "Epoch 830/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.4303 - loss_1: 0.0576 - root_mean_squared_error: 1.6450 - val_loss: 6.7095 - val_loss_1: 0.0577 - val_root_mean_squared_error: 1.8226loss: 5.4515 - loss_1: 0.0573 - root_mean_squared_e\n",
      "Epoch 831/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.4807 - loss_1: 0.0572 - root_mean_squared_error: 1.6475 - val_loss: 6.4980 - val_loss_1: 0.0566 - val_root_mean_squared_error: 1.8209\n",
      "Epoch 832/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.4926 - loss_1: 0.0569 - root_mean_squared_error: 1.6502 - val_loss: 6.4060 - val_loss_1: 0.0564 - val_root_mean_squared_error: 1.7777\n",
      "Epoch 833/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.4848 - loss_1: 0.0570 - root_mean_squared_error: 1.6535 - val_loss: 6.6251 - val_loss_1: 0.0567 - val_root_mean_squared_error: 1.8164\n",
      "Epoch 834/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3636 - loss_1: 0.0562 - root_mean_squared_error: 1.6472 - val_loss: 6.5162 - val_loss_1: 0.0568 - val_root_mean_squared_error: 1.8128\n",
      "Epoch 835/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3325 - loss_1: 0.0572 - root_mean_squared_error: 1.6394 - val_loss: 6.8799 - val_loss_1: 0.0577 - val_root_mean_squared_error: 1.8461\n",
      "Epoch 836/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3036 - loss_1: 0.0571 - root_mean_squared_error: 1.6273 - val_loss: 6.8753 - val_loss_1: 0.0571 - val_root_mean_squared_error: 1.8436\n",
      "Epoch 837/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.4490 - loss_1: 0.0575 - root_mean_squared_error: 1.6410 - val_loss: 6.7073 - val_loss_1: 0.0572 - val_root_mean_squared_error: 1.8392\n",
      "Epoch 838/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.5652 - loss_1: 0.0569 - root_mean_squared_error: 1.6613 - val_loss: 6.7148 - val_loss_1: 0.0570 - val_root_mean_squared_error: 1.8194\n",
      "Epoch 839/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.4046 - loss_1: 0.0570 - root_mean_squared_error: 1.6393 - val_loss: 6.2858 - val_loss_1: 0.0567 - val_root_mean_squared_error: 1.7598\n",
      "Epoch 840/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.3547 - loss_1: 0.0567 - root_mean_squared_error: 1.6329 - val_loss: 6.6276 - val_loss_1: 0.0569 - val_root_mean_squared_error: 1.8096- loss: 5.3652 - loss_1: 0.0566 - root_mean_squared_error: 1.\n",
      "Epoch 841/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.4107 - loss_1: 0.0573 - root_mean_squared_error: 1.6423 - val_loss: 6.9529 - val_loss_1: 0.0577 - val_root_mean_squared_error: 1.8461\n",
      "Epoch 842/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3629 - loss_1: 0.0575 - root_mean_squared_error: 1.6400 - val_loss: 6.5442 - val_loss_1: 0.0567 - val_root_mean_squared_error: 1.8200\n",
      "Epoch 843/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3222 - loss_1: 0.0561 - root_mean_squared_error: 1.6363 - val_loss: 6.4735 - val_loss_1: 0.0559 - val_root_mean_squared_error: 1.7919\n",
      "Epoch 844/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3573 - loss_1: 0.0562 - root_mean_squared_error: 1.6411 - val_loss: 6.5093 - val_loss_1: 0.0561 - val_root_mean_squared_error: 1.7982\n",
      "Epoch 845/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.2848 - loss_1: 0.0568 - root_mean_squared_error: 1.6211 - val_loss: 6.4530 - val_loss_1: 0.0572 - val_root_mean_squared_error: 1.7919\n",
      "Epoch 846/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2463 - loss_1: 0.0570 - root_mean_squared_error: 1.6150 - val_loss: 6.5269 - val_loss_1: 0.0567 - val_root_mean_squared_error: 1.8147\n",
      "Epoch 847/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.4660 - loss_1: 0.0564 - root_mean_squared_error: 1.6478 - val_loss: 6.2319 - val_loss_1: 0.0558 - val_root_mean_squared_error: 1.7608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3014 - loss_1: 0.0560 - root_mean_squared_error: 1.6210 - val_loss: 6.3463 - val_loss_1: 0.0560 - val_root_mean_squared_error: 1.7774\n",
      "Epoch 849/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2808 - loss_1: 0.0553 - root_mean_squared_error: 1.6278 - val_loss: 6.2026 - val_loss_1: 0.0554 - val_root_mean_squared_error: 1.7728\n",
      "Epoch 850/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.2554 - loss_1: 0.0566 - root_mean_squared_error: 1.6237 - val_loss: 6.8534 - val_loss_1: 0.0570 - val_root_mean_squared_error: 1.8449\n",
      "Epoch 851/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.4242 - loss_1: 0.0562 - root_mean_squared_error: 1.6490 - val_loss: 6.9768 - val_loss_1: 0.0563 - val_root_mean_squared_error: 1.8503\n",
      "Epoch 852/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3030 - loss_1: 0.0567 - root_mean_squared_error: 1.6185 - val_loss: 6.8822 - val_loss_1: 0.0566 - val_root_mean_squared_error: 1.8172\n",
      "Epoch 853/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2599 - loss_1: 0.0559 - root_mean_squared_error: 1.6220 - val_loss: 6.4539 - val_loss_1: 0.0553 - val_root_mean_squared_error: 1.7975\n",
      "Epoch 854/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.4634 - loss_1: 0.0562 - root_mean_squared_error: 1.6400 - val_loss: 6.6233 - val_loss_1: 0.0568 - val_root_mean_squared_error: 1.8286\n",
      "Epoch 855/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3973 - loss_1: 0.0568 - root_mean_squared_error: 1.6369 - val_loss: 6.4023 - val_loss_1: 0.0560 - val_root_mean_squared_error: 1.7611\n",
      "Epoch 856/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3111 - loss_1: 0.0560 - root_mean_squared_error: 1.6341 - val_loss: 6.5388 - val_loss_1: 0.0568 - val_root_mean_squared_error: 1.7848\n",
      "Epoch 857/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.3270 - loss_1: 0.0564 - root_mean_squared_error: 1.6276 - val_loss: 6.6853 - val_loss_1: 0.0562 - val_root_mean_squared_error: 1.8195\n",
      "Epoch 858/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.2733 - loss_1: 0.0562 - root_mean_squared_error: 1.6171 - val_loss: 6.1830 - val_loss_1: 0.0557 - val_root_mean_squared_error: 1.7809\n",
      "Epoch 859/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.2298 - loss_1: 0.0556 - root_mean_squared_error: 1.6231 - val_loss: 6.4989 - val_loss_1: 0.0558 - val_root_mean_squared_error: 1.8108\n",
      "Epoch 860/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1101 - loss_1: 0.0556 - root_mean_squared_error: 1.5971 - val_loss: 6.1478 - val_loss_1: 0.0559 - val_root_mean_squared_error: 1.7532\n",
      "Epoch 861/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3700 - loss_1: 0.0560 - root_mean_squared_error: 1.6319 - val_loss: 6.6659 - val_loss_1: 0.0570 - val_root_mean_squared_error: 1.8147\n",
      "Epoch 862/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1646 - loss_1: 0.0563 - root_mean_squared_error: 1.6101 - val_loss: 6.3236 - val_loss_1: 0.0556 - val_root_mean_squared_error: 1.7644\n",
      "Epoch 863/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.3151 - loss_1: 0.0561 - root_mean_squared_error: 1.6313 - val_loss: 6.5458 - val_loss_1: 0.0568 - val_root_mean_squared_error: 1.8008\n",
      "Epoch 864/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1918 - loss_1: 0.0569 - root_mean_squared_error: 1.6081 - val_loss: 6.2849 - val_loss_1: 0.0557 - val_root_mean_squared_error: 1.7619\n",
      "Epoch 865/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 5.2099 - loss_1: 0.0557 - root_mean_squared_error: 1.6131 - val_loss: 6.3178 - val_loss_1: 0.0555 - val_root_mean_squared_error: 1.7740\n",
      "Epoch 866/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1444 - loss_1: 0.0560 - root_mean_squared_error: 1.6074 - val_loss: 6.3044 - val_loss_1: 0.0560 - val_root_mean_squared_error: 1.7707\n",
      "Epoch 867/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.3031 - loss_1: 0.0557 - root_mean_squared_error: 1.6226 - val_loss: 6.3154 - val_loss_1: 0.0557 - val_root_mean_squared_error: 1.7788\n",
      "Epoch 868/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 5.2440 - loss_1: 0.0555 - root_mean_squared_error: 1.6166 - val_loss: 6.3332 - val_loss_1: 0.0553 - val_root_mean_squared_error: 1.7808\n",
      "Epoch 869/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2766 - loss_1: 0.0553 - root_mean_squared_error: 1.6272 - val_loss: 6.1825 - val_loss_1: 0.0559 - val_root_mean_squared_error: 1.7592\n",
      "Epoch 870/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1119 - loss_1: 0.0556 - root_mean_squared_error: 1.6067 - val_loss: 6.3236 - val_loss_1: 0.0557 - val_root_mean_squared_error: 1.7760\n",
      "Epoch 871/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.0914 - loss_1: 0.0556 - root_mean_squared_error: 1.6039 - val_loss: 6.4320 - val_loss_1: 0.0557 - val_root_mean_squared_error: 1.7829\n",
      "Epoch 872/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2110 - loss_1: 0.0553 - root_mean_squared_error: 1.6115 - val_loss: 6.5158 - val_loss_1: 0.0553 - val_root_mean_squared_error: 1.7912\n",
      "Epoch 873/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.1981 - loss_1: 0.0556 - root_mean_squared_error: 1.6124 - val_loss: 6.1447 - val_loss_1: 0.0559 - val_root_mean_squared_error: 1.7474\n",
      "Epoch 874/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0853 - loss_1: 0.0552 - root_mean_squared_error: 1.5867 - val_loss: 6.4130 - val_loss_1: 0.0547 - val_root_mean_squared_error: 1.8004\n",
      "Epoch 875/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.2810 - loss_1: 0.0551 - root_mean_squared_error: 1.6181 - val_loss: 6.3352 - val_loss_1: 0.0558 - val_root_mean_squared_error: 1.7926\n",
      "Epoch 876/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.2944 - loss_1: 0.0551 - root_mean_squared_error: 1.6066 - val_loss: 6.3575 - val_loss_1: 0.0551 - val_root_mean_squared_error: 1.7649\n",
      "Epoch 877/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2578 - loss_1: 0.0552 - root_mean_squared_error: 1.6143 - val_loss: 6.3350 - val_loss_1: 0.0558 - val_root_mean_squared_error: 1.7837\n",
      "Epoch 878/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1182 - loss_1: 0.0557 - root_mean_squared_error: 1.6101 - val_loss: 6.3045 - val_loss_1: 0.0553 - val_root_mean_squared_error: 1.7829\n",
      "Epoch 879/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1807 - loss_1: 0.0551 - root_mean_squared_error: 1.6109 - val_loss: 6.4768 - val_loss_1: 0.0553 - val_root_mean_squared_error: 1.7962\n",
      "Epoch 880/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0999 - loss_1: 0.0551 - root_mean_squared_error: 1.5823 - val_loss: 6.3646 - val_loss_1: 0.0549 - val_root_mean_squared_error: 1.7870\n",
      "Epoch 881/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1452 - loss_1: 0.0546 - root_mean_squared_error: 1.6064 - val_loss: 6.3390 - val_loss_1: 0.0542 - val_root_mean_squared_error: 1.7709\n",
      "Epoch 882/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.0714 - loss_1: 0.0552 - root_mean_squared_error: 1.5868 - val_loss: 6.1821 - val_loss_1: 0.0552 - val_root_mean_squared_error: 1.7504\n",
      "Epoch 883/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1689 - loss_1: 0.0551 - root_mean_squared_error: 1.6093 - val_loss: 5.9017 - val_loss_1: 0.0542 - val_root_mean_squared_error: 1.7126\n",
      "Epoch 884/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.1053 - loss_1: 0.0541 - root_mean_squared_error: 1.6004 - val_loss: 5.9442 - val_loss_1: 0.0545 - val_root_mean_squared_error: 1.7112\n",
      "Epoch 885/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1059 - loss_1: 0.0552 - root_mean_squared_error: 1.5953 - val_loss: 6.3414 - val_loss_1: 0.0554 - val_root_mean_squared_error: 1.7880\n",
      "Epoch 886/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1525 - loss_1: 0.0546 - root_mean_squared_error: 1.6123 - val_loss: 6.2746 - val_loss_1: 0.0553 - val_root_mean_squared_error: 1.7630\n",
      "Epoch 887/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1229 - loss_1: 0.0553 - root_mean_squared_error: 1.5909 - val_loss: 6.2887 - val_loss_1: 0.0549 - val_root_mean_squared_error: 1.7606\n",
      "Epoch 888/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.0890 - loss_1: 0.0549 - root_mean_squared_error: 1.5972 - val_loss: 6.1679 - val_loss_1: 0.0548 - val_root_mean_squared_error: 1.7632\n",
      "Epoch 889/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1534 - loss_1: 0.0545 - root_mean_squared_error: 1.5995 - val_loss: 6.5701 - val_loss_1: 0.0539 - val_root_mean_squared_error: 1.7851\n",
      "Epoch 890/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1924 - loss_1: 0.0542 - root_mean_squared_error: 1.6060 - val_loss: 6.2124 - val_loss_1: 0.0547 - val_root_mean_squared_error: 1.7583\n",
      "Epoch 891/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0877 - loss_1: 0.0546 - root_mean_squared_error: 1.6014 - val_loss: 6.3600 - val_loss_1: 0.0543 - val_root_mean_squared_error: 1.7886\n",
      "Epoch 892/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.2310 - loss_1: 0.0545 - root_mean_squared_error: 1.6131 - val_loss: 6.2302 - val_loss_1: 0.0544 - val_root_mean_squared_error: 1.7826\n",
      "Epoch 893/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1751 - loss_1: 0.0551 - root_mean_squared_error: 1.6033 - val_loss: 6.3950 - val_loss_1: 0.0552 - val_root_mean_squared_error: 1.7751\n",
      "Epoch 894/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.0750 - loss_1: 0.0548 - root_mean_squared_error: 1.5955 - val_loss: 6.4192 - val_loss_1: 0.0548 - val_root_mean_squared_error: 1.7851\n",
      "Epoch 895/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.2214 - loss_1: 0.0551 - root_mean_squared_error: 1.6203 - val_loss: 6.2518 - val_loss_1: 0.0548 - val_root_mean_squared_error: 1.7640\n",
      "Epoch 896/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.0747 - loss_1: 0.0543 - root_mean_squared_error: 1.5921 - val_loss: 6.2369 - val_loss_1: 0.0542 - val_root_mean_squared_error: 1.7633\n",
      "Epoch 897/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1420 - loss_1: 0.0546 - root_mean_squared_error: 1.5964 - val_loss: 6.0634 - val_loss_1: 0.0548 - val_root_mean_squared_error: 1.7478\n",
      "Epoch 898/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.0456 - loss_1: 0.0543 - root_mean_squared_error: 1.6011 - val_loss: 6.2292 - val_loss_1: 0.0536 - val_root_mean_squared_error: 1.7594\n",
      "Epoch 899/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.2216 - loss_1: 0.0543 - root_mean_squared_error: 1.6162 - val_loss: 6.0758 - val_loss_1: 0.0544 - val_root_mean_squared_error: 1.7682\n",
      "Epoch 900/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0572 - loss_1: 0.0544 - root_mean_squared_error: 1.5894 - val_loss: 6.4794 - val_loss_1: 0.0541 - val_root_mean_squared_error: 1.7768\n",
      "Epoch 901/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1507 - loss_1: 0.0544 - root_mean_squared_error: 1.6034 - val_loss: 5.8834 - val_loss_1: 0.0548 - val_root_mean_squared_error: 1.7166\n",
      "Epoch 902/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1006 - loss_1: 0.0542 - root_mean_squared_error: 1.5944 - val_loss: 6.6544 - val_loss_1: 0.0539 - val_root_mean_squared_error: 1.8228\n",
      "Epoch 903/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.0277 - loss_1: 0.0541 - root_mean_squared_error: 1.5870 - val_loss: 6.1237 - val_loss_1: 0.0543 - val_root_mean_squared_error: 1.7374\n",
      "Epoch 904/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.9904 - loss_1: 0.0545 - root_mean_squared_error: 1.5804 - val_loss: 6.2985 - val_loss_1: 0.0542 - val_root_mean_squared_error: 1.7641\n",
      "Epoch 905/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0545 - loss_1: 0.0537 - root_mean_squared_error: 1.5878 - val_loss: 6.2073 - val_loss_1: 0.0537 - val_root_mean_squared_error: 1.7710\n",
      "Epoch 906/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8027 - loss_1: 0.0542 - root_mean_squared_error: 1.5645 - val_loss: 6.4423 - val_loss_1: 0.0542 - val_root_mean_squared_error: 1.7643\n",
      "Epoch 907/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1195 - loss_1: 0.0542 - root_mean_squared_error: 1.6086 - val_loss: 6.4354 - val_loss_1: 0.0543 - val_root_mean_squared_error: 1.7956\n",
      "Epoch 908/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8791 - loss_1: 0.0546 - root_mean_squared_error: 1.5691 - val_loss: 6.2388 - val_loss_1: 0.0543 - val_root_mean_squared_error: 1.7861\n",
      "Epoch 909/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.1321 - loss_1: 0.0543 - root_mean_squared_error: 1.5980 - val_loss: 6.1696 - val_loss_1: 0.0541 - val_root_mean_squared_error: 1.7469\n",
      "Epoch 910/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.1220 - loss_1: 0.0546 - root_mean_squared_error: 1.6013 - val_loss: 6.1086 - val_loss_1: 0.0543 - val_root_mean_squared_error: 1.7555\n",
      "Epoch 911/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.9697 - loss_1: 0.0540 - root_mean_squared_error: 1.5721 - val_loss: 6.3297 - val_loss_1: 0.0541 - val_root_mean_squared_error: 1.7637\n",
      "Epoch 912/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.0736 - loss_1: 0.0537 - root_mean_squared_error: 1.5994 - val_loss: 6.3096 - val_loss_1: 0.0548 - val_root_mean_squared_error: 1.7713\n",
      "Epoch 913/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.0246 - loss_1: 0.0546 - root_mean_squared_error: 1.5885 - val_loss: 6.3091 - val_loss_1: 0.0551 - val_root_mean_squared_error: 1.7641\n",
      "Epoch 914/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.9996 - loss_1: 0.0544 - root_mean_squared_error: 1.5914 - val_loss: 6.1679 - val_loss_1: 0.0541 - val_root_mean_squared_error: 1.7550\n",
      "Epoch 915/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 4.9562 - loss_1: 0.0542 - root_mean_squared_error: 1.5831 - val_loss: 6.1069 - val_loss_1: 0.0539 - val_root_mean_squared_error: 1.7570\n",
      "Epoch 916/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.0523 - loss_1: 0.0544 - root_mean_squared_error: 1.5874 - val_loss: 6.1738 - val_loss_1: 0.0544 - val_root_mean_squared_error: 1.7485\n",
      "Epoch 917/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.9047 - loss_1: 0.0535 - root_mean_squared_error: 1.5651 - val_loss: 6.1275 - val_loss_1: 0.0541 - val_root_mean_squared_error: 1.7366\n",
      "Epoch 918/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.1065 - loss_1: 0.0540 - root_mean_squared_error: 1.6007 - val_loss: 6.2624 - val_loss_1: 0.0539 - val_root_mean_squared_error: 1.7704\n",
      "Epoch 919/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0297 - loss_1: 0.0538 - root_mean_squared_error: 1.5828 - val_loss: 6.3875 - val_loss_1: 0.0536 - val_root_mean_squared_error: 1.7881\n",
      "Epoch 920/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.9878 - loss_1: 0.0538 - root_mean_squared_error: 1.5817 - val_loss: 6.0816 - val_loss_1: 0.0530 - val_root_mean_squared_error: 1.7402\n",
      "Epoch 921/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.0265 - loss_1: 0.0532 - root_mean_squared_error: 1.5865 - val_loss: 6.0099 - val_loss_1: 0.0545 - val_root_mean_squared_error: 1.7313\n",
      "Epoch 922/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8490 - loss_1: 0.0536 - root_mean_squared_error: 1.5627 - val_loss: 6.3772 - val_loss_1: 0.0540 - val_root_mean_squared_error: 1.7980\n",
      "Epoch 923/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8730 - loss_1: 0.0535 - root_mean_squared_error: 1.5658 - val_loss: 6.2035 - val_loss_1: 0.0537 - val_root_mean_squared_error: 1.7362\n",
      "Epoch 924/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0310 - loss_1: 0.0536 - root_mean_squared_error: 1.5798 - val_loss: 5.9492 - val_loss_1: 0.0532 - val_root_mean_squared_error: 1.7296\n",
      "Epoch 925/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.9856 - loss_1: 0.0527 - root_mean_squared_error: 1.5790 - val_loss: 5.7326 - val_loss_1: 0.0525 - val_root_mean_squared_error: 1.6988\n",
      "Epoch 926/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.9380 - loss_1: 0.0534 - root_mean_squared_error: 1.5728 - val_loss: 6.3039 - val_loss_1: 0.0531 - val_root_mean_squared_error: 1.7726\n",
      "Epoch 927/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8861 - loss_1: 0.0532 - root_mean_squared_error: 1.5680 - val_loss: 6.0608 - val_loss_1: 0.0528 - val_root_mean_squared_error: 1.7509\n",
      "Epoch 928/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8989 - loss_1: 0.0534 - root_mean_squared_error: 1.5711 - val_loss: 6.1191 - val_loss_1: 0.0535 - val_root_mean_squared_error: 1.7418\n",
      "Epoch 929/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 4.8539 - loss_1: 0.0532 - root_mean_squared_error: 1.56 - 1s 76us/step - loss: 4.8451 - loss_1: 0.0531 - root_mean_squared_error: 1.5589 - val_loss: 6.0025 - val_loss_1: 0.0530 - val_root_mean_squared_error: 1.7417\n",
      "Epoch 930/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8740 - loss_1: 0.0528 - root_mean_squared_error: 1.5607 - val_loss: 6.0655 - val_loss_1: 0.0530 - val_root_mean_squared_error: 1.7393\n",
      "Epoch 931/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.9857 - loss_1: 0.0531 - root_mean_squared_error: 1.5749 - val_loss: 6.2826 - val_loss_1: 0.0536 - val_root_mean_squared_error: 1.7772\n",
      "Epoch 932/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8914 - loss_1: 0.0535 - root_mean_squared_error: 1.5615 - val_loss: 6.0158 - val_loss_1: 0.0536 - val_root_mean_squared_error: 1.7492\n",
      "Epoch 933/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.9231 - loss_1: 0.0535 - root_mean_squared_error: 1.5721 - val_loss: 6.0018 - val_loss_1: 0.0533 - val_root_mean_squared_error: 1.7360\n",
      "Epoch 934/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8244 - loss_1: 0.0535 - root_mean_squared_error: 1.5588 - val_loss: 6.0997 - val_loss_1: 0.0531 - val_root_mean_squared_error: 1.7347\n",
      "Epoch 935/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8866 - loss_1: 0.0533 - root_mean_squared_error: 1.5718 - val_loss: 6.1320 - val_loss_1: 0.0534 - val_root_mean_squared_error: 1.7531\n",
      "Epoch 936/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8938 - loss_1: 0.0536 - root_mean_squared_error: 1.5688 - val_loss: 6.1030 - val_loss_1: 0.0539 - val_root_mean_squared_error: 1.7569\n",
      "Epoch 937/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.9929 - loss_1: 0.0536 - root_mean_squared_error: 1.5809 - val_loss: 6.1358 - val_loss_1: 0.0531 - val_root_mean_squared_error: 1.7331\n",
      "Epoch 938/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.9979 - loss_1: 0.0527 - root_mean_squared_error: 1.5790 - val_loss: 6.3615 - val_loss_1: 0.0530 - val_root_mean_squared_error: 1.7913\n",
      "Epoch 939/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.9397 - loss_1: 0.0533 - root_mean_squared_error: 1.5741 - val_loss: 6.2284 - val_loss_1: 0.0530 - val_root_mean_squared_error: 1.7779\n",
      "Epoch 940/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8988 - loss_1: 0.0531 - root_mean_squared_error: 1.5661 - val_loss: 6.4522 - val_loss_1: 0.0528 - val_root_mean_squared_error: 1.7813\n",
      "Epoch 941/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8349 - loss_1: 0.0530 - root_mean_squared_error: 1.5622 - val_loss: 6.1538 - val_loss_1: 0.0530 - val_root_mean_squared_error: 1.7559\n",
      "Epoch 942/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.9087 - loss_1: 0.0527 - root_mean_squared_error: 1.5683 - val_loss: 6.0816 - val_loss_1: 0.0524 - val_root_mean_squared_error: 1.7463\n",
      "Epoch 943/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7504 - loss_1: 0.0531 - root_mean_squared_error: 1.5490 - val_loss: 6.1708 - val_loss_1: 0.0529 - val_root_mean_squared_error: 1.7513\n",
      "Epoch 944/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.0165 - loss_1: 0.0528 - root_mean_squared_error: 1.5880 - val_loss: 6.3435 - val_loss_1: 0.0534 - val_root_mean_squared_error: 1.7925\n",
      "Epoch 945/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.9655 - loss_1: 0.0533 - root_mean_squared_error: 1.5759 - val_loss: 6.0408 - val_loss_1: 0.0528 - val_root_mean_squared_error: 1.7271\n",
      "Epoch 946/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.7908 - loss_1: 0.0521 - root_mean_squared_error: 1.5547 - val_loss: 5.9303 - val_loss_1: 0.0529 - val_root_mean_squared_error: 1.7216\n",
      "Epoch 947/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8444 - loss_1: 0.0525 - root_mean_squared_error: 1.5511 - val_loss: 5.9564 - val_loss_1: 0.0526 - val_root_mean_squared_error: 1.7389\n",
      "Epoch 948/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8542 - loss_1: 0.0527 - root_mean_squared_error: 1.5594 - val_loss: 6.2140 - val_loss_1: 0.0522 - val_root_mean_squared_error: 1.7546\n",
      "Epoch 949/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7460 - loss_1: 0.0523 - root_mean_squared_error: 1.5411 - val_loss: 6.2188 - val_loss_1: 0.0524 - val_root_mean_squared_error: 1.7533\n",
      "Epoch 950/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8171 - loss_1: 0.0527 - root_mean_squared_error: 1.5498 - val_loss: 6.1510 - val_loss_1: 0.0528 - val_root_mean_squared_error: 1.7668\n",
      "Epoch 951/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.7625 - loss_1: 0.0528 - root_mean_squared_error: 1.5439 - val_loss: 6.0116 - val_loss_1: 0.0525 - val_root_mean_squared_error: 1.7373\n",
      "Epoch 952/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8407 - loss_1: 0.0528 - root_mean_squared_error: 1.5574 - val_loss: 6.0185 - val_loss_1: 0.0530 - val_root_mean_squared_error: 1.7325\n",
      "Epoch 953/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8850 - loss_1: 0.0526 - root_mean_squared_error: 1.5676 - val_loss: 6.1924 - val_loss_1: 0.0526 - val_root_mean_squared_error: 1.7727\n",
      "Epoch 954/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.7932 - loss_1: 0.0526 - root_mean_squared_error: 1.5509 - val_loss: 6.0934 - val_loss_1: 0.0527 - val_root_mean_squared_error: 1.7602\n",
      "Epoch 955/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8652 - loss_1: 0.0527 - root_mean_squared_error: 1.5642 - val_loss: 6.0085 - val_loss_1: 0.0521 - val_root_mean_squared_error: 1.7363\n",
      "Epoch 956/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8341 - loss_1: 0.0521 - root_mean_squared_error: 1.5579 - val_loss: 5.9909 - val_loss_1: 0.0525 - val_root_mean_squared_error: 1.7237\n",
      "Epoch 957/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.7873 - loss_1: 0.0524 - root_mean_squared_error: 1.5540 - val_loss: 6.2747 - val_loss_1: 0.0524 - val_root_mean_squared_error: 1.7512\n",
      "Epoch 958/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.6269 - loss_1: 0.0531 - root_mean_squared_error: 1.5298 - val_loss: 6.0878 - val_loss_1: 0.0528 - val_root_mean_squared_error: 1.7388\n",
      "Epoch 959/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8482 - loss_1: 0.0527 - root_mean_squared_error: 1.5520 - val_loss: 6.2184 - val_loss_1: 0.0527 - val_root_mean_squared_error: 1.7601\n",
      "Epoch 960/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8543 - loss_1: 0.0522 - root_mean_squared_error: 1.5594 - val_loss: 6.3972 - val_loss_1: 0.0521 - val_root_mean_squared_error: 1.7692\n",
      "Epoch 961/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7389 - loss_1: 0.0525 - root_mean_squared_error: 1.5453 - val_loss: 6.0552 - val_loss_1: 0.0523 - val_root_mean_squared_error: 1.7331\n",
      "Epoch 962/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.7697 - loss_1: 0.0523 - root_mean_squared_error: 1.5404 - val_loss: 5.9937 - val_loss_1: 0.0524 - val_root_mean_squared_error: 1.7097\n",
      "Epoch 963/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.6997 - loss_1: 0.0522 - root_mean_squared_error: 1.5331 - val_loss: 6.5478 - val_loss_1: 0.0528 - val_root_mean_squared_error: 1.8009\n",
      "Epoch 964/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7964 - loss_1: 0.0520 - root_mean_squared_error: 1.5575 - val_loss: 6.0772 - val_loss_1: 0.0519 - val_root_mean_squared_error: 1.7191\n",
      "Epoch 965/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8140 - loss_1: 0.0518 - root_mean_squared_error: 1.5479 - val_loss: 6.1621 - val_loss_1: 0.0521 - val_root_mean_squared_error: 1.7571\n",
      "Epoch 966/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8112 - loss_1: 0.0518 - root_mean_squared_error: 1.5383 - val_loss: 6.1082 - val_loss_1: 0.0522 - val_root_mean_squared_error: 1.7602\n",
      "Epoch 967/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8232 - loss_1: 0.0521 - root_mean_squared_error: 1.5524 - val_loss: 6.2887 - val_loss_1: 0.0522 - val_root_mean_squared_error: 1.7527\n",
      "Epoch 968/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.6565 - loss_1: 0.0522 - root_mean_squared_error: 1.5278 - val_loss: 6.3179 - val_loss_1: 0.0519 - val_root_mean_squared_error: 1.7739\n",
      "Epoch 969/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 4.7003 - loss_1: 0.0519 - root_mean_squared_error: 1.5393 - val_loss: 5.9243 - val_loss_1: 0.0523 - val_root_mean_squared_error: 1.7136\n",
      "Epoch 970/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.6399 - loss_1: 0.0524 - root_mean_squared_error: 1.5224 - val_loss: 6.1401 - val_loss_1: 0.0526 - val_root_mean_squared_error: 1.7478\n",
      "Epoch 971/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.6874 - loss_1: 0.0515 - root_mean_squared_error: 1.5269 - val_loss: 5.5997 - val_loss_1: 0.0515 - val_root_mean_squared_error: 1.6795\n",
      "Epoch 972/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8911 - loss_1: 0.0518 - root_mean_squared_error: 1.5584 - val_loss: 6.0829 - val_loss_1: 0.0524 - val_root_mean_squared_error: 1.7627\n",
      "Epoch 973/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7983 - loss_1: 0.0524 - root_mean_squared_error: 1.5472 - val_loss: 5.9416 - val_loss_1: 0.0529 - val_root_mean_squared_error: 1.7478\n",
      "Epoch 974/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7019 - loss_1: 0.0522 - root_mean_squared_error: 1.5358 - val_loss: 6.1333 - val_loss_1: 0.0516 - val_root_mean_squared_error: 1.7556\n",
      "Epoch 975/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7785 - loss_1: 0.0514 - root_mean_squared_error: 1.5385 - val_loss: 6.2911 - val_loss_1: 0.0514 - val_root_mean_squared_error: 1.7521\n",
      "Epoch 976/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.7791 - loss_1: 0.0519 - root_mean_squared_error: 1.5445 - val_loss: 5.6681 - val_loss_1: 0.0517 - val_root_mean_squared_error: 1.6960\n",
      "Epoch 977/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7596 - loss_1: 0.0520 - root_mean_squared_error: 1.5369 - val_loss: 5.9842 - val_loss_1: 0.0511 - val_root_mean_squared_error: 1.7280\n",
      "Epoch 978/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.9182 - loss_1: 0.0515 - root_mean_squared_error: 1.5523 - val_loss: 6.0218 - val_loss_1: 0.0514 - val_root_mean_squared_error: 1.7342\n",
      "Epoch 979/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.8484 - loss_1: 0.0519 - root_mean_squared_error: 1.5607 - val_loss: 6.1702 - val_loss_1: 0.0521 - val_root_mean_squared_error: 1.7657\n",
      "Epoch 980/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8394 - loss_1: 0.0517 - root_mean_squared_error: 1.5400 - val_loss: 6.0371 - val_loss_1: 0.0517 - val_root_mean_squared_error: 1.7402\n",
      "Epoch 981/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.7528 - loss_1: 0.0514 - root_mean_squared_error: 1.5298 - val_loss: 5.8810 - val_loss_1: 0.0513 - val_root_mean_squared_error: 1.7320\n",
      "Epoch 982/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.8210 - loss_1: 0.0518 - root_mean_squared_error: 1.5562 - val_loss: 6.2015 - val_loss_1: 0.0517 - val_root_mean_squared_error: 1.7512\n",
      "Epoch 983/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.6805 - loss_1: 0.0518 - root_mean_squared_error: 1.5364 - val_loss: 6.0904 - val_loss_1: 0.0524 - val_root_mean_squared_error: 1.7484\n",
      "Epoch 984/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.8278 - loss_1: 0.0513 - root_mean_squared_error: 1.5504 - val_loss: 6.1413 - val_loss_1: 0.0509 - val_root_mean_squared_error: 1.7541\n",
      "Epoch 985/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.7556 - loss_1: 0.0514 - root_mean_squared_error: 1.5511 - val_loss: 6.2115 - val_loss_1: 0.0520 - val_root_mean_squared_error: 1.7669\n",
      "Epoch 986/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 4.6447 - loss_1: 0.0517 - root_mean_squared_error: 1.53 - 1s 76us/step - loss: 4.6680 - loss_1: 0.0516 - root_mean_squared_error: 1.5335 - val_loss: 6.0115 - val_loss_1: 0.0510 - val_root_mean_squared_error: 1.7298\n",
      "Epoch 987/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.7026 - loss_1: 0.0516 - root_mean_squared_error: 1.5304 - val_loss: 6.0308 - val_loss_1: 0.0523 - val_root_mean_squared_error: 1.7359\n",
      "Epoch 988/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.6965 - loss_1: 0.0519 - root_mean_squared_error: 1.5323 - val_loss: 5.8377 - val_loss_1: 0.0520 - val_root_mean_squared_error: 1.7141\n",
      "Epoch 989/1000\n",
      "10760/10760 [==============================] - 1s 84us/step - loss: 4.7265 - loss_1: 0.0517 - root_mean_squared_error: 1.5331 - val_loss: 6.0211 - val_loss_1: 0.0525 - val_root_mean_squared_error: 1.7314\n",
      "Epoch 990/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 4.7130 - loss_1: 0.0519 - root_mean_squared_error: 1.5346 - val_loss: 5.8141 - val_loss_1: 0.0513 - val_root_mean_squared_error: 1.7223\n",
      "Epoch 991/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 4.7305 - loss_1: 0.0517 - root_mean_squared_error: 1.5400 - val_loss: 5.9629 - val_loss_1: 0.0520 - val_root_mean_squared_error: 1.7328\n",
      "Epoch 992/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.7509 - loss_1: 0.0516 - root_mean_squared_error: 1.5302 - val_loss: 5.9893 - val_loss_1: 0.0518 - val_root_mean_squared_error: 1.7398\n",
      "Epoch 993/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 4.6844 - loss_1: 0.0514 - root_mean_squared_error: 1.5301 - val_loss: 6.0699 - val_loss_1: 0.0518 - val_root_mean_squared_error: 1.7469\n",
      "Epoch 994/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.7627 - loss_1: 0.0512 - root_mean_squared_error: 1.5434 - val_loss: 6.0237 - val_loss_1: 0.0510 - val_root_mean_squared_error: 1.7418\n",
      "Epoch 995/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 4.7178 - loss_1: 0.0512 - root_mean_squared_error: 1.5385 - val_loss: 5.8756 - val_loss_1: 0.0512 - val_root_mean_squared_error: 1.7128\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 4.6708 - loss_1: 0.0511 - root_mean_squared_error: 1.5234 - val_loss: 5.9127 - val_loss_1: 0.0515 - val_root_mean_squared_error: 1.7062\n",
      "Epoch 997/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 4.6049 - loss_1: 0.0514 - root_mean_squared_error: 1.5124 - val_loss: 6.0398 - val_loss_1: 0.0516 - val_root_mean_squared_error: 1.7228\n",
      "Epoch 998/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 4.6628 - loss_1: 0.0510 - root_mean_squared_error: 1.5253 - val_loss: 5.8913 - val_loss_1: 0.0513 - val_root_mean_squared_error: 1.7203\n",
      "Epoch 999/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 4.5585 - loss_1: 0.0517 - root_mean_squared_error: 1.5055 - val_loss: 6.2581 - val_loss_1: 0.0517 - val_root_mean_squared_error: 1.7666\n",
      "Epoch 1000/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 4.5695 - loss_1: 0.0513 - root_mean_squared_error: 1.5090 - val_loss: 5.7894 - val_loss_1: 0.0516 - val_root_mean_squared_error: 1.7055\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "[4.695381164550781, 0.05094550549983978, 1.7309995889663696]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.720558364391327"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses=[]\n",
    "std_rmses=[]\n",
    "for ii in ([13450]):\n",
    "    test_rmse, history = pass_arg(50, ii, 0.1)\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    mean_rmses.append(mean_rmse)\n",
    "    std_rmses.append(std_rmse)\n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 13450\n",
      "Train on 10760 samples, validate on 2690 samples\n",
      "Epoch 1/1000\n",
      "10760/10760 [==============================] - 1s 90us/step - loss: 227.8268 - loss_1: 0.0039 - root_mean_squared_error: 13.9049 - val_loss: 210.8628 - val_loss_1: 0.0034 - val_root_mean_squared_error: 12.9264\n",
      "Epoch 2/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 222.1735 - loss_1: 0.0033 - root_mean_squared_error: 13.7082 - val_loss: 205.7087 - val_loss_1: 0.0033 - val_root_mean_squared_error: 12.7369\n",
      "Epoch 3/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 216.6190 - loss_1: 0.0035 - root_mean_squared_error: 13.5092 - val_loss: 200.2697 - val_loss_1: 0.0039 - val_root_mean_squared_error: 12.5328\n",
      "Epoch 4/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 210.9718 - loss_1: 0.0043 - root_mean_squared_error: 13.3062 - val_loss: 194.7229 - val_loss_1: 0.0048 - val_root_mean_squared_error: 12.3189\n",
      "Epoch 5/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 205.1256 - loss_1: 0.0052 - root_mean_squared_error: 13.0902 - val_loss: 189.2089 - val_loss_1: 0.0058 - val_root_mean_squared_error: 12.1038\n",
      "Epoch 6/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 199.2444 - loss_1: 0.0063 - root_mean_squared_error: 12.8666 - val_loss: 183.3920 - val_loss_1: 0.0068 - val_root_mean_squared_error: 11.8678\n",
      "Epoch 7/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 193.0016 - loss_1: 0.0073 - root_mean_squared_error: 12.6270 - val_loss: 176.7784 - val_loss_1: 0.0078 - val_root_mean_squared_error: 11.6002\n",
      "Epoch 8/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 186.0395 - loss_1: 0.0082 - root_mean_squared_error: 12.3522 - val_loss: 170.0058 - val_loss_1: 0.0087 - val_root_mean_squared_error: 11.3076\n",
      "Epoch 9/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 177.7079 - loss_1: 0.0088 - root_mean_squared_error: 12.0154 - val_loss: 160.7008 - val_loss_1: 0.0090 - val_root_mean_squared_error: 10.9307\n",
      "Epoch 10/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 167.4821 - loss_1: 0.0090 - root_mean_squared_error: 11.5969 - val_loss: 150.3966 - val_loss_1: 0.0089 - val_root_mean_squared_error: 10.4863\n",
      "Epoch 11/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 155.9026 - loss_1: 0.0086 - root_mean_squared_error: 11.1144 - val_loss: 138.8780 - val_loss_1: 0.0079 - val_root_mean_squared_error: 9.9849\n",
      "Epoch 12/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 143.1776 - loss_1: 0.0073 - root_mean_squared_error: 10.5678 - val_loss: 126.5597 - val_loss_1: 0.0063 - val_root_mean_squared_error: 9.4368\n",
      "Epoch 13/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 131.1386 - loss_1: 0.0057 - root_mean_squared_error: 10.0041 - val_loss: 114.9157 - val_loss_1: 0.0052 - val_root_mean_squared_error: 8.8824\n",
      "Epoch 14/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 117.9527 - loss_1: 0.0056 - root_mean_squared_error: 9.3662 - val_loss: 103.2097 - val_loss_1: 0.0067 - val_root_mean_squared_error: 8.2910\n",
      "Epoch 15/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 104.6154 - loss_1: 0.0089 - root_mean_squared_error: 8.6591 - val_loss: 90.3454 - val_loss_1: 0.0123 - val_root_mean_squared_error: 7.6155\n",
      "Epoch 16/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 90.4987 - loss_1: 0.0164 - root_mean_squared_error: 7.8745 - val_loss: 77.9592 - val_loss_1: 0.0218 - val_root_mean_squared_error: 6.9198\n",
      "Epoch 17/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 77.8326 - loss_1: 0.0269 - root_mean_squared_error: 7.124 - 1s 74us/step - loss: 77.1207 - loss_1: 0.0275 - root_mean_squared_error: 7.0850 - val_loss: 67.6422 - val_loss_1: 0.0349 - val_root_mean_squared_error: 6.3163\n",
      "Epoch 18/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 65.6686 - loss_1: 0.0421 - root_mean_squared_error: 6.3386 - val_loss: 58.5068 - val_loss_1: 0.0518 - val_root_mean_squared_error: 5.7983\n",
      "Epoch 19/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 54.6396 - loss_1: 0.0606 - root_mean_squared_error: 5.6862 - val_loss: 51.5216 - val_loss_1: 0.0717 - val_root_mean_squared_error: 5.5298\n",
      "Epoch 20/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 46.6539 - loss_1: 0.0828 - root_mean_squared_error: 5.2144 - val_loss: 46.6560 - val_loss_1: 0.0964 - val_root_mean_squared_error: 5.3910\n",
      "Epoch 21/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 40.8886 - loss_1: 0.1083 - root_mean_squared_error: 4.9833 - val_loss: 44.1374 - val_loss_1: 0.1228 - val_root_mean_squared_error: 5.4099\n",
      "Epoch 22/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 38.1700 - loss_1: 0.1341 - root_mean_squared_error: 4.9112 - val_loss: 45.8480 - val_loss_1: 0.1434 - val_root_mean_squared_error: 5.6200\n",
      "Epoch 23/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 37.0317 - loss_1: 0.1416 - root_mean_squared_error: 4.8775 - val_loss: 43.6268 - val_loss_1: 0.1371 - val_root_mean_squared_error: 5.4760\n",
      "Epoch 24/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 35.1006 - loss_1: 0.1317 - root_mean_squared_error: 4.7155 - val_loss: 40.3755 - val_loss_1: 0.1269 - val_root_mean_squared_error: 5.2144\n",
      "Epoch 25/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 34.2103 - loss_1: 0.1269 - root_mean_squared_error: 4.6201 - val_loss: 38.3025 - val_loss_1: 0.1278 - val_root_mean_squared_error: 5.1020\n",
      "Epoch 26/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 32.3050 - loss_1: 0.1288 - root_mean_squared_error: 4.5118 - val_loss: 37.5983 - val_loss_1: 0.1300 - val_root_mean_squared_error: 5.0537\n",
      "Epoch 27/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 31.1642 - loss_1: 0.1290 - root_mean_squared_error: 4.4223 - val_loss: 35.5012 - val_loss_1: 0.1271 - val_root_mean_squared_error: 4.8858\n",
      "Epoch 28/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 30.6404 - loss_1: 0.1271 - root_mean_squared_error: 4.3862 - val_loss: 34.2831 - val_loss_1: 0.1275 - val_root_mean_squared_error: 4.8277\n",
      "Epoch 29/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 29.4638 - loss_1: 0.1263 - root_mean_squared_error: 4.2962 - val_loss: 31.3309 - val_loss_1: 0.1264 - val_root_mean_squared_error: 4.5765\n",
      "Epoch 30/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 28.1037 - loss_1: 0.1289 - root_mean_squared_error: 4.1841 - val_loss: 31.8366 - val_loss_1: 0.1286 - val_root_mean_squared_error: 4.5426\n",
      "Epoch 31/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 27.7243 - loss_1: 0.1274 - root_mean_squared_error: 4.1290 - val_loss: 29.3096 - val_loss_1: 0.1277 - val_root_mean_squared_error: 4.3164\n",
      "Epoch 32/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 26.6253 - loss_1: 0.1293 - root_mean_squared_error: 4.0360 - val_loss: 28.4275 - val_loss_1: 0.1319 - val_root_mean_squared_error: 4.2204\n",
      "Epoch 33/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 26.0343 - loss_1: 0.1305 - root_mean_squared_error: 3.9869 - val_loss: 27.6677 - val_loss_1: 0.1292 - val_root_mean_squared_error: 4.1197\n",
      "Epoch 34/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 25.1189 - loss_1: 0.1293 - root_mean_squared_error: 3.9121 - val_loss: 27.1149 - val_loss_1: 0.1315 - val_root_mean_squared_error: 4.0816\n",
      "Epoch 35/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 24.6907 - loss_1: 0.1323 - root_mean_squared_error: 3.8709 - val_loss: 24.9108 - val_loss_1: 0.1321 - val_root_mean_squared_error: 3.9092\n",
      "Epoch 36/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 23.4797 - loss_1: 0.1321 - root_mean_squared_error: 3.7462 - val_loss: 24.0908 - val_loss_1: 0.1340 - val_root_mean_squared_error: 3.8259\n",
      "Epoch 37/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 22.8913 - loss_1: 0.1349 - root_mean_squared_error: 3.6801 - val_loss: 23.1741 - val_loss_1: 0.1348 - val_root_mean_squared_error: 3.7321\n",
      "Epoch 38/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 22.7546 - loss_1: 0.1336 - root_mean_squared_error: 3.6588 - val_loss: 23.3027 - val_loss_1: 0.1336 - val_root_mean_squared_error: 3.6681\n",
      "Epoch 39/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 22.2426 - loss_1: 0.1352 - root_mean_squared_error: 3.6086 - val_loss: 22.3379 - val_loss_1: 0.1367 - val_root_mean_squared_error: 3.5969\n",
      "Epoch 40/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 21.5302 - loss_1: 0.1369 - root_mean_squared_error: 3.5333 - val_loss: 21.9352 - val_loss_1: 0.1366 - val_root_mean_squared_error: 3.5867\n",
      "Epoch 41/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 21.0254 - loss_1: 0.1369 - root_mean_squared_error: 3.4882 - val_loss: 21.4191 - val_loss_1: 0.1356 - val_root_mean_squared_error: 3.4838\n",
      "Epoch 42/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 20.4024 - loss_1: 0.1357 - root_mean_squared_error: 3.4307 - val_loss: 19.7460 - val_loss_1: 0.1355 - val_root_mean_squared_error: 3.3353\n",
      "Epoch 43/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 19.7796 - loss_1: 0.1376 - root_mean_squared_error: 3.3518 - val_loss: 20.0320 - val_loss_1: 0.1396 - val_root_mean_squared_error: 3.4028\n",
      "Epoch 44/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 19.9107 - loss_1: 0.1394 - root_mean_squared_error: 3.3715 - val_loss: 20.1801 - val_loss_1: 0.1381 - val_root_mean_squared_error: 3.3750\n",
      "Epoch 45/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 19.8893 - loss_1: 0.1386 - root_mean_squared_error: 3.3670 - val_loss: 19.4789 - val_loss_1: 0.1369 - val_root_mean_squared_error: 3.3412\n",
      "Epoch 46/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 19.5464 - loss_1: 0.1382 - root_mean_squared_error: 3.3307 - val_loss: 18.9094 - val_loss_1: 0.1394 - val_root_mean_squared_error: 3.2654\n",
      "Epoch 47/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 19.2469 - loss_1: 0.1368 - root_mean_squared_error: 3.2919 - val_loss: 19.3255 - val_loss_1: 0.1390 - val_root_mean_squared_error: 3.3171\n",
      "Epoch 48/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 19.2946 - loss_1: 0.1390 - root_mean_squared_error: 3.2975 - val_loss: 19.0759 - val_loss_1: 0.1376 - val_root_mean_squared_error: 3.2991\n",
      "Epoch 49/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 18.8901 - loss_1: 0.1379 - root_mean_squared_error: 3.260 - 1s 74us/step - loss: 18.9369 - loss_1: 0.1381 - root_mean_squared_error: 3.2658 - val_loss: 19.2746 - val_loss_1: 0.1405 - val_root_mean_squared_error: 3.2995\n",
      "Epoch 50/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 18.9711 - loss_1: 0.1371 - root_mean_squared_error: 3.2600 - val_loss: 18.9925 - val_loss_1: 0.1381 - val_root_mean_squared_error: 3.2767\n",
      "Epoch 51/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 18.8508 - loss_1: 0.1394 - root_mean_squared_error: 3.2560 - val_loss: 18.6113 - val_loss_1: 0.1381 - val_root_mean_squared_error: 3.2334\n",
      "Epoch 52/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 18.3481 - loss_1: 0.1385 - root_mean_squared_error: 3.2119 - val_loss: 18.8681 - val_loss_1: 0.1385 - val_root_mean_squared_error: 3.2829\n",
      "Epoch 53/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 18.1423 - loss_1: 0.1374 - root_mean_squared_error: 3.1932 - val_loss: 18.7992 - val_loss_1: 0.1365 - val_root_mean_squared_error: 3.2691\n",
      "Epoch 54/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 18.2103 - loss_1: 0.1372 - root_mean_squared_error: 3.1982 - val_loss: 18.3579 - val_loss_1: 0.1372 - val_root_mean_squared_error: 3.2193\n",
      "Epoch 55/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 18.2626 - loss_1: 0.1351 - root_mean_squared_error: 3.199 - 1s 76us/step - loss: 18.2632 - loss_1: 0.1353 - root_mean_squared_error: 3.2032 - val_loss: 18.6542 - val_loss_1: 0.1385 - val_root_mean_squared_error: 3.2257\n",
      "Epoch 56/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 17.8465 - loss_1: 0.1386 - root_mean_squared_error: 3.1740 - val_loss: 18.3556 - val_loss_1: 0.1359 - val_root_mean_squared_error: 3.2302\n",
      "Epoch 57/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 18.0028 - loss_1: 0.1366 - root_mean_squared_error: 3.1833 - val_loss: 18.6829 - val_loss_1: 0.1403 - val_root_mean_squared_error: 3.2531\n",
      "Epoch 58/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 17.7784 - loss_1: 0.1366 - root_mean_squared_error: 3.1660 - val_loss: 18.7151 - val_loss_1: 0.1347 - val_root_mean_squared_error: 3.2478\n",
      "Epoch 59/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 18.1215 - loss_1: 0.1356 - root_mean_squared_error: 3.1893 - val_loss: 17.7125 - val_loss_1: 0.1355 - val_root_mean_squared_error: 3.1199\n",
      "Epoch 60/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 17.7946 - loss_1: 0.1348 - root_mean_squared_error: 3.1603 - val_loss: 17.5828 - val_loss_1: 0.1322 - val_root_mean_squared_error: 3.1535\n",
      "Epoch 61/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 17.5669 - loss_1: 0.1341 - root_mean_squared_error: 3.1356 - val_loss: 18.2641 - val_loss_1: 0.1362 - val_root_mean_squared_error: 3.1751\n",
      "Epoch 62/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 17.5418 - loss_1: 0.1339 - root_mean_squared_error: 3.1521 - val_loss: 17.8473 - val_loss_1: 0.1353 - val_root_mean_squared_error: 3.1505\n",
      "Epoch 63/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 17.4833 - loss_1: 0.1346 - root_mean_squared_error: 3.1347 - val_loss: 17.4616 - val_loss_1: 0.1330 - val_root_mean_squared_error: 3.1468\n",
      "Epoch 64/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 17.2807 - loss_1: 0.1335 - root_mean_squared_error: 3.1192 - val_loss: 17.0010 - val_loss_1: 0.1326 - val_root_mean_squared_error: 3.0815\n",
      "Epoch 65/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 17.1012 - loss_1: 0.1324 - root_mean_squared_error: 3.0961 - val_loss: 16.9647 - val_loss_1: 0.1330 - val_root_mean_squared_error: 3.0763\n",
      "Epoch 66/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 17.1916 - loss_1: 0.1330 - root_mean_squared_error: 3.1112 - val_loss: 17.5198 - val_loss_1: 0.1332 - val_root_mean_squared_error: 3.1508\n",
      "Epoch 67/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 16.9043 - loss_1: 0.1312 - root_mean_squared_error: 3.0820 - val_loss: 16.9499 - val_loss_1: 0.1332 - val_root_mean_squared_error: 3.0728\n",
      "Epoch 68/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.8852 - loss_1: 0.1319 - root_mean_squared_error: 3.0782 - val_loss: 16.4792 - val_loss_1: 0.1295 - val_root_mean_squared_error: 3.0001\n",
      "Epoch 69/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.7143 - loss_1: 0.1323 - root_mean_squared_error: 3.0417 - val_loss: 16.2971 - val_loss_1: 0.1324 - val_root_mean_squared_error: 3.0164\n",
      "Epoch 70/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 16.4090 - loss_1: 0.1296 - root_mean_squared_error: 3.0387 - val_loss: 16.0030 - val_loss_1: 0.1302 - val_root_mean_squared_error: 2.9953\n",
      "Epoch 71/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.7568 - loss_1: 0.1336 - root_mean_squared_error: 3.0650 - val_loss: 16.7473 - val_loss_1: 0.1308 - val_root_mean_squared_error: 3.0406\n",
      "Epoch 72/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 16.7870 - loss_1: 0.1285 - root_mean_squared_error: 3.0645 - val_loss: 16.8327 - val_loss_1: 0.1316 - val_root_mean_squared_error: 3.0745\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.3645 - loss_1: 0.1311 - root_mean_squared_error: 3.0313 - val_loss: 16.5629 - val_loss_1: 0.1299 - val_root_mean_squared_error: 3.0458\n",
      "Epoch 74/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.4494 - loss_1: 0.1310 - root_mean_squared_error: 3.0187 - val_loss: 16.9576 - val_loss_1: 0.1312 - val_root_mean_squared_error: 3.0993\n",
      "Epoch 75/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 16.1853 - loss_1: 0.1296 - root_mean_squared_error: 3.0090 - val_loss: 15.9799 - val_loss_1: 0.1290 - val_root_mean_squared_error: 2.9945\n",
      "Epoch 76/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 16.0028 - loss_1: 0.1285 - root_mean_squared_error: 2.9818 - val_loss: 16.1364 - val_loss_1: 0.1276 - val_root_mean_squared_error: 2.9957\n",
      "Epoch 77/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.8999 - loss_1: 0.1281 - root_mean_squared_error: 2.9890 - val_loss: 15.5395 - val_loss_1: 0.1266 - val_root_mean_squared_error: 2.9442\n",
      "Epoch 78/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 15.8222 - loss_1: 0.1280 - root_mean_squared_error: 2.9775 - val_loss: 15.8665 - val_loss_1: 0.1296 - val_root_mean_squared_error: 2.9763\n",
      "Epoch 79/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 16.1508 - loss_1: 0.1278 - root_mean_squared_error: 3.005 - 1s 74us/step - loss: 16.1653 - loss_1: 0.1279 - root_mean_squared_error: 3.0070 - val_loss: 15.8293 - val_loss_1: 0.1297 - val_root_mean_squared_error: 2.9601\n",
      "Epoch 80/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.8580 - loss_1: 0.1277 - root_mean_squared_error: 2.9624 - val_loss: 15.8328 - val_loss_1: 0.1246 - val_root_mean_squared_error: 2.9363\n",
      "Epoch 81/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 15.6520 - loss_1: 0.1272 - root_mean_squared_error: 2.9594 - val_loss: 14.9079 - val_loss_1: 0.1284 - val_root_mean_squared_error: 2.8689\n",
      "Epoch 82/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.4817 - loss_1: 0.1275 - root_mean_squared_error: 2.9238 - val_loss: 15.1322 - val_loss_1: 0.1242 - val_root_mean_squared_error: 2.8788\n",
      "Epoch 83/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.7209 - loss_1: 0.1253 - root_mean_squared_error: 2.9568 - val_loss: 15.2396 - val_loss_1: 0.1262 - val_root_mean_squared_error: 2.9016\n",
      "Epoch 84/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.7965 - loss_1: 0.1263 - root_mean_squared_error: 2.9667 - val_loss: 14.6676 - val_loss_1: 0.1271 - val_root_mean_squared_error: 2.8209\n",
      "Epoch 85/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 15.5884 - loss_1: 0.1270 - root_mean_squared_error: 2.923 - 1s 75us/step - loss: 15.5708 - loss_1: 0.1269 - root_mean_squared_error: 2.9241 - val_loss: 14.7798 - val_loss_1: 0.1249 - val_root_mean_squared_error: 2.8319\n",
      "Epoch 86/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 15.0006 - loss_1: 0.1252 - root_mean_squared_error: 2.8749 - val_loss: 14.3860 - val_loss_1: 0.1279 - val_root_mean_squared_error: 2.8095\n",
      "Epoch 87/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 15.0708 - loss_1: 0.1278 - root_mean_squared_error: 2.8934 - val_loss: 14.8160 - val_loss_1: 0.1244 - val_root_mean_squared_error: 2.8371\n",
      "Epoch 88/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 15.0123 - loss_1: 0.1243 - root_mean_squared_error: 2.8846 - val_loss: 15.1303 - val_loss_1: 0.1282 - val_root_mean_squared_error: 2.8980\n",
      "Epoch 89/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 14.6199 - loss_1: 0.1264 - root_mean_squared_error: 2.8527 - val_loss: 14.4019 - val_loss_1: 0.1248 - val_root_mean_squared_error: 2.7855\n",
      "Epoch 90/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.5987 - loss_1: 0.1257 - root_mean_squared_error: 2.8301 - val_loss: 14.7774 - val_loss_1: 0.1247 - val_root_mean_squared_error: 2.8326\n",
      "Epoch 91/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.4989 - loss_1: 0.1241 - root_mean_squared_error: 2.8332 - val_loss: 14.6676 - val_loss_1: 0.1266 - val_root_mean_squared_error: 2.8122\n",
      "Epoch 92/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.9253 - loss_1: 0.1249 - root_mean_squared_error: 2.8665 - val_loss: 14.0438 - val_loss_1: 0.1246 - val_root_mean_squared_error: 2.7789\n",
      "Epoch 93/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 14.6137 - loss_1: 0.1254 - root_mean_squared_error: 2.8408 - val_loss: 14.2055 - val_loss_1: 0.1243 - val_root_mean_squared_error: 2.7853\n",
      "Epoch 94/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.5787 - loss_1: 0.1237 - root_mean_squared_error: 2.8291 - val_loss: 13.8346 - val_loss_1: 0.1232 - val_root_mean_squared_error: 2.7502\n",
      "Epoch 95/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 14.4842 - loss_1: 0.1254 - root_mean_squared_error: 2.8164 - val_loss: 14.0242 - val_loss_1: 0.1225 - val_root_mean_squared_error: 2.7508\n",
      "Epoch 96/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 14.0286 - loss_1: 0.1229 - root_mean_squared_error: 2.7866 - val_loss: 13.7612 - val_loss_1: 0.1242 - val_root_mean_squared_error: 2.7554\n",
      "Epoch 97/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 14.3896 - loss_1: 0.1230 - root_mean_squared_error: 2.7993 - val_loss: 13.8521 - val_loss_1: 0.1214 - val_root_mean_squared_error: 2.7432\n",
      "Epoch 98/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 14.2337 - loss_1: 0.1240 - root_mean_squared_error: 2.8022 - val_loss: 13.7064 - val_loss_1: 0.1237 - val_root_mean_squared_error: 2.7276\n",
      "Epoch 99/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 13.9608 - loss_1: 0.1205 - root_mean_squared_error: 2.7640 - val_loss: 13.6719 - val_loss_1: 0.1204 - val_root_mean_squared_error: 2.7158\n",
      "Epoch 100/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 14.0049 - loss_1: 0.1217 - root_mean_squared_error: 2.7703 - val_loss: 13.8515 - val_loss_1: 0.1234 - val_root_mean_squared_error: 2.7151\n",
      "Epoch 101/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 13.8699 - loss_1: 0.1223 - root_mean_squared_error: 2.7595 - val_loss: 13.4869 - val_loss_1: 0.1221 - val_root_mean_squared_error: 2.6972\n",
      "Epoch 102/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 13.9595 - loss_1: 0.1211 - root_mean_squared_error: 2.7536 - val_loss: 13.2367 - val_loss_1: 0.1224 - val_root_mean_squared_error: 2.6769\n",
      "Epoch 103/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.9044 - loss_1: 0.1217 - root_mean_squared_error: 2.7481 - val_loss: 13.6220 - val_loss_1: 0.1206 - val_root_mean_squared_error: 2.7114\n",
      "Epoch 104/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 13.5767 - loss_1: 0.1202 - root_mean_squared_error: 2.6965 - val_loss: 13.3899 - val_loss_1: 0.1211 - val_root_mean_squared_error: 2.6989\n",
      "Epoch 105/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.2809 - loss_1: 0.1204 - root_mean_squared_error: 2.6892 - val_loss: 12.8089 - val_loss_1: 0.1181 - val_root_mean_squared_error: 2.6125\n",
      "Epoch 106/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 13.5419 - loss_1: 0.1191 - root_mean_squared_error: 2.7094 - val_loss: 13.3425 - val_loss_1: 0.1211 - val_root_mean_squared_error: 2.6826\n",
      "Epoch 107/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 13.3162 - loss_1: 0.1204 - root_mean_squared_error: 2.6870 - val_loss: 12.4699 - val_loss_1: 0.1182 - val_root_mean_squared_error: 2.6011\n",
      "Epoch 108/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 13.3093 - loss_1: 0.1195 - root_mean_squared_error: 2.6744 - val_loss: 13.3222 - val_loss_1: 0.1189 - val_root_mean_squared_error: 2.6667\n",
      "Epoch 109/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 13.4998 - loss_1: 0.1179 - root_mean_squared_error: 2.6934 - val_loss: 12.9315 - val_loss_1: 0.1196 - val_root_mean_squared_error: 2.6321\n",
      "Epoch 110/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.0066 - loss_1: 0.1183 - root_mean_squared_error: 2.6338 - val_loss: 12.6992 - val_loss_1: 0.1170 - val_root_mean_squared_error: 2.6102\n",
      "Epoch 111/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 13.2128 - loss_1: 0.1175 - root_mean_squared_error: 2.6660 - val_loss: 12.7146 - val_loss_1: 0.1202 - val_root_mean_squared_error: 2.6273\n",
      "Epoch 112/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 13.0818 - loss_1: 0.1193 - root_mean_squared_error: 2.6459 - val_loss: 13.1965 - val_loss_1: 0.1157 - val_root_mean_squared_error: 2.6406\n",
      "Epoch 113/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.6105 - loss_1: 0.1171 - root_mean_squared_error: 2.6169 - val_loss: 12.1135 - val_loss_1: 0.1187 - val_root_mean_squared_error: 2.5380\n",
      "Epoch 114/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.9821 - loss_1: 0.1168 - root_mean_squared_error: 2.6386 - val_loss: 12.7585 - val_loss_1: 0.1165 - val_root_mean_squared_error: 2.6212\n",
      "Epoch 115/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 12.7483 - loss_1: 0.1172 - root_mean_squared_error: 2.6174 - val_loss: 12.4896 - val_loss_1: 0.1179 - val_root_mean_squared_error: 2.5914\n",
      "Epoch 116/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.5435 - loss_1: 0.1153 - root_mean_squared_error: 2.5900 - val_loss: 11.8167 - val_loss_1: 0.1151 - val_root_mean_squared_error: 2.5060\n",
      "Epoch 117/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.5899 - loss_1: 0.1164 - root_mean_squared_error: 2.5854 - val_loss: 12.3045 - val_loss_1: 0.1176 - val_root_mean_squared_error: 2.5761\n",
      "Epoch 118/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.2520 - loss_1: 0.1168 - root_mean_squared_error: 2.5518 - val_loss: 12.7526 - val_loss_1: 0.1166 - val_root_mean_squared_error: 2.6313\n",
      "Epoch 119/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.1283 - loss_1: 0.1169 - root_mean_squared_error: 2.5447 - val_loss: 12.2433 - val_loss_1: 0.1150 - val_root_mean_squared_error: 2.5720\n",
      "Epoch 120/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.3924 - loss_1: 0.1168 - root_mean_squared_error: 2.5770 - val_loss: 12.2509 - val_loss_1: 0.1178 - val_root_mean_squared_error: 2.5357\n",
      "Epoch 121/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.1151 - loss_1: 0.1149 - root_mean_squared_error: 2.5253 - val_loss: 11.9025 - val_loss_1: 0.1142 - val_root_mean_squared_error: 2.5098\n",
      "Epoch 122/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.1385 - loss_1: 0.1152 - root_mean_squared_error: 2.5224 - val_loss: 11.7493 - val_loss_1: 0.1158 - val_root_mean_squared_error: 2.4852\n",
      "Epoch 123/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.5110 - loss_1: 0.1139 - root_mean_squared_error: 2.5596 - val_loss: 11.8186 - val_loss_1: 0.1131 - val_root_mean_squared_error: 2.5139\n",
      "Epoch 124/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 12.2217 - loss_1: 0.1153 - root_mean_squared_error: 2.5274 - val_loss: 12.2582 - val_loss_1: 0.1152 - val_root_mean_squared_error: 2.5491\n",
      "Epoch 125/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.1901 - loss_1: 0.1137 - root_mean_squared_error: 2.5277 - val_loss: 11.7562 - val_loss_1: 0.1128 - val_root_mean_squared_error: 2.5098\n",
      "Epoch 126/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 12.0488 - loss_1: 0.1142 - root_mean_squared_error: 2.5048 - val_loss: 12.3302 - val_loss_1: 0.1151 - val_root_mean_squared_error: 2.5400\n",
      "Epoch 127/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.9271 - loss_1: 0.1152 - root_mean_squared_error: 2.5040 - val_loss: 12.0561 - val_loss_1: 0.1152 - val_root_mean_squared_error: 2.5319\n",
      "Epoch 128/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 12.2652 - loss_1: 0.1150 - root_mean_squared_error: 2.5296 - val_loss: 11.5332 - val_loss_1: 0.1143 - val_root_mean_squared_error: 2.4568\n",
      "Epoch 129/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 11.6965 - loss_1: 0.1149 - root_mean_squared_error: 2.4768 - val_loss: 12.4706 - val_loss_1: 0.1155 - val_root_mean_squared_error: 2.5751\n",
      "Epoch 130/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.7040 - loss_1: 0.1155 - root_mean_squared_error: 2.4720 - val_loss: 11.0594 - val_loss_1: 0.1144 - val_root_mean_squared_error: 2.4385\n",
      "Epoch 131/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 11.6848 - loss_1: 0.1141 - root_mean_squared_error: 2.4628 - val_loss: 12.0736 - val_loss_1: 0.1153 - val_root_mean_squared_error: 2.5437\n",
      "Epoch 132/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 11.8030 - loss_1: 0.1135 - root_mean_squared_error: 2.4691 - val_loss: 11.5839 - val_loss_1: 0.1151 - val_root_mean_squared_error: 2.4705\n",
      "Epoch 133/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.7509 - loss_1: 0.1145 - root_mean_squared_error: 2.4656 - val_loss: 11.6288 - val_loss_1: 0.1119 - val_root_mean_squared_error: 2.4858\n",
      "Epoch 134/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 11.3832 - loss_1: 0.1123 - root_mean_squared_error: 2.4172 - val_loss: 11.4877 - val_loss_1: 0.1130 - val_root_mean_squared_error: 2.4776\n",
      "Epoch 135/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.1839 - loss_1: 0.1135 - root_mean_squared_error: 2.4058 - val_loss: 11.2412 - val_loss_1: 0.1125 - val_root_mean_squared_error: 2.4396\n",
      "Epoch 136/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 11.4147 - loss_1: 0.1127 - root_mean_squared_error: 2.4217 - val_loss: 12.0793 - val_loss_1: 0.1155 - val_root_mean_squared_error: 2.5455\n",
      "Epoch 137/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.4547 - loss_1: 0.1135 - root_mean_squared_error: 2.4451 - val_loss: 11.2726 - val_loss_1: 0.1116 - val_root_mean_squared_error: 2.4241\n",
      "Epoch 138/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.2934 - loss_1: 0.1133 - root_mean_squared_error: 2.4268 - val_loss: 11.0987 - val_loss_1: 0.1140 - val_root_mean_squared_error: 2.4173\n",
      "Epoch 139/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.2113 - loss_1: 0.1132 - root_mean_squared_error: 2.4049 - val_loss: 10.6895 - val_loss_1: 0.1131 - val_root_mean_squared_error: 2.3674\n",
      "Epoch 140/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.2244 - loss_1: 0.1129 - root_mean_squared_error: 2.4081 - val_loss: 10.6779 - val_loss_1: 0.1108 - val_root_mean_squared_error: 2.3754\n",
      "Epoch 141/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.9182 - loss_1: 0.1114 - root_mean_squared_error: 2.3782 - val_loss: 11.5658 - val_loss_1: 0.1122 - val_root_mean_squared_error: 2.4574\n",
      "Epoch 142/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.1839 - loss_1: 0.1116 - root_mean_squared_error: 2.3946 - val_loss: 10.3653 - val_loss_1: 0.1110 - val_root_mean_squared_error: 2.3281\n",
      "Epoch 143/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.7960 - loss_1: 0.1117 - root_mean_squared_error: 2.3586 - val_loss: 11.0775 - val_loss_1: 0.1112 - val_root_mean_squared_error: 2.4293\n",
      "Epoch 144/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 11.2233 - loss_1: 0.1122 - root_mean_squared_error: 2.4162 - val_loss: 11.0185 - val_loss_1: 0.1128 - val_root_mean_squared_error: 2.4300\n",
      "Epoch 145/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.9256 - loss_1: 0.1111 - root_mean_squared_error: 2.3624 - val_loss: 10.5361 - val_loss_1: 0.1103 - val_root_mean_squared_error: 2.3411\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 77us/step - loss: 11.0345 - loss_1: 0.1126 - root_mean_squared_error: 2.3714 - val_loss: 10.9045 - val_loss_1: 0.1131 - val_root_mean_squared_error: 2.4092\n",
      "Epoch 147/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 10.7797 - loss_1: 0.1114 - root_mean_squared_error: 2.354 - 1s 76us/step - loss: 10.8372 - loss_1: 0.1115 - root_mean_squared_error: 2.3619 - val_loss: 11.3124 - val_loss_1: 0.1114 - val_root_mean_squared_error: 2.4316\n",
      "Epoch 148/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.8489 - loss_1: 0.1116 - root_mean_squared_error: 2.3469 - val_loss: 11.1185 - val_loss_1: 0.1116 - val_root_mean_squared_error: 2.3878\n",
      "Epoch 149/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 10.6649 - loss_1: 0.1106 - root_mean_squared_error: 2.3203 - val_loss: 10.5483 - val_loss_1: 0.1118 - val_root_mean_squared_error: 2.3528\n",
      "Epoch 150/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.9707 - loss_1: 0.1117 - root_mean_squared_error: 2.3609 - val_loss: 10.5321 - val_loss_1: 0.1103 - val_root_mean_squared_error: 2.3572\n",
      "Epoch 151/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.7174 - loss_1: 0.1101 - root_mean_squared_error: 2.3385 - val_loss: 11.2194 - val_loss_1: 0.1101 - val_root_mean_squared_error: 2.4065\n",
      "Epoch 152/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.5996 - loss_1: 0.1103 - root_mean_squared_error: 2.3290 - val_loss: 10.6427 - val_loss_1: 0.1104 - val_root_mean_squared_error: 2.3593\n",
      "Epoch 153/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.8390 - loss_1: 0.1109 - root_mean_squared_error: 2.3413 - val_loss: 10.6375 - val_loss_1: 0.1130 - val_root_mean_squared_error: 2.3520\n",
      "Epoch 154/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.5246 - loss_1: 0.1110 - root_mean_squared_error: 2.3150 - val_loss: 10.9405 - val_loss_1: 0.1103 - val_root_mean_squared_error: 2.3714\n",
      "Epoch 155/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.4507 - loss_1: 0.1108 - root_mean_squared_error: 2.3156 - val_loss: 10.7321 - val_loss_1: 0.1119 - val_root_mean_squared_error: 2.3509\n",
      "Epoch 156/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.6188 - loss_1: 0.1116 - root_mean_squared_error: 2.3281 - val_loss: 10.3949 - val_loss_1: 0.1110 - val_root_mean_squared_error: 2.3097\n",
      "Epoch 157/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.8632 - loss_1: 0.1113 - root_mean_squared_error: 2.3588 - val_loss: 10.3268 - val_loss_1: 0.1112 - val_root_mean_squared_error: 2.3134\n",
      "Epoch 158/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.5324 - loss_1: 0.1094 - root_mean_squared_error: 2.3185 - val_loss: 10.1813 - val_loss_1: 0.1106 - val_root_mean_squared_error: 2.2706\n",
      "Epoch 159/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.4894 - loss_1: 0.1107 - root_mean_squared_error: 2.3109 - val_loss: 10.5418 - val_loss_1: 0.1113 - val_root_mean_squared_error: 2.3676\n",
      "Epoch 160/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.3645 - loss_1: 0.1100 - root_mean_squared_error: 2.2908 - val_loss: 10.2776 - val_loss_1: 0.1098 - val_root_mean_squared_error: 2.3065\n",
      "Epoch 161/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.2552 - loss_1: 0.1105 - root_mean_squared_error: 2.2730 - val_loss: 10.8206 - val_loss_1: 0.1107 - val_root_mean_squared_error: 2.3661\n",
      "Epoch 162/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.4718 - loss_1: 0.1087 - root_mean_squared_error: 2.2994 - val_loss: 10.9849 - val_loss_1: 0.1100 - val_root_mean_squared_error: 2.3583\n",
      "Epoch 163/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.4367 - loss_1: 0.1108 - root_mean_squared_error: 2.2962 - val_loss: 10.7806 - val_loss_1: 0.1119 - val_root_mean_squared_error: 2.3532\n",
      "Epoch 164/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 10.3298 - loss_1: 0.1097 - root_mean_squared_error: 2.2971 - val_loss: 10.8965 - val_loss_1: 0.1099 - val_root_mean_squared_error: 2.3867\n",
      "Epoch 165/1000\n",
      "10760/10760 [==============================] - 1s 86us/step - loss: 10.2795 - loss_1: 0.1093 - root_mean_squared_error: 2.2765 - val_loss: 10.4213 - val_loss_1: 0.1082 - val_root_mean_squared_error: 2.3379\n",
      "Epoch 166/1000\n",
      "10760/10760 [==============================] - 1s 83us/step - loss: 10.5213 - loss_1: 0.1087 - root_mean_squared_error: 2.3082 - val_loss: 10.5312 - val_loss_1: 0.1105 - val_root_mean_squared_error: 2.3265\n",
      "Epoch 167/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.2246 - loss_1: 0.1102 - root_mean_squared_error: 2.2884 - val_loss: 10.4445 - val_loss_1: 0.1065 - val_root_mean_squared_error: 2.3434\n",
      "Epoch 168/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 10.4306 - loss_1: 0.1080 - root_mean_squared_error: 2.2973 - val_loss: 10.7216 - val_loss_1: 0.1120 - val_root_mean_squared_error: 2.3546\n",
      "Epoch 169/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.3096 - loss_1: 0.1112 - root_mean_squared_error: 2.2793 - val_loss: 10.4580 - val_loss_1: 0.1074 - val_root_mean_squared_error: 2.3275\n",
      "Epoch 170/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.3768 - loss_1: 0.1072 - root_mean_squared_error: 2.2817 - val_loss: 10.3614 - val_loss_1: 0.1086 - val_root_mean_squared_error: 2.3340\n",
      "Epoch 171/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 10.3049 - loss_1: 0.1100 - root_mean_squared_error: 2.2940 - val_loss: 10.7341 - val_loss_1: 0.1071 - val_root_mean_squared_error: 2.3404\n",
      "Epoch 172/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.2276 - loss_1: 0.1088 - root_mean_squared_error: 2.2562 - val_loss: 10.6844 - val_loss_1: 0.1132 - val_root_mean_squared_error: 2.3409\n",
      "Epoch 173/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.1678 - loss_1: 0.1111 - root_mean_squared_error: 2.2801 - val_loss: 10.0819 - val_loss_1: 0.1083 - val_root_mean_squared_error: 2.2739\n",
      "Epoch 174/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.3999 - loss_1: 0.1086 - root_mean_squared_error: 2.2858 - val_loss: 10.4430 - val_loss_1: 0.1103 - val_root_mean_squared_error: 2.3247\n",
      "Epoch 175/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 10.1056 - loss_1: 0.1092 - root_mean_squared_error: 2.2688 - val_loss: 10.3391 - val_loss_1: 0.1093 - val_root_mean_squared_error: 2.2991\n",
      "Epoch 176/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.1694 - loss_1: 0.1087 - root_mean_squared_error: 2.2582 - val_loss: 10.5793 - val_loss_1: 0.1088 - val_root_mean_squared_error: 2.3436\n",
      "Epoch 177/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.9510 - loss_1: 0.1092 - root_mean_squared_error: 2.2469 - val_loss: 10.2305 - val_loss_1: 0.1089 - val_root_mean_squared_error: 2.2758\n",
      "Epoch 178/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 10.0069 - loss_1: 0.1086 - root_mean_squared_error: 2.2450 - val_loss: 10.3851 - val_loss_1: 0.1087 - val_root_mean_squared_error: 2.3221\n",
      "Epoch 179/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6806 - loss_1: 0.1088 - root_mean_squared_error: 2.2148 - val_loss: 10.4418 - val_loss_1: 0.1085 - val_root_mean_squared_error: 2.3280\n",
      "Epoch 180/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 10.1168 - loss_1: 0.1074 - root_mean_squared_error: 2.2488 - val_loss: 11.0991 - val_loss_1: 0.1080 - val_root_mean_squared_error: 2.3703\n",
      "Epoch 181/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.7143 - loss_1: 0.1090 - root_mean_squared_error: 2.2232 - val_loss: 9.9119 - val_loss_1: 0.1076 - val_root_mean_squared_error: 2.2362\n",
      "Epoch 182/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.9196 - loss_1: 0.1077 - root_mean_squared_error: 2.2345 - val_loss: 10.3436 - val_loss_1: 0.1083 - val_root_mean_squared_error: 2.3135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.8498 - loss_1: 0.1081 - root_mean_squared_error: 2.2359 - val_loss: 10.1089 - val_loss_1: 0.1070 - val_root_mean_squared_error: 2.2667\n",
      "Epoch 184/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.9331 - loss_1: 0.1075 - root_mean_squared_error: 2.2216 - val_loss: 10.1776 - val_loss_1: 0.1089 - val_root_mean_squared_error: 2.3029\n",
      "Epoch 185/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.7478 - loss_1: 0.1081 - root_mean_squared_error: 2.2101 - val_loss: 10.2442 - val_loss_1: 0.1090 - val_root_mean_squared_error: 2.3171\n",
      "Epoch 186/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.8851 - loss_1: 0.1075 - root_mean_squared_error: 2.2347 - val_loss: 10.4026 - val_loss_1: 0.1074 - val_root_mean_squared_error: 2.3076\n",
      "Epoch 187/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.7478 - loss_1: 0.1075 - root_mean_squared_error: 2.2185 - val_loss: 10.0346 - val_loss_1: 0.1075 - val_root_mean_squared_error: 2.2799\n",
      "Epoch 188/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.8324 - loss_1: 0.1082 - root_mean_squared_error: 2.2263 - val_loss: 10.6037 - val_loss_1: 0.1099 - val_root_mean_squared_error: 2.3303\n",
      "Epoch 189/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.7681 - loss_1: 0.1086 - root_mean_squared_error: 2.2111 - val_loss: 10.2851 - val_loss_1: 0.1060 - val_root_mean_squared_error: 2.2829\n",
      "Epoch 190/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.7937 - loss_1: 0.1085 - root_mean_squared_error: 2.2153 - val_loss: 10.2439 - val_loss_1: 0.1089 - val_root_mean_squared_error: 2.2832\n",
      "Epoch 191/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.5764 - loss_1: 0.1071 - root_mean_squared_error: 2.1880 - val_loss: 10.1683 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.2823\n",
      "Epoch 192/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.7011 - loss_1: 0.1076 - root_mean_squared_error: 2.2109 - val_loss: 10.3220 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.2925\n",
      "Epoch 193/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.7625 - loss_1: 0.1073 - root_mean_squared_error: 2.2203 - val_loss: 9.9319 - val_loss_1: 0.1065 - val_root_mean_squared_error: 2.2680\n",
      "Epoch 194/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.9274 - loss_1: 0.1070 - root_mean_squared_error: 2.2262 - val_loss: 10.2189 - val_loss_1: 0.1081 - val_root_mean_squared_error: 2.2939\n",
      "Epoch 195/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6482 - loss_1: 0.1077 - root_mean_squared_error: 2.2087 - val_loss: 10.0987 - val_loss_1: 0.1085 - val_root_mean_squared_error: 2.2827\n",
      "Epoch 196/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.7408 - loss_1: 0.1072 - root_mean_squared_error: 2.2023 - val_loss: 10.1247 - val_loss_1: 0.1053 - val_root_mean_squared_error: 2.2601\n",
      "Epoch 197/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.3872 - loss_1: 0.1060 - root_mean_squared_error: 2.1691 - val_loss: 10.0873 - val_loss_1: 0.1061 - val_root_mean_squared_error: 2.2773\n",
      "Epoch 198/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6425 - loss_1: 0.1071 - root_mean_squared_error: 2.1961 - val_loss: 10.3665 - val_loss_1: 0.1063 - val_root_mean_squared_error: 2.2809\n",
      "Epoch 199/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.5265 - loss_1: 0.1068 - root_mean_squared_error: 2.1946 - val_loss: 9.8877 - val_loss_1: 0.1056 - val_root_mean_squared_error: 2.2702\n",
      "Epoch 200/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 9.7443 - loss_1: 0.1060 - root_mean_squared_error: 2.1970 - val_loss: 10.3815 - val_loss_1: 0.1073 - val_root_mean_squared_error: 2.3076\n",
      "Epoch 201/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 9.3818 - loss_1: 0.1072 - root_mean_squared_error: 2.1635 - val_loss: 10.2619 - val_loss_1: 0.1061 - val_root_mean_squared_error: 2.3064\n",
      "Epoch 202/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 9.7432 - loss_1: 0.1062 - root_mean_squared_error: 2.2017 - val_loss: 10.5102 - val_loss_1: 0.1067 - val_root_mean_squared_error: 2.3214\n",
      "Epoch 203/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 9.4386 - loss_1: 0.1071 - root_mean_squared_error: 2.1852 - val_loss: 10.2110 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.2808\n",
      "Epoch 204/1000\n",
      "10760/10760 [==============================] - 1s 82us/step - loss: 9.7906 - loss_1: 0.1069 - root_mean_squared_error: 2.2003 - val_loss: 9.8595 - val_loss_1: 0.1068 - val_root_mean_squared_error: 2.2429\n",
      "Epoch 205/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 9.5159 - loss_1: 0.1066 - root_mean_squared_error: 2.1835 - val_loss: 9.5460 - val_loss_1: 0.1057 - val_root_mean_squared_error: 2.2078\n",
      "Epoch 206/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 9.6235 - loss_1: 0.1070 - root_mean_squared_error: 2.1849 - val_loss: 10.0043 - val_loss_1: 0.1059 - val_root_mean_squared_error: 2.2526\n",
      "Epoch 207/1000\n",
      "10760/10760 [==============================] - 1s 82us/step - loss: 9.6054 - loss_1: 0.1060 - root_mean_squared_error: 2.1946 - val_loss: 10.3270 - val_loss_1: 0.1074 - val_root_mean_squared_error: 2.2951\n",
      "Epoch 208/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 9.3801 - loss_1: 0.1075 - root_mean_squared_error: 2.1587 - val_loss: 9.9517 - val_loss_1: 0.1057 - val_root_mean_squared_error: 2.2569\n",
      "Epoch 209/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 9.4307 - loss_1: 0.1060 - root_mean_squared_error: 2.1828 - val_loss: 9.8869 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.2191\n",
      "Epoch 210/1000\n",
      "10760/10760 [==============================] - 1s 82us/step - loss: 9.6444 - loss_1: 0.1071 - root_mean_squared_error: 2.1934 - val_loss: 10.0796 - val_loss_1: 0.1064 - val_root_mean_squared_error: 2.2605\n",
      "Epoch 211/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 9.5559 - loss_1: 0.1061 - root_mean_squared_error: 2.1781 - val_loss: 9.7959 - val_loss_1: 0.1040 - val_root_mean_squared_error: 2.2255\n",
      "Epoch 212/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.6628 - loss_1: 0.1056 - root_mean_squared_error: 2.1744 - val_loss: 10.3775 - val_loss_1: 0.1085 - val_root_mean_squared_error: 2.3182\n",
      "Epoch 213/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.6639 - loss_1: 0.1054 - root_mean_squared_error: 2.1979 - val_loss: 9.8365 - val_loss_1: 0.1045 - val_root_mean_squared_error: 2.2377\n",
      "Epoch 214/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.5113 - loss_1: 0.1067 - root_mean_squared_error: 2.1943 - val_loss: 10.0826 - val_loss_1: 0.1062 - val_root_mean_squared_error: 2.2572\n",
      "Epoch 215/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6249 - loss_1: 0.1048 - root_mean_squared_error: 2.2009 - val_loss: 10.1769 - val_loss_1: 0.1051 - val_root_mean_squared_error: 2.2828\n",
      "Epoch 216/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.6416 - loss_1: 0.1057 - root_mean_squared_error: 2.1818 - val_loss: 9.8822 - val_loss_1: 0.1044 - val_root_mean_squared_error: 2.2400\n",
      "Epoch 217/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.3110 - loss_1: 0.1046 - root_mean_squared_error: 2.1451 - val_loss: 10.1996 - val_loss_1: 0.1058 - val_root_mean_squared_error: 2.2572\n",
      "Epoch 218/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.4769 - loss_1: 0.1052 - root_mean_squared_error: 2.1728 - val_loss: 10.1628 - val_loss_1: 0.1056 - val_root_mean_squared_error: 2.2819\n",
      "Epoch 219/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.3886 - loss_1: 0.1045 - root_mean_squared_error: 2.1740 - val_loss: 9.8241 - val_loss_1: 0.1051 - val_root_mean_squared_error: 2.1941\n",
      "Epoch 220/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.1731 - loss_1: 0.1059 - root_mean_squared_error: 2.1467 - val_loss: 10.0444 - val_loss_1: 0.1059 - val_root_mean_squared_error: 2.2705\n",
      "Epoch 221/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.1989 - loss_1: 0.1043 - root_mean_squared_error: 2.1405 - val_loss: 9.7972 - val_loss_1: 0.1047 - val_root_mean_squared_error: 2.2218\n",
      "Epoch 222/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.3316 - loss_1: 0.1050 - root_mean_squared_error: 2.1649 - val_loss: 9.9896 - val_loss_1: 0.1041 - val_root_mean_squared_error: 2.2550\n",
      "Epoch 223/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.5243 - loss_1: 0.1042 - root_mean_squared_error: 2.1785 - val_loss: 10.0872 - val_loss_1: 0.1063 - val_root_mean_squared_error: 2.2544\n",
      "Epoch 224/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.1645 - loss_1: 0.1057 - root_mean_squared_error: 2.1450 - val_loss: 9.7272 - val_loss_1: 0.1040 - val_root_mean_squared_error: 2.2164\n",
      "Epoch 225/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.4033 - loss_1: 0.1044 - root_mean_squared_error: 2.1781 - val_loss: 9.2638 - val_loss_1: 0.1051 - val_root_mean_squared_error: 2.1969\n",
      "Epoch 226/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.4898 - loss_1: 0.1043 - root_mean_squared_error: 2.1816 - val_loss: 10.0045 - val_loss_1: 0.1037 - val_root_mean_squared_error: 2.2739\n",
      "Epoch 227/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.0490 - loss_1: 0.1051 - root_mean_squared_error: 2.1420 - val_loss: 10.2998 - val_loss_1: 0.1045 - val_root_mean_squared_error: 2.2747\n",
      "Epoch 228/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.1264 - loss_1: 0.1037 - root_mean_squared_error: 2.1319 - val_loss: 10.1928 - val_loss_1: 0.1054 - val_root_mean_squared_error: 2.2731\n",
      "Epoch 229/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.6377 - loss_1: 0.1061 - root_mean_squared_error: 2.1953 - val_loss: 9.6549 - val_loss_1: 0.1037 - val_root_mean_squared_error: 2.1829\n",
      "Epoch 230/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 9.5050 - loss_1: 0.1029 - root_mean_squared_error: 2.1776 - val_loss: 10.1956 - val_loss_1: 0.1048 - val_root_mean_squared_error: 2.2873\n",
      "Epoch 231/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.4342 - loss_1: 0.1042 - root_mean_squared_error: 2.1608 - val_loss: 10.1930 - val_loss_1: 0.1042 - val_root_mean_squared_error: 2.2611\n",
      "Epoch 232/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.1947 - loss_1: 0.1033 - root_mean_squared_error: 2.1469 - val_loss: 9.8582 - val_loss_1: 0.1034 - val_root_mean_squared_error: 2.2294\n",
      "Epoch 233/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.3220 - loss_1: 0.1043 - root_mean_squared_error: 2.1510 - val_loss: 9.7045 - val_loss_1: 0.1040 - val_root_mean_squared_error: 2.2062\n",
      "Epoch 234/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.2087 - loss_1: 0.1045 - root_mean_squared_error: 2.1437 - val_loss: 10.0089 - val_loss_1: 0.1044 - val_root_mean_squared_error: 2.2713\n",
      "Epoch 235/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.1911 - loss_1: 0.1037 - root_mean_squared_error: 2.1474 - val_loss: 10.0703 - val_loss_1: 0.1012 - val_root_mean_squared_error: 2.2388\n",
      "Epoch 236/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 9.3351 - loss_1: 0.1028 - root_mean_squared_error: 2.1573 - val_loss: 9.5519 - val_loss_1: 0.1047 - val_root_mean_squared_error: 2.2353\n",
      "Epoch 237/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.1620 - loss_1: 0.1041 - root_mean_squared_error: 2.1304 - val_loss: 9.5132 - val_loss_1: 0.1026 - val_root_mean_squared_error: 2.1962\n",
      "Epoch 238/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.2803 - loss_1: 0.1035 - root_mean_squared_error: 2.1513 - val_loss: 10.3589 - val_loss_1: 0.1056 - val_root_mean_squared_error: 2.3152\n",
      "Epoch 239/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.3476 - loss_1: 0.1038 - root_mean_squared_error: 2.1528 - val_loss: 9.7023 - val_loss_1: 0.1018 - val_root_mean_squared_error: 2.2256\n",
      "Epoch 240/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 9.1090 - loss_1: 0.1040 - root_mean_squared_error: 2.1449 - val_loss: 9.4260 - val_loss_1: 0.1050 - val_root_mean_squared_error: 2.1918\n",
      "Epoch 241/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 9.3543 - loss_1: 0.1033 - root_mean_squared_error: 2.1554 - val_loss: 10.0303 - val_loss_1: 0.1038 - val_root_mean_squared_error: 2.2710\n",
      "Epoch 242/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.9547 - loss_1: 0.1032 - root_mean_squared_error: 2.1040 - val_loss: 10.1429 - val_loss_1: 0.1036 - val_root_mean_squared_error: 2.2505\n",
      "Epoch 243/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.3274 - loss_1: 0.1041 - root_mean_squared_error: 2.1638 - val_loss: 9.9917 - val_loss_1: 0.1030 - val_root_mean_squared_error: 2.2136\n",
      "Epoch 244/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.9337 - loss_1: 0.1024 - root_mean_squared_error: 2.1150 - val_loss: 9.8334 - val_loss_1: 0.1037 - val_root_mean_squared_error: 2.2292\n",
      "Epoch 245/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.3103 - loss_1: 0.1031 - root_mean_squared_error: 2.1397 - val_loss: 9.7912 - val_loss_1: 0.1014 - val_root_mean_squared_error: 2.2218\n",
      "Epoch 246/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.1315 - loss_1: 0.1031 - root_mean_squared_error: 2.1372 - val_loss: 10.1249 - val_loss_1: 0.1037 - val_root_mean_squared_error: 2.2859\n",
      "Epoch 247/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.2738 - loss_1: 0.1028 - root_mean_squared_error: 2.1501 - val_loss: 9.5812 - val_loss_1: 0.1035 - val_root_mean_squared_error: 2.2046\n",
      "Epoch 248/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8892 - loss_1: 0.1027 - root_mean_squared_error: 2.0944 - val_loss: 9.7424 - val_loss_1: 0.1023 - val_root_mean_squared_error: 2.1912\n",
      "Epoch 249/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 9.0876 - loss_1: 0.1020 - root_mean_squared_error: 2.1238 - val_loss: 10.1336 - val_loss_1: 0.1008 - val_root_mean_squared_error: 2.2880\n",
      "Epoch 250/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0535 - loss_1: 0.1025 - root_mean_squared_error: 2.1456 - val_loss: 9.7561 - val_loss_1: 0.1020 - val_root_mean_squared_error: 2.2293\n",
      "Epoch 251/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.0994 - loss_1: 0.1015 - root_mean_squared_error: 2.1292 - val_loss: 10.2753 - val_loss_1: 0.1030 - val_root_mean_squared_error: 2.2770\n",
      "Epoch 252/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0563 - loss_1: 0.1032 - root_mean_squared_error: 2.1071 - val_loss: 9.9420 - val_loss_1: 0.1019 - val_root_mean_squared_error: 2.2427\n",
      "Epoch 253/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0608 - loss_1: 0.1015 - root_mean_squared_error: 2.1231 - val_loss: 9.7080 - val_loss_1: 0.1017 - val_root_mean_squared_error: 2.2373\n",
      "Epoch 254/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.1305 - loss_1: 0.1015 - root_mean_squared_error: 2.1398 - val_loss: 9.8179 - val_loss_1: 0.1038 - val_root_mean_squared_error: 2.2414\n",
      "Epoch 255/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0533 - loss_1: 0.1022 - root_mean_squared_error: 2.1234 - val_loss: 10.0739 - val_loss_1: 0.1015 - val_root_mean_squared_error: 2.2547\n",
      "Epoch 256/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.9652 - loss_1: 0.1023 - root_mean_squared_error: 2.1107 - val_loss: 9.8755 - val_loss_1: 0.1013 - val_root_mean_squared_error: 2.2402\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.2029 - loss_1: 0.1007 - root_mean_squared_error: 2.1374 - val_loss: 10.1113 - val_loss_1: 0.1030 - val_root_mean_squared_error: 2.2759\n",
      "Epoch 258/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.9227 - loss_1: 0.1030 - root_mean_squared_error: 2.0998 - val_loss: 9.5218 - val_loss_1: 0.1000 - val_root_mean_squared_error: 2.2071\n",
      "Epoch 259/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.2108 - loss_1: 0.1005 - root_mean_squared_error: 2.1379 - val_loss: 9.8491 - val_loss_1: 0.1026 - val_root_mean_squared_error: 2.2485\n",
      "Epoch 260/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.9566 - loss_1: 0.1011 - root_mean_squared_error: 2.1116 - val_loss: 9.6204 - val_loss_1: 0.1015 - val_root_mean_squared_error: 2.2083\n",
      "Epoch 261/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0292 - loss_1: 0.1022 - root_mean_squared_error: 2.1156 - val_loss: 9.7292 - val_loss_1: 0.1008 - val_root_mean_squared_error: 2.2306\n",
      "Epoch 262/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.9926 - loss_1: 0.1005 - root_mean_squared_error: 2.1204 - val_loss: 9.4594 - val_loss_1: 0.1018 - val_root_mean_squared_error: 2.1854\n",
      "Epoch 263/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.9064 - loss_1: 0.1013 - root_mean_squared_error: 2.0926 - val_loss: 10.0462 - val_loss_1: 0.0989 - val_root_mean_squared_error: 2.2298\n",
      "Epoch 264/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.6557 - loss_1: 0.1009 - root_mean_squared_error: 2.0758 - val_loss: 9.8199 - val_loss_1: 0.1013 - val_root_mean_squared_error: 2.2345\n",
      "Epoch 265/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.0041 - loss_1: 0.1011 - root_mean_squared_error: 2.1179 - val_loss: 10.0364 - val_loss_1: 0.1012 - val_root_mean_squared_error: 2.2764\n",
      "Epoch 266/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.1922 - loss_1: 0.1012 - root_mean_squared_error: 2.1461 - val_loss: 9.2816 - val_loss_1: 0.0999 - val_root_mean_squared_error: 2.1900\n",
      "Epoch 267/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.9139 - loss_1: 0.1009 - root_mean_squared_error: 2.1005 - val_loss: 9.7468 - val_loss_1: 0.1009 - val_root_mean_squared_error: 2.2348\n",
      "Epoch 268/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 9.0942 - loss_1: 0.1013 - root_mean_squared_error: 2.1272 - val_loss: 9.6303 - val_loss_1: 0.1004 - val_root_mean_squared_error: 2.2111\n",
      "Epoch 269/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 9.0076 - loss_1: 0.1018 - root_mean_squared_error: 2.1149 - val_loss: 8.9520 - val_loss_1: 0.1008 - val_root_mean_squared_error: 2.1222\n",
      "Epoch 270/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.9973 - loss_1: 0.0998 - root_mean_squared_error: 2.1186 - val_loss: 10.0939 - val_loss_1: 0.1017 - val_root_mean_squared_error: 2.2810\n",
      "Epoch 271/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8834 - loss_1: 0.1017 - root_mean_squared_error: 2.1125 - val_loss: 10.3138 - val_loss_1: 0.1005 - val_root_mean_squared_error: 2.2974\n",
      "Epoch 272/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.7120 - loss_1: 0.1018 - root_mean_squared_error: 2.0874 - val_loss: 9.3400 - val_loss_1: 0.1006 - val_root_mean_squared_error: 2.1786\n",
      "Epoch 273/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.9440 - loss_1: 0.1000 - root_mean_squared_error: 2.1116 - val_loss: 9.7541 - val_loss_1: 0.1018 - val_root_mean_squared_error: 2.2389\n",
      "Epoch 274/1000\n",
      "10760/10760 [==============================] - 1s 82us/step - loss: 8.7308 - loss_1: 0.1009 - root_mean_squared_error: 2.0894 - val_loss: 9.8349 - val_loss_1: 0.1009 - val_root_mean_squared_error: 2.2285\n",
      "Epoch 275/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.8528 - loss_1: 0.1013 - root_mean_squared_error: 2.1085 - val_loss: 9.8443 - val_loss_1: 0.1006 - val_root_mean_squared_error: 2.2590\n",
      "Epoch 276/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 9.0884 - loss_1: 0.1007 - root_mean_squared_error: 2.1206 - val_loss: 9.8720 - val_loss_1: 0.1010 - val_root_mean_squared_error: 2.2691\n",
      "Epoch 277/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 9.0638 - loss_1: 0.1004 - root_mean_squared_error: 2.1146 - val_loss: 9.9576 - val_loss_1: 0.1002 - val_root_mean_squared_error: 2.2560\n",
      "Epoch 278/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.9042 - loss_1: 0.1007 - root_mean_squared_error: 2.1002 - val_loss: 9.8945 - val_loss_1: 0.0997 - val_root_mean_squared_error: 2.2714\n",
      "Epoch 279/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.7685 - loss_1: 0.0999 - root_mean_squared_error: 2.0961 - val_loss: 9.6039 - val_loss_1: 0.0991 - val_root_mean_squared_error: 2.2058\n",
      "Epoch 280/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8334 - loss_1: 0.1002 - root_mean_squared_error: 2.0862 - val_loss: 9.8968 - val_loss_1: 0.1001 - val_root_mean_squared_error: 2.2394\n",
      "Epoch 281/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.6482 - loss_1: 0.0996 - root_mean_squared_error: 2.0799 - val_loss: 9.1832 - val_loss_1: 0.0982 - val_root_mean_squared_error: 2.1777\n",
      "Epoch 282/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8104 - loss_1: 0.0997 - root_mean_squared_error: 2.0933 - val_loss: 9.8215 - val_loss_1: 0.1002 - val_root_mean_squared_error: 2.2373\n",
      "Epoch 283/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.8050 - loss_1: 0.0998 - root_mean_squared_error: 2.0882 - val_loss: 9.2252 - val_loss_1: 0.0990 - val_root_mean_squared_error: 2.1751\n",
      "Epoch 284/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.7072 - loss_1: 0.1003 - root_mean_squared_error: 2.0754 - val_loss: 9.4286 - val_loss_1: 0.1004 - val_root_mean_squared_error: 2.1975\n",
      "Epoch 285/1000\n",
      "10760/10760 [==============================] - 1s 86us/step - loss: 8.7031 - loss_1: 0.0991 - root_mean_squared_error: 2.0828 - val_loss: 9.8279 - val_loss_1: 0.1000 - val_root_mean_squared_error: 2.2440\n",
      "Epoch 286/1000\n",
      "10760/10760 [==============================] - 1s 87us/step - loss: 8.8950 - loss_1: 0.1001 - root_mean_squared_error: 2.1099 - val_loss: 9.0426 - val_loss_1: 0.0981 - val_root_mean_squared_error: 2.1655\n",
      "Epoch 287/1000\n",
      "10760/10760 [==============================] - 1s 88us/step - loss: 8.6931 - loss_1: 0.0983 - root_mean_squared_error: 2.0898 - val_loss: 9.7720 - val_loss_1: 0.0998 - val_root_mean_squared_error: 2.2316\n",
      "Epoch 288/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 8.7071 - loss_1: 0.1003 - root_mean_squared_error: 2.0948 - val_loss: 9.1266 - val_loss_1: 0.0980 - val_root_mean_squared_error: 2.1561\n",
      "Epoch 289/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.6591 - loss_1: 0.0987 - root_mean_squared_error: 2.0734 - val_loss: 9.9233 - val_loss_1: 0.0991 - val_root_mean_squared_error: 2.2653\n",
      "Epoch 290/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.6127 - loss_1: 0.0986 - root_mean_squared_error: 2.0749 - val_loss: 9.6430 - val_loss_1: 0.0991 - val_root_mean_squared_error: 2.2364\n",
      "Epoch 291/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 8.8071 - loss_1: 0.0993 - root_mean_squared_error: 2.08 - 1s 74us/step - loss: 8.8555 - loss_1: 0.0993 - root_mean_squared_error: 2.0906 - val_loss: 9.8432 - val_loss_1: 0.0995 - val_root_mean_squared_error: 2.2405\n",
      "Epoch 292/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.9696 - loss_1: 0.0994 - root_mean_squared_error: 2.1131 - val_loss: 9.5609 - val_loss_1: 0.0999 - val_root_mean_squared_error: 2.2334\n",
      "Epoch 293/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.6776 - loss_1: 0.0995 - root_mean_squared_error: 2.0763 - val_loss: 9.6929 - val_loss_1: 0.0993 - val_root_mean_squared_error: 2.2254\n",
      "Epoch 294/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.5419 - loss_1: 0.0993 - root_mean_squared_error: 2.0638 - val_loss: 9.1649 - val_loss_1: 0.0985 - val_root_mean_squared_error: 2.1695\n",
      "Epoch 295/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.3734 - loss_1: 0.0990 - root_mean_squared_error: 2.0405 - val_loss: 9.5108 - val_loss_1: 0.0988 - val_root_mean_squared_error: 2.2226\n",
      "Epoch 296/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.6061 - loss_1: 0.0993 - root_mean_squared_error: 2.0623 - val_loss: 9.4025 - val_loss_1: 0.1005 - val_root_mean_squared_error: 2.2262\n",
      "Epoch 297/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.8910 - loss_1: 0.0997 - root_mean_squared_error: 2.0973 - val_loss: 9.6378 - val_loss_1: 0.0983 - val_root_mean_squared_error: 2.2196\n",
      "Epoch 298/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.7191 - loss_1: 0.0988 - root_mean_squared_error: 2.0809 - val_loss: 9.5191 - val_loss_1: 0.0985 - val_root_mean_squared_error: 2.2089\n",
      "Epoch 299/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.7537 - loss_1: 0.0991 - root_mean_squared_error: 2.0829 - val_loss: 9.2574 - val_loss_1: 0.0988 - val_root_mean_squared_error: 2.2019\n",
      "Epoch 300/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.6802 - loss_1: 0.0988 - root_mean_squared_error: 2.0808 - val_loss: 9.4527 - val_loss_1: 0.0992 - val_root_mean_squared_error: 2.1959\n",
      "Epoch 301/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.4607 - loss_1: 0.0989 - root_mean_squared_error: 2.0488 - val_loss: 9.2895 - val_loss_1: 0.0990 - val_root_mean_squared_error: 2.1878\n",
      "Epoch 302/1000\n",
      "10760/10760 [==============================] - 1s 82us/step - loss: 8.5738 - loss_1: 0.0991 - root_mean_squared_error: 2.0619 - val_loss: 10.1150 - val_loss_1: 0.0983 - val_root_mean_squared_error: 2.2676\n",
      "Epoch 303/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3891 - loss_1: 0.0974 - root_mean_squared_error: 2.0384 - val_loss: 9.7684 - val_loss_1: 0.0995 - val_root_mean_squared_error: 2.2456\n",
      "Epoch 304/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 8.7143 - loss_1: 0.0993 - root_mean_squared_error: 2.0909 - val_loss: 9.2989 - val_loss_1: 0.0985 - val_root_mean_squared_error: 2.1770\n",
      "Epoch 305/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.4143 - loss_1: 0.0986 - root_mean_squared_error: 2.0487 - val_loss: 9.7273 - val_loss_1: 0.0995 - val_root_mean_squared_error: 2.2232\n",
      "Epoch 306/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.8290 - loss_1: 0.0977 - root_mean_squared_error: 2.0768 - val_loss: 9.3742 - val_loss_1: 0.0988 - val_root_mean_squared_error: 2.2137\n",
      "Epoch 307/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.6079 - loss_1: 0.0998 - root_mean_squared_error: 2.0763 - val_loss: 9.7968 - val_loss_1: 0.0972 - val_root_mean_squared_error: 2.2377\n",
      "Epoch 308/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.5604 - loss_1: 0.0977 - root_mean_squared_error: 2.0596 - val_loss: 9.2143 - val_loss_1: 0.0977 - val_root_mean_squared_error: 2.1916\n",
      "Epoch 309/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.5432 - loss_1: 0.0984 - root_mean_squared_error: 2.0568 - val_loss: 9.5974 - val_loss_1: 0.0990 - val_root_mean_squared_error: 2.2205\n",
      "Epoch 310/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.2785 - loss_1: 0.0977 - root_mean_squared_error: 2.0200 - val_loss: 9.4452 - val_loss_1: 0.0988 - val_root_mean_squared_error: 2.2098\n",
      "Epoch 311/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.6145 - loss_1: 0.0989 - root_mean_squared_error: 2.0650 - val_loss: 9.6186 - val_loss_1: 0.0992 - val_root_mean_squared_error: 2.2244\n",
      "Epoch 312/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.4609 - loss_1: 0.0983 - root_mean_squared_error: 2.0535 - val_loss: 9.4010 - val_loss_1: 0.0975 - val_root_mean_squared_error: 2.2356\n",
      "Epoch 313/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.4035 - loss_1: 0.0976 - root_mean_squared_error: 2.0376 - val_loss: 9.3309 - val_loss_1: 0.0986 - val_root_mean_squared_error: 2.1953\n",
      "Epoch 314/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.9237 - loss_1: 0.0983 - root_mean_squared_error: 2.1014 - val_loss: 8.9677 - val_loss_1: 0.0978 - val_root_mean_squared_error: 2.1626\n",
      "Epoch 315/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.5571 - loss_1: 0.0979 - root_mean_squared_error: 2.0636 - val_loss: 9.3915 - val_loss_1: 0.0975 - val_root_mean_squared_error: 2.2009\n",
      "Epoch 316/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.4984 - loss_1: 0.0982 - root_mean_squared_error: 2.0581 - val_loss: 9.6286 - val_loss_1: 0.0996 - val_root_mean_squared_error: 2.2299\n",
      "Epoch 317/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.4579 - loss_1: 0.0994 - root_mean_squared_error: 2.0619 - val_loss: 9.4202 - val_loss_1: 0.0971 - val_root_mean_squared_error: 2.2165\n",
      "Epoch 318/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 8.6632 - loss_1: 0.0974 - root_mean_squared_error: 2.0665 - val_loss: 9.3969 - val_loss_1: 0.0993 - val_root_mean_squared_error: 2.2200\n",
      "Epoch 319/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.5002 - loss_1: 0.0978 - root_mean_squared_error: 2.0536 - val_loss: 9.5340 - val_loss_1: 0.0994 - val_root_mean_squared_error: 2.2306\n",
      "Epoch 320/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.5312 - loss_1: 0.0985 - root_mean_squared_error: 2.0594 - val_loss: 8.9620 - val_loss_1: 0.0958 - val_root_mean_squared_error: 2.1300\n",
      "Epoch 321/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.6177 - loss_1: 0.0957 - root_mean_squared_error: 2.0835 - val_loss: 9.3905 - val_loss_1: 0.0977 - val_root_mean_squared_error: 2.1913\n",
      "Epoch 322/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 8.6103 - loss_1: 0.0978 - root_mean_squared_error: 2.0797 - val_loss: 9.1527 - val_loss_1: 0.0987 - val_root_mean_squared_error: 2.1719\n",
      "Epoch 323/1000\n",
      "10760/10760 [==============================] - 1s 84us/step - loss: 8.4004 - loss_1: 0.0977 - root_mean_squared_error: 2.0537 - val_loss: 9.2583 - val_loss_1: 0.0966 - val_root_mean_squared_error: 2.1890\n",
      "Epoch 324/1000\n",
      "10760/10760 [==============================] - 1s 83us/step - loss: 8.5704 - loss_1: 0.0970 - root_mean_squared_error: 2.0627 - val_loss: 9.5490 - val_loss_1: 0.0975 - val_root_mean_squared_error: 2.2480\n",
      "Epoch 325/1000\n",
      "10760/10760 [==============================] - 1s 81us/step - loss: 8.3559 - loss_1: 0.0964 - root_mean_squared_error: 2.0404 - val_loss: 9.2875 - val_loss_1: 0.0964 - val_root_mean_squared_error: 2.2062\n",
      "Epoch 326/1000\n",
      "10760/10760 [==============================] - 1s 86us/step - loss: 8.6246 - loss_1: 0.0970 - root_mean_squared_error: 2.0610 - val_loss: 8.8158 - val_loss_1: 0.0965 - val_root_mean_squared_error: 2.1380\n",
      "Epoch 327/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 8.6462 - loss_1: 0.0982 - root_mean_squared_error: 2.0778 - val_loss: 9.2197 - val_loss_1: 0.0974 - val_root_mean_squared_error: 2.1754\n",
      "Epoch 328/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.5636 - loss_1: 0.0971 - root_mean_squared_error: 2.0571 - val_loss: 9.5523 - val_loss_1: 0.0985 - val_root_mean_squared_error: 2.2217\n",
      "Epoch 329/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.5045 - loss_1: 0.0967 - root_mean_squared_error: 2.0643 - val_loss: 9.3554 - val_loss_1: 0.0970 - val_root_mean_squared_error: 2.1941\n",
      "Epoch 330/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.4621 - loss_1: 0.0975 - root_mean_squared_error: 2.0491 - val_loss: 9.0595 - val_loss_1: 0.0960 - val_root_mean_squared_error: 2.1655\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.4176 - loss_1: 0.0975 - root_mean_squared_error: 2.0333 - val_loss: 9.7990 - val_loss_1: 0.0967 - val_root_mean_squared_error: 2.2529\n",
      "Epoch 332/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.5289 - loss_1: 0.0970 - root_mean_squared_error: 2.0652 - val_loss: 9.3602 - val_loss_1: 0.0989 - val_root_mean_squared_error: 2.1930\n",
      "Epoch 333/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2808 - loss_1: 0.0972 - root_mean_squared_error: 2.0231 - val_loss: 9.6125 - val_loss_1: 0.0967 - val_root_mean_squared_error: 2.2308\n",
      "Epoch 334/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.3034 - loss_1: 0.0966 - root_mean_squared_error: 2.0442 - val_loss: 9.0749 - val_loss_1: 0.0969 - val_root_mean_squared_error: 2.1650\n",
      "Epoch 335/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.2990 - loss_1: 0.0974 - root_mean_squared_error: 2.0460 - val_loss: 9.4927 - val_loss_1: 0.0960 - val_root_mean_squared_error: 2.2203\n",
      "Epoch 336/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.5002 - loss_1: 0.0968 - root_mean_squared_error: 2.0498 - val_loss: 9.4467 - val_loss_1: 0.0961 - val_root_mean_squared_error: 2.2239\n",
      "Epoch 337/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3248 - loss_1: 0.0966 - root_mean_squared_error: 2.0410 - val_loss: 9.7447 - val_loss_1: 0.0963 - val_root_mean_squared_error: 2.2353\n",
      "Epoch 338/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.0475 - loss_1: 0.0969 - root_mean_squared_error: 2.0098 - val_loss: 9.3308 - val_loss_1: 0.0968 - val_root_mean_squared_error: 2.2137\n",
      "Epoch 339/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.2958 - loss_1: 0.0965 - root_mean_squared_error: 2.0397 - val_loss: 9.4772 - val_loss_1: 0.0969 - val_root_mean_squared_error: 2.2251\n",
      "Epoch 340/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.4583 - loss_1: 0.0966 - root_mean_squared_error: 2.0465 - val_loss: 9.5566 - val_loss_1: 0.0981 - val_root_mean_squared_error: 2.2556\n",
      "Epoch 341/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.4142 - loss_1: 0.0969 - root_mean_squared_error: 2.0503 - val_loss: 9.4082 - val_loss_1: 0.0959 - val_root_mean_squared_error: 2.2259\n",
      "Epoch 342/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2244 - loss_1: 0.0961 - root_mean_squared_error: 2.0173 - val_loss: 8.9934 - val_loss_1: 0.0951 - val_root_mean_squared_error: 2.1634\n",
      "Epoch 343/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.2289 - loss_1: 0.0960 - root_mean_squared_error: 2.0440 - val_loss: 9.6074 - val_loss_1: 0.0963 - val_root_mean_squared_error: 2.2522\n",
      "Epoch 344/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.2363 - loss_1: 0.0954 - root_mean_squared_error: 2.0273 - val_loss: 9.6631 - val_loss_1: 0.0971 - val_root_mean_squared_error: 2.2368\n",
      "Epoch 345/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.5476 - loss_1: 0.0968 - root_mean_squared_error: 2.0535 - val_loss: 8.8854 - val_loss_1: 0.0964 - val_root_mean_squared_error: 2.1616\n",
      "Epoch 346/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 8.2817 - loss_1: 0.0968 - root_mean_squared_error: 2.0276 - val_loss: 9.3450 - val_loss_1: 0.0971 - val_root_mean_squared_error: 2.2102\n",
      "Epoch 347/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.4760 - loss_1: 0.0962 - root_mean_squared_error: 2.0565 - val_loss: 8.6653 - val_loss_1: 0.0957 - val_root_mean_squared_error: 2.1282\n",
      "Epoch 348/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2358 - loss_1: 0.0954 - root_mean_squared_error: 2.0266 - val_loss: 9.9479 - val_loss_1: 0.0959 - val_root_mean_squared_error: 2.2644\n",
      "Epoch 349/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.4386 - loss_1: 0.0972 - root_mean_squared_error: 2.0563 - val_loss: 9.3523 - val_loss_1: 0.0966 - val_root_mean_squared_error: 2.1888\n",
      "Epoch 350/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3237 - loss_1: 0.0957 - root_mean_squared_error: 2.0449 - val_loss: 9.1977 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.1695\n",
      "Epoch 351/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 8.4465 - loss_1: 0.0959 - root_mean_squared_error: 2.0468 - val_loss: 9.2408 - val_loss_1: 0.0971 - val_root_mean_squared_error: 2.1880\n",
      "Epoch 352/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.2066 - loss_1: 0.0957 - root_mean_squared_error: 2.0193 - val_loss: 8.9878 - val_loss_1: 0.0957 - val_root_mean_squared_error: 2.1961\n",
      "Epoch 353/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.1378 - loss_1: 0.0961 - root_mean_squared_error: 2.0141 - val_loss: 8.7631 - val_loss_1: 0.0976 - val_root_mean_squared_error: 2.1618\n",
      "Epoch 354/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.3884 - loss_1: 0.0963 - root_mean_squared_error: 2.0428 - val_loss: 9.3095 - val_loss_1: 0.0966 - val_root_mean_squared_error: 2.2156\n",
      "Epoch 355/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.4699 - loss_1: 0.0960 - root_mean_squared_error: 2.0588 - val_loss: 9.0589 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.2151\n",
      "Epoch 356/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.3433 - loss_1: 0.0960 - root_mean_squared_error: 2.0459 - val_loss: 9.0288 - val_loss_1: 0.0960 - val_root_mean_squared_error: 2.1668\n",
      "Epoch 357/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.1282 - loss_1: 0.0963 - root_mean_squared_error: 2.0226 - val_loss: 9.0807 - val_loss_1: 0.0960 - val_root_mean_squared_error: 2.1803\n",
      "Epoch 358/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0631 - loss_1: 0.0951 - root_mean_squared_error: 2.0143 - val_loss: 9.3614 - val_loss_1: 0.0966 - val_root_mean_squared_error: 2.2196\n",
      "Epoch 359/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 8.3111 - loss_1: 0.0956 - root_mean_squared_error: 2.0317 - val_loss: 8.8773 - val_loss_1: 0.0943 - val_root_mean_squared_error: 2.1282\n",
      "Epoch 360/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 8.2391 - loss_1: 0.0948 - root_mean_squared_error: 2.0319 - val_loss: 8.9608 - val_loss_1: 0.0946 - val_root_mean_squared_error: 2.1976\n",
      "Epoch 361/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0726 - loss_1: 0.0956 - root_mean_squared_error: 2.0043 - val_loss: 8.8072 - val_loss_1: 0.0951 - val_root_mean_squared_error: 2.1504\n",
      "Epoch 362/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0888 - loss_1: 0.0949 - root_mean_squared_error: 1.9937 - val_loss: 9.3101 - val_loss_1: 0.0953 - val_root_mean_squared_error: 2.2097\n",
      "Epoch 363/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.2981 - loss_1: 0.0958 - root_mean_squared_error: 2.0308 - val_loss: 9.3014 - val_loss_1: 0.0948 - val_root_mean_squared_error: 2.1890\n",
      "Epoch 364/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2326 - loss_1: 0.0951 - root_mean_squared_error: 2.0283 - val_loss: 9.3044 - val_loss_1: 0.0962 - val_root_mean_squared_error: 2.2222\n",
      "Epoch 365/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2522 - loss_1: 0.0957 - root_mean_squared_error: 2.0347 - val_loss: 9.4976 - val_loss_1: 0.0963 - val_root_mean_squared_error: 2.2280\n",
      "Epoch 366/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2667 - loss_1: 0.0954 - root_mean_squared_error: 2.0369 - val_loss: 9.3731 - val_loss_1: 0.0949 - val_root_mean_squared_error: 2.2090\n",
      "Epoch 367/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0085 - loss_1: 0.0948 - root_mean_squared_error: 2.0031 - val_loss: 9.5483 - val_loss_1: 0.0958 - val_root_mean_squared_error: 2.2381\n",
      "Epoch 368/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.1057 - loss_1: 0.0968 - root_mean_squared_error: 2.0209 - val_loss: 9.2288 - val_loss_1: 0.0947 - val_root_mean_squared_error: 2.2046\n",
      "Epoch 369/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0023 - loss_1: 0.0948 - root_mean_squared_error: 1.9947 - val_loss: 9.0995 - val_loss_1: 0.0966 - val_root_mean_squared_error: 2.1946\n",
      "Epoch 370/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.1754 - loss_1: 0.0953 - root_mean_squared_error: 2.0200 - val_loss: 9.6778 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.2616\n",
      "Epoch 371/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2110 - loss_1: 0.0954 - root_mean_squared_error: 2.0256 - val_loss: 9.5246 - val_loss_1: 0.0947 - val_root_mean_squared_error: 2.2288\n",
      "Epoch 372/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.2200 - loss_1: 0.0950 - root_mean_squared_error: 2.0200 - val_loss: 9.7637 - val_loss_1: 0.0959 - val_root_mean_squared_error: 2.2723\n",
      "Epoch 373/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.2628 - loss_1: 0.0949 - root_mean_squared_error: 2.0225 - val_loss: 9.0928 - val_loss_1: 0.0960 - val_root_mean_squared_error: 2.2103\n",
      "Epoch 374/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.1214 - loss_1: 0.0946 - root_mean_squared_error: 2.0168 - val_loss: 8.9353 - val_loss_1: 0.0952 - val_root_mean_squared_error: 2.1824\n",
      "Epoch 375/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9126 - loss_1: 0.0956 - root_mean_squared_error: 1.9909 - val_loss: 8.8936 - val_loss_1: 0.0941 - val_root_mean_squared_error: 2.1507\n",
      "Epoch 376/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2507 - loss_1: 0.0945 - root_mean_squared_error: 2.0236 - val_loss: 9.7429 - val_loss_1: 0.0965 - val_root_mean_squared_error: 2.2510\n",
      "Epoch 377/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 8.0472 - loss_1: 0.0954 - root_mean_squared_error: 1.9983 - val_loss: 9.1300 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.2041\n",
      "Epoch 378/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.2132 - loss_1: 0.0962 - root_mean_squared_error: 2.0276 - val_loss: 9.6335 - val_loss_1: 0.0963 - val_root_mean_squared_error: 2.2272\n",
      "Epoch 379/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9379 - loss_1: 0.0943 - root_mean_squared_error: 1.9966 - val_loss: 8.7275 - val_loss_1: 0.0949 - val_root_mean_squared_error: 2.1372\n",
      "Epoch 380/1000\n",
      "10760/10760 [==============================] - 1s 82us/step - loss: 8.1104 - loss_1: 0.0954 - root_mean_squared_error: 2.0134 - val_loss: 9.0809 - val_loss_1: 0.0961 - val_root_mean_squared_error: 2.1849\n",
      "Epoch 381/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9925 - loss_1: 0.0949 - root_mean_squared_error: 1.9977 - val_loss: 8.8610 - val_loss_1: 0.0960 - val_root_mean_squared_error: 2.1463\n",
      "Epoch 382/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.1011 - loss_1: 0.0958 - root_mean_squared_error: 2.0067 - val_loss: 8.9890 - val_loss_1: 0.0958 - val_root_mean_squared_error: 2.1681\n",
      "Epoch 383/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 7.8497 - loss_1: 0.0951 - root_mean_squared_error: 1.9749 - val_loss: 9.1267 - val_loss_1: 0.0945 - val_root_mean_squared_error: 2.1893\n",
      "Epoch 384/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0952 - loss_1: 0.0951 - root_mean_squared_error: 1.9947 - val_loss: 8.7718 - val_loss_1: 0.0937 - val_root_mean_squared_error: 2.1431\n",
      "Epoch 385/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9014 - loss_1: 0.0939 - root_mean_squared_error: 1.9861 - val_loss: 9.1292 - val_loss_1: 0.0947 - val_root_mean_squared_error: 2.1781\n",
      "Epoch 386/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.8218 - loss_1: 0.0953 - root_mean_squared_error: 1.9662 - val_loss: 8.7884 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.1051\n",
      "Epoch 387/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0536 - loss_1: 0.0955 - root_mean_squared_error: 1.9949 - val_loss: 9.1929 - val_loss_1: 0.0940 - val_root_mean_squared_error: 2.1470\n",
      "Epoch 388/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 8.0220 - loss_1: 0.0942 - root_mean_squared_error: 1.9876 - val_loss: 9.2350 - val_loss_1: 0.0966 - val_root_mean_squared_error: 2.1858\n",
      "Epoch 389/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 8.0301 - loss_1: 0.0954 - root_mean_squared_error: 2.0008 - val_loss: 9.2050 - val_loss_1: 0.0931 - val_root_mean_squared_error: 2.1335\n",
      "Epoch 390/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.8106 - loss_1: 0.0953 - root_mean_squared_error: 1.9758 - val_loss: 8.8661 - val_loss_1: 0.0970 - val_root_mean_squared_error: 2.1270\n",
      "Epoch 391/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9388 - loss_1: 0.0950 - root_mean_squared_error: 1.9915 - val_loss: 9.1256 - val_loss_1: 0.0948 - val_root_mean_squared_error: 2.1463\n",
      "Epoch 392/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6685 - loss_1: 0.0952 - root_mean_squared_error: 1.9529 - val_loss: 8.9130 - val_loss_1: 0.0948 - val_root_mean_squared_error: 2.0931\n",
      "Epoch 393/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.0884 - loss_1: 0.0945 - root_mean_squared_error: 1.9995 - val_loss: 8.7121 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.1336\n",
      "Epoch 394/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.9809 - loss_1: 0.0938 - root_mean_squared_error: 1.98 - 1s 76us/step - loss: 8.0377 - loss_1: 0.0939 - root_mean_squared_error: 1.9956 - val_loss: 8.7559 - val_loss_1: 0.0959 - val_root_mean_squared_error: 2.1033\n",
      "Epoch 395/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.9070 - loss_1: 0.0962 - root_mean_squared_error: 1.9816 - val_loss: 8.9313 - val_loss_1: 0.0954 - val_root_mean_squared_error: 2.1423\n",
      "Epoch 396/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.8343 - loss_1: 0.0946 - root_mean_squared_error: 1.9538 - val_loss: 8.9674 - val_loss_1: 0.0950 - val_root_mean_squared_error: 2.1444\n",
      "Epoch 397/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9607 - loss_1: 0.0956 - root_mean_squared_error: 1.9930 - val_loss: 8.5450 - val_loss_1: 0.0948 - val_root_mean_squared_error: 2.1117\n",
      "Epoch 398/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9119 - loss_1: 0.0951 - root_mean_squared_error: 1.9639 - val_loss: 8.6598 - val_loss_1: 0.0953 - val_root_mean_squared_error: 2.1037\n",
      "Epoch 399/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9301 - loss_1: 0.0949 - root_mean_squared_error: 1.9846 - val_loss: 8.8927 - val_loss_1: 0.0937 - val_root_mean_squared_error: 2.1275\n",
      "Epoch 400/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9635 - loss_1: 0.0941 - root_mean_squared_error: 1.9787 - val_loss: 9.0151 - val_loss_1: 0.0947 - val_root_mean_squared_error: 2.1443\n",
      "Epoch 401/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7743 - loss_1: 0.0949 - root_mean_squared_error: 1.9522 - val_loss: 8.5758 - val_loss_1: 0.0943 - val_root_mean_squared_error: 2.0811\n",
      "Epoch 402/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8108 - loss_1: 0.0953 - root_mean_squared_error: 1.9639 - val_loss: 8.9193 - val_loss_1: 0.0947 - val_root_mean_squared_error: 2.1421\n",
      "Epoch 403/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.5922 - loss_1: 0.0941 - root_mean_squared_error: 1.94 - 1s 75us/step - loss: 7.5617 - loss_1: 0.0941 - root_mean_squared_error: 1.9376 - val_loss: 8.7125 - val_loss_1: 0.0945 - val_root_mean_squared_error: 2.1076\n",
      "Epoch 404/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7685 - loss_1: 0.0960 - root_mean_squared_error: 1.9539 - val_loss: 9.1045 - val_loss_1: 0.0969 - val_root_mean_squared_error: 2.1664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.0292 - loss_1: 0.0960 - root_mean_squared_error: 1.9765 - val_loss: 9.0230 - val_loss_1: 0.0943 - val_root_mean_squared_error: 2.1371\n",
      "Epoch 406/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.1713 - loss_1: 0.0944 - root_mean_squared_error: 1.9993 - val_loss: 9.1052 - val_loss_1: 0.0956 - val_root_mean_squared_error: 2.1607\n",
      "Epoch 407/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 8.0092 - loss_1: 0.0958 - root_mean_squared_error: 1.9830 - val_loss: 9.2625 - val_loss_1: 0.0950 - val_root_mean_squared_error: 2.1799\n",
      "Epoch 408/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.8243 - loss_1: 0.0942 - root_mean_squared_error: 1.9538 - val_loss: 8.7478 - val_loss_1: 0.0945 - val_root_mean_squared_error: 2.1018\n",
      "Epoch 409/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8829 - loss_1: 0.0942 - root_mean_squared_error: 1.9679 - val_loss: 9.3155 - val_loss_1: 0.0944 - val_root_mean_squared_error: 2.1748\n",
      "Epoch 410/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7175 - loss_1: 0.0937 - root_mean_squared_error: 1.9463 - val_loss: 8.9660 - val_loss_1: 0.0937 - val_root_mean_squared_error: 2.1362\n",
      "Epoch 411/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6843 - loss_1: 0.0948 - root_mean_squared_error: 1.9400 - val_loss: 8.8897 - val_loss_1: 0.0944 - val_root_mean_squared_error: 2.1232\n",
      "Epoch 412/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.7941 - loss_1: 0.0938 - root_mean_squared_error: 1.9481 - val_loss: 9.0400 - val_loss_1: 0.0944 - val_root_mean_squared_error: 2.1326\n",
      "Epoch 413/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9181 - loss_1: 0.0948 - root_mean_squared_error: 1.9726 - val_loss: 8.1227 - val_loss_1: 0.0935 - val_root_mean_squared_error: 2.0487\n",
      "Epoch 414/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6507 - loss_1: 0.0939 - root_mean_squared_error: 1.9410 - val_loss: 8.8199 - val_loss_1: 0.0942 - val_root_mean_squared_error: 2.1182\n",
      "Epoch 415/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.9029 - loss_1: 0.0936 - root_mean_squared_error: 1.9786 - val_loss: 9.1411 - val_loss_1: 0.0953 - val_root_mean_squared_error: 2.1313\n",
      "Epoch 416/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6878 - loss_1: 0.0960 - root_mean_squared_error: 1.9526 - val_loss: 9.1078 - val_loss_1: 0.0953 - val_root_mean_squared_error: 2.1552\n",
      "Epoch 417/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5226 - loss_1: 0.0936 - root_mean_squared_error: 1.9310 - val_loss: 8.9229 - val_loss_1: 0.0943 - val_root_mean_squared_error: 2.1631\n",
      "Epoch 418/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.9931 - loss_1: 0.0945 - root_mean_squared_error: 1.9891 - val_loss: 8.7249 - val_loss_1: 0.0938 - val_root_mean_squared_error: 2.0843\n",
      "Epoch 419/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8540 - loss_1: 0.0944 - root_mean_squared_error: 1.9683 - val_loss: 8.6210 - val_loss_1: 0.0945 - val_root_mean_squared_error: 2.0958\n",
      "Epoch 420/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.7350 - loss_1: 0.0940 - root_mean_squared_error: 1.9519 - val_loss: 8.6269 - val_loss_1: 0.0941 - val_root_mean_squared_error: 2.1059\n",
      "Epoch 421/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7641 - loss_1: 0.0945 - root_mean_squared_error: 1.9418 - val_loss: 9.4223 - val_loss_1: 0.0927 - val_root_mean_squared_error: 2.1707\n",
      "Epoch 422/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.8039 - loss_1: 0.0937 - root_mean_squared_error: 1.9587 - val_loss: 9.0417 - val_loss_1: 0.0947 - val_root_mean_squared_error: 2.1686\n",
      "Epoch 423/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7348 - loss_1: 0.0939 - root_mean_squared_error: 1.9545 - val_loss: 8.5652 - val_loss_1: 0.0938 - val_root_mean_squared_error: 2.0906\n",
      "Epoch 424/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.6771 - loss_1: 0.0942 - root_mean_squared_error: 1.9518 - val_loss: 8.9619 - val_loss_1: 0.0942 - val_root_mean_squared_error: 2.1161\n",
      "Epoch 425/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6604 - loss_1: 0.0940 - root_mean_squared_error: 1.9330 - val_loss: 8.5492 - val_loss_1: 0.0944 - val_root_mean_squared_error: 2.0963\n",
      "Epoch 426/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.7154 - loss_1: 0.0939 - root_mean_squared_error: 1.9540 - val_loss: 8.8876 - val_loss_1: 0.0960 - val_root_mean_squared_error: 2.1265\n",
      "Epoch 427/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.7203 - loss_1: 0.0944 - root_mean_squared_error: 1.9488 - val_loss: 8.7920 - val_loss_1: 0.0927 - val_root_mean_squared_error: 2.0906\n",
      "Epoch 428/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8951 - loss_1: 0.0942 - root_mean_squared_error: 1.9691 - val_loss: 8.7906 - val_loss_1: 0.0946 - val_root_mean_squared_error: 2.0954\n",
      "Epoch 429/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6205 - loss_1: 0.0939 - root_mean_squared_error: 1.9303 - val_loss: 8.9846 - val_loss_1: 0.0928 - val_root_mean_squared_error: 2.1382\n",
      "Epoch 430/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5903 - loss_1: 0.0930 - root_mean_squared_error: 1.9298 - val_loss: 8.0230 - val_loss_1: 0.0938 - val_root_mean_squared_error: 2.0163\n",
      "Epoch 431/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6428 - loss_1: 0.0946 - root_mean_squared_error: 1.9471 - val_loss: 8.7770 - val_loss_1: 0.0940 - val_root_mean_squared_error: 2.0955\n",
      "Epoch 432/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.4267 - loss_1: 0.0930 - root_mean_squared_error: 1.9143 - val_loss: 8.7985 - val_loss_1: 0.0934 - val_root_mean_squared_error: 2.1110\n",
      "Epoch 433/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4609 - loss_1: 0.0937 - root_mean_squared_error: 1.9204 - val_loss: 8.5467 - val_loss_1: 0.0935 - val_root_mean_squared_error: 2.0840\n",
      "Epoch 434/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.8299 - loss_1: 0.0931 - root_mean_squared_error: 1.9630 - val_loss: 8.0479 - val_loss_1: 0.0931 - val_root_mean_squared_error: 2.0288\n",
      "Epoch 435/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6664 - loss_1: 0.0932 - root_mean_squared_error: 1.9496 - val_loss: 8.5836 - val_loss_1: 0.0938 - val_root_mean_squared_error: 2.0926\n",
      "Epoch 436/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.8120 - loss_1: 0.0942 - root_mean_squared_error: 1.9525 - val_loss: 8.9945 - val_loss_1: 0.0946 - val_root_mean_squared_error: 2.1380\n",
      "Epoch 437/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5181 - loss_1: 0.0938 - root_mean_squared_error: 1.9266 - val_loss: 8.7044 - val_loss_1: 0.0937 - val_root_mean_squared_error: 2.0840\n",
      "Epoch 438/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.7375 - loss_1: 0.0935 - root_mean_squared_error: 1.9498 - val_loss: 8.8749 - val_loss_1: 0.0936 - val_root_mean_squared_error: 2.1290\n",
      "Epoch 439/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5352 - loss_1: 0.0943 - root_mean_squared_error: 1.9324 - val_loss: 8.7767 - val_loss_1: 0.0937 - val_root_mean_squared_error: 2.0971\n",
      "Epoch 440/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5652 - loss_1: 0.0931 - root_mean_squared_error: 1.9357 - val_loss: 8.4300 - val_loss_1: 0.0924 - val_root_mean_squared_error: 2.0793\n",
      "Epoch 441/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5454 - loss_1: 0.0920 - root_mean_squared_error: 1.9231 - val_loss: 8.5784 - val_loss_1: 0.0931 - val_root_mean_squared_error: 2.0713\n",
      "Epoch 442/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.7871 - loss_1: 0.0933 - root_mean_squared_error: 1.9534 - val_loss: 8.3552 - val_loss_1: 0.0923 - val_root_mean_squared_error: 2.0863ss: 7.8605 - loss_1: 0.0933 - root_mean_squared_error: 1.\n",
      "Epoch 443/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5158 - loss_1: 0.0918 - root_mean_squared_error: 1.9263 - val_loss: 8.2284 - val_loss_1: 0.0931 - val_root_mean_squared_error: 2.0285\n",
      "Epoch 444/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6071 - loss_1: 0.0942 - root_mean_squared_error: 1.9248 - val_loss: 8.8537 - val_loss_1: 0.0930 - val_root_mean_squared_error: 2.1403\n",
      "Epoch 445/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.6134 - loss_1: 0.0919 - root_mean_squared_error: 1.9456 - val_loss: 8.4997 - val_loss_1: 0.0927 - val_root_mean_squared_error: 2.1018\n",
      "Epoch 446/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4633 - loss_1: 0.0931 - root_mean_squared_error: 1.9137 - val_loss: 8.5649 - val_loss_1: 0.0933 - val_root_mean_squared_error: 2.0773\n",
      "Epoch 447/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3780 - loss_1: 0.0929 - root_mean_squared_error: 1.9049 - val_loss: 8.6939 - val_loss_1: 0.0921 - val_root_mean_squared_error: 2.0896\n",
      "Epoch 448/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6157 - loss_1: 0.0926 - root_mean_squared_error: 1.9444 - val_loss: 8.5049 - val_loss_1: 0.0939 - val_root_mean_squared_error: 2.0818\n",
      "Epoch 449/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6720 - loss_1: 0.0927 - root_mean_squared_error: 1.9283 - val_loss: 8.5213 - val_loss_1: 0.0921 - val_root_mean_squared_error: 2.0821\n",
      "Epoch 450/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4481 - loss_1: 0.0924 - root_mean_squared_error: 1.9195 - val_loss: 8.8614 - val_loss_1: 0.0923 - val_root_mean_squared_error: 2.1385\n",
      "Epoch 451/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5623 - loss_1: 0.0932 - root_mean_squared_error: 1.9182 - val_loss: 8.4352 - val_loss_1: 0.0923 - val_root_mean_squared_error: 2.0768\n",
      "Epoch 452/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5277 - loss_1: 0.0914 - root_mean_squared_error: 1.9193 - val_loss: 8.3965 - val_loss_1: 0.0920 - val_root_mean_squared_error: 2.0538\n",
      "Epoch 453/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3280 - loss_1: 0.0929 - root_mean_squared_error: 1.8952 - val_loss: 8.6253 - val_loss_1: 0.0926 - val_root_mean_squared_error: 2.0773\n",
      "Epoch 454/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.7921 - loss_1: 0.0928 - root_mean_squared_error: 1.9499 - val_loss: 8.3291 - val_loss_1: 0.0932 - val_root_mean_squared_error: 2.0641\n",
      "Epoch 455/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.7025 - loss_1: 0.0926 - root_mean_squared_error: 1.9503 - val_loss: 9.0372 - val_loss_1: 0.0935 - val_root_mean_squared_error: 2.1337loss: 7.7029 - loss_1: 0.0925 - root_mean_squared_error\n",
      "Epoch 456/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5894 - loss_1: 0.0924 - root_mean_squared_error: 1.9324 - val_loss: 8.2251 - val_loss_1: 0.0925 - val_root_mean_squared_error: 2.0483\n",
      "Epoch 457/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 7.5155 - loss_1: 0.0920 - root_mean_squared_error: 1.9303 - val_loss: 8.4071 - val_loss_1: 0.0906 - val_root_mean_squared_error: 2.0440\n",
      "Epoch 458/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.4538 - loss_1: 0.0915 - root_mean_squared_error: 1.9111 - val_loss: 8.8021 - val_loss_1: 0.0916 - val_root_mean_squared_error: 2.1180\n",
      "Epoch 459/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5483 - loss_1: 0.0920 - root_mean_squared_error: 1.9331 - val_loss: 8.4923 - val_loss_1: 0.0913 - val_root_mean_squared_error: 2.0954\n",
      "Epoch 460/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5502 - loss_1: 0.0929 - root_mean_squared_error: 1.9325 - val_loss: 8.2030 - val_loss_1: 0.0920 - val_root_mean_squared_error: 2.0328\n",
      "Epoch 461/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5149 - loss_1: 0.0914 - root_mean_squared_error: 1.9213 - val_loss: 9.1429 - val_loss_1: 0.0925 - val_root_mean_squared_error: 2.1380\n",
      "Epoch 462/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.4722 - loss_1: 0.0919 - root_mean_squared_error: 1.92 - 1s 75us/step - loss: 7.4761 - loss_1: 0.0918 - root_mean_squared_error: 1.9284 - val_loss: 8.3614 - val_loss_1: 0.0914 - val_root_mean_squared_error: 2.0623\n",
      "Epoch 463/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4220 - loss_1: 0.0919 - root_mean_squared_error: 1.9195 - val_loss: 8.0924 - val_loss_1: 0.0920 - val_root_mean_squared_error: 2.0346\n",
      "Epoch 464/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4077 - loss_1: 0.0923 - root_mean_squared_error: 1.9138 - val_loss: 8.5951 - val_loss_1: 0.0920 - val_root_mean_squared_error: 2.1126\n",
      "Epoch 465/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3213 - loss_1: 0.0916 - root_mean_squared_error: 1.9004 - val_loss: 8.5654 - val_loss_1: 0.0924 - val_root_mean_squared_error: 2.0746\n",
      "Epoch 466/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.4425 - loss_1: 0.0916 - root_mean_squared_error: 1.9177 - val_loss: 8.9243 - val_loss_1: 0.0919 - val_root_mean_squared_error: 2.1231\n",
      "Epoch 467/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1415 - loss_1: 0.0915 - root_mean_squared_error: 1.8682 - val_loss: 7.9415 - val_loss_1: 0.0920 - val_root_mean_squared_error: 2.0049\n",
      "Epoch 468/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3959 - loss_1: 0.0914 - root_mean_squared_error: 1.9112 - val_loss: 8.1419 - val_loss_1: 0.0913 - val_root_mean_squared_error: 2.0238\n",
      "Epoch 469/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6956 - loss_1: 0.0907 - root_mean_squared_error: 1.9376 - val_loss: 8.4500 - val_loss_1: 0.0930 - val_root_mean_squared_error: 2.0625\n",
      "Epoch 470/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6149 - loss_1: 0.0919 - root_mean_squared_error: 1.9321 - val_loss: 8.2820 - val_loss_1: 0.0912 - val_root_mean_squared_error: 2.0307\n",
      "Epoch 471/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3869 - loss_1: 0.0904 - root_mean_squared_error: 1.9056 - val_loss: 8.5420 - val_loss_1: 0.0923 - val_root_mean_squared_error: 2.0751\n",
      "Epoch 472/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4554 - loss_1: 0.0909 - root_mean_squared_error: 1.9128 - val_loss: 8.3090 - val_loss_1: 0.0900 - val_root_mean_squared_error: 2.0270\n",
      "Epoch 473/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.5818 - loss_1: 0.0910 - root_mean_squared_error: 1.9267 - val_loss: 8.0721 - val_loss_1: 0.0905 - val_root_mean_squared_error: 2.0276\n",
      "Epoch 474/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.6030 - loss_1: 0.0907 - root_mean_squared_error: 1.9342 - val_loss: 8.6463 - val_loss_1: 0.0925 - val_root_mean_squared_error: 2.0759\n",
      "Epoch 475/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4276 - loss_1: 0.0913 - root_mean_squared_error: 1.9020 - val_loss: 8.3574 - val_loss_1: 0.0914 - val_root_mean_squared_error: 2.0491\n",
      "Epoch 476/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.5686 - loss_1: 0.0907 - root_mean_squared_error: 1.9177 - val_loss: 8.3532 - val_loss_1: 0.0929 - val_root_mean_squared_error: 2.0793\n",
      "Epoch 477/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2142 - loss_1: 0.0916 - root_mean_squared_error: 1.8824 - val_loss: 8.4919 - val_loss_1: 0.0887 - val_root_mean_squared_error: 2.0474\n",
      "Epoch 478/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.2515 - loss_1: 0.0907 - root_mean_squared_error: 1.89 - 1s 76us/step - loss: 7.2464 - loss_1: 0.0909 - root_mean_squared_error: 1.8950 - val_loss: 8.4797 - val_loss_1: 0.0916 - val_root_mean_squared_error: 2.0814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2670 - loss_1: 0.0906 - root_mean_squared_error: 1.8925 - val_loss: 8.3851 - val_loss_1: 0.0903 - val_root_mean_squared_error: 2.0643\n",
      "Epoch 480/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2818 - loss_1: 0.0906 - root_mean_squared_error: 1.8883 - val_loss: 8.2700 - val_loss_1: 0.0915 - val_root_mean_squared_error: 2.0425\n",
      "Epoch 481/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2448 - loss_1: 0.0911 - root_mean_squared_error: 1.8907 - val_loss: 8.2588 - val_loss_1: 0.0909 - val_root_mean_squared_error: 2.0459\n",
      "Epoch 482/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3161 - loss_1: 0.0910 - root_mean_squared_error: 1.8901 - val_loss: 8.4794 - val_loss_1: 0.0899 - val_root_mean_squared_error: 2.0721\n",
      "Epoch 483/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4341 - loss_1: 0.0910 - root_mean_squared_error: 1.9133 - val_loss: 8.5704 - val_loss_1: 0.0906 - val_root_mean_squared_error: 2.0471\n",
      "Epoch 484/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4841 - loss_1: 0.0906 - root_mean_squared_error: 1.9161 - val_loss: 8.2812 - val_loss_1: 0.0906 - val_root_mean_squared_error: 2.0255\n",
      "Epoch 485/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3282 - loss_1: 0.0908 - root_mean_squared_error: 1.8991 - val_loss: 8.2578 - val_loss_1: 0.0912 - val_root_mean_squared_error: 2.0330\n",
      "Epoch 486/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.5212 - loss_1: 0.0902 - root_mean_squared_error: 1.9141 - val_loss: 8.4690 - val_loss_1: 0.0904 - val_root_mean_squared_error: 2.0578\n",
      "Epoch 487/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4250 - loss_1: 0.0904 - root_mean_squared_error: 1.9074 - val_loss: 7.8182 - val_loss_1: 0.0913 - val_root_mean_squared_error: 1.9888\n",
      "Epoch 488/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.4444 - loss_1: 0.0907 - root_mean_squared_error: 1.9076 - val_loss: 8.8621 - val_loss_1: 0.0897 - val_root_mean_squared_error: 2.0859\n",
      "Epoch 489/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3397 - loss_1: 0.0894 - root_mean_squared_error: 1.8915 - val_loss: 8.3485 - val_loss_1: 0.0906 - val_root_mean_squared_error: 2.0634\n",
      "Epoch 490/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3080 - loss_1: 0.0915 - root_mean_squared_error: 1.8971 - val_loss: 8.3991 - val_loss_1: 0.0895 - val_root_mean_squared_error: 2.0624\n",
      "Epoch 491/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.0867 - loss_1: 0.0899 - root_mean_squared_error: 1.8640 - val_loss: 7.6992 - val_loss_1: 0.0911 - val_root_mean_squared_error: 1.9800\n",
      "Epoch 492/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3878 - loss_1: 0.0906 - root_mean_squared_error: 1.8968 - val_loss: 8.0452 - val_loss_1: 0.0894 - val_root_mean_squared_error: 2.0251\n",
      "Epoch 493/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.4212 - loss_1: 0.0899 - root_mean_squared_error: 1.9141 - val_loss: 8.2217 - val_loss_1: 0.0885 - val_root_mean_squared_error: 2.0488\n",
      "Epoch 494/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3599 - loss_1: 0.0900 - root_mean_squared_error: 1.8910 - val_loss: 8.5076 - val_loss_1: 0.0901 - val_root_mean_squared_error: 2.0989\n",
      "Epoch 495/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.2778 - loss_1: 0.0913 - root_mean_squared_error: 1.8931 - val_loss: 8.6202 - val_loss_1: 0.0912 - val_root_mean_squared_error: 2.0831\n",
      "Epoch 496/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3885 - loss_1: 0.0903 - root_mean_squared_error: 1.9071 - val_loss: 8.5338 - val_loss_1: 0.0907 - val_root_mean_squared_error: 2.0945\n",
      "Epoch 497/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.4281 - loss_1: 0.0897 - root_mean_squared_error: 1.9104 - val_loss: 7.8528 - val_loss_1: 0.0894 - val_root_mean_squared_error: 1.9949\n",
      "Epoch 498/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.0624 - loss_1: 0.0894 - root_mean_squared_error: 1.8633 - val_loss: 8.3846 - val_loss_1: 0.0910 - val_root_mean_squared_error: 2.0524\n",
      "Epoch 499/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2769 - loss_1: 0.0902 - root_mean_squared_error: 1.8808 - val_loss: 8.2031 - val_loss_1: 0.0903 - val_root_mean_squared_error: 2.0584\n",
      "Epoch 500/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1523 - loss_1: 0.0906 - root_mean_squared_error: 1.8639 - val_loss: 8.2643 - val_loss_1: 0.0899 - val_root_mean_squared_error: 2.0530\n",
      "Epoch 501/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1810 - loss_1: 0.0902 - root_mean_squared_error: 1.8783 - val_loss: 8.3452 - val_loss_1: 0.0897 - val_root_mean_squared_error: 2.0571\n",
      "Epoch 502/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3308 - loss_1: 0.0906 - root_mean_squared_error: 1.8951 - val_loss: 8.2678 - val_loss_1: 0.0914 - val_root_mean_squared_error: 2.0493\n",
      "Epoch 503/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1021 - loss_1: 0.0899 - root_mean_squared_error: 1.8638 - val_loss: 7.9505 - val_loss_1: 0.0896 - val_root_mean_squared_error: 2.0083\n",
      "Epoch 504/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2619 - loss_1: 0.0897 - root_mean_squared_error: 1.8838 - val_loss: 8.5516 - val_loss_1: 0.0910 - val_root_mean_squared_error: 2.0766\n",
      "Epoch 505/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3381 - loss_1: 0.0905 - root_mean_squared_error: 1.8954 - val_loss: 8.0080 - val_loss_1: 0.0890 - val_root_mean_squared_error: 2.0124\n",
      "Epoch 506/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2587 - loss_1: 0.0892 - root_mean_squared_error: 1.8850 - val_loss: 7.9871 - val_loss_1: 0.0888 - val_root_mean_squared_error: 2.0223\n",
      "Epoch 507/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1981 - loss_1: 0.0902 - root_mean_squared_error: 1.8842 - val_loss: 7.8792 - val_loss_1: 0.0917 - val_root_mean_squared_error: 1.9944\n",
      "Epoch 508/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1501 - loss_1: 0.0900 - root_mean_squared_error: 1.8803 - val_loss: 8.1304 - val_loss_1: 0.0890 - val_root_mean_squared_error: 2.0251\n",
      "Epoch 509/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1622 - loss_1: 0.0900 - root_mean_squared_error: 1.8779 - val_loss: 8.3016 - val_loss_1: 0.0898 - val_root_mean_squared_error: 2.0427\n",
      "Epoch 510/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1382 - loss_1: 0.0897 - root_mean_squared_error: 1.8787 - val_loss: 8.2510 - val_loss_1: 0.0888 - val_root_mean_squared_error: 2.0330\n",
      "Epoch 511/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2448 - loss_1: 0.0897 - root_mean_squared_error: 1.8859 - val_loss: 8.3566 - val_loss_1: 0.0895 - val_root_mean_squared_error: 2.0036\n",
      "Epoch 512/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2634 - loss_1: 0.0894 - root_mean_squared_error: 1.8817 - val_loss: 8.0608 - val_loss_1: 0.0900 - val_root_mean_squared_error: 2.0285\n",
      "Epoch 513/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2419 - loss_1: 0.0894 - root_mean_squared_error: 1.8727 - val_loss: 8.0333 - val_loss_1: 0.0890 - val_root_mean_squared_error: 2.0225\n",
      "Epoch 514/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.3436 - loss_1: 0.0889 - root_mean_squared_error: 1.8958 - val_loss: 8.4208 - val_loss_1: 0.0902 - val_root_mean_squared_error: 2.0468\n",
      "Epoch 515/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9494 - loss_1: 0.0895 - root_mean_squared_error: 1.8548 - val_loss: 8.1983 - val_loss_1: 0.0887 - val_root_mean_squared_error: 2.0271\n",
      "Epoch 516/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3799 - loss_1: 0.0887 - root_mean_squared_error: 1.8939 - val_loss: 8.4217 - val_loss_1: 0.0900 - val_root_mean_squared_error: 2.0672\n",
      "Epoch 517/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.0302 - loss_1: 0.0901 - root_mean_squared_error: 1.8735 - val_loss: 8.2953 - val_loss_1: 0.0878 - val_root_mean_squared_error: 2.0113\n",
      "Epoch 518/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.2531 - loss_1: 0.0879 - root_mean_squared_error: 1.8925 - val_loss: 8.6057 - val_loss_1: 0.0893 - val_root_mean_squared_error: 2.1160\n",
      "Epoch 519/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1431 - loss_1: 0.0883 - root_mean_squared_error: 1.8628 - val_loss: 8.1777 - val_loss_1: 0.0886 - val_root_mean_squared_error: 2.0213\n",
      "Epoch 520/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.0363 - loss_1: 0.0894 - root_mean_squared_error: 1.8579 - val_loss: 8.2143 - val_loss_1: 0.0900 - val_root_mean_squared_error: 2.0430\n",
      "Epoch 521/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3790 - loss_1: 0.0885 - root_mean_squared_error: 1.8994 - val_loss: 7.9904 - val_loss_1: 0.0891 - val_root_mean_squared_error: 2.0006\n",
      "Epoch 522/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1925 - loss_1: 0.0890 - root_mean_squared_error: 1.8914 - val_loss: 8.3684 - val_loss_1: 0.0885 - val_root_mean_squared_error: 2.0550\n",
      "Epoch 523/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1076 - loss_1: 0.0898 - root_mean_squared_error: 1.8679 - val_loss: 8.0228 - val_loss_1: 0.0886 - val_root_mean_squared_error: 2.0408\n",
      "Epoch 524/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2538 - loss_1: 0.0891 - root_mean_squared_error: 1.8849 - val_loss: 8.3016 - val_loss_1: 0.0876 - val_root_mean_squared_error: 2.0384\n",
      "Epoch 525/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.3359 - loss_1: 0.0880 - root_mean_squared_error: 1.8821 - val_loss: 8.0805 - val_loss_1: 0.0888 - val_root_mean_squared_error: 2.0214\n",
      "Epoch 526/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2279 - loss_1: 0.0882 - root_mean_squared_error: 1.8819 - val_loss: 7.7450 - val_loss_1: 0.0886 - val_root_mean_squared_error: 1.9794\n",
      "Epoch 527/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 7.2520 - loss_1: 0.0887 - root_mean_squared_error: 1.8856 - val_loss: 8.0790 - val_loss_1: 0.0874 - val_root_mean_squared_error: 2.0158\n",
      "Epoch 528/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1286 - loss_1: 0.0887 - root_mean_squared_error: 1.8786 - val_loss: 8.4226 - val_loss_1: 0.0904 - val_root_mean_squared_error: 2.0824\n",
      "Epoch 529/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9711 - loss_1: 0.0884 - root_mean_squared_error: 1.8558 - val_loss: 8.4465 - val_loss_1: 0.0869 - val_root_mean_squared_error: 2.0684\n",
      "Epoch 530/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 7.1975 - loss_1: 0.0876 - root_mean_squared_error: 1.8740 - val_loss: 7.7618 - val_loss_1: 0.0885 - val_root_mean_squared_error: 1.9873\n",
      "Epoch 531/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2605 - loss_1: 0.0886 - root_mean_squared_error: 1.8925 - val_loss: 8.4054 - val_loss_1: 0.0881 - val_root_mean_squared_error: 2.0331\n",
      "Epoch 532/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0012 - loss_1: 0.0880 - root_mean_squared_error: 1.8596 - val_loss: 8.4272 - val_loss_1: 0.0885 - val_root_mean_squared_error: 2.0612\n",
      "Epoch 533/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1228 - loss_1: 0.0876 - root_mean_squared_error: 1.8731 - val_loss: 7.9302 - val_loss_1: 0.0896 - val_root_mean_squared_error: 1.9838\n",
      "Epoch 534/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0911 - loss_1: 0.0890 - root_mean_squared_error: 1.8677 - val_loss: 8.0313 - val_loss_1: 0.0886 - val_root_mean_squared_error: 2.0328\n",
      "Epoch 535/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8535 - loss_1: 0.0882 - root_mean_squared_error: 1.8390 - val_loss: 8.1091 - val_loss_1: 0.0873 - val_root_mean_squared_error: 2.0084\n",
      "Epoch 536/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.2244 - loss_1: 0.0879 - root_mean_squared_error: 1.8846 - val_loss: 8.2227 - val_loss_1: 0.0903 - val_root_mean_squared_error: 2.0450\n",
      "Epoch 537/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1845 - loss_1: 0.0898 - root_mean_squared_error: 1.8740 - val_loss: 7.9647 - val_loss_1: 0.0880 - val_root_mean_squared_error: 1.9901\n",
      "Epoch 538/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9980 - loss_1: 0.0870 - root_mean_squared_error: 1.8469 - val_loss: 8.5367 - val_loss_1: 0.0886 - val_root_mean_squared_error: 2.0844\n",
      "Epoch 539/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.3048 - loss_1: 0.0880 - root_mean_squared_error: 1.8793 - val_loss: 8.0597 - val_loss_1: 0.0886 - val_root_mean_squared_error: 2.0126\n",
      "Epoch 540/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.9460 - loss_1: 0.0879 - root_mean_squared_error: 1.8494 - val_loss: 7.7359 - val_loss_1: 0.0865 - val_root_mean_squared_error: 1.9653\n",
      "Epoch 541/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2768 - loss_1: 0.0869 - root_mean_squared_error: 1.8860 - val_loss: 7.9865 - val_loss_1: 0.0870 - val_root_mean_squared_error: 2.0266\n",
      "Epoch 542/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.2490 - loss_1: 0.0874 - root_mean_squared_error: 1.8793 - val_loss: 8.1749 - val_loss_1: 0.0883 - val_root_mean_squared_error: 2.0335\n",
      "Epoch 543/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8931 - loss_1: 0.0877 - root_mean_squared_error: 1.8442 - val_loss: 7.8251 - val_loss_1: 0.0873 - val_root_mean_squared_error: 1.9967\n",
      "Epoch 544/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1481 - loss_1: 0.0877 - root_mean_squared_error: 1.8697 - val_loss: 8.2572 - val_loss_1: 0.0885 - val_root_mean_squared_error: 2.0665\n",
      "Epoch 545/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.1292 - loss_1: 0.0874 - root_mean_squared_error: 1.8693 - val_loss: 7.9654 - val_loss_1: 0.0882 - val_root_mean_squared_error: 2.0143\n",
      "Epoch 546/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8321 - loss_1: 0.0879 - root_mean_squared_error: 1.8310 - val_loss: 7.9382 - val_loss_1: 0.0884 - val_root_mean_squared_error: 2.0205\n",
      "Epoch 547/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.0589 - loss_1: 0.0877 - root_mean_squared_error: 1.8631 - val_loss: 7.9320 - val_loss_1: 0.0879 - val_root_mean_squared_error: 2.0054\n",
      "Epoch 548/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8329 - loss_1: 0.0877 - root_mean_squared_error: 1.8486 - val_loss: 7.8583 - val_loss_1: 0.0874 - val_root_mean_squared_error: 1.9883\n",
      "Epoch 549/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0659 - loss_1: 0.0870 - root_mean_squared_error: 1.8745 - val_loss: 8.2425 - val_loss_1: 0.0870 - val_root_mean_squared_error: 2.0352\n",
      "Epoch 550/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0161 - loss_1: 0.0876 - root_mean_squared_error: 1.8636 - val_loss: 8.1281 - val_loss_1: 0.0868 - val_root_mean_squared_error: 2.0354\n",
      "Epoch 551/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9328 - loss_1: 0.0874 - root_mean_squared_error: 1.8455 - val_loss: 8.5665 - val_loss_1: 0.0879 - val_root_mean_squared_error: 2.0567\n",
      "Epoch 552/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0812 - loss_1: 0.0869 - root_mean_squared_error: 1.8736 - val_loss: 8.2037 - val_loss_1: 0.0867 - val_root_mean_squared_error: 2.0229\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8444 - loss_1: 0.0871 - root_mean_squared_error: 1.8390 - val_loss: 8.2749 - val_loss_1: 0.0867 - val_root_mean_squared_error: 2.0494\n",
      "Epoch 554/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.1466 - loss_1: 0.0869 - root_mean_squared_error: 1.8622 - val_loss: 8.1222 - val_loss_1: 0.0870 - val_root_mean_squared_error: 2.0212\n",
      "Epoch 555/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.0049 - loss_1: 0.0875 - root_mean_squared_error: 1.8555 - val_loss: 7.9884 - val_loss_1: 0.0874 - val_root_mean_squared_error: 2.0087\n",
      "Epoch 556/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9100 - loss_1: 0.0867 - root_mean_squared_error: 1.8439 - val_loss: 7.9481 - val_loss_1: 0.0875 - val_root_mean_squared_error: 2.0059\n",
      "Epoch 557/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8542 - loss_1: 0.0865 - root_mean_squared_error: 1.8514 - val_loss: 7.7086 - val_loss_1: 0.0866 - val_root_mean_squared_error: 1.9761\n",
      "Epoch 558/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 7.0191 - loss_1: 0.0876 - root_mean_squared_error: 1.8594 - val_loss: 7.8108 - val_loss_1: 0.0881 - val_root_mean_squared_error: 2.0044\n",
      "Epoch 559/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7543 - loss_1: 0.0874 - root_mean_squared_error: 1.8253 - val_loss: 8.1497 - val_loss_1: 0.0869 - val_root_mean_squared_error: 2.0053\n",
      "Epoch 560/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.8402 - loss_1: 0.0873 - root_mean_squared_error: 1.8343 - val_loss: 7.7748 - val_loss_1: 0.0861 - val_root_mean_squared_error: 1.97316.7820 - loss_1: 0.0873 - root_mean_squared_error: 1.83\n",
      "Epoch 561/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.0875 - loss_1: 0.0869 - root_mean_squared_error: 1.86 - 1s 75us/step - loss: 7.0694 - loss_1: 0.0868 - root_mean_squared_error: 1.8597 - val_loss: 7.9739 - val_loss_1: 0.0869 - val_root_mean_squared_error: 1.9976\n",
      "Epoch 562/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.9338 - loss_1: 0.0876 - root_mean_squared_error: 1.8459 - val_loss: 8.2816 - val_loss_1: 0.0863 - val_root_mean_squared_error: 2.0476\n",
      "Epoch 563/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.1076 - loss_1: 0.0859 - root_mean_squared_error: 1.8579 - val_loss: 7.6718 - val_loss_1: 0.0870 - val_root_mean_squared_error: 1.9807\n",
      "Epoch 564/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0716 - loss_1: 0.0867 - root_mean_squared_error: 1.8680 - val_loss: 8.0165 - val_loss_1: 0.0868 - val_root_mean_squared_error: 1.9989\n",
      "Epoch 565/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8843 - loss_1: 0.0871 - root_mean_squared_error: 1.8394 - val_loss: 7.3346 - val_loss_1: 0.0855 - val_root_mean_squared_error: 1.9240\n",
      "Epoch 566/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.9383 - loss_1: 0.0861 - root_mean_squared_error: 1.8435 - val_loss: 8.0405 - val_loss_1: 0.0860 - val_root_mean_squared_error: 2.0407\n",
      "Epoch 567/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8209 - loss_1: 0.0856 - root_mean_squared_error: 1.8412 - val_loss: 7.6017 - val_loss_1: 0.0866 - val_root_mean_squared_error: 1.9749\n",
      "Epoch 568/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0304 - loss_1: 0.0871 - root_mean_squared_error: 1.8445 - val_loss: 7.6006 - val_loss_1: 0.0856 - val_root_mean_squared_error: 1.9618\n",
      "Epoch 569/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0472 - loss_1: 0.0863 - root_mean_squared_error: 1.8550 - val_loss: 7.4602 - val_loss_1: 0.0868 - val_root_mean_squared_error: 1.9660\n",
      "Epoch 570/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8449 - loss_1: 0.0865 - root_mean_squared_error: 1.8278 - val_loss: 8.1259 - val_loss_1: 0.0859 - val_root_mean_squared_error: 2.0244\n",
      "Epoch 571/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0235 - loss_1: 0.0861 - root_mean_squared_error: 1.8565 - val_loss: 8.2861 - val_loss_1: 0.0867 - val_root_mean_squared_error: 2.0258\n",
      "Epoch 572/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9950 - loss_1: 0.0876 - root_mean_squared_error: 1.8508 - val_loss: 7.9266 - val_loss_1: 0.0866 - val_root_mean_squared_error: 2.0205\n",
      "Epoch 573/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 7.0938 - loss_1: 0.0854 - root_mean_squared_error: 1.85 - 1s 77us/step - loss: 7.0702 - loss_1: 0.0855 - root_mean_squared_error: 1.8490 - val_loss: 7.8416 - val_loss_1: 0.0870 - val_root_mean_squared_error: 1.9889\n",
      "Epoch 574/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8700 - loss_1: 0.0873 - root_mean_squared_error: 1.8428 - val_loss: 7.8102 - val_loss_1: 0.0861 - val_root_mean_squared_error: 2.0186\n",
      "Epoch 575/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 7.0759 - loss_1: 0.0862 - root_mean_squared_error: 1.8712 - val_loss: 7.6866 - val_loss_1: 0.0868 - val_root_mean_squared_error: 1.9818\n",
      "Epoch 576/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8163 - loss_1: 0.0867 - root_mean_squared_error: 1.8316 - val_loss: 7.9479 - val_loss_1: 0.0870 - val_root_mean_squared_error: 1.9929\n",
      "Epoch 577/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6693 - loss_1: 0.0864 - root_mean_squared_error: 1.8147 - val_loss: 7.6825 - val_loss_1: 0.0859 - val_root_mean_squared_error: 1.9756\n",
      "Epoch 578/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9438 - loss_1: 0.0864 - root_mean_squared_error: 1.8362 - val_loss: 8.2274 - val_loss_1: 0.0876 - val_root_mean_squared_error: 2.0422\n",
      "Epoch 579/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0388 - loss_1: 0.0866 - root_mean_squared_error: 1.8632 - val_loss: 7.8081 - val_loss_1: 0.0854 - val_root_mean_squared_error: 1.9883\n",
      "Epoch 580/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0476 - loss_1: 0.0859 - root_mean_squared_error: 1.8477 - val_loss: 7.9815 - val_loss_1: 0.0866 - val_root_mean_squared_error: 2.0174\n",
      "Epoch 581/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8947 - loss_1: 0.0858 - root_mean_squared_error: 1.8392 - val_loss: 7.5597 - val_loss_1: 0.0871 - val_root_mean_squared_error: 1.9476\n",
      "Epoch 582/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.8227 - loss_1: 0.0865 - root_mean_squared_error: 1.8429 - val_loss: 8.0600 - val_loss_1: 0.0860 - val_root_mean_squared_error: 1.9892\n",
      "Epoch 583/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8682 - loss_1: 0.0862 - root_mean_squared_error: 1.8384 - val_loss: 7.8702 - val_loss_1: 0.0859 - val_root_mean_squared_error: 2.0060\n",
      "Epoch 584/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8250 - loss_1: 0.0861 - root_mean_squared_error: 1.8307 - val_loss: 7.7641 - val_loss_1: 0.0857 - val_root_mean_squared_error: 1.9813\n",
      "Epoch 585/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.7216 - loss_1: 0.0859 - root_mean_squared_error: 1.8200 - val_loss: 7.8639 - val_loss_1: 0.0862 - val_root_mean_squared_error: 2.0035\n",
      "Epoch 586/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7896 - loss_1: 0.0860 - root_mean_squared_error: 1.8367 - val_loss: 7.8454 - val_loss_1: 0.0854 - val_root_mean_squared_error: 1.9956\n",
      "Epoch 587/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7809 - loss_1: 0.0860 - root_mean_squared_error: 1.8270 - val_loss: 8.1079 - val_loss_1: 0.0859 - val_root_mean_squared_error: 2.0143\n",
      "Epoch 588/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8322 - loss_1: 0.0859 - root_mean_squared_error: 1.8244 - val_loss: 7.8387 - val_loss_1: 0.0859 - val_root_mean_squared_error: 1.9885\n",
      "Epoch 589/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8229 - loss_1: 0.0850 - root_mean_squared_error: 1.8259 - val_loss: 7.8332 - val_loss_1: 0.0850 - val_root_mean_squared_error: 2.0073\n",
      "Epoch 590/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8131 - loss_1: 0.0859 - root_mean_squared_error: 1.8243 - val_loss: 7.8388 - val_loss_1: 0.0857 - val_root_mean_squared_error: 1.9798\n",
      "Epoch 591/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6944 - loss_1: 0.0858 - root_mean_squared_error: 1.8320 - val_loss: 7.7464 - val_loss_1: 0.0859 - val_root_mean_squared_error: 1.9811\n",
      "Epoch 592/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8355 - loss_1: 0.0851 - root_mean_squared_error: 1.8170 - val_loss: 7.4860 - val_loss_1: 0.0848 - val_root_mean_squared_error: 1.9557\n",
      "Epoch 593/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.8100 - loss_1: 0.0855 - root_mean_squared_error: 1.8271 - val_loss: 7.5925 - val_loss_1: 0.0852 - val_root_mean_squared_error: 1.9609\n",
      "Epoch 594/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.9300 - loss_1: 0.0855 - root_mean_squared_error: 1.8448 - val_loss: 8.0277 - val_loss_1: 0.0857 - val_root_mean_squared_error: 2.0197\n",
      "Epoch 595/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.8515 - loss_1: 0.0853 - root_mean_squared_error: 1.82 - 1s 77us/step - loss: 6.8280 - loss_1: 0.0853 - root_mean_squared_error: 1.8226 - val_loss: 8.1038 - val_loss_1: 0.0851 - val_root_mean_squared_error: 2.0115\n",
      "Epoch 596/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6534 - loss_1: 0.0855 - root_mean_squared_error: 1.8127 - val_loss: 7.8227 - val_loss_1: 0.0853 - val_root_mean_squared_error: 1.9796\n",
      "Epoch 597/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4879 - loss_1: 0.0857 - root_mean_squared_error: 1.7897 - val_loss: 8.0981 - val_loss_1: 0.0860 - val_root_mean_squared_error: 2.0165\n",
      "Epoch 598/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9171 - loss_1: 0.0846 - root_mean_squared_error: 1.8583 - val_loss: 7.7402 - val_loss_1: 0.0841 - val_root_mean_squared_error: 1.9712\n",
      "Epoch 599/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7937 - loss_1: 0.0850 - root_mean_squared_error: 1.8260 - val_loss: 7.4600 - val_loss_1: 0.0850 - val_root_mean_squared_error: 1.9636\n",
      "Epoch 600/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7773 - loss_1: 0.0845 - root_mean_squared_error: 1.8165 - val_loss: 7.9725 - val_loss_1: 0.0853 - val_root_mean_squared_error: 2.0038\n",
      "Epoch 601/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6993 - loss_1: 0.0863 - root_mean_squared_error: 1.8177 - val_loss: 7.5181 - val_loss_1: 0.0854 - val_root_mean_squared_error: 1.9450\n",
      "Epoch 602/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9191 - loss_1: 0.0850 - root_mean_squared_error: 1.8304 - val_loss: 7.6805 - val_loss_1: 0.0853 - val_root_mean_squared_error: 1.9902\n",
      "Epoch 603/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.8188 - loss_1: 0.0846 - root_mean_squared_error: 1.81 - 1s 76us/step - loss: 6.7880 - loss_1: 0.0846 - root_mean_squared_error: 1.8142 - val_loss: 7.8686 - val_loss_1: 0.0853 - val_root_mean_squared_error: 1.9869\n",
      "Epoch 604/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 6.7906 - loss_1: 0.0848 - root_mean_squared_error: 1.8196 - val_loss: 7.3417 - val_loss_1: 0.0851 - val_root_mean_squared_error: 1.9088\n",
      "Epoch 605/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7470 - loss_1: 0.0845 - root_mean_squared_error: 1.8311 - val_loss: 7.9922 - val_loss_1: 0.0849 - val_root_mean_squared_error: 2.0339\n",
      "Epoch 606/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8589 - loss_1: 0.0854 - root_mean_squared_error: 1.8412 - val_loss: 8.0434 - val_loss_1: 0.0850 - val_root_mean_squared_error: 2.0131\n",
      "Epoch 607/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.9958 - loss_1: 0.0842 - root_mean_squared_error: 1.8400 - val_loss: 8.0541 - val_loss_1: 0.0856 - val_root_mean_squared_error: 2.0294\n",
      "Epoch 608/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.7351 - loss_1: 0.0845 - root_mean_squared_error: 1.81 - 1s 76us/step - loss: 6.7720 - loss_1: 0.0844 - root_mean_squared_error: 1.8224 - val_loss: 8.0120 - val_loss_1: 0.0830 - val_root_mean_squared_error: 2.0196\n",
      "Epoch 609/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.7926 - loss_1: 0.0846 - root_mean_squared_error: 1.8254 - val_loss: 7.6265 - val_loss_1: 0.0857 - val_root_mean_squared_error: 1.9622\n",
      "Epoch 610/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7853 - loss_1: 0.0854 - root_mean_squared_error: 1.8187 - val_loss: 7.6010 - val_loss_1: 0.0854 - val_root_mean_squared_error: 1.9482\n",
      "Epoch 611/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6480 - loss_1: 0.0847 - root_mean_squared_error: 1.8104 - val_loss: 7.5879 - val_loss_1: 0.0847 - val_root_mean_squared_error: 1.9661\n",
      "Epoch 612/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7170 - loss_1: 0.0844 - root_mean_squared_error: 1.8104 - val_loss: 7.8551 - val_loss_1: 0.0849 - val_root_mean_squared_error: 2.0189\n",
      "Epoch 613/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 7.0285 - loss_1: 0.0841 - root_mean_squared_error: 1.8481 - val_loss: 7.6218 - val_loss_1: 0.0842 - val_root_mean_squared_error: 1.9740\n",
      "Epoch 614/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.8520 - loss_1: 0.0843 - root_mean_squared_error: 1.8309 - val_loss: 7.6982 - val_loss_1: 0.0841 - val_root_mean_squared_error: 1.9733\n",
      "Epoch 615/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6959 - loss_1: 0.0841 - root_mean_squared_error: 1.7976 - val_loss: 8.0955 - val_loss_1: 0.0847 - val_root_mean_squared_error: 2.0312\n",
      "Epoch 616/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5725 - loss_1: 0.0852 - root_mean_squared_error: 1.7900 - val_loss: 7.7934 - val_loss_1: 0.0843 - val_root_mean_squared_error: 1.9924\n",
      "Epoch 617/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7790 - loss_1: 0.0843 - root_mean_squared_error: 1.8229 - val_loss: 7.5432 - val_loss_1: 0.0845 - val_root_mean_squared_error: 1.9377\n",
      "Epoch 618/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6988 - loss_1: 0.0841 - root_mean_squared_error: 1.8015 - val_loss: 7.4028 - val_loss_1: 0.0844 - val_root_mean_squared_error: 1.9370\n",
      "Epoch 619/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5808 - loss_1: 0.0850 - root_mean_squared_error: 1.7974 - val_loss: 7.5868 - val_loss_1: 0.0836 - val_root_mean_squared_error: 1.9464\n",
      "Epoch 620/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7367 - loss_1: 0.0840 - root_mean_squared_error: 1.8125 - val_loss: 7.4743 - val_loss_1: 0.0846 - val_root_mean_squared_error: 1.9665\n",
      "Epoch 621/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6756 - loss_1: 0.0846 - root_mean_squared_error: 1.8095 - val_loss: 7.6296 - val_loss_1: 0.0827 - val_root_mean_squared_error: 1.9428\n",
      "Epoch 622/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.8322 - loss_1: 0.0843 - root_mean_squared_error: 1.8374 - val_loss: 7.3597 - val_loss_1: 0.0845 - val_root_mean_squared_error: 1.9407\n",
      "Epoch 623/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7924 - loss_1: 0.0836 - root_mean_squared_error: 1.8153 - val_loss: 7.5653 - val_loss_1: 0.0838 - val_root_mean_squared_error: 1.9660\n",
      "Epoch 624/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7445 - loss_1: 0.0841 - root_mean_squared_error: 1.8010 - val_loss: 7.3326 - val_loss_1: 0.0847 - val_root_mean_squared_error: 1.9445\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7136 - loss_1: 0.0840 - root_mean_squared_error: 1.8169 - val_loss: 7.9770 - val_loss_1: 0.0841 - val_root_mean_squared_error: 2.0132\n",
      "Epoch 626/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.8760 - loss_1: 0.0841 - root_mean_squared_error: 1.8343 - val_loss: 7.4029 - val_loss_1: 0.0830 - val_root_mean_squared_error: 1.9408\n",
      "Epoch 627/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6384 - loss_1: 0.0830 - root_mean_squared_error: 1.8124 - val_loss: 7.8523 - val_loss_1: 0.0855 - val_root_mean_squared_error: 1.9856\n",
      "Epoch 628/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7576 - loss_1: 0.0845 - root_mean_squared_error: 1.8106 - val_loss: 7.7815 - val_loss_1: 0.0837 - val_root_mean_squared_error: 1.9751\n",
      "Epoch 629/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7070 - loss_1: 0.0838 - root_mean_squared_error: 1.8150 - val_loss: 7.7182 - val_loss_1: 0.0838 - val_root_mean_squared_error: 1.9715\n",
      "Epoch 630/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6968 - loss_1: 0.0837 - root_mean_squared_error: 1.8075 - val_loss: 7.7448 - val_loss_1: 0.0833 - val_root_mean_squared_error: 1.9746\n",
      "Epoch 631/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4833 - loss_1: 0.0831 - root_mean_squared_error: 1.7823 - val_loss: 7.5870 - val_loss_1: 0.0837 - val_root_mean_squared_error: 1.9814\n",
      "Epoch 632/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5853 - loss_1: 0.0849 - root_mean_squared_error: 1.7940 - val_loss: 7.6130 - val_loss_1: 0.0840 - val_root_mean_squared_error: 1.9793\n",
      "Epoch 633/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.7047 - loss_1: 0.0831 - root_mean_squared_error: 1.8133 - val_loss: 7.8573 - val_loss_1: 0.0827 - val_root_mean_squared_error: 1.9901\n",
      "Epoch 634/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5805 - loss_1: 0.0838 - root_mean_squared_error: 1.7908 - val_loss: 7.6502 - val_loss_1: 0.0835 - val_root_mean_squared_error: 1.9654\n",
      "Epoch 635/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6149 - loss_1: 0.0829 - root_mean_squared_error: 1.7934 - val_loss: 8.0610 - val_loss_1: 0.0844 - val_root_mean_squared_error: 2.0044\n",
      "Epoch 636/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6466 - loss_1: 0.0843 - root_mean_squared_error: 1.7982 - val_loss: 7.9632 - val_loss_1: 0.0838 - val_root_mean_squared_error: 2.0061\n",
      "Epoch 637/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7158 - loss_1: 0.0828 - root_mean_squared_error: 1.8092 - val_loss: 7.5340 - val_loss_1: 0.0829 - val_root_mean_squared_error: 1.9601\n",
      "Epoch 638/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4620 - loss_1: 0.0841 - root_mean_squared_error: 1.7819 - val_loss: 7.4990 - val_loss_1: 0.0823 - val_root_mean_squared_error: 1.9483\n",
      "Epoch 639/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.7578 - loss_1: 0.0830 - root_mean_squared_error: 1.8025 - val_loss: 7.8052 - val_loss_1: 0.0830 - val_root_mean_squared_error: 2.0175\n",
      "Epoch 640/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6086 - loss_1: 0.0834 - root_mean_squared_error: 1.8033 - val_loss: 7.2831 - val_loss_1: 0.0828 - val_root_mean_squared_error: 1.9240\n",
      "Epoch 641/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6848 - loss_1: 0.0830 - root_mean_squared_error: 1.7939 - val_loss: 7.6334 - val_loss_1: 0.0821 - val_root_mean_squared_error: 1.9413\n",
      "Epoch 642/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6950 - loss_1: 0.0833 - root_mean_squared_error: 1.8124 - val_loss: 7.2119 - val_loss_1: 0.0827 - val_root_mean_squared_error: 1.9163\n",
      "Epoch 643/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.9475 - loss_1: 0.0831 - root_mean_squared_error: 1.8291 - val_loss: 7.9695 - val_loss_1: 0.0846 - val_root_mean_squared_error: 2.0116\n",
      "Epoch 644/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5086 - loss_1: 0.0843 - root_mean_squared_error: 1.7848 - val_loss: 7.4037 - val_loss_1: 0.0827 - val_root_mean_squared_error: 1.9175\n",
      "Epoch 645/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.4692 - loss_1: 0.0823 - root_mean_squared_error: 1.7764 - val_loss: 7.6633 - val_loss_1: 0.0834 - val_root_mean_squared_error: 1.9790\n",
      "Epoch 646/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5648 - loss_1: 0.0828 - root_mean_squared_error: 1.7954 - val_loss: 7.7551 - val_loss_1: 0.0817 - val_root_mean_squared_error: 1.9683\n",
      "Epoch 647/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4951 - loss_1: 0.0829 - root_mean_squared_error: 1.7905 - val_loss: 7.5530 - val_loss_1: 0.0843 - val_root_mean_squared_error: 1.9750\n",
      "Epoch 648/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5792 - loss_1: 0.0830 - root_mean_squared_error: 1.7897 - val_loss: 7.6487 - val_loss_1: 0.0827 - val_root_mean_squared_error: 1.9587\n",
      "Epoch 649/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6781 - loss_1: 0.0838 - root_mean_squared_error: 1.8012 - val_loss: 7.5849 - val_loss_1: 0.0839 - val_root_mean_squared_error: 1.9706\n",
      "Epoch 650/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7061 - loss_1: 0.0827 - root_mean_squared_error: 1.8074 - val_loss: 7.5802 - val_loss_1: 0.0828 - val_root_mean_squared_error: 1.9777\n",
      "Epoch 651/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5878 - loss_1: 0.0826 - root_mean_squared_error: 1.7999 - val_loss: 7.2018 - val_loss_1: 0.0818 - val_root_mean_squared_error: 1.9130\n",
      "Epoch 652/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.7306 - loss_1: 0.0824 - root_mean_squared_error: 1.8039 - val_loss: 7.9765 - val_loss_1: 0.0825 - val_root_mean_squared_error: 2.0132\n",
      "Epoch 653/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5398 - loss_1: 0.0829 - root_mean_squared_error: 1.7905 - val_loss: 7.5667 - val_loss_1: 0.0829 - val_root_mean_squared_error: 1.9543\n",
      "Epoch 654/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4446 - loss_1: 0.0820 - root_mean_squared_error: 1.7804 - val_loss: 7.1684 - val_loss_1: 0.0829 - val_root_mean_squared_error: 1.9034\n",
      "Epoch 655/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6245 - loss_1: 0.0830 - root_mean_squared_error: 1.7834 - val_loss: 7.5937 - val_loss_1: 0.0828 - val_root_mean_squared_error: 1.9525\n",
      "Epoch 656/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.6528 - loss_1: 0.0826 - root_mean_squared_error: 1.7996 - val_loss: 7.2258 - val_loss_1: 0.0818 - val_root_mean_squared_error: 1.9253\n",
      "Epoch 657/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.7548 - loss_1: 0.0819 - root_mean_squared_error: 1.8134 - val_loss: 7.9830 - val_loss_1: 0.0834 - val_root_mean_squared_error: 1.9988\n",
      "Epoch 658/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5341 - loss_1: 0.0846 - root_mean_squared_error: 1.7943 - val_loss: 7.2953 - val_loss_1: 0.0821 - val_root_mean_squared_error: 1.9283\n",
      "Epoch 659/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3720 - loss_1: 0.0816 - root_mean_squared_error: 1.7645 - val_loss: 7.1339 - val_loss_1: 0.0821 - val_root_mean_squared_error: 1.9138\n",
      "Epoch 660/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5269 - loss_1: 0.0822 - root_mean_squared_error: 1.7866 - val_loss: 7.6711 - val_loss_1: 0.0830 - val_root_mean_squared_error: 1.9683\n",
      "Epoch 661/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4077 - loss_1: 0.0825 - root_mean_squared_error: 1.7822 - val_loss: 7.7885 - val_loss_1: 0.0823 - val_root_mean_squared_error: 1.9741\n",
      "Epoch 662/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.4249 - loss_1: 0.0830 - root_mean_squared_error: 1.7734 - val_loss: 7.7343 - val_loss_1: 0.0824 - val_root_mean_squared_error: 1.9634\n",
      "Epoch 663/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5828 - loss_1: 0.0818 - root_mean_squared_error: 1.7949 - val_loss: 7.7324 - val_loss_1: 0.0839 - val_root_mean_squared_error: 1.9737\n",
      "Epoch 664/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.6151 - loss_1: 0.0830 - root_mean_squared_error: 1.7963 - val_loss: 7.0820 - val_loss_1: 0.0807 - val_root_mean_squared_error: 1.8860\n",
      "Epoch 665/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4426 - loss_1: 0.0811 - root_mean_squared_error: 1.7679 - val_loss: 7.7791 - val_loss_1: 0.0823 - val_root_mean_squared_error: 1.9834\n",
      "Epoch 666/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3547 - loss_1: 0.0825 - root_mean_squared_error: 1.7688 - val_loss: 7.2891 - val_loss_1: 0.0828 - val_root_mean_squared_error: 1.9229\n",
      "Epoch 667/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5457 - loss_1: 0.0830 - root_mean_squared_error: 1.7919 - val_loss: 7.6342 - val_loss_1: 0.0827 - val_root_mean_squared_error: 1.9790\n",
      "Epoch 668/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5601 - loss_1: 0.0818 - root_mean_squared_error: 1.7967 - val_loss: 7.5406 - val_loss_1: 0.0814 - val_root_mean_squared_error: 1.9339\n",
      "Epoch 669/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5693 - loss_1: 0.0828 - root_mean_squared_error: 1.7878 - val_loss: 7.8657 - val_loss_1: 0.0825 - val_root_mean_squared_error: 2.0056\n",
      "Epoch 670/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.5224 - loss_1: 0.0814 - root_mean_squared_error: 1.7883 - val_loss: 7.4666 - val_loss_1: 0.0814 - val_root_mean_squared_error: 1.9538\n",
      "Epoch 671/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6729 - loss_1: 0.0829 - root_mean_squared_error: 1.7955 - val_loss: 7.1700 - val_loss_1: 0.0813 - val_root_mean_squared_error: 1.8958\n",
      "Epoch 672/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3507 - loss_1: 0.0819 - root_mean_squared_error: 1.7646 - val_loss: 7.5821 - val_loss_1: 0.0823 - val_root_mean_squared_error: 1.9808\n",
      "Epoch 673/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5176 - loss_1: 0.0817 - root_mean_squared_error: 1.7797 - val_loss: 7.3594 - val_loss_1: 0.0805 - val_root_mean_squared_error: 1.9382\n",
      "Epoch 674/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.6005 - loss_1: 0.0818 - root_mean_squared_error: 1.7965 - val_loss: 7.6376 - val_loss_1: 0.0829 - val_root_mean_squared_error: 1.9664\n",
      "Epoch 675/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4553 - loss_1: 0.0817 - root_mean_squared_error: 1.7729 - val_loss: 7.5135 - val_loss_1: 0.0807 - val_root_mean_squared_error: 1.9364\n",
      "Epoch 676/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5285 - loss_1: 0.0815 - root_mean_squared_error: 1.7848 - val_loss: 7.5659 - val_loss_1: 0.0813 - val_root_mean_squared_error: 1.9461\n",
      "Epoch 677/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4130 - loss_1: 0.0828 - root_mean_squared_error: 1.7693 - val_loss: 7.8079 - val_loss_1: 0.0836 - val_root_mean_squared_error: 1.9591\n",
      "Epoch 678/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3936 - loss_1: 0.0817 - root_mean_squared_error: 1.7624 - val_loss: 7.1621 - val_loss_1: 0.0819 - val_root_mean_squared_error: 1.8996\n",
      "Epoch 679/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5592 - loss_1: 0.0818 - root_mean_squared_error: 1.7781 - val_loss: 7.4750 - val_loss_1: 0.0812 - val_root_mean_squared_error: 1.9402\n",
      "Epoch 680/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4957 - loss_1: 0.0820 - root_mean_squared_error: 1.7729 - val_loss: 7.5211 - val_loss_1: 0.0815 - val_root_mean_squared_error: 1.9573\n",
      "Epoch 681/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4329 - loss_1: 0.0823 - root_mean_squared_error: 1.7702 - val_loss: 7.1046 - val_loss_1: 0.0820 - val_root_mean_squared_error: 1.8893\n",
      "Epoch 682/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4202 - loss_1: 0.0811 - root_mean_squared_error: 1.7762 - val_loss: 7.5538 - val_loss_1: 0.0809 - val_root_mean_squared_error: 1.9610\n",
      "Epoch 683/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3890 - loss_1: 0.0821 - root_mean_squared_error: 1.7675 - val_loss: 7.4813 - val_loss_1: 0.0809 - val_root_mean_squared_error: 1.9339\n",
      "Epoch 684/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4576 - loss_1: 0.0811 - root_mean_squared_error: 1.7741 - val_loss: 7.4006 - val_loss_1: 0.0819 - val_root_mean_squared_error: 1.9309\n",
      "Epoch 685/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4693 - loss_1: 0.0822 - root_mean_squared_error: 1.7788 - val_loss: 7.2575 - val_loss_1: 0.0815 - val_root_mean_squared_error: 1.9230\n",
      "Epoch 686/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5395 - loss_1: 0.0824 - root_mean_squared_error: 1.7804 - val_loss: 7.3994 - val_loss_1: 0.0820 - val_root_mean_squared_error: 1.9247\n",
      "Epoch 687/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4466 - loss_1: 0.0813 - root_mean_squared_error: 1.7748 - val_loss: 7.6486 - val_loss_1: 0.0813 - val_root_mean_squared_error: 1.9968\n",
      "Epoch 688/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3719 - loss_1: 0.0809 - root_mean_squared_error: 1.7578 - val_loss: 7.4300 - val_loss_1: 0.0817 - val_root_mean_squared_error: 1.9346\n",
      "Epoch 689/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5260 - loss_1: 0.0813 - root_mean_squared_error: 1.7806 - val_loss: 7.5339 - val_loss_1: 0.0811 - val_root_mean_squared_error: 1.9497\n",
      "Epoch 690/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3323 - loss_1: 0.0810 - root_mean_squared_error: 1.7604 - val_loss: 7.0245 - val_loss_1: 0.0803 - val_root_mean_squared_error: 1.9105\n",
      "Epoch 691/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.4237 - loss_1: 0.0809 - root_mean_squared_error: 1.76 - 1s 76us/step - loss: 6.4098 - loss_1: 0.0809 - root_mean_squared_error: 1.7602 - val_loss: 7.4017 - val_loss_1: 0.0807 - val_root_mean_squared_error: 1.9366\n",
      "Epoch 692/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3793 - loss_1: 0.0806 - root_mean_squared_error: 1.7599 - val_loss: 7.8514 - val_loss_1: 0.0816 - val_root_mean_squared_error: 1.9745\n",
      "Epoch 693/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.4056 - loss_1: 0.0817 - root_mean_squared_error: 1.7578 - val_loss: 7.6816 - val_loss_1: 0.0812 - val_root_mean_squared_error: 1.9747\n",
      "Epoch 694/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4429 - loss_1: 0.0815 - root_mean_squared_error: 1.7660 - val_loss: 7.2801 - val_loss_1: 0.0808 - val_root_mean_squared_error: 1.9364\n",
      "Epoch 695/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3602 - loss_1: 0.0806 - root_mean_squared_error: 1.7655 - val_loss: 7.5300 - val_loss_1: 0.0802 - val_root_mean_squared_error: 1.9361\n",
      "Epoch 696/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4026 - loss_1: 0.0806 - root_mean_squared_error: 1.7718 - val_loss: 7.7342 - val_loss_1: 0.0816 - val_root_mean_squared_error: 1.9920\n",
      "Epoch 697/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2534 - loss_1: 0.0808 - root_mean_squared_error: 1.7537 - val_loss: 7.2807 - val_loss_1: 0.0803 - val_root_mean_squared_error: 1.9142\n",
      "Epoch 698/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4900 - loss_1: 0.0813 - root_mean_squared_error: 1.7834 - val_loss: 6.9782 - val_loss_1: 0.0801 - val_root_mean_squared_error: 1.8567\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4433 - loss_1: 0.0806 - root_mean_squared_error: 1.7735 - val_loss: 7.6434 - val_loss_1: 0.0807 - val_root_mean_squared_error: 1.9897\n",
      "Epoch 700/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.4530 - loss_1: 0.0801 - root_mean_squared_error: 1.7692 - val_loss: 7.2408 - val_loss_1: 0.0794 - val_root_mean_squared_error: 1.8874\n",
      "Epoch 701/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3789 - loss_1: 0.0813 - root_mean_squared_error: 1.7658 - val_loss: 7.6092 - val_loss_1: 0.0813 - val_root_mean_squared_error: 1.9605\n",
      "Epoch 702/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.5137 - loss_1: 0.0802 - root_mean_squared_error: 1.7834 - val_loss: 7.1027 - val_loss_1: 0.0804 - val_root_mean_squared_error: 1.8914\n",
      "Epoch 703/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3008 - loss_1: 0.0814 - root_mean_squared_error: 1.7513 - val_loss: 7.3352 - val_loss_1: 0.0806 - val_root_mean_squared_error: 1.9340\n",
      "Epoch 704/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3629 - loss_1: 0.0806 - root_mean_squared_error: 1.7590 - val_loss: 7.1055 - val_loss_1: 0.0814 - val_root_mean_squared_error: 1.9131\n",
      "Epoch 705/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3869 - loss_1: 0.0809 - root_mean_squared_error: 1.7682 - val_loss: 7.6317 - val_loss_1: 0.0800 - val_root_mean_squared_error: 1.9544\n",
      "Epoch 706/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.4399 - loss_1: 0.0802 - root_mean_squared_error: 1.77 - 1s 76us/step - loss: 6.4388 - loss_1: 0.0802 - root_mean_squared_error: 1.7685 - val_loss: 7.0530 - val_loss_1: 0.0817 - val_root_mean_squared_error: 1.9001\n",
      "Epoch 707/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2291 - loss_1: 0.0804 - root_mean_squared_error: 1.7512 - val_loss: 7.6812 - val_loss_1: 0.0809 - val_root_mean_squared_error: 1.9871\n",
      "Epoch 708/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3712 - loss_1: 0.0807 - root_mean_squared_error: 1.7673 - val_loss: 7.9277 - val_loss_1: 0.0810 - val_root_mean_squared_error: 1.9980\n",
      "Epoch 709/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5734 - loss_1: 0.0809 - root_mean_squared_error: 1.7858 - val_loss: 7.4934 - val_loss_1: 0.0802 - val_root_mean_squared_error: 1.9374\n",
      "Epoch 710/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.2491 - loss_1: 0.0808 - root_mean_squared_error: 1.7415 - val_loss: 6.9411 - val_loss_1: 0.0805 - val_root_mean_squared_error: 1.8686\n",
      "Epoch 711/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3061 - loss_1: 0.0799 - root_mean_squared_error: 1.7627 - val_loss: 7.4514 - val_loss_1: 0.0806 - val_root_mean_squared_error: 1.9381\n",
      "Epoch 712/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.5727 - loss_1: 0.0805 - root_mean_squared_error: 1.7717 - val_loss: 7.3498 - val_loss_1: 0.0803 - val_root_mean_squared_error: 1.9284\n",
      "Epoch 713/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3883 - loss_1: 0.0800 - root_mean_squared_error: 1.7686 - val_loss: 7.1933 - val_loss_1: 0.0810 - val_root_mean_squared_error: 1.8999\n",
      "Epoch 714/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2768 - loss_1: 0.0805 - root_mean_squared_error: 1.7518 - val_loss: 7.3256 - val_loss_1: 0.0805 - val_root_mean_squared_error: 1.9134\n",
      "Epoch 715/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.5075 - loss_1: 0.0812 - root_mean_squared_error: 1.7784 - val_loss: 7.0799 - val_loss_1: 0.0802 - val_root_mean_squared_error: 1.9071\n",
      "Epoch 716/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1783 - loss_1: 0.0799 - root_mean_squared_error: 1.7429 - val_loss: 7.2992 - val_loss_1: 0.0806 - val_root_mean_squared_error: 1.9208\n",
      "Epoch 717/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2718 - loss_1: 0.0800 - root_mean_squared_error: 1.7564 - val_loss: 7.2506 - val_loss_1: 0.0801 - val_root_mean_squared_error: 1.9190\n",
      "Epoch 718/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1718 - loss_1: 0.0799 - root_mean_squared_error: 1.7473 - val_loss: 7.4142 - val_loss_1: 0.0811 - val_root_mean_squared_error: 1.9388\n",
      "Epoch 719/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3454 - loss_1: 0.0802 - root_mean_squared_error: 1.7526 - val_loss: 7.2878 - val_loss_1: 0.0797 - val_root_mean_squared_error: 1.9039\n",
      "Epoch 720/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3019 - loss_1: 0.0804 - root_mean_squared_error: 1.7452 - val_loss: 7.5015 - val_loss_1: 0.0808 - val_root_mean_squared_error: 1.9266\n",
      "Epoch 721/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3618 - loss_1: 0.0809 - root_mean_squared_error: 1.7530 - val_loss: 7.5207 - val_loss_1: 0.0807 - val_root_mean_squared_error: 1.9420- loss: 6.3887 - loss_1: 0.0809 - root_mean_squared_error: 1.\n",
      "Epoch 722/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.4562 - loss_1: 0.0800 - root_mean_squared_error: 1.7703 - val_loss: 7.0623 - val_loss_1: 0.0804 - val_root_mean_squared_error: 1.8975\n",
      "Epoch 723/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1597 - loss_1: 0.0803 - root_mean_squared_error: 1.7354 - val_loss: 7.5661 - val_loss_1: 0.0797 - val_root_mean_squared_error: 1.9484\n",
      "Epoch 724/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3833 - loss_1: 0.0803 - root_mean_squared_error: 1.7702 - val_loss: 7.4058 - val_loss_1: 0.0811 - val_root_mean_squared_error: 1.9257\n",
      "Epoch 725/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.2875 - loss_1: 0.0804 - root_mean_squared_error: 1.7582 - val_loss: 6.8091 - val_loss_1: 0.0808 - val_root_mean_squared_error: 1.8691\n",
      "Epoch 726/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3180 - loss_1: 0.0807 - root_mean_squared_error: 1.7500 - val_loss: 7.3941 - val_loss_1: 0.0804 - val_root_mean_squared_error: 1.9351\n",
      "Epoch 727/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2868 - loss_1: 0.0803 - root_mean_squared_error: 1.7535 - val_loss: 7.5604 - val_loss_1: 0.0795 - val_root_mean_squared_error: 1.9454\n",
      "Epoch 728/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1699 - loss_1: 0.0797 - root_mean_squared_error: 1.7312 - val_loss: 7.1931 - val_loss_1: 0.0800 - val_root_mean_squared_error: 1.9034\n",
      "Epoch 729/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3288 - loss_1: 0.0792 - root_mean_squared_error: 1.7527 - val_loss: 6.9313 - val_loss_1: 0.0802 - val_root_mean_squared_error: 1.8734\n",
      "Epoch 730/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2931 - loss_1: 0.0804 - root_mean_squared_error: 1.7567 - val_loss: 7.3031 - val_loss_1: 0.0790 - val_root_mean_squared_error: 1.9132\n",
      "Epoch 731/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4369 - loss_1: 0.0791 - root_mean_squared_error: 1.7727 - val_loss: 7.4721 - val_loss_1: 0.0794 - val_root_mean_squared_error: 1.9370\n",
      "Epoch 732/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1648 - loss_1: 0.0800 - root_mean_squared_error: 1.7379 - val_loss: 7.5657 - val_loss_1: 0.0803 - val_root_mean_squared_error: 1.9497\n",
      "Epoch 733/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2274 - loss_1: 0.0796 - root_mean_squared_error: 1.7488 - val_loss: 7.5493 - val_loss_1: 0.0782 - val_root_mean_squared_error: 1.9476\n",
      "Epoch 734/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.4723 - loss_1: 0.0795 - root_mean_squared_error: 1.7588 - val_loss: 7.5819 - val_loss_1: 0.0802 - val_root_mean_squared_error: 1.9520\n",
      "Epoch 735/1000\n",
      "10760/10760 [==============================] - 1s 84us/step - loss: 6.3221 - loss_1: 0.0796 - root_mean_squared_error: 1.7479 - val_loss: 7.3433 - val_loss_1: 0.0806 - val_root_mean_squared_error: 1.9439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 736/1000\n",
      "10760/10760 [==============================] - 1s 82us/step - loss: 6.3042 - loss_1: 0.0789 - root_mean_squared_error: 1.7518 - val_loss: 7.4747 - val_loss_1: 0.0799 - val_root_mean_squared_error: 1.9523\n",
      "Epoch 737/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3146 - loss_1: 0.0801 - root_mean_squared_error: 1.7528 - val_loss: 7.1683 - val_loss_1: 0.0788 - val_root_mean_squared_error: 1.8999\n",
      "Epoch 738/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1890 - loss_1: 0.0794 - root_mean_squared_error: 1.7390 - val_loss: 7.2897 - val_loss_1: 0.0804 - val_root_mean_squared_error: 1.9450\n",
      "Epoch 739/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.2760 - loss_1: 0.0797 - root_mean_squared_error: 1.7410 - val_loss: 7.2735 - val_loss_1: 0.0780 - val_root_mean_squared_error: 1.9294\n",
      "Epoch 740/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2929 - loss_1: 0.0790 - root_mean_squared_error: 1.7518 - val_loss: 7.1690 - val_loss_1: 0.0811 - val_root_mean_squared_error: 1.9028\n",
      "Epoch 741/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.3897 - loss_1: 0.0793 - root_mean_squared_error: 1.7679 - val_loss: 7.2076 - val_loss_1: 0.0796 - val_root_mean_squared_error: 1.9136\n",
      "Epoch 742/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1566 - loss_1: 0.0798 - root_mean_squared_error: 1.7357 - val_loss: 7.3720 - val_loss_1: 0.0796 - val_root_mean_squared_error: 1.9303\n",
      "Epoch 743/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3754 - loss_1: 0.0791 - root_mean_squared_error: 1.7580 - val_loss: 7.2356 - val_loss_1: 0.0797 - val_root_mean_squared_error: 1.9046\n",
      "Epoch 744/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1377 - loss_1: 0.0796 - root_mean_squared_error: 1.7270 - val_loss: 7.6465 - val_loss_1: 0.0780 - val_root_mean_squared_error: 1.9680\n",
      "Epoch 745/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1629 - loss_1: 0.0790 - root_mean_squared_error: 1.7378 - val_loss: 7.4998 - val_loss_1: 0.0797 - val_root_mean_squared_error: 1.9459\n",
      "Epoch 746/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2838 - loss_1: 0.0797 - root_mean_squared_error: 1.7496 - val_loss: 7.2101 - val_loss_1: 0.0783 - val_root_mean_squared_error: 1.8726\n",
      "Epoch 747/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2696 - loss_1: 0.0789 - root_mean_squared_error: 1.7475 - val_loss: 6.9564 - val_loss_1: 0.0783 - val_root_mean_squared_error: 1.8884\n",
      "Epoch 748/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1624 - loss_1: 0.0797 - root_mean_squared_error: 1.7237 - val_loss: 7.2984 - val_loss_1: 0.0798 - val_root_mean_squared_error: 1.9247\n",
      "Epoch 749/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2358 - loss_1: 0.0788 - root_mean_squared_error: 1.7432 - val_loss: 7.5506 - val_loss_1: 0.0791 - val_root_mean_squared_error: 1.9650\n",
      "Epoch 750/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4139 - loss_1: 0.0797 - root_mean_squared_error: 1.7664 - val_loss: 7.3261 - val_loss_1: 0.0787 - val_root_mean_squared_error: 1.9322\n",
      "Epoch 751/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.2734 - loss_1: 0.0788 - root_mean_squared_error: 1.7337 - val_loss: 7.3107 - val_loss_1: 0.0791 - val_root_mean_squared_error: 1.9428\n",
      "Epoch 752/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1849 - loss_1: 0.0790 - root_mean_squared_error: 1.7277 - val_loss: 7.1270 - val_loss_1: 0.0783 - val_root_mean_squared_error: 1.9005\n",
      "Epoch 753/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4128 - loss_1: 0.0790 - root_mean_squared_error: 1.7636 - val_loss: 7.5953 - val_loss_1: 0.0797 - val_root_mean_squared_error: 1.9583\n",
      "Epoch 754/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.2935 - loss_1: 0.0787 - root_mean_squared_error: 1.7436 - val_loss: 7.3333 - val_loss_1: 0.0786 - val_root_mean_squared_error: 1.9346\n",
      "Epoch 755/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1521 - loss_1: 0.0792 - root_mean_squared_error: 1.7389 - val_loss: 7.4852 - val_loss_1: 0.0798 - val_root_mean_squared_error: 1.9554\n",
      "Epoch 756/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2136 - loss_1: 0.0792 - root_mean_squared_error: 1.7462 - val_loss: 7.3732 - val_loss_1: 0.0784 - val_root_mean_squared_error: 1.9020\n",
      "Epoch 757/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3979 - loss_1: 0.0776 - root_mean_squared_error: 1.7607 - val_loss: 7.2456 - val_loss_1: 0.0788 - val_root_mean_squared_error: 1.9339\n",
      "Epoch 758/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.4365 - loss_1: 0.0792 - root_mean_squared_error: 1.7708 - val_loss: 7.4470 - val_loss_1: 0.0788 - val_root_mean_squared_error: 1.9359\n",
      "Epoch 759/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2072 - loss_1: 0.0786 - root_mean_squared_error: 1.7473 - val_loss: 7.0688 - val_loss_1: 0.0783 - val_root_mean_squared_error: 1.9060\n",
      "Epoch 760/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2728 - loss_1: 0.0786 - root_mean_squared_error: 1.7472 - val_loss: 7.3396 - val_loss_1: 0.0793 - val_root_mean_squared_error: 1.9238\n",
      "Epoch 761/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2688 - loss_1: 0.0794 - root_mean_squared_error: 1.7412 - val_loss: 7.3096 - val_loss_1: 0.0791 - val_root_mean_squared_error: 1.9044\n",
      "Epoch 762/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1356 - loss_1: 0.0789 - root_mean_squared_error: 1.7283 - val_loss: 7.4091 - val_loss_1: 0.0790 - val_root_mean_squared_error: 1.9376\n",
      "Epoch 763/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2561 - loss_1: 0.0782 - root_mean_squared_error: 1.7516 - val_loss: 7.0589 - val_loss_1: 0.0791 - val_root_mean_squared_error: 1.8910\n",
      "Epoch 764/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2386 - loss_1: 0.0778 - root_mean_squared_error: 1.7453 - val_loss: 7.0557 - val_loss_1: 0.0785 - val_root_mean_squared_error: 1.9016\n",
      "Epoch 765/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2499 - loss_1: 0.0781 - root_mean_squared_error: 1.7495 - val_loss: 7.4769 - val_loss_1: 0.0781 - val_root_mean_squared_error: 1.9600\n",
      "Epoch 766/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2488 - loss_1: 0.0788 - root_mean_squared_error: 1.7457 - val_loss: 7.5367 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.9474\n",
      "Epoch 767/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.2936 - loss_1: 0.0773 - root_mean_squared_error: 1.7441 - val_loss: 7.5472 - val_loss_1: 0.0789 - val_root_mean_squared_error: 1.9668\n",
      "Epoch 768/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0054 - loss_1: 0.0793 - root_mean_squared_error: 1.7100 - val_loss: 7.1134 - val_loss_1: 0.0785 - val_root_mean_squared_error: 1.8829\n",
      "Epoch 769/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.2303 - loss_1: 0.0782 - root_mean_squared_error: 1.7342 - val_loss: 7.3626 - val_loss_1: 0.0784 - val_root_mean_squared_error: 1.9307\n",
      "Epoch 770/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1567 - loss_1: 0.0788 - root_mean_squared_error: 1.7229 - val_loss: 7.3782 - val_loss_1: 0.0776 - val_root_mean_squared_error: 1.9457\n",
      "Epoch 771/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0595 - loss_1: 0.0782 - root_mean_squared_error: 1.7199 - val_loss: 7.2155 - val_loss_1: 0.0787 - val_root_mean_squared_error: 1.8972\n",
      "Epoch 772/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0755 - loss_1: 0.0785 - root_mean_squared_error: 1.7171 - val_loss: 7.0058 - val_loss_1: 0.0782 - val_root_mean_squared_error: 1.8806\n",
      "Epoch 773/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.1339 - loss_1: 0.0781 - root_mean_squared_error: 1.72 - ETA: 0s - loss: 6.1786 - loss_1: 0.0778 - root_mean_squared_error: 1.72 - 1s 75us/step - loss: 6.1549 - loss_1: 0.0778 - root_mean_squared_error: 1.7217 - val_loss: 7.0525 - val_loss_1: 0.0774 - val_root_mean_squared_error: 1.8894\n",
      "Epoch 774/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1537 - loss_1: 0.0788 - root_mean_squared_error: 1.7238 - val_loss: 7.4491 - val_loss_1: 0.0787 - val_root_mean_squared_error: 1.9592\n",
      "Epoch 775/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2711 - loss_1: 0.0783 - root_mean_squared_error: 1.7484 - val_loss: 7.2590 - val_loss_1: 0.0787 - val_root_mean_squared_error: 1.9124\n",
      "Epoch 776/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0488 - loss_1: 0.0779 - root_mean_squared_error: 1.7119 - val_loss: 7.1120 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.9045\n",
      "Epoch 777/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0545 - loss_1: 0.0779 - root_mean_squared_error: 1.7085 - val_loss: 7.3208 - val_loss_1: 0.0785 - val_root_mean_squared_error: 1.9353\n",
      "Epoch 778/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1858 - loss_1: 0.0778 - root_mean_squared_error: 1.7255 - val_loss: 7.1627 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.8917\n",
      "Epoch 779/1000\n",
      "10760/10760 [==============================] - 1s 80us/step - loss: 6.3635 - loss_1: 0.0779 - root_mean_squared_error: 1.7439 - val_loss: 7.0590 - val_loss_1: 0.0774 - val_root_mean_squared_error: 1.8841\n",
      "Epoch 780/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.9612 - loss_1: 0.0780 - root_mean_squared_error: 1.7063 - val_loss: 6.9855 - val_loss_1: 0.0785 - val_root_mean_squared_error: 1.8975\n",
      "Epoch 781/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1206 - loss_1: 0.0779 - root_mean_squared_error: 1.7213 - val_loss: 7.3887 - val_loss_1: 0.0770 - val_root_mean_squared_error: 1.9456\n",
      "Epoch 782/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1682 - loss_1: 0.0782 - root_mean_squared_error: 1.7370 - val_loss: 7.1147 - val_loss_1: 0.0781 - val_root_mean_squared_error: 1.8987\n",
      "Epoch 783/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.2271 - loss_1: 0.0767 - root_mean_squared_error: 1.7313 - val_loss: 7.2667 - val_loss_1: 0.0774 - val_root_mean_squared_error: 1.9217\n",
      "Epoch 784/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0836 - loss_1: 0.0788 - root_mean_squared_error: 1.7156 - val_loss: 7.0515 - val_loss_1: 0.0781 - val_root_mean_squared_error: 1.8815\n",
      "Epoch 785/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1644 - loss_1: 0.0772 - root_mean_squared_error: 1.7388 - val_loss: 7.7000 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.9771\n",
      "Epoch 786/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.2220 - loss_1: 0.0780 - root_mean_squared_error: 1.7375 - val_loss: 7.0709 - val_loss_1: 0.0757 - val_root_mean_squared_error: 1.9158\n",
      "Epoch 787/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1013 - loss_1: 0.0771 - root_mean_squared_error: 1.7228 - val_loss: 7.5204 - val_loss_1: 0.0775 - val_root_mean_squared_error: 1.9605\n",
      "Epoch 788/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1046 - loss_1: 0.0772 - root_mean_squared_error: 1.7242 - val_loss: 7.4079 - val_loss_1: 0.0778 - val_root_mean_squared_error: 1.9424\n",
      "Epoch 789/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2475 - loss_1: 0.0783 - root_mean_squared_error: 1.7330 - val_loss: 7.0203 - val_loss_1: 0.0763 - val_root_mean_squared_error: 1.8680\n",
      "Epoch 790/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0634 - loss_1: 0.0770 - root_mean_squared_error: 1.7193 - val_loss: 7.0291 - val_loss_1: 0.0781 - val_root_mean_squared_error: 1.8815\n",
      "Epoch 791/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1650 - loss_1: 0.0777 - root_mean_squared_error: 1.7186 - val_loss: 7.1841 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.9137\n",
      "Epoch 792/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.3432 - loss_1: 0.0767 - root_mean_squared_error: 1.7574 - val_loss: 7.1179 - val_loss_1: 0.0778 - val_root_mean_squared_error: 1.8849\n",
      "Epoch 793/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.2027 - loss_1: 0.0775 - root_mean_squared_error: 1.7382 - val_loss: 6.9359 - val_loss_1: 0.0772 - val_root_mean_squared_error: 1.8448\n",
      "Epoch 794/1000\n",
      "10760/10760 [==============================] - ETA: 0s - loss: 6.2433 - loss_1: 0.0778 - root_mean_squared_error: 1.72 - 1s 76us/step - loss: 6.2446 - loss_1: 0.0777 - root_mean_squared_error: 1.7303 - val_loss: 7.1118 - val_loss_1: 0.0778 - val_root_mean_squared_error: 1.8963\n",
      "Epoch 795/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 6.0272 - loss_1: 0.0779 - root_mean_squared_error: 1.7126 - val_loss: 7.0063 - val_loss_1: 0.0780 - val_root_mean_squared_error: 1.9129\n",
      "Epoch 796/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.0325 - loss_1: 0.0785 - root_mean_squared_error: 1.7130 - val_loss: 7.2209 - val_loss_1: 0.0772 - val_root_mean_squared_error: 1.8979\n",
      "Epoch 797/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.3272 - loss_1: 0.0777 - root_mean_squared_error: 1.7499 - val_loss: 7.1453 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.9175\n",
      "Epoch 798/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.1454 - loss_1: 0.0777 - root_mean_squared_error: 1.7311 - val_loss: 7.1804 - val_loss_1: 0.0772 - val_root_mean_squared_error: 1.9102\n",
      "Epoch 799/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.2594 - loss_1: 0.0773 - root_mean_squared_error: 1.7477 - val_loss: 6.9792 - val_loss_1: 0.0767 - val_root_mean_squared_error: 1.8675\n",
      "Epoch 800/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0705 - loss_1: 0.0773 - root_mean_squared_error: 1.7174 - val_loss: 7.2225 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.9189\n",
      "Epoch 801/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.1994 - loss_1: 0.0773 - root_mean_squared_error: 1.7265 - val_loss: 6.9829 - val_loss_1: 0.0770 - val_root_mean_squared_error: 1.8748\n",
      "Epoch 802/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0654 - loss_1: 0.0764 - root_mean_squared_error: 1.7212 - val_loss: 7.2456 - val_loss_1: 0.0770 - val_root_mean_squared_error: 1.9038\n",
      "Epoch 803/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0769 - loss_1: 0.0771 - root_mean_squared_error: 1.7236 - val_loss: 7.3786 - val_loss_1: 0.0776 - val_root_mean_squared_error: 1.9338\n",
      "Epoch 804/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.0206 - loss_1: 0.0776 - root_mean_squared_error: 1.7213 - val_loss: 7.1515 - val_loss_1: 0.0770 - val_root_mean_squared_error: 1.9095\n",
      "Epoch 805/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.9727 - loss_1: 0.0778 - root_mean_squared_error: 1.7105 - val_loss: 6.9396 - val_loss_1: 0.0779 - val_root_mean_squared_error: 1.8773\n",
      "Epoch 806/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.1382 - loss_1: 0.0766 - root_mean_squared_error: 1.7226 - val_loss: 7.0188 - val_loss_1: 0.0771 - val_root_mean_squared_error: 1.9013\n",
      "Epoch 807/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.1502 - loss_1: 0.0769 - root_mean_squared_error: 1.7327 - val_loss: 7.1648 - val_loss_1: 0.0764 - val_root_mean_squared_error: 1.9054\n",
      "Epoch 808/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 5.9150 - loss_1: 0.0772 - root_mean_squared_error: 1.6951 - val_loss: 7.2499 - val_loss_1: 0.0778 - val_root_mean_squared_error: 1.9025\n",
      "Epoch 809/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.1987 - loss_1: 0.0780 - root_mean_squared_error: 1.7370 - val_loss: 7.0424 - val_loss_1: 0.0768 - val_root_mean_squared_error: 1.8862\n",
      "Epoch 810/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0872 - loss_1: 0.0769 - root_mean_squared_error: 1.7168 - val_loss: 7.4223 - val_loss_1: 0.0778 - val_root_mean_squared_error: 1.9369\n",
      "Epoch 811/1000\n",
      "10760/10760 [==============================] - 1s 74us/step - loss: 6.0557 - loss_1: 0.0774 - root_mean_squared_error: 1.7226 - val_loss: 7.1349 - val_loss_1: 0.0773 - val_root_mean_squared_error: 1.8883\n",
      "Epoch 812/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0823 - loss_1: 0.0775 - root_mean_squared_error: 1.7196 - val_loss: 7.1476 - val_loss_1: 0.0772 - val_root_mean_squared_error: 1.9176\n",
      "Epoch 813/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0374 - loss_1: 0.0768 - root_mean_squared_error: 1.7272 - val_loss: 6.9146 - val_loss_1: 0.0770 - val_root_mean_squared_error: 1.8707\n",
      "Epoch 814/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 5.9774 - loss_1: 0.0768 - root_mean_squared_error: 1.7046 - val_loss: 6.9295 - val_loss_1: 0.0768 - val_root_mean_squared_error: 1.8739\n",
      "Epoch 815/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 5.9985 - loss_1: 0.0770 - root_mean_squared_error: 1.7083 - val_loss: 7.2488 - val_loss_1: 0.0768 - val_root_mean_squared_error: 1.9346\n",
      "Epoch 816/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9755 - loss_1: 0.0760 - root_mean_squared_error: 1.7126 - val_loss: 7.1511 - val_loss_1: 0.0761 - val_root_mean_squared_error: 1.9074\n",
      "Epoch 817/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 6.1104 - loss_1: 0.0771 - root_mean_squared_error: 1.7235 - val_loss: 7.2025 - val_loss_1: 0.0775 - val_root_mean_squared_error: 1.9031\n",
      "Epoch 818/1000\n",
      "10760/10760 [==============================] - 1s 77us/step - loss: 6.0480 - loss_1: 0.0765 - root_mean_squared_error: 1.7095 - val_loss: 7.2446 - val_loss_1: 0.0757 - val_root_mean_squared_error: 1.9222\n",
      "Epoch 819/1000\n",
      "10760/10760 [==============================] - 1s 75us/step - loss: 6.0603 - loss_1: 0.0768 - root_mean_squared_error: 1.7133 - val_loss: 7.2115 - val_loss_1: 0.0764 - val_root_mean_squared_error: 1.9000\n",
      "Epoch 820/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0527 - loss_1: 0.0766 - root_mean_squared_error: 1.7123 - val_loss: 6.8834 - val_loss_1: 0.0757 - val_root_mean_squared_error: 1.8636\n",
      "Epoch 821/1000\n",
      "10760/10760 [==============================] - 1s 78us/step - loss: 6.0679 - loss_1: 0.0760 - root_mean_squared_error: 1.7139 - val_loss: 7.1851 - val_loss_1: 0.0777 - val_root_mean_squared_error: 1.9067\n",
      "Epoch 822/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0596 - loss_1: 0.0771 - root_mean_squared_error: 1.7219 - val_loss: 6.9983 - val_loss_1: 0.0765 - val_root_mean_squared_error: 1.8923\n",
      "Epoch 823/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 6.0331 - loss_1: 0.0764 - root_mean_squared_error: 1.7094 - val_loss: 7.1932 - val_loss_1: 0.0759 - val_root_mean_squared_error: 1.8960\n",
      "Epoch 824/1000\n",
      "10760/10760 [==============================] - 1s 79us/step - loss: 6.2047 - loss_1: 0.0768 - root_mean_squared_error: 1.7281 - val_loss: 7.0924 - val_loss_1: 0.0777 - val_root_mean_squared_error: 1.9060\n",
      "Epoch 825/1000\n",
      "10760/10760 [==============================] - 1s 76us/step - loss: 5.9895 - loss_1: 0.0763 - root_mean_squared_error: 1.7033 - val_loss: 7.2651 - val_loss_1: 0.0764 - val_root_mean_squared_error: 1.9180\n",
      "Epoch 00825: early stopping\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "[9.279793815612793, 0.07640000432729721, 2.6239984035491943]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.638970651626587"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses=[]\n",
    "std_rmses=[]\n",
    "for ii in ([13450]):\n",
    "    test_rmse, history = pass_arg(50, ii, 0.1)\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    mean_rmses.append(mean_rmse)\n",
    "    std_rmses.append(std_rmse)\n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3501212549209596]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1543289931784834]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(mean_rmses, \"../mean_rmse_dnn_loss_MC.dat\")\n",
    "save_obj(std_rmses, \"../std_rmse_dnn_loss_MC.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05279518, 0.03283933, 0.0537447 , 0.03974609, 0.03457924,\n",
       "       0.03742982, 0.04465229, 0.05489689, 0.0322278 , 0.04860931,\n",
       "       0.05708254, 0.04503478, 0.06214603, 0.04120987, 0.04285658,\n",
       "       0.03374553, 0.04266082, 0.04460517, 0.04174339, 0.0369988 ,\n",
       "       0.06102522, 0.04720526, 0.03547252, 0.04057915, 0.06028698,\n",
       "       0.04594869, 0.03679036, 0.04504748, 0.05434823, 0.05183214,\n",
       "       0.04711368, 0.03764421, 0.03771775, 0.05239221, 0.04771913,\n",
       "       0.04199286, 0.05519148, 0.04541095, 0.06952468, 0.04033285,\n",
       "       0.04858945, 0.03479638, 0.03056115, 0.03366404, 0.05692469,\n",
       "       0.05566785, 0.0399124 , 0.04820377, 0.04281671, 0.03658003,\n",
       "       0.05378899, 0.04206469, 0.04401018, 0.03655737, 0.06820614,\n",
       "       0.05063169, 0.04610386, 0.05112227, 0.0458006 , 0.04457092,\n",
       "       0.03266823, 0.04351811, 0.03674877, 0.03626641, 0.06036571,\n",
       "       0.04281345, 0.04486926, 0.05853532, 0.0412476 , 0.03061781,\n",
       "       0.03981644, 0.04545145, 0.04714443, 0.0347507 , 0.0435339 ,\n",
       "       0.0563973 , 0.0462813 , 0.03278266, 0.03832164, 0.04817164,\n",
       "       0.04458795, 0.03405588, 0.04257753, 0.04751948, 0.03065004,\n",
       "       0.03623127, 0.02619934, 0.03702716, 0.02890221, 0.06691784,\n",
       "       0.04177232, 0.04288093, 0.04231226, 0.03492444, 0.0536108 ,\n",
       "       0.03288045, 0.04017974, 0.05028878, 0.02899871, 0.04921668,\n",
       "       0.0544173 , 0.06278119, 0.03588118, 0.05201441, 0.04280652,\n",
       "       0.06454953, 0.04821771, 0.04457631, 0.05032665, 0.04444049,\n",
       "       0.04416846, 0.03295628, 0.06199717, 0.06398957, 0.03572344,\n",
       "       0.04308823, 0.03726914, 0.03696414, 0.03961926, 0.05957818,\n",
       "       0.04563537, 0.05378069, 0.01528705, 0.04214678, 0.0434939 ,\n",
       "       0.05372976, 0.05624967, 0.0261834 , 0.03281919, 0.04216101,\n",
       "       0.03712658, 0.06280787, 0.07287747, 0.06073531, 0.0448016 ,\n",
       "       0.03773594, 0.03362345, 0.04283446, 0.03972682, 0.05943469,\n",
       "       0.04580568, 0.03576661, 0.04975818, 0.04071469, 0.0422328 ,\n",
       "       0.05092936, 0.05575986, 0.05577863, 0.04989756, 0.02099567,\n",
       "       0.03364211, 0.04367697, 0.0414076 , 0.04126591, 0.04021514,\n",
       "       0.06240829, 0.06253503, 0.05431565, 0.04770659, 0.05804824,\n",
       "       0.05336291, 0.03884013, 0.04068544, 0.04030986, 0.0343623 ,\n",
       "       0.05537937, 0.03943855, 0.0437831 , 0.03251111, 0.04641122,\n",
       "       0.04650781, 0.06336901, 0.03897109, 0.0525963 , 0.04402711,\n",
       "       0.04272104, 0.05419434, 0.04758772, 0.01059438, 0.0397981 ,\n",
       "       0.04009419, 0.03988982, 0.04115646, 0.06074953, 0.03537698,\n",
       "       0.05409338, 0.03621498, 0.04268951, 0.02742414, 0.06314985,\n",
       "       0.04056774, 0.03371869, 0.05680367, 0.04027347, 0.0423556 ,\n",
       "       0.04359945, 0.03329067, 0.06083277, 0.03186129, 0.04327793,\n",
       "       0.04347276, 0.06906273, 0.06251105, 0.03914563, 0.04627613,\n",
       "       0.04470402, 0.04327693, 0.03847009, 0.03701867, 0.03641728,\n",
       "       0.04423818, 0.04275543, 0.04751433, 0.01598257, 0.0361139 ,\n",
       "       0.06344987, 0.04440669, 0.0590071 , 0.03750511, 0.04802949,\n",
       "       0.04319545, 0.03292385, 0.05683002, 0.04306199, 0.07553553,\n",
       "       0.04664924, 0.02615323, 0.04164355, 0.04017032, 0.04845427,\n",
       "       0.01524437, 0.04560505, 0.04755528, 0.04621894, 0.035671  ,\n",
       "       0.05214545, 0.04782487, 0.03974194, 0.04686124, 0.03011703,\n",
       "       0.04219105, 0.00512406, 0.04616782, 0.04027798, 0.03635201,\n",
       "       0.04006006, 0.04698586, 0.04916538, 0.04942863, 0.04301912,\n",
       "       0.01242082, 0.04586679, 0.04452428, 0.05462679, 0.04546325,\n",
       "       0.04317021, 0.04421661, 0.04328338, 0.03609335, 0.01322834,\n",
       "       0.06298792, 0.05936319, 0.05422922, 0.02276836, 0.04393116,\n",
       "       0.03929581, 0.03899974, 0.04848171, 0.06487098, 0.03819473,\n",
       "       0.04477736, 0.05434734, 0.02750718, 0.04081893, 0.0329066 ,\n",
       "       0.06147749, 0.0481715 , 0.04027211, 0.03971713, 0.02977636,\n",
       "       0.04933265, 0.04041059, 0.00676761, 0.03140671, 0.06092018,\n",
       "       0.03260735, 0.04498848, 0.04263134, 0.03973242, 0.06383008,\n",
       "       0.04699862, 0.04485212, 0.04147894, 0.0351189 , 0.03459029,\n",
       "       0.03605019, 0.05538899, 0.03960966, 0.06022389, 0.06221807,\n",
       "       0.05112661, 0.04046448, 0.03787848, 0.03318763, 0.04231551,\n",
       "       0.03408996, 0.04793409, 0.04374145, 0.0370138 , 0.03402049,\n",
       "       0.04871874, 0.03599902, 0.04268842, 0.031595  , 0.06650469,\n",
       "       0.04995964, 0.04491393, 0.04104722, 0.03849293, 0.03155924,\n",
       "       0.03873638, 0.03353048, 0.06421298, 0.05130164, 0.02741468,\n",
       "       0.04650908, 0.03832591, 0.03874923, 0.04615496, 0.04358387,\n",
       "       0.04240591, 0.03957541, 0.04253527, 0.05690234, 0.04045956,\n",
       "       0.04065699, 0.0403286 , 0.03424413, 0.03766483, 0.03705497,\n",
       "       0.05626259, 0.04910798, 0.01901662, 0.04778707, 0.04089962,\n",
       "       0.04454983, 0.03830842, 0.04658324, 0.03315055, 0.04952156,\n",
       "       0.03471559, 0.0379632 , 0.05008176, 0.04855555, 0.03418293,\n",
       "       0.04798516, 0.0462708 , 0.03557218, 0.05841213, 0.06195722,\n",
       "       0.06544988, 0.05256044, 0.03281475, 0.05309714, 0.03220435,\n",
       "       0.03524032, 0.05978776, 0.01114547, 0.0403653 , 0.01870047,\n",
       "       0.04483945, 0.0600082 , 0.06017193, 0.04687081, 0.03984557,\n",
       "       0.03926663, 0.03725995, 0.04146082, 0.03977628, 0.04412157,\n",
       "       0.05626578, 0.04534624, 0.05506472, 0.04392665, 0.03638872,\n",
       "       0.0433717 , 0.02737629, 0.04461788, 0.03761269, 0.05160951,\n",
       "       0.0459027 , 0.039365  , 0.04209209, 0.03908138, 0.0412695 ,\n",
       "       0.03313401, 0.03775529, 0.04635129, 0.05896781, 0.05973145,\n",
       "       0.04243883, 0.05048671, 0.01785599, 0.06609472, 0.05757917,\n",
       "       0.0508724 , 0.03826016, 0.0431794 , 0.03648675, 0.04202123,\n",
       "       0.04486038, 0.04739558, 0.04292233, 0.01210807, 0.06012275,\n",
       "       0.04378906, 0.04868803, 0.06150983, 0.04017437, 0.04108255,\n",
       "       0.03956662, 0.03133844, 0.02841418, 0.05882077, 0.03911506,\n",
       "       0.01570129, 0.05334627, 0.03734942, 0.05917521, 0.04017762,\n",
       "       0.03722735, 0.0487099 , 0.04183091, 0.03963765, 0.0420479 ,\n",
       "       0.04516809, 0.04795982, 0.04286966, 0.05817571, 0.04632949,\n",
       "       0.04989766, 0.06223575, 0.04001621, 0.03295584, 0.03740323,\n",
       "       0.03808199, 0.05160694, 0.0491569 , 0.04337936, 0.048905  ,\n",
       "       0.04065185, 0.04902779, 0.04377836, 0.04476486, 0.03879192,\n",
       "       0.03586128, 0.04934675, 0.0444076 , 0.03212309, 0.04081418,\n",
       "       0.03653471, 0.04613219, 0.05204809, 0.04459298, 0.02870271,\n",
       "       0.04963794, 0.03938055, 0.03699584, 0.03089659, 0.03601137,\n",
       "       0.05182813, 0.04269172, 0.05679964, 0.04807729, 0.03759655,\n",
       "       0.03311763, 0.04822993, 0.06901485, 0.03831674, 0.05005316,\n",
       "       0.03735617, 0.03801285, 0.0400143 , 0.03984103, 0.03762729,\n",
       "       0.04846573, 0.05011744, 0.04316266, 0.04659165, 0.03932131,\n",
       "       0.04832724, 0.05914959, 0.04246675, 0.05139846, 0.0508204 ,\n",
       "       0.04245749, 0.03920192, 0.04374741, 0.04440278, 0.07043009,\n",
       "       0.04326815, 0.04529073, 0.03765638, 0.0441573 , 0.03938232,\n",
       "       0.01724157, 0.03735636, 0.03937669, 0.04155016, 0.02828331,\n",
       "       0.04484601, 0.05684888, 0.02101439, 0.04529534, 0.06719849,\n",
       "       0.00785868, 0.04776655, 0.04360517, 0.03004374, 0.03659462,\n",
       "       0.04283959, 0.03819267, 0.03446211, 0.04613439, 0.05960507,\n",
       "       0.04953236, 0.04579959, 0.05572011, 0.08103574, 0.04239484,\n",
       "       0.0478289 , 0.03910539, 0.03254723, 0.051312  , 0.04611661,\n",
       "       0.06050571, 0.0377232 , 0.03930637, 0.03020538, 0.05295208,\n",
       "       0.04577718, 0.04675239, 0.05126189, 0.0391922 , 0.04722361,\n",
       "       0.05681045, 0.0632087 , 0.04919884, 0.05349575, 0.03658286,\n",
       "       0.03607224, 0.0319424 , 0.03775658, 0.05663596, 0.05217598,\n",
       "       0.05512119, 0.04675249, 0.05234021, 0.02559543, 0.03197379,\n",
       "       0.03413805, 0.05056763, 0.03869798, 0.03434749, 0.04637082,\n",
       "       0.04871831, 0.04047071, 0.03855848, 0.03460875, 0.03146775,\n",
       "       0.05392698, 0.03979561, 0.03449735, 0.03743624, 0.0364854 ,\n",
       "       0.0420774 , 0.04710102, 0.03939492, 0.07279739, 0.03991805,\n",
       "       0.06620637, 0.03318482, 0.03911456, 0.06113617, 0.03583329,\n",
       "       0.05212792, 0.00909505, 0.01897203, 0.03747234, 0.04254362,\n",
       "       0.05099336, 0.03262505, 0.03730283, 0.03660676, 0.06245321,\n",
       "       0.04067576, 0.0513083 , 0.04261226, 0.05343415, 0.03869383,\n",
       "       0.04666749, 0.0410488 , 0.04059319, 0.05083061, 0.05239444,\n",
       "       0.03725563, 0.0416708 , 0.02188714, 0.04207311, 0.04458124,\n",
       "       0.03172497, 0.03064107, 0.04012884, 0.0435473 , 0.02927088,\n",
       "       0.03498768, 0.03759187, 0.05255836, 0.02694392, 0.02856888,\n",
       "       0.04275145, 0.04285615, 0.03719417, 0.01546929, 0.04376385,\n",
       "       0.04912224, 0.05249702, 0.030741  , 0.04435243, 0.03981445,\n",
       "       0.0488332 , 0.04108545, 0.04184182, 0.05161147, 0.03938922,\n",
       "       0.04480792, 0.04779361, 0.04829352, 0.03413004, 0.04666568,\n",
       "       0.05765747, 0.04353295, 0.03942567, 0.04229992, 0.03991237,\n",
       "       0.04353385, 0.04595402, 0.05245533, 0.06009521, 0.02747586,\n",
       "       0.02660296, 0.04335519, 0.03618021, 0.04261728, 0.07055166,\n",
       "       0.04877911, 0.05935969, 0.06776973, 0.03014638, 0.06124297,\n",
       "       0.03810485, 0.05287892, 0.05246849, 0.03665496, 0.0514911 ,\n",
       "       0.04859405, 0.0357625 , 0.05218095, 0.04716004, 0.04407423,\n",
       "       0.04240528, 0.0384133 , 0.0276382 , 0.03420068, 0.04132637,\n",
       "       0.04130692, 0.06216715, 0.04646367, 0.03099644, 0.04031827,\n",
       "       0.0433968 , 0.04563094, 0.04900436, 0.04065592, 0.04600475,\n",
       "       0.03992416, 0.04139792, 0.04306282, 0.0426866 , 0.05377676,\n",
       "       0.04957552, 0.04282311, 0.0593105 , 0.04953005, 0.04462589,\n",
       "       0.05209666, 0.04784837, 0.04749036, 0.04169641, 0.03935406,\n",
       "       0.03148273, 0.0292948 , 0.03290548, 0.03081997, 0.04000999,\n",
       "       0.03713587, 0.04765454, 0.03433583, 0.0277455 , 0.04272005,\n",
       "       0.03749274, 0.01784158, 0.04547046, 0.0454343 , 0.0381241 ,\n",
       "       0.04488645, 0.0302513 , 0.04575409, 0.04263332, 0.04567531,\n",
       "       0.07201058, 0.04110647, 0.04458228, 0.05615763, 0.03986882,\n",
       "       0.04677866, 0.03729148, 0.03993796, 0.03930625, 0.05375721,\n",
       "       0.04512943, 0.0502216 , 0.0370604 , 0.05051342, 0.043832  ,\n",
       "       0.04091546, 0.0488181 , 0.04731522, 0.05351252, 0.04101642,\n",
       "       0.06737964, 0.03662672, 0.06605085, 0.03913338, 0.04276843,\n",
       "       0.03077391, 0.02763186, 0.04508662, 0.04627687, 0.04350668,\n",
       "       0.03212296, 0.03580047, 0.04155901, 0.06370017, 0.06135947,\n",
       "       0.05175262, 0.03688934, 0.04580327, 0.04490193, 0.0435379 ,\n",
       "       0.04474186, 0.03925879, 0.03720258, 0.06179819, 0.03544012,\n",
       "       0.05358851, 0.04013669, 0.0515479 , 0.04348711, 0.05909012,\n",
       "       0.05236348, 0.04427191, 0.03218457, 0.04462882, 0.04067846,\n",
       "       0.04115688, 0.0473131 , 0.04852907, 0.05232359, 0.04305536,\n",
       "       0.04975556, 0.0515929 , 0.05626136, 0.03924873, 0.02953034,\n",
       "       0.04186771, 0.06266486, 0.0329607 , 0.0326166 , 0.04566088,\n",
       "       0.03255178, 0.05521293, 0.04981787, 0.01767337, 0.0505938 ,\n",
       "       0.0427512 , 0.0383315 , 0.04246178, 0.04451006, 0.04170784,\n",
       "       0.04483588, 0.05869438, 0.02208606, 0.04019042, 0.07423872,\n",
       "       0.03747218, 0.06630869, 0.04457509, 0.03722416, 0.04440615,\n",
       "       0.02937616, 0.01594665, 0.06227311, 0.05477206, 0.02566287,\n",
       "       0.04144973, 0.05330642, 0.04925497, 0.0083856 , 0.06281556,\n",
       "       0.026724  , 0.04038114, 0.05707906, 0.04809815, 0.0438485 ,\n",
       "       0.04062607, 0.05219135, 0.04211576, 0.03868686, 0.04587659,\n",
       "       0.05822401, 0.05003511, 0.05675057, 0.04219415, 0.05703018,\n",
       "       0.04310456, 0.04202121, 0.0387982 , 0.01830204, 0.07487979,\n",
       "       0.03625273, 0.04076526, 0.04786075, 0.03864377, 0.0316664 ,\n",
       "       0.04531031, 0.05207087, 0.04461835, 0.0414838 , 0.03798683,\n",
       "       0.04492886, 0.04319296, 0.01454918, 0.0674394 , 0.03927596,\n",
       "       0.04223438, 0.03697844, 0.04586577, 0.06195136, 0.0375639 ,\n",
       "       0.05623294, 0.05637901, 0.05116555, 0.04249465, 0.04175164,\n",
       "       0.04177836, 0.04401038, 0.05125599, 0.04363798, 0.04488043,\n",
       "       0.0354461 , 0.0502258 , 0.03325381, 0.06194891, 0.04361294,\n",
       "       0.04793674, 0.03304671, 0.04730592, 0.04986428, 0.04312812,\n",
       "       0.04228811, 0.04614924, 0.07385568, 0.04078123, 0.05538186,\n",
       "       0.0466128 , 0.05417765, 0.06136123, 0.05777773, 0.04320841,\n",
       "       0.0390791 , 0.03683809, 0.04249642, 0.03677712, 0.04103402,\n",
       "       0.03523289, 0.03799768, 0.03447225, 0.03944195, 0.04412178,\n",
       "       0.05269638, 0.06503177, 0.03954517, 0.06083582, 0.04179038,\n",
       "       0.03806328, 0.06386146, 0.04112491, 0.0315623 , 0.06591168,\n",
       "       0.03369149, 0.04154384, 0.04696532, 0.03912373, 0.0422404 ,\n",
       "       0.04908294, 0.04998066, 0.04156994, 0.03341593, 0.02907764,\n",
       "       0.06051515, 0.04634394, 0.05049663, 0.0365489 , 0.04277272,\n",
       "       0.0234484 , 0.05364086, 0.03429641, 0.01467825, 0.04606941,\n",
       "       0.02708082, 0.04125452, 0.06629837, 0.04426799, 0.04452875,\n",
       "       0.04056318, 0.05406957, 0.04711315, 0.03340158, 0.0308817 ,\n",
       "       0.05007011, 0.0412897 , 0.0628581 , 0.02801358, 0.04091408,\n",
       "       0.0463423 , 0.02876052, 0.03848444, 0.0427662 , 0.04813664,\n",
       "       0.03248874, 0.04402324, 0.06565332, 0.06107773, 0.04572601,\n",
       "       0.03911167, 0.02988927, 0.0439564 , 0.01421903, 0.04449343,\n",
       "       0.03843656, 0.03675603, 0.04277168, 0.03808434, 0.03302428,\n",
       "       0.04509344, 0.02819183, 0.04512571, 0.06677135, 0.0513861 ,\n",
       "       0.06597431, 0.03706232, 0.04766389, 0.05875278, 0.04985196,\n",
       "       0.06338655, 0.05396913, 0.04378147, 0.05825808, 0.05275422,\n",
       "       0.04775405, 0.06275615, 0.05154007, 0.04484907, 0.06624148,\n",
       "       0.01763078, 0.0381368 , 0.04106071, 0.05132953, 0.05279565,\n",
       "       0.05026697, 0.04257726, 0.04233714, 0.04048957, 0.02463468,\n",
       "       0.04597154, 0.04659113, 0.04622385, 0.05537616, 0.04542978],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_pred=np.mean(pred,axis=0)\n",
    "mc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(mc_pred, \"../pred_loss_MC_Xx.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
