{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "\n",
    "def pass_arg(nsim, tr_size):\n",
    "    print(\"Tr_size:\", tr_size)\n",
    "    def fix_seeds(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    #     K.set_session(sess)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    ss = 1\n",
    "    fix_seeds(ss)\n",
    "\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # def save_obj(obj, name):\n",
    "    #     with open(name, 'wb') as f:\n",
    "    #         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "    # # Making sure dimensionless bond length is less than 1\n",
    "    # def bond(bl):\n",
    "    #     return bl-1.0\n",
    "\n",
    "    # Making sure dimensionless bond length is less than 1\n",
    "    def bond(bl):\n",
    "        bln = -bl*(bl<0)\n",
    "        blp = bl*(bl>=1.0) - 1*(bl>=1.0)\n",
    "        return bln+blp\n",
    "\n",
    "    # # Making sure final porosity is less than initial\n",
    "    # def poros(poroi, porof):\n",
    "    # #     porof[porof < 0] = 1-porof[porof < 0]\n",
    "    #     porof[porof < 0] = poroi[0]-porof[porof < 0]\n",
    "    #     print(porof)\n",
    "    #     return porof-poroi\n",
    "\n",
    "    # Making sure final porosity is less than initial\n",
    "    def poros(poroi, porof):\n",
    "        porofn = -porof*(porof<0)\n",
    "        porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "        return porofp+porofn\n",
    "\n",
    "    def strength1(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        corr_bl_sorted = np.sort(bl, axis=-1)  # sorts along first axis (down)\n",
    "        return corr_bl_sorted-bl_sorted\n",
    "\n",
    "    def strength2(bl, porof, nlayer=6):\n",
    "        sigma01, sigma02 = 6, 31\n",
    "        C1s = 21\n",
    "        sigma_long = sigma01*(np.exp((1.0-porof)**(C1s*nlayer))-porof) + sigma02*(1.0-porof)\n",
    "        sigma_long_sorted = np.sort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        ind = np.argsort(sigma_long, axis=-1)  # sorts along first axis (down)\n",
    "        bl_sorted = np.take_along_axis(bl, ind, axis=-1)  # same as np.sort(x, axis=0)\n",
    "        return sum(bl_sorted[1:]-bl_sorted[:-1]<0)/14\n",
    "\n",
    "    def phy_loss_mean(params):\n",
    "        # useful for cross-checking training\n",
    "        loss1, loss2, loss3, loss4, lam1, lam2 = params\n",
    "        x1, x2, x3 = loss1*(loss1>0), loss2*(loss2>0), loss3*(loss3>0)\n",
    "\n",
    "        if x1.any() and x1.shape[0]>1:\n",
    "            X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "            x1 = X_scaled1\n",
    "        if x2.any() and x2.shape[0]>1:\n",
    "            X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "            x2 = X_scaled2\n",
    "        if x3.any() and x3.shape[0]>1:\n",
    "            X_scaled3 = (x3 - np.min(x3)) / (np.max(x3) - np.min(x3))\n",
    "            x3 = X_scaled3\n",
    "        return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3))\n",
    "    #     return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3) + lam2*loss4)\n",
    "\n",
    "    def PGNN_train_test(optimizer_name, optimizer_val, pre_train, tr_size, lamda, iteration, n_nodes, n_layers, drop_frac, reg, samp):\n",
    "\n",
    "        # Hyper-parameters of the training process\n",
    "    #     batch_size = int(tr_size/2)\n",
    "        batch_size = 1\n",
    "        num_epochs = 50\n",
    "        val_frac = 0.2\n",
    "        patience_val = 50\n",
    "\n",
    "        # Initializing results filename\n",
    "        exp_name = \"DNN_pre_hyb_\" + pre_train + optimizer_name + '_trsize' + str(tr_size) + '_lamda' + str(lamda) + '_iter' + str(iteration)\n",
    "        exp_name = exp_name.replace('.','pt')\n",
    "        results_dir = '../results/'\n",
    "        model_name = results_dir + exp_name + '_NoPhyInfomodel.h5' # storing the trained model\n",
    "        if reg==True and samp==25:\n",
    "            results_name = results_dir + exp_name + '_results_25_regularizer.dat' # storing the results of the model\n",
    "        elif reg==False and samp==25:\n",
    "            results_name = results_dir + exp_name + '_results_25.dat' # storing the results of the model\n",
    "        elif reg==True and samp==1519:\n",
    "            results_name = results_dir + exp_name + '_results_1519_regularizer.dat' # storing the results of the model\n",
    "        elif reg==False and samp==1519:\n",
    "            results_name = results_dir + exp_name + '_results_1519.dat' # storing the results of the model\n",
    "        \n",
    "        # Load labeled data\n",
    "        data = np.loadtxt('../data/labeled_data.dat')\n",
    "        x_label = data[:, :-3] # -2 because we do not need porosity predictions\n",
    "        x_labeled = np.hstack((x_label[:,:2],x_label[:,-2:]))\n",
    "        y_labeled = data[:, -3:-1]\n",
    "\n",
    "#         if samp==25:\n",
    "#             data2 = np.loadtxt('../data/unlabeled_data_BK_constw_v2_25.dat')\n",
    "#             x_unlabeled = data2[:, :]\n",
    "#         elif samp==1519:\n",
    "#             data2 = np.loadtxt('../data/unlabeled_data_BK_constw_v2_1525.dat')\n",
    "\n",
    "#         data1 = data2[:1303, :]\n",
    "#         data2 = data2[-6:, :]\n",
    "#         datah = np.vstack((data1,data2))\n",
    "# #         np.random.shuffle(datah)\n",
    "#         x_labeled = np.hstack((datah[:, :2],datah[:,-3:-1]))\n",
    "# #         x_unlabeled = datah[:, :2] # 1303 last regular sample\n",
    "#         y_unlabeled = datah[:, -3:-1]\n",
    "        \n",
    "        # normalize dataset with MinMaxScaler\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "        x_labeled = scaler.fit_transform(x_labeled)\n",
    "#         y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "        # train and test data\n",
    "        trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "    #     testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "    #     init_poro = data[tr_size:, -1]\n",
    "        testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "        init_poro = data[tr_size:, -1]\n",
    "\n",
    "        dependencies = {\n",
    "         'root_mean_squared_error': root_mean_squared_error\n",
    "            }\n",
    "\n",
    "        # load the pre-trained model using non-calibrated physics-based model predictions (./data/unlabeled.dat)\n",
    "        loaded_model = load_model(results_dir + pre_train, custom_objects=dependencies)\n",
    "    \n",
    "        # Creating the model\n",
    "        model = Sequential()\n",
    "        for layer in np.arange(n_layers):\n",
    "            if layer == 0:\n",
    "                model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "            else:\n",
    "                if reg:\n",
    "                    model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.001, l2=.001)))\n",
    "                else:\n",
    "                    model.add(Dense(n_nodes, activation='relu'))\n",
    "            model.add(Dropout(rate=drop_frac))\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "\n",
    "        # pass the weights to all layers but 1st input layer, whose dimensions are updated\n",
    "        for new_layer, layer in zip(model.layers[1:], loaded_model.layers[1:]):\n",
    "            new_layer.set_weights(layer.get_weights())\n",
    "\t\t\t\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizer_val,\n",
    "                      metrics=[root_mean_squared_error])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "\n",
    "        print('Running...' + optimizer_name)\n",
    "        history = model.fit(trainX, trainY,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=num_epochs,\n",
    "                            verbose=0,\n",
    "                            validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "\n",
    "        test_score = model.evaluate(testX, testY, verbose=1)\n",
    "        print(test_score)\n",
    "        # predictions = model.predict(testX)\n",
    "    # #     inv_pred = scaler.inverse_transform(predictions)\n",
    "        # phyloss1 = bond(predictions[:,0]) # physics loss 1\n",
    "\n",
    "    # #     init_poro_ndim = np.ones((init_poro.shape))\n",
    "    # #     diff2 = poros(init_poro_ndim, predictions[:,1]) # physics loss 2\n",
    "\n",
    "        # phyloss2 = poros(init_poro, predictions[:,1]) # physics loss 2\n",
    "        # phyloss3 = strength1(predictions[:,0], predictions[:,1])\n",
    "        # phyloss4 = strength2(predictions[:,0], predictions[:,1])\n",
    "\n",
    "        # lam1, lam2 = lamda[0], lamda[1]    \n",
    "        # phyloss = phy_loss_mean([phyloss1, phyloss2, phyloss3, phyloss4, lam1, lam2])\n",
    "\n",
    "        # print('iter: ' + str(iteration) + \n",
    "              # ' nL: ' + str(n_layers) + ' nN: ' + str(n_nodes) + \n",
    "              # ' trsize: ' + str(tr_size) + \n",
    "              # ' TestRMSE: ' + str(test_score[1]) + ' PhyLoss: ' + str(phyloss), \"\\n\")\n",
    "\n",
    "    # #     model.save(model_name)\n",
    "\n",
    "        # # save results\n",
    "        # results = {'train_rmse':history.history['root_mean_squared_error'], \n",
    "                                    # 'val_rmse':history.history['val_root_mean_squared_error'],\n",
    "                                    # 'test_rmse':test_score[1], 'PhyLoss':phyloss}\n",
    "\n",
    "    #     save_obj(results, results_name)\n",
    "\n",
    "        # return results, results_name, predictions, testY, test_score[1]\n",
    "        # predictions = model.predict(Xx)\n",
    "\n",
    "        Xx = np.random.uniform(0,1,(1000,2))\n",
    "        xx1 = np.ones((1000,2))\n",
    "        Xx = np.hstack((Xx,xx1))\n",
    "        \n",
    "        samples = []\n",
    "        for i in range(int(nsim)):\n",
    "            print(\"simulation num:\",i)\n",
    "            predictions = model.predict(Xx)\n",
    "            predictions = predictions[:,1]\n",
    "            samples.append(predictions[:,np.newaxis])\n",
    "        return np.array(samples)\n",
    "\n",
    "\n",
    "\n",
    "    # Main Function\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        fix_seeds(1)\n",
    "\n",
    "        # List of optimizers to choose from    \n",
    "        optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "        optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "\n",
    "        # selecting the optimizer\n",
    "        optimizer_num = 1\n",
    "        optimizer_name = optimizer_names[optimizer_num]\n",
    "        optimizer_val = optimizer_vals[optimizer_num]\n",
    "\n",
    "        # Selecting Other Hyper-parameters\n",
    "        drop_frac = 0.1 # Fraction of nodes to be dropped out\n",
    "        n_layers = 2 # Number of hidden layers\n",
    "        n_nodes = 5 # Number of nodes per hidden layer\n",
    "\n",
    "        # # Iterating over different training fractions and splitting indices for train-test splits\n",
    "        # trsize_range = [4,6,8,10,20]\n",
    "\n",
    "        # #default training size = 5000\n",
    "        # tr_size = trsize_range[4]\n",
    "\n",
    "        # pre-trained model\n",
    "        pre_train = 'Pre-trainAdadelta_drop0_nL2_nN5_trsize1308_iter0.h5'\n",
    "\n",
    "        tr_size = int(tr_size)\n",
    "\n",
    "        # use regularizer\n",
    "        reg = True\n",
    "\n",
    "        # sample size used\n",
    "        samp = 1519\n",
    "\n",
    "        #set lamda=0 for pgnn0\n",
    "        lamda = [1, 1] # Physics-based regularization constant\n",
    "\n",
    "        # total number of runs\n",
    "        iter_range = np.arange(1)\n",
    "        testrmse=[]\n",
    "        # iterating through all possible params\n",
    "        for iteration in iter_range:\n",
    "            # results, result_file, pred, obs, rmse = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            # iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "            # testrmse.append(rmse)\n",
    "            pred = PGNN_train_test(optimizer_name, optimizer_val, \n",
    "                                               pre_train, tr_size, lamda, iteration, n_nodes, n_layers, drop_frac, reg, samp)\n",
    "    \n",
    "    return np.squeeze(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 20\n",
      "Running...Adadelta\n",
      "19/19 [==============================] - 0s 0us/step\n",
      "[0.02160559594631195, 0.11348665505647659]\n",
      "simulation num: 0\n"
     ]
    }
   ],
   "source": [
    "pred = pass_arg(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.98468089e-02,  4.71867733e-02,  6.73395544e-02,  1.06227212e-02,\n",
       "        4.24931943e-03,  9.02877599e-02, -1.28245391e-02, -1.42458007e-02,\n",
       "        5.53922467e-02,  5.04063331e-02,  1.10124685e-02, -1.87949017e-02,\n",
       "       -1.11572854e-02,  7.99391419e-04, -1.52710229e-02,  4.18467857e-02,\n",
       "       -1.73114240e-04, -2.87033990e-02, -2.96762958e-03,  8.72713625e-02,\n",
       "        1.69321410e-02, -2.64240056e-03,  5.90089373e-02, -2.88954750e-03,\n",
       "        5.75652532e-02,  4.39595468e-02,  3.54594551e-02, -2.10014060e-02,\n",
       "       -2.45845728e-02,  7.97037333e-02,  1.16365775e-03,  2.79115923e-02,\n",
       "        1.18233524e-02, -2.58512795e-03,  1.90151110e-03,  5.21534421e-02,\n",
       "       -1.29869655e-02, -5.50975278e-03,  3.73375379e-02,  2.45133825e-02,\n",
       "        7.20491558e-02,  3.96171696e-02,  7.52684176e-02,  5.18177487e-02,\n",
       "        5.40693067e-02,  3.84103507e-04,  5.30516841e-02,  7.03634471e-02,\n",
       "        1.64955966e-02,  4.92783897e-02, -4.14467230e-02, -7.84793496e-03,\n",
       "        3.72287631e-03,  1.79085471e-02,  5.26125841e-02,  8.52705538e-02,\n",
       "       -2.51210872e-02,  3.14013623e-02,  2.70618759e-02, -3.40137258e-03,\n",
       "        6.83475286e-02, -7.05733150e-03,  5.33794798e-02,  4.07299586e-02,\n",
       "        1.88895129e-02,  5.02606817e-02, -4.29170132e-02,  5.07749245e-03,\n",
       "        2.86860652e-02,  5.10823540e-02,  8.59246030e-03, -3.37035656e-02,\n",
       "        7.83527195e-02,  8.83931220e-02,  2.04332583e-02, -1.68960728e-02,\n",
       "       -2.92590316e-02,  2.37436481e-02,  7.69082159e-02, -2.55423393e-02,\n",
       "       -3.35257575e-02,  7.59486556e-02,  4.34411131e-02,  4.91828360e-02,\n",
       "        5.33918701e-02,  8.57906938e-02,  5.92181496e-02,  8.22351724e-02,\n",
       "        7.38641024e-02, -1.37502328e-02,  4.67595495e-02, -2.50609592e-03,\n",
       "        3.94276641e-02,  8.77527744e-02,  7.65685439e-02,  2.34973244e-02,\n",
       "        6.05372004e-02,  5.17813377e-02,  3.61207239e-02, -1.04005933e-02,\n",
       "        6.08966611e-02, -3.08557972e-02,  3.05768289e-02,  4.61841561e-02,\n",
       "        5.15567511e-03,  4.08958532e-02,  5.70977442e-02, -2.21316740e-02,\n",
       "        7.44799823e-02, -1.77510828e-02, -2.70247608e-02,  9.15731192e-02,\n",
       "        1.67524628e-02,  3.08940150e-02,  1.57080702e-02,  1.47661194e-03,\n",
       "        3.24219726e-02,  4.67239507e-02,  2.75563709e-02,  6.58521503e-02,\n",
       "       -2.77806707e-02,  6.11663572e-02,  1.08299643e-01,  2.84396373e-02,\n",
       "        8.07098597e-02, -1.12707317e-02,  4.70149703e-02,  5.67224063e-02,\n",
       "        9.65118259e-02, -4.97572869e-03,  4.54538129e-02,  1.38217695e-02,\n",
       "       -2.37481203e-02,  1.29701756e-02,  8.10542852e-02,  4.17193361e-02,\n",
       "        7.74463415e-02, -6.40870258e-03,  5.35250716e-02,  6.58663362e-03,\n",
       "        8.16768408e-02,  7.50463456e-03, -1.56856924e-02, -8.55157524e-03,\n",
       "       -4.75510359e-02,  6.72130585e-02, -6.79943338e-03,  3.99727710e-02,\n",
       "       -2.02136487e-03,  1.04632378e-01,  4.74144258e-02, -2.64251754e-02,\n",
       "        3.53175886e-02, -5.17166778e-03,  1.83208473e-02, -2.83606220e-02,\n",
       "       -2.84104906e-02, -1.16911270e-02, -2.11554989e-02, -1.51227564e-02,\n",
       "        6.38287514e-02,  1.13306008e-02,  4.40571047e-02,  2.64312811e-02,\n",
       "        3.12948935e-02, -1.23827271e-02,  3.34762782e-03,  6.95589781e-02,\n",
       "        8.34311098e-02, -1.03627257e-02,  6.28238320e-02,  1.86459385e-02,\n",
       "        3.99492867e-02,  3.96002345e-02, -2.12182775e-02,  3.14851590e-02,\n",
       "        3.21308635e-02, -7.79165700e-03,  1.01714358e-01,  2.44341977e-02,\n",
       "        6.20615594e-02,  9.15886164e-02,  5.99242188e-02, -3.51181850e-02,\n",
       "        4.09628339e-02,  6.17972873e-02,  7.35952258e-02, -4.64715213e-02,\n",
       "        6.30527884e-02,  1.60550587e-02,  4.37593050e-02,  6.71175420e-02,\n",
       "       -5.00304252e-03,  2.14362256e-02,  2.75701024e-02, -3.19804624e-02,\n",
       "        8.19659531e-02,  3.16105969e-02,  6.56154454e-02,  7.17192888e-05,\n",
       "       -3.46153602e-02,  6.16827123e-02,  4.66568060e-02,  3.52920331e-02,\n",
       "       -4.54143994e-02, -4.65410352e-02, -1.11841410e-03,  2.43671648e-02,\n",
       "        5.96577190e-02,  7.03156441e-02,  1.78519078e-02,  8.78107101e-02,\n",
       "       -4.04036641e-02,  1.01753309e-01,  6.24668188e-02, -2.62762997e-02,\n",
       "        3.61476839e-03,  3.72037329e-02,  2.30790190e-02,  2.30568089e-02,\n",
       "        8.04464146e-03,  3.51022296e-02, -5.60276210e-04,  6.54991865e-02,\n",
       "       -2.41585709e-02,  5.66131882e-02,  9.80120599e-02,  2.27127038e-02,\n",
       "       -7.58200511e-03, -4.52704802e-02,  1.01018026e-01, -4.52771783e-04,\n",
       "       -1.91054493e-03,  4.50835861e-02,  2.35052742e-02,  7.34307766e-02,\n",
       "        4.07423414e-02,  9.93881002e-03,  6.34915829e-02,  4.65191491e-02,\n",
       "       -1.15482546e-02,  1.12182394e-01,  6.87210262e-02,  1.26636587e-02,\n",
       "        2.22866051e-02,  3.85964178e-02, -2.92654075e-02, -9.79228690e-03,\n",
       "        6.05804287e-02,  2.85941921e-02,  1.06492937e-01, -3.42513248e-02,\n",
       "        6.83455169e-03,  5.22878282e-02, -3.09218634e-02,  1.92195289e-02,\n",
       "        6.19657971e-02,  6.35497272e-05,  3.08653079e-02,  1.08500421e-01,\n",
       "        1.82795189e-02,  1.18970610e-02,  3.13943885e-02,  9.32165235e-02,\n",
       "        3.09114344e-02,  1.01426058e-02, -8.80543143e-03,  6.31887168e-02,\n",
       "        3.33052166e-02,  8.55678916e-02,  6.06649704e-02,  3.75815369e-02,\n",
       "        9.70383883e-02,  4.00260091e-04,  9.56400111e-03,  1.49175562e-02,\n",
       "       -2.67447457e-02,  3.32023576e-03,  2.11525746e-02,  5.11680581e-02,\n",
       "        6.57369941e-03,  1.64717175e-02,  1.10296458e-01,  7.53292143e-02,\n",
       "        8.61334428e-03,  9.18735564e-02,  4.72690538e-03,  5.91874011e-02,\n",
       "        3.65729295e-02,  1.65700354e-02,  4.98737805e-02,  7.20596462e-02,\n",
       "        6.41442984e-02,  4.76387255e-02,  2.09955834e-02,  4.34595235e-02,\n",
       "       -5.23441657e-03,  5.81472628e-02,  8.11041147e-03,  2.26198472e-02,\n",
       "        5.05543910e-02,  5.98507747e-03,  5.88341169e-02,  9.11387354e-02,\n",
       "        2.69271396e-02,  9.41880941e-02,  4.10958342e-02,  4.45780270e-02,\n",
       "        6.96866214e-03,  4.42568846e-02,  4.51962911e-02,  2.91916244e-02,\n",
       "       -1.27699487e-02,  8.91584158e-02,  4.31270413e-02,  7.28747845e-02,\n",
       "       -3.95198278e-02,  8.53372216e-02,  1.06994994e-02,  6.57812357e-02,\n",
       "        8.34949017e-02,  3.78205590e-02,  2.57282518e-02,  6.16352670e-02,\n",
       "        9.42820460e-02,  8.20281953e-02, -1.18682683e-02, -3.34556028e-03,\n",
       "        7.31104612e-02, -1.93039887e-02,  2.48696990e-02,  5.88452257e-02,\n",
       "        7.30039552e-03,  2.62990929e-02, -4.34234738e-03, -1.41909719e-03,\n",
       "        6.06689565e-02,  5.81875108e-02,  4.52576540e-02,  1.31214447e-02,\n",
       "       -3.31473202e-02,  8.23342800e-02,  1.00304857e-01,  5.04325964e-02,\n",
       "       -4.48155031e-03, -3.02634388e-03,  1.25993527e-02,  7.68329799e-02,\n",
       "        4.89256568e-02,  4.63724099e-02,  3.36044393e-02,  2.80876122e-02,\n",
       "       -1.60595700e-02,  7.75785595e-02,  8.52369517e-02,  7.33808875e-02,\n",
       "        7.50019699e-02,  3.08652855e-02,  2.04992183e-02,  5.88836558e-02,\n",
       "        5.30104823e-02,  7.61252493e-02,  9.38213170e-02,  5.96068613e-02,\n",
       "        5.78923635e-02,  8.69898200e-02,  1.12260245e-02,  1.04623601e-01,\n",
       "        7.72532076e-04,  1.01496190e-01, -2.96497419e-02,  1.44129731e-02,\n",
       "        3.07506211e-02, -2.62390301e-02,  6.26456439e-02,  2.28689201e-02,\n",
       "        6.04198128e-03,  2.79429182e-03,  7.64804333e-03, -2.84748673e-02,\n",
       "       -2.11842358e-04,  5.85101359e-02,  5.13096340e-02, -2.53729876e-02,\n",
       "        4.78080176e-02, -3.89465690e-03,  8.72101486e-02, -4.81073521e-02,\n",
       "        2.01183073e-02,  1.90273635e-02, -2.15527900e-02,  6.52666241e-02,\n",
       "        5.00453636e-03,  8.54853988e-02,  6.03814423e-03,  3.72736119e-02,\n",
       "        8.73468369e-02,  5.91368228e-03,  2.18501352e-02, -3.42415087e-02,\n",
       "       -1.56412795e-02,  7.78589994e-02,  1.03533000e-01,  3.09033059e-02,\n",
       "        2.20502913e-03, -1.87910497e-02,  1.52194612e-02,  4.85895239e-02,\n",
       "        1.83672346e-02,  1.23483129e-02, -2.78818440e-02,  3.82271297e-02,\n",
       "       -1.70735791e-02,  1.07529774e-01,  3.60939465e-02, -3.17919590e-02,\n",
       "        4.89963703e-02,  2.92645358e-02,  4.09938022e-03,  3.22711207e-02,\n",
       "        2.08620988e-02,  8.80408585e-02,  9.33509618e-02,  1.76808611e-03,\n",
       "        3.17413472e-02,  1.00762278e-01,  7.34811574e-02,  3.49450521e-02,\n",
       "       -2.26790830e-03,  6.20479994e-02,  3.23895253e-02, -3.86681408e-02,\n",
       "        5.68655692e-02,  6.61156923e-02,  5.35319410e-02, -2.20027156e-02,\n",
       "       -2.41419747e-02,  1.51462816e-02,  4.38448600e-02,  7.14538991e-02,\n",
       "        6.47632331e-02,  4.81510498e-02,  8.05481151e-03,  3.54436822e-02,\n",
       "        5.91626652e-02,  8.50552768e-02,  7.69138187e-02, -2.16163024e-02,\n",
       "       -1.32693425e-02,  7.79057145e-02, -1.73934922e-03, -2.70291138e-02,\n",
       "        7.56185651e-02, -4.46220599e-02,  6.67876303e-02,  3.31126638e-02,\n",
       "        5.90338893e-02, -3.47430483e-02,  7.22116679e-02,  1.87317766e-02,\n",
       "        3.77366580e-02,  4.03515436e-02,  5.25511689e-02,  6.69314563e-02,\n",
       "        9.44308788e-02,  5.52418567e-02,  5.97225875e-03,  1.71590708e-02,\n",
       "        8.90576541e-02,  4.65225913e-02,  7.09813535e-02,  1.75338276e-02,\n",
       "        6.18336983e-02, -5.64471632e-03,  2.95865051e-02,  3.57488729e-02,\n",
       "        6.83347285e-02,  4.89254706e-02,  3.29118930e-02, -1.04911625e-02,\n",
       "        2.81940363e-02,  4.30047177e-02,  7.68345445e-02,  1.07933395e-02,\n",
       "        9.08379108e-02, -1.82770900e-02,  4.30116802e-03,  7.28963912e-02,\n",
       "        7.28977174e-02,  3.12897153e-02,  4.19297703e-02,  5.14541902e-02,\n",
       "       -3.23766097e-03,  6.34201914e-02, -1.00323148e-02,  7.99661875e-03,\n",
       "        6.79346547e-03,  2.87847631e-02,  2.59537585e-02, -3.41931470e-02,\n",
       "        2.35687941e-04, -1.70042738e-02,  8.50449055e-02,  2.34728269e-02,\n",
       "        2.05587186e-02,  1.04051203e-01,  5.63871227e-02, -1.06776506e-03,\n",
       "        6.68338835e-02,  7.43650794e-02, -1.68770216e-02,  6.41316622e-02,\n",
       "        1.03325054e-01, -3.17853764e-02,  6.03087209e-02,  1.12412676e-01,\n",
       "       -2.08803937e-02, -2.05081068e-02,  9.11279321e-02,  3.84340174e-02,\n",
       "        3.04831304e-02,  2.30937190e-02,  9.42463726e-02,  7.65069425e-02,\n",
       "        4.61014621e-02,  1.20663382e-02,  6.54868782e-04,  1.89540908e-03,\n",
       "       -2.14302577e-02,  1.70471109e-02,  4.83172126e-02, -4.88838553e-03,\n",
       "        7.68623054e-02,  8.06564540e-02,  2.44273581e-02,  1.11306272e-02,\n",
       "       -5.77233732e-04,  1.42208971e-02,  9.64685678e-02,  2.24442668e-02,\n",
       "       -3.65453959e-02, -1.16112158e-02,  8.04134086e-03,  3.36574055e-02,\n",
       "        6.99785203e-02, -3.40999663e-03,  1.86810680e-02,  5.50570972e-02,\n",
       "        2.14585625e-02,  8.84620696e-02,  4.05308343e-02,  4.95798253e-02,\n",
       "        4.52333279e-02,  5.68966083e-02,  7.39848167e-02,  4.27121781e-02,\n",
       "        4.73025404e-02, -4.24789265e-02,  9.51303989e-02,  6.12242557e-02,\n",
       "        8.74782503e-02, -5.69753349e-03,  2.75927000e-02,  8.87601674e-02,\n",
       "        7.30439126e-02,  8.35130811e-02,  7.13063478e-02, -1.14459768e-02,\n",
       "        3.54778059e-02,  9.18951631e-02, -2.34931707e-02,  5.78341447e-02,\n",
       "        2.38103531e-02,  1.97662897e-02,  2.21496634e-02,  4.00502123e-02,\n",
       "        6.06495254e-02,  3.14163417e-03, -2.14816257e-02,  7.17802346e-03,\n",
       "        3.47213708e-02,  6.45949841e-02,  1.75919197e-02,  2.70682536e-02,\n",
       "        6.26670122e-02, -3.53366137e-04,  1.03549272e-01,  1.08049512e-01,\n",
       "        3.94764803e-02,  2.95278914e-02, -1.54565424e-02,  6.04677387e-02,\n",
       "        4.38425355e-02,  4.20219079e-03, -3.48690450e-02,  3.76663394e-02,\n",
       "       -1.30199753e-02, -1.08953565e-03,  7.44031817e-02,  5.68318740e-03,\n",
       "        4.86202650e-02, -1.04329064e-02,  8.46028030e-02,  3.82391997e-02,\n",
       "       -1.28250942e-03,  1.86594985e-02,  3.42730060e-03,  9.80258733e-02,\n",
       "        3.26878838e-02, -4.67083678e-02,  3.64789031e-02,  5.18100150e-02,\n",
       "        3.86962630e-02,  3.53242718e-02,  9.61305052e-02,  6.20474182e-02,\n",
       "        8.05199593e-02,  6.40023500e-02,  5.26067726e-02,  4.90147881e-02,\n",
       "        1.10966899e-02,  2.72693820e-02,  1.54431425e-02,  1.01238474e-01,\n",
       "        8.62518251e-02,  1.43306293e-02,  8.02152008e-02,  5.98819517e-02,\n",
       "        5.05611412e-02,  2.09998228e-02,  5.05216457e-02,  5.19521572e-02,\n",
       "       -6.25927374e-03,  8.17014873e-02,  2.12731771e-02,  7.83592165e-02,\n",
       "        2.59063952e-02,  5.46746366e-02,  3.99846323e-02,  3.21810655e-02,\n",
       "        2.49792263e-03, -3.51487473e-03, -2.04597116e-02, -9.94213670e-03,\n",
       "        2.96648033e-02, -4.34914082e-02,  5.01112007e-02,  4.31445874e-02,\n",
       "        6.23758845e-02,  9.56356376e-02,  6.80942237e-02, -1.29044205e-02,\n",
       "        4.45809253e-02,  6.48275316e-02, -2.38230042e-02, -3.91802900e-02,\n",
       "        5.43888696e-02,  2.64244936e-02,  8.81544650e-02,  6.61419034e-02,\n",
       "        6.12331443e-02,  7.73592442e-02,  3.90695818e-02,  2.38403566e-02,\n",
       "        7.55145550e-02,  6.15734942e-02,  5.90593107e-02,  6.77453876e-02,\n",
       "        2.62678526e-02, -1.95103362e-02,  3.54844891e-02, -9.65426490e-03,\n",
       "        9.90160555e-02,  6.32275641e-02, -4.27090749e-03,  6.80662841e-02,\n",
       "        1.96382441e-02,  7.26495981e-02,  1.06431581e-02,  2.99050175e-02,\n",
       "       -9.37651470e-03, -2.11565979e-02, -3.01503371e-02,  5.92860617e-02,\n",
       "       -4.31531407e-02,  1.76398940e-02,  1.30987056e-02,  3.52993868e-02,\n",
       "       -2.46388018e-02,  5.84881753e-03, -2.33529601e-02,  3.42068449e-03,\n",
       "        7.21658766e-03,  7.04660267e-02, -3.59588750e-02,  6.06470890e-02,\n",
       "        7.82792419e-02, -9.52411816e-03, -1.44642964e-03,  7.07924739e-03,\n",
       "        4.90281768e-02,  9.03617740e-02,  8.45784247e-02,  5.70050590e-02,\n",
       "        6.29758239e-02,  2.99537368e-02, -3.35608199e-02,  4.99944426e-02,\n",
       "        6.70733899e-02,  4.26841415e-02,  3.64523418e-02,  1.08508468e-01,\n",
       "        6.36731684e-02,  3.51738892e-02,  4.33455296e-02,  7.68056661e-02,\n",
       "        5.68837114e-02,  6.57586455e-02,  2.77629867e-03,  4.66776304e-02,\n",
       "        6.60437942e-02, -1.06226467e-02, -1.30397193e-02,  6.14397489e-02,\n",
       "        9.61067900e-03,  3.03057618e-02,  8.72355998e-02,  2.32224949e-02,\n",
       "        1.98892094e-02, -1.81065686e-02,  7.06758499e-02,  3.20395045e-02,\n",
       "        1.82012655e-02,  3.14560495e-02,  5.46237454e-03,  1.10782944e-02,\n",
       "        4.79919799e-02,  6.92613721e-02, -3.69313657e-02,  5.88452481e-02,\n",
       "       -3.12539265e-02,  2.74150558e-02,  3.91421206e-02,  1.41998120e-02,\n",
       "        8.03795457e-02,  6.55289590e-02,  9.13188756e-02, -2.97333933e-02,\n",
       "        6.99146986e-02, -5.22757322e-03,  6.14492856e-02,  9.35129076e-02,\n",
       "       -7.05800951e-04,  2.29098685e-02, -2.66320668e-02, -2.95327902e-02,\n",
       "        4.61563952e-02, -5.77325374e-03,  4.21193242e-03,  6.32795542e-02,\n",
       "        5.23068495e-02,  7.01138377e-03,  4.05902676e-02,  5.84500916e-02,\n",
       "        8.94769430e-02,  7.16564655e-02,  4.78755869e-02,  6.86264336e-02,\n",
       "       -3.19182873e-04,  3.84423882e-03,  7.01391101e-02,  8.70103538e-02,\n",
       "        2.29210593e-02, -4.81687263e-02,  5.33457473e-03, -7.73297250e-03,\n",
       "        6.31794482e-02,  7.40489811e-02, -1.78482682e-02, -3.70412171e-02,\n",
       "        1.79061256e-02,  5.48218451e-02,  1.27555095e-02,  7.91767389e-02,\n",
       "        6.47411793e-02,  1.54356472e-02,  5.90255372e-02,  5.84304072e-02,\n",
       "        6.62492663e-02,  8.73691216e-03,  5.64756952e-02,  3.58986072e-02,\n",
       "        7.18045533e-02,  1.04051039e-01,  4.64719348e-02,  1.30418129e-02,\n",
       "       -2.09160894e-03,  3.84027623e-02, -3.93885262e-02,  3.79135348e-02,\n",
       "        6.70187175e-03, -2.61385385e-02,  9.42804813e-02,  1.30131952e-02,\n",
       "       -1.75770037e-02,  5.64049520e-02,  3.29232030e-02,  4.10018489e-03,\n",
       "        1.79080032e-02,  1.56853981e-02,  5.71227930e-02,  9.94087905e-02,\n",
       "       -1.08107254e-02, -4.01376635e-02,  9.83817428e-02,  6.11692928e-02,\n",
       "        6.98413998e-02,  1.22195147e-02,  1.10350206e-01,  2.46524699e-02,\n",
       "        9.18563306e-02,  2.60274298e-02,  6.36126101e-02, -7.46143982e-03,\n",
       "       -6.58896565e-03,  1.05154924e-02,  7.31565654e-02, -1.02686547e-02,\n",
       "        3.12592424e-02,  1.29936375e-02,  4.01262976e-02, -1.14307925e-02,\n",
       "        7.05500841e-02,  9.62169096e-03,  3.69602405e-02, -4.29328233e-02,\n",
       "       -2.52402332e-02,  4.25661840e-02,  9.77216959e-02, -1.94593072e-02,\n",
       "        9.09398198e-02,  2.91513987e-02,  5.12360521e-02,  2.58825459e-02,\n",
       "        1.95244439e-02,  1.41145475e-02,  6.09936751e-02,  4.17050906e-02,\n",
       "        3.45514715e-03,  7.07545131e-02, -1.62536465e-02,  2.42588669e-03,\n",
       "        1.08287036e-01,  3.75749059e-02,  1.74538381e-02,  8.83228630e-02,\n",
       "        1.69929527e-02,  7.81694949e-02,  3.45818438e-02,  2.88014486e-03,\n",
       "        5.87753169e-02, -2.07671523e-02,  6.83048964e-02, -9.78334993e-03,\n",
       "       -6.47296384e-03,  4.18798886e-02,  1.28137358e-02,  8.39592516e-02,\n",
       "        6.63772225e-02, -3.24478969e-02,  8.32556039e-02,  8.31600130e-02,\n",
       "        3.74831371e-02,  6.08638190e-02, -1.21221505e-02,  4.97507267e-02,\n",
       "        2.57688500e-02,  1.63863935e-02,  7.68973231e-02, -6.72478229e-03,\n",
       "        1.12035908e-02,  4.85352613e-02, -2.90244222e-02, -1.84342265e-04,\n",
       "       -3.10557764e-02,  6.40318841e-02, -2.62193363e-02,  4.24675606e-02,\n",
       "       -1.86225250e-02, -1.85500085e-02,  9.76974145e-03,  8.56560171e-02,\n",
       "        6.96707517e-02,  9.19907838e-02,  3.74245979e-02,  3.05812545e-02,\n",
       "        2.87106149e-02,  9.17485803e-02,  2.03124546e-02, -4.66724373e-02,\n",
       "        5.41569255e-02,  6.27002567e-02, -1.65247358e-02,  9.56667587e-03,\n",
       "        1.65740587e-02,  5.80700524e-02, -1.44799091e-02,  6.03034459e-02,\n",
       "        7.37007111e-02,  6.78521693e-02,  2.66633667e-02, -1.09910928e-02,\n",
       "        3.19036432e-02,  4.61573042e-02,  5.88651113e-02,  8.19718391e-02,\n",
       "        6.00245185e-02, -1.05690211e-02,  1.32207461e-02,  4.49244566e-02,\n",
       "        1.06385313e-02, -4.40709665e-03,  6.75800890e-02,  4.10189666e-02,\n",
       "        7.41851628e-02,  1.03628069e-01,  7.09883422e-02,  6.71520084e-02,\n",
       "        9.90631580e-02, -3.61439995e-02,  9.16953534e-02,  1.07857920e-02,\n",
       "       -1.97706744e-02, -1.49257109e-03, -2.12282985e-02,  8.17075372e-02,\n",
       "        5.80790155e-02,  4.48577218e-02,  6.69772178e-03,  7.24302232e-02,\n",
       "        7.62848109e-02,  1.60472579e-02,  2.33133174e-02,  9.68970060e-02,\n",
       "        5.80569319e-02, -7.52713531e-03,  9.76064056e-02,  7.15692490e-02,\n",
       "        1.51425116e-02,  5.51413335e-02,  8.68687481e-02, -1.84478164e-02,\n",
       "       -3.03985327e-02,  3.45279612e-02, -1.24588907e-02,  8.18750262e-03,\n",
       "        5.91528453e-02,  4.33798619e-02,  1.00975618e-01,  1.37884505e-02,\n",
       "        1.28761344e-02,  2.15256251e-02, -3.51183787e-02,  3.98599766e-02,\n",
       "        6.48191422e-02, -2.63360124e-02,  6.49893135e-02, -4.58489358e-03,\n",
       "        6.08748458e-02,  7.93652236e-02,  2.70673148e-02,  2.82808356e-02,\n",
       "        6.36376739e-02,  4.55585755e-02,  7.66387582e-02, -2.28951089e-02,\n",
       "        3.76831181e-02, -8.83392990e-03,  5.84341623e-02,  7.53590316e-02,\n",
       "       -2.17295028e-02, -3.84286568e-02,  2.01923661e-02, -4.33163345e-02,\n",
       "        5.84900416e-02,  1.01662546e-01,  2.89106108e-02,  2.36448385e-02,\n",
       "       -2.98592541e-02,  7.85498172e-02, -4.16663885e-02,  1.86487660e-03,\n",
       "        5.15827909e-03,  2.63454653e-02,  9.79255736e-02, -1.26039051e-02,\n",
       "        7.32406080e-02, -4.06999737e-02,  2.89044194e-02, -2.46110912e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(pred, \"../pred_upd_hyb_Xx.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
