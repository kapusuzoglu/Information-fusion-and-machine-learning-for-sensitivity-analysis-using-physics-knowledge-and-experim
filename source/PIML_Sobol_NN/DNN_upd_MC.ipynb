{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Normalize the data.\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "import random\n",
    "\n",
    "def pass_arg(nsim, tr_size, dropoutrate):\n",
    "    print(\"Tr_size:\", tr_size)\n",
    "    def fix_seeds(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    #     K.set_session(sess)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    ss = 1\n",
    "    fix_seeds(ss)\n",
    "\n",
    "    # MC dropout\n",
    "    class MCDropout(Dropout):\n",
    "        def call(self, inputs, training=None):\n",
    "            return super(MCDropout, self).call(inputs, training=True)\n",
    "\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # def save_obj(obj, name):\n",
    "    #     with open(name, 'wb') as f:\n",
    "    #         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Compute the RMSE given the ground truth (y_true) and the predictions(y_pred)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "    # Making sure final porosity is less than initial\n",
    "    def poros(poroi, porof):\n",
    "        porofn = -porof*(porof<0)\n",
    "        porofp = porof*(porof>=poroi) - poroi*(porof>=poroi)\n",
    "        return porofp+porofn\n",
    "\n",
    "\n",
    "    def phy_loss_mean(params):\n",
    "        # useful for cross-checking training\n",
    "        loss1, loss2, loss3, loss4, lam1, lam2 = params\n",
    "        x1, x2, x3 = loss1*(loss1>0), loss2*(loss2>0), loss3*(loss3>0)\n",
    "    #     print(np.mean(x1), x1.shape[0])\n",
    "    #     print(np.mean(x2), x2.shape[0])\n",
    "    #     print(np.mean(x3), x3.shape[0])\n",
    "\n",
    "        if x1.any() and x1.shape[0]>1:\n",
    "            X_scaled1 = (x1 - np.min(x1)) / (np.max(x1) - np.min(x1))\n",
    "            x1 = X_scaled1\n",
    "        if x2.any() and x2.shape[0]>1:\n",
    "            X_scaled2 = (x2 - np.min(x2)) / (np.max(x2) - np.min(x2))\n",
    "            x2 = X_scaled2\n",
    "        if x3.any() and x3.shape[0]>1:\n",
    "            X_scaled3 = (x3 - np.min(x3)) / (np.max(x3) - np.min(x3))\n",
    "            x3 = X_scaled3\n",
    "        return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3))\n",
    "    #     return (lam1*np.mean(x1) + lam2*np.mean(x2) + lam2*np.mean(x3) + lam2*loss4)\n",
    "\n",
    "    def PGNN_train_test(optimizer_name, optimizer_val, drop_rate, iteration, n_layers, n_nodes, tr_size, pre_train):\n",
    "\n",
    "        # Hyper-parameters of the training process\n",
    "    #     batch_size = int(tr_size/2)\n",
    "        batch_size = 10\n",
    "        num_epochs = 300\n",
    "        val_frac = 0.25\n",
    "        patience_val = 80\n",
    "\n",
    "        # Initializing results filename\n",
    "        exp_name = \"Pre-train\" + optimizer_name + '_drop' + str(drop_rate) + '_nL' + str(n_layers) + '_nN' + str(n_nodes) + '_trsize' + str(tr_size) + '_iter' + str(iteration)\n",
    "        exp_name = exp_name.replace('.','pt')\n",
    "        results_dir = '../results/'\n",
    "        model_name = results_dir + exp_name + '.h5' # storing the trained model\n",
    "        results_name = results_dir + exp_name + '_results.dat' # storing the results of the model\n",
    "        \n",
    "        # Load labeled data\n",
    "        # data = np.loadtxt('../data/unlabeled_data_BK_constw_v2_1525.dat')\n",
    "        \n",
    "        # data1 = data[:1303, :]\n",
    "        # data2 = data[-6:, :]\n",
    "        # datah = np.vstack((data1,data2))\n",
    "        # np.random.shuffle(datah)\n",
    "        # x_unlabeled = datah[:, :2] # 1303 last regular sample\n",
    "        # y_unlabeled = datah[:, -3:-1]\n",
    "\n",
    "        # Load labeled data\n",
    "        data = np.loadtxt('../data/labeled_data.dat')\n",
    "        x_labeled = data[:, :2] # -2 because we do not need porosity predictions\n",
    "        y_labeled = data[:, -2:-1] # dimensionless bond length and\n",
    "\n",
    "        # normalize dataset with MinMaxScaler\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(0, 1.0))\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "        x_labeled = scaler.fit_transform(x_labeled)\n",
    "        # x_unlabeled = scaler.fit_transform(x_unlabeled)\n",
    "        # y_labeled = scaler.fit_transform(y_labeled)\n",
    "\n",
    "        # train and test data\n",
    "        trainX, trainY = x_labeled[:tr_size,:], y_labeled[:tr_size]\n",
    "#         testX, testY = x_labeled[tr_size:,:], y_labeled[tr_size:]\n",
    "        testX, testY = x_labeled[30:,:], y_labeled[30:]\n",
    "\n",
    "        dependencies = {'root_mean_squared_error': root_mean_squared_error}\n",
    "\n",
    "        # load the pre-trained model using non-calibrated physics-based model predictions (./data/unlabeled.dat)\n",
    "        loaded_model = load_model(results_dir + pre_train, custom_objects=dependencies)\n",
    "\n",
    "        # Creating the model\n",
    "        model = Sequential()\n",
    "        for layer in np.arange(n_layers):\n",
    "            if layer == 0:\n",
    "                model.add(Dense(n_nodes, activation='relu', input_shape=(np.shape(trainX)[1],)))\n",
    "            else:\n",
    "                model.add(Dense(n_nodes, activation='relu', kernel_regularizer=l1_l2(l1=.001, l2=.001)))\n",
    "            # model.add(Dropout(rate=drop_rate))\n",
    "            model.add(MCDropout(rate=drop_rate))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        # pass the weights to all layers but 1st input layer, whose dimensions are updated\n",
    "        for new_layer, layer in zip(model.layers[1:], loaded_model.layers[1:]):\n",
    "            new_layer.set_weights(layer.get_weights())\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizer_val,\n",
    "                      metrics=[root_mean_squared_error])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val,verbose=1)\n",
    "\n",
    "        print('Running...' + optimizer_name)\n",
    "        history = model.fit(trainX, trainY,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=num_epochs,\n",
    "                            verbose=0,\n",
    "                            validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])\n",
    "\n",
    "        test_score = model.evaluate(testX, testY, verbose=1)\n",
    "        print(test_score)\n",
    "\n",
    "            \n",
    "        test_scores = []\n",
    "        for i in range(int(nsim)):\n",
    "#             print(\"simulation num:\",i)\n",
    "#             predictions = model.predict(testX)\n",
    "#             samples.append(predictions)\n",
    "            test_score = model.evaluate(testX, testY, verbose=1)\n",
    "            test_scores.append(test_score[1])\n",
    "        return np.array(test_scores)\n",
    "    \n",
    "\n",
    "\n",
    "    # Main Function\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        fix_seeds(1)\n",
    "\n",
    "        # List of optimizers to choose from    \n",
    "        optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']\n",
    "        optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1), RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]\n",
    "\n",
    "        # selecting the optimizer\n",
    "        optimizer_num = 1\n",
    "        optimizer_name = optimizer_names[optimizer_num]\n",
    "        optimizer_val = optimizer_vals[optimizer_num]\n",
    "\n",
    "        # Selecting Other Hyper-parameters\n",
    "        drop_rate = dropoutrate # Fraction of nodes to be dropped out\n",
    "        n_layers = 2 # Number of hidden layers\n",
    "        n_nodes = 5 # Number of nodes per hidden layer\n",
    "\n",
    "        # # Iterating over different training fractions and splitting indices for train-test splits\n",
    "        # trsize_range = [4,6,8,10,20]\n",
    "\n",
    "        # #default training size = 5000\n",
    "        # tr_size = trsize_range[4]\n",
    "        \n",
    "        # pre-trained model\n",
    "        pre_train = 'Poro_Pre-trainAdadelta_drop0_nL2_nN5_trsize1308_iter0.h5'\n",
    "        tr_size = int(tr_size)\n",
    "\n",
    "#         # use regularizer\n",
    "#         reg = True\n",
    "\n",
    "#         #set lamda=0 for pgnn0\n",
    "#         lamda = [1, 1] # Physics-based regularization constant\n",
    "\n",
    "        # total number of runs\n",
    "        iter_range = np.arange(1)\n",
    "        testrmse=[]\n",
    "        # iterating through all possible params\n",
    "        for iteration in iter_range:\n",
    "            # results, result_file, pred, obs, rmse = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                            # iteration, n_layers, n_nodes, tr_size, lamda, reg)\n",
    "            # testrmse.append(rmse)\n",
    "            pred = PGNN_train_test(optimizer_name, optimizer_val, drop_rate, \n",
    "                        iteration, n_layers, n_nodes, tr_size, pre_train)\n",
    "    \n",
    "    return np.squeeze(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr_size: 5\n",
      "Running...Adadelta\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "[0.004705499857664108, 0.017763651907444]\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 110us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 110us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 222us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 112us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "Tr_size: 10\n",
      "Running...Adadelta\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "[0.003831044305115938, 0.011233353056013584]\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 110us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 222us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "Tr_size: 15\n",
      "Running...Adadelta\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "[0.0004809132660739124, 0.015418878756463528]\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 222us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 222us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 109us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 111us/step\n",
      "Tr_size: 20\n",
      "Running...Adadelta\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "[0.000388483633287251, 0.013521510176360607]\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 112us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "Tr_size: 30\n",
      "Running...Adadelta\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "[0.0002809964935295284, 0.013321500271558762]\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 107us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 116us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 107us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 112us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 107us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 110us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 0us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n",
      "9/9 [==============================] - 0s 111us/step\n"
     ]
    }
   ],
   "source": [
    "mean_rmses=[]\n",
    "std_rmses=[]\n",
    "# for ii in ([.005,.01,.02,.05,.1,.15,.2,.25,.3,0.5]):\n",
    "for ii in ([5,10,15,20,30]):\n",
    "    test_rmse = pass_arg(50, ii, 0.05)\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    mean_rmses.append(mean_rmse)\n",
    "    std_rmses.append(std_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.013819292970001697,\n",
       " 0.008959805900231004,\n",
       " 0.014267750959843397,\n",
       " 0.013454186040908098,\n",
       " 0.013600420970469713]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002429259320554208,\n",
       " 0.001850709734460213,\n",
       " 0.0007153421020521668,\n",
       " 0.0005223524645082339,\n",
       " 0.0009140530362462718]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(mean_rmses, \"../mean_rmse_dnn_upd_MC.dat\")\n",
    "save_obj(std_rmses, \"../std_rmse_dnn_upd_MC.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.62061860e-02,  1.87012106e-02,  2.03988180e-02,  1.67454164e-02,\n",
       "        1.15877548e-02,  1.77968144e-02, -1.27896736e-03, -1.31999478e-02,\n",
       "        2.60994807e-02,  1.33960219e-02,  2.77881604e-02,  9.34297452e-04,\n",
       "        6.04256568e-03,  1.26129938e-02,  7.02638784e-03,  2.18978971e-02,\n",
       "        2.32310016e-02, -4.19802684e-03,  1.63644198e-02,  2.18827017e-02,\n",
       "        2.80083790e-02,  2.09308118e-02,  2.16732565e-02,  1.84855182e-02,\n",
       "        1.77870262e-02,  3.32493819e-02,  1.94747355e-02, -9.24617343e-04,\n",
       "       -1.61748938e-02,  4.68686111e-02,  1.53396726e-02,  3.43751386e-02,\n",
       "        1.31887319e-02,  2.40315683e-02,  2.57186349e-02,  1.02430042e-02,\n",
       "        4.46724612e-03,  7.93455448e-03,  3.40867825e-02,  1.84419602e-02,\n",
       "        9.89243481e-03,  2.23036781e-02,  2.42859274e-02,  2.76430584e-02,\n",
       "        2.40111295e-02,  1.80043541e-02,  1.87582728e-02,  2.57925484e-02,\n",
       "        1.78488772e-02,  2.23268848e-02, -3.57775800e-02,  1.67228747e-02,\n",
       "        2.13348549e-02,  1.62876416e-02,  3.51711325e-02,  5.41875185e-03,\n",
       "       -1.05746528e-02,  9.24437959e-03,  2.71540899e-02,  9.22800787e-03,\n",
       "        1.35992244e-02,  1.32819526e-02,  2.81667691e-02,  2.45825816e-02,\n",
       "        1.92828849e-02,  2.16883868e-02, -3.71940173e-02,  1.70139186e-02,\n",
       "        1.69736687e-02,  3.17162424e-02,  2.69306023e-02, -2.31546387e-02,\n",
       "        1.39678465e-02,  1.77130774e-02,  2.55093947e-02, -1.64369773e-02,\n",
       "       -1.47703532e-02,  2.42347009e-02,  3.29724699e-02, -9.71338060e-03,\n",
       "       -2.24325508e-02,  2.93998457e-02,  1.94693338e-02,  3.16009764e-03,\n",
       "        2.97182649e-02,  3.13080028e-02,  1.90848075e-02,  2.61120778e-02,\n",
       "        2.11019889e-02, -4.06723935e-03,  3.67575511e-02,  8.76579527e-03,\n",
       "        2.10106745e-02,  9.19287372e-03,  1.75985340e-02,  1.67480633e-02,\n",
       "        2.21972838e-02,  2.03938540e-02,  1.58368871e-02,  6.43181207e-04,\n",
       "        2.22689621e-02, -1.92655530e-02,  2.51673609e-02,  2.19595525e-02,\n",
       "        1.36240423e-02,  2.04341784e-02,  9.69002116e-03, -1.08252168e-02,\n",
       "        1.28642842e-02,  6.55106967e-03, -9.87382047e-03,  8.49158783e-03,\n",
       "        1.63517967e-02,  1.67814419e-02,  2.23781206e-02,  2.10977439e-02,\n",
       "        2.69694943e-02,  3.39885578e-02,  2.06377003e-02,  2.66615842e-02,\n",
       "       -1.30927274e-02,  1.14753917e-02,  4.82655456e-03,  1.66676454e-02,\n",
       "        1.84103921e-02,  1.21473742e-03,  3.27242278e-02,  1.69483684e-02,\n",
       "        2.00475790e-02,  1.48288012e-02,  2.07434893e-02,  1.51739428e-02,\n",
       "       -1.73872318e-02,  2.35697962e-02,  1.10559557e-02,  2.39772126e-02,\n",
       "        2.00993735e-02,  7.10650021e-03,  2.16613691e-02,  1.64576434e-02,\n",
       "        2.33318955e-02,  1.74897127e-02, -4.63938341e-03,  5.79373678e-03,\n",
       "       -4.21535634e-02,  1.66285690e-02,  8.37850291e-03,  1.98336020e-02,\n",
       "        1.62028894e-02,  1.96451563e-02,  3.45925950e-02, -1.03940247e-02,\n",
       "        2.51110215e-02,  1.29894800e-02,  1.53892934e-02, -2.52446104e-02,\n",
       "       -2.28407048e-02,  1.53690334e-02, -8.15223530e-03, -4.27116500e-03,\n",
       "        3.15926559e-02,  1.65971257e-02,  1.23760309e-02,  2.89236754e-02,\n",
       "        1.96175650e-02,  1.09921340e-02,  1.46107450e-02,  2.10147351e-02,\n",
       "        2.57003158e-02,  1.78363901e-02,  9.26276948e-03,  4.97121084e-03,\n",
       "        2.31496263e-02,  1.32730715e-02,  1.59288431e-03,  1.67266894e-02,\n",
       "        1.25313094e-02, -3.71488932e-05,  2.75400709e-02,  2.82312110e-02,\n",
       "        1.08002340e-02,  9.69523657e-03,  9.91025940e-03, -2.99212858e-02,\n",
       "        1.14227235e-02,  8.36914685e-03,  3.13469917e-02, -3.62715609e-02,\n",
       "        1.63998920e-02,  5.91629883e-03,  2.14886405e-02,  1.35743953e-02,\n",
       "        1.52574126e-02,  1.87309403e-02,  1.99505799e-02, -1.95353534e-02,\n",
       "        4.89337603e-04,  2.42281053e-02,  3.32765765e-02,  1.17868828e-02,\n",
       "       -1.96905546e-02,  2.39220634e-02,  2.17205640e-02,  2.05015521e-02,\n",
       "       -3.75865363e-02, -3.87285016e-02,  2.27564406e-02,  3.02923508e-02,\n",
       "        2.00732704e-02,  3.08585335e-02,  1.71403289e-02,  1.03223266e-03,\n",
       "       -3.31548676e-02,  1.69167574e-02,  1.65723544e-02, -2.02462096e-02,\n",
       "        1.77253373e-02,  2.16941647e-02,  2.24444345e-02,  1.62825454e-02,\n",
       "        1.33646773e-02,  2.84221079e-02,  2.32560467e-02,  1.10307634e-02,\n",
       "       -1.81796271e-02,  1.43153938e-02,  1.51545219e-02,  2.80932002e-02,\n",
       "        2.55552549e-02, -3.54654901e-02,  1.03059933e-02,  1.97395682e-02,\n",
       "        2.31354684e-02,  1.10414531e-02,  2.27602459e-02,  1.84972063e-02,\n",
       "        1.61959473e-02,  1.99292544e-02,  1.13916183e-02,  2.60221045e-02,\n",
       "        1.32725192e-02,  1.84279715e-03,  1.81945376e-02,  1.24370633e-02,\n",
       "        2.28288416e-02,  2.13897675e-02, -1.57463066e-02,  1.12814168e-02,\n",
       "        2.31646150e-02,  2.13103071e-02,  3.47870477e-02, -2.31183842e-02,\n",
       "        2.41658948e-02,  1.77610442e-02, -1.58084780e-02,  9.26142372e-03,\n",
       "        2.97518279e-02,  1.74596272e-02,  2.45557949e-02,  5.07818013e-02,\n",
       "        1.93818789e-02,  1.83754023e-02,  2.58459039e-02,  9.39069688e-03,\n",
       "        1.38158984e-02,  1.19734658e-02,  9.26321093e-03,  2.66052578e-02,\n",
       "        2.82636192e-02,  1.30805327e-02,  3.43222097e-02,  2.69842744e-02,\n",
       "        4.65746745e-02,  1.89511459e-02,  1.46921221e-02,  6.12794561e-03,\n",
       "       -1.90754049e-02,  3.14598926e-03,  9.92555823e-03,  2.83938833e-02,\n",
       "        8.69000703e-03,  1.52403163e-02,  3.63411419e-02,  7.44573819e-03,\n",
       "        1.06237689e-02,  2.86432691e-02,  9.11177043e-03,  3.66394520e-02,\n",
       "        1.58294868e-02,  7.82671664e-03,  2.65343413e-02, -3.10472376e-03,\n",
       "        2.72102468e-03,  2.23939084e-02,  2.30663940e-02,  2.38107163e-02,\n",
       "        1.48934480e-02,  2.40693111e-02,  2.37905364e-02,  2.33891755e-02,\n",
       "        2.48503909e-02,  2.24410221e-02,  2.39187386e-02,  1.88865308e-02,\n",
       "        2.59639043e-03,  1.97212230e-02,  2.52574738e-02,  2.47733928e-02,\n",
       "        2.44928263e-02,  2.41156481e-02,  2.44170614e-02,  1.54349580e-02,\n",
       "        5.50566753e-03,  2.49813478e-02,  2.28749262e-03,  1.90000869e-02,\n",
       "       -2.30847001e-02,  7.17753218e-03,  1.88669413e-02,  9.14063025e-03,\n",
       "        2.98045520e-02,  3.32568437e-02,  2.21696235e-02,  1.88668054e-02,\n",
       "        1.30279325e-02,  3.06034591e-02, -3.94721562e-03,  1.07175363e-02,\n",
       "        2.04799511e-02, -2.50258204e-03,  2.14277525e-02,  1.45214982e-02,\n",
       "        2.31723376e-02,  2.11038589e-02,  2.27065440e-02,  1.36531331e-02,\n",
       "        1.81026869e-02,  2.06937864e-02,  3.24295051e-02,  1.04929432e-02,\n",
       "       -2.68447325e-02,  1.65229198e-02,  4.08154540e-02,  1.41456751e-02,\n",
       "        1.86372809e-02,  1.27795653e-03,  1.89327970e-02,  2.72984393e-02,\n",
       "        1.02848457e-02,  2.19052788e-02,  1.71828344e-02,  2.05535460e-02,\n",
       "       -2.28844606e-03,  1.02755176e-02,  2.38146838e-02,  2.28068735e-02,\n",
       "        2.07658578e-02,  2.14104243e-02,  1.89980678e-02,  3.39137502e-02,\n",
       "        1.31386509e-02,  1.55360941e-02,  2.31828671e-02,  3.15534249e-02,\n",
       "        1.80295296e-02,  2.82689873e-02,  2.04474702e-02,  2.11204533e-02,\n",
       "        1.05901305e-02,  8.00574478e-03, -2.41432451e-02,  1.68354157e-02,\n",
       "        1.81406885e-02, -6.93520438e-03,  2.66679768e-02,  1.71356872e-02,\n",
       "        1.38339559e-02,  1.62491277e-02,  2.48632487e-02, -2.07162518e-02,\n",
       "        5.10632293e-03,  2.51759812e-02,  2.81151906e-02, -1.36054810e-02,\n",
       "        2.86039431e-02,  2.09911224e-02,  3.63454111e-02, -4.59765941e-02,\n",
       "        1.19071482e-02,  2.69456059e-02,  6.11843122e-03,  2.74798106e-02,\n",
       "        2.21209265e-02,  3.12265866e-02,  2.21229717e-02,  1.44943846e-02,\n",
       "        3.83688062e-02,  2.26959139e-02,  2.00825110e-02, -2.26621870e-02,\n",
       "       -1.59968855e-03,  3.92194130e-02,  4.24626879e-02,  2.63781212e-02,\n",
       "        7.14008976e-03, -1.31385811e-02,  8.43988080e-03,  2.04232186e-02,\n",
       "        1.72812156e-02,  1.73916891e-02, -1.25690773e-02,  1.90393534e-02,\n",
       "        1.50133716e-03,  2.04553604e-02,  2.18942352e-02, -2.09471602e-02,\n",
       "        1.52980778e-02,  1.73617732e-02,  1.43164182e-02,  1.76784042e-02,\n",
       "        1.97620317e-02,  2.74089389e-02,  2.11552624e-02,  1.84663441e-02,\n",
       "        2.56163850e-02,  2.56731994e-02,  4.07657996e-02,  2.50948835e-02,\n",
       "        2.26617828e-02,  3.80936489e-02,  1.26774935e-02, -2.82396749e-02,\n",
       "        5.96847897e-03,  6.30533975e-03,  1.11045912e-02,  4.12773294e-03,\n",
       "       -1.01514030e-02,  1.64247788e-02,  3.45198326e-02,  3.18377577e-02,\n",
       "        2.99995486e-02,  1.73554476e-02,  3.02107483e-02,  2.99726799e-02,\n",
       "        2.62351967e-02,  3.41272727e-02,  2.93026734e-02,  1.49878120e-04,\n",
       "        1.28109939e-02,  1.60581749e-02,  2.33745929e-02, -1.46829626e-02,\n",
       "        2.02927571e-02, -3.34631093e-02,  2.06366424e-02,  1.88169517e-02,\n",
       "        1.98386554e-02, -2.17417292e-02,  3.14188376e-02,  2.42021531e-02,\n",
       "        2.14031432e-02,  6.15756027e-03,  1.89982504e-02,  1.37454001e-02,\n",
       "        1.28805991e-02,  1.42423995e-02,  1.06729530e-02,  1.71230529e-02,\n",
       "        3.16687189e-02,  1.08336331e-02,  3.14402804e-02,  2.27116868e-02,\n",
       "        3.06390449e-02,  1.15176784e-02,  1.71283465e-02,  2.58174520e-02,\n",
       "        1.02480140e-03,  2.24292781e-02,  1.51078533e-02, -3.88880540e-03,\n",
       "        2.78801136e-02,  2.59085819e-02,  9.12309904e-03,  1.82794109e-02,\n",
       "        3.05600651e-02, -4.19522356e-03,  2.93313805e-02,  4.20674309e-02,\n",
       "        1.98014230e-02,  3.56544144e-02,  2.99400501e-02,  2.22062133e-02,\n",
       "        3.48423384e-02,  2.34366134e-02, -3.23507399e-03,  2.40849163e-02,\n",
       "        2.20278408e-02,  2.33445261e-02,  1.22132208e-02, -2.85345633e-02,\n",
       "        1.35984803e-02,  7.69158499e-03,  2.68465336e-02,  1.67944375e-02,\n",
       "        7.31366454e-03,  3.01255565e-02,  2.57867631e-02,  1.87918544e-02,\n",
       "        2.39921361e-02,  1.55779533e-02,  5.30642690e-03,  2.54300255e-02,\n",
       "        2.52777841e-02, -1.28932223e-02,  9.26160254e-03,  1.99055653e-02,\n",
       "       -1.15068015e-02, -8.34756251e-03,  2.18135267e-02,  1.91606339e-02,\n",
       "        1.01242913e-03,  2.47060135e-02,  1.34241451e-02,  2.68173032e-02,\n",
       "        3.01188175e-02,  3.39085283e-03,  1.92826018e-02,  6.68040989e-03,\n",
       "       -1.31113138e-02,  1.58703551e-02,  1.87166557e-02,  1.53869381e-02,\n",
       "        1.30105829e-02,  8.03039689e-03,  2.14518420e-02,  1.74070280e-02,\n",
       "        1.81005355e-02,  1.23586012e-02,  2.88004447e-02,  2.08899062e-02,\n",
       "       -2.53772512e-02,  1.04679670e-02,  2.57201530e-02,  3.40449326e-02,\n",
       "        1.66635551e-02,  2.01381762e-02,  2.38378067e-02,  2.21513063e-02,\n",
       "        1.12418029e-02,  3.47165912e-02,  2.21397113e-02,  3.21913064e-02,\n",
       "        3.07910629e-02,  8.56047496e-03,  1.87567342e-02,  1.76074635e-02,\n",
       "        2.79828068e-02, -3.64302993e-02,  2.78057307e-02,  1.75370816e-02,\n",
       "        4.06271368e-02,  1.64235588e-02,  1.77285094e-02,  1.31065752e-02,\n",
       "        2.49485131e-02,  3.02163381e-02,  2.87031047e-02,  2.96916347e-03,\n",
       "        1.26411822e-02,  2.89521497e-02, -8.16879142e-03,  2.08742395e-02,\n",
       "        1.65407918e-02,  1.33649744e-02,  2.24113241e-02,  1.84887405e-02,\n",
       "        3.66089935e-03,  1.75096113e-02, -2.02029124e-02,  1.79436412e-02,\n",
       "        3.45545858e-02,  1.75881032e-02,  1.69134922e-02,  1.94305386e-02,\n",
       "        3.72505821e-02,  8.44647922e-03,  1.95680819e-02,  2.23143641e-02,\n",
       "        2.03982443e-02,  2.41818540e-02,  8.58786982e-04,  3.04987207e-02,\n",
       "        2.98738889e-02,  2.27932613e-02, -2.16543451e-02,  1.10446522e-02,\n",
       "        5.21841506e-03,  2.00830195e-02,  2.22795960e-02,  2.00242177e-02,\n",
       "        1.23617109e-02,  1.81371458e-02,  2.11112257e-02,  8.09093378e-03,\n",
       "        2.46787295e-02,  2.83862855e-02,  7.48682674e-03,  1.71947964e-02,\n",
       "        1.11286938e-02, -4.15814370e-02,  2.68883258e-02,  2.90693995e-02,\n",
       "        2.44719498e-02,  9.76770278e-03,  2.45867874e-02,  2.68334728e-02,\n",
       "        3.30112055e-02,  1.79740526e-02,  2.39485186e-02,  1.39948679e-02,\n",
       "        1.60183720e-02,  2.68007796e-02,  1.59895308e-02,  1.79268960e-02,\n",
       "        7.77280796e-03,  1.71735846e-02,  2.62069926e-02,  2.68746521e-02,\n",
       "        2.46913452e-02,  1.99721344e-02,  1.32610630e-02,  1.90508049e-02,\n",
       "        4.40497091e-03,  1.51341902e-02,  1.71718560e-02,  3.14326175e-02,\n",
       "        1.76546518e-02,  2.97569707e-02,  2.38467678e-02,  2.71510575e-02,\n",
       "        6.77757012e-03,  1.22393556e-02, -1.37098422e-02,  1.73473787e-02,\n",
       "        2.97963303e-02, -3.76331508e-02,  1.19257318e-02,  2.48379987e-02,\n",
       "        3.48553434e-02,  2.20231824e-02,  2.77812425e-02,  9.98652168e-03,\n",
       "        2.42655613e-02,  3.22164409e-02, -1.63789336e-02, -3.08407042e-02,\n",
       "        1.44062554e-02,  1.79653931e-02,  2.62669567e-02,  3.22300494e-02,\n",
       "        2.05301270e-02,  1.06096081e-02,  1.94912795e-02,  1.27361501e-02,\n",
       "        1.90211274e-02,  2.13859528e-02,  3.65292430e-02,  2.39573121e-02,\n",
       "        1.64806619e-02, -7.90784135e-03,  1.91332158e-02,  1.85330790e-02,\n",
       "        1.52450418e-02,  2.49097105e-02,  1.28804902e-02,  2.69742180e-02,\n",
       "        1.25976093e-02,  4.02759314e-02,  2.32878514e-02,  1.59131419e-02,\n",
       "        1.80920679e-02, -1.27966441e-02, -1.82586052e-02,  2.93583870e-02,\n",
       "       -3.98649946e-02,  1.63706522e-02,  2.85736900e-02,  2.79983543e-02,\n",
       "       -7.88168050e-03,  7.49114016e-03, -1.26692327e-03,  2.32023913e-02,\n",
       "        2.81202942e-02,  1.82476286e-02, -2.36763097e-02,  1.96009055e-02,\n",
       "        1.55514237e-02,  8.44565779e-03,  1.93448681e-02,  5.97118028e-03,\n",
       "        1.75434090e-02,  1.78676173e-02,  1.76574830e-02,  1.64653081e-02,\n",
       "        1.49230901e-02,  2.54161116e-02, -2.33980734e-02,  3.41260992e-02,\n",
       "        2.40856819e-02,  2.84249838e-02,  1.98730975e-02,  1.17623238e-02,\n",
       "        4.32620896e-03,  1.77909061e-02,  1.21621201e-02,  3.28384116e-02,\n",
       "        1.68144573e-02,  9.80590377e-03,  2.33674552e-02,  1.74017493e-02,\n",
       "        2.83718258e-02,  2.90101441e-03,  5.44180395e-03,  2.21219063e-02,\n",
       "        2.07826123e-02,  1.76556520e-02,  1.05656683e-02,  1.04438951e-02,\n",
       "        2.74541378e-02,  5.11604315e-03,  2.01505162e-02,  1.62826031e-02,\n",
       "        1.79891251e-02,  1.75770819e-02,  1.80496424e-02,  1.40722068e-02,\n",
       "        2.30948329e-02,  1.54967560e-02, -3.06064840e-02,  1.43414186e-02,\n",
       "       -2.51085088e-02,  1.97517816e-02,  1.36464359e-02,  1.00942506e-02,\n",
       "        1.80738829e-02,  1.68393627e-02,  3.03702727e-02, -1.41755855e-02,\n",
       "        1.05809020e-02,  5.01313386e-03,  3.05961873e-02,  9.79350787e-03,\n",
       "        2.32253857e-02,  1.38072446e-02, -2.02122740e-02, -2.30282228e-02,\n",
       "        2.21271943e-02,  1.06067499e-02,  1.88961327e-02,  2.47976873e-02,\n",
       "        1.92119163e-02,  1.64560899e-02,  1.32639660e-02,  2.10862737e-02,\n",
       "        3.85314189e-02,  2.47265249e-02,  3.75669240e-03,  3.52620631e-02,\n",
       "        2.23754700e-02,  1.19686751e-02,  1.93220563e-02,  1.10372044e-02,\n",
       "        1.98219195e-02, -3.91540639e-02,  1.66592710e-02,  2.65401863e-02,\n",
       "        2.01337822e-02,  2.10547522e-02, -4.40048473e-03, -2.57255193e-02,\n",
       "        6.31719222e-03,  2.31958050e-02,  1.91315524e-02,  1.88068226e-02,\n",
       "        1.76330879e-02,  1.98584069e-02,  1.96024645e-02,  1.76136903e-02,\n",
       "        1.15794875e-02,  1.47863766e-02,  2.92292237e-02,  2.51419134e-02,\n",
       "        1.95939448e-02,  2.30382513e-02,  3.36871371e-02,  1.84024293e-02,\n",
       "        2.43927762e-02,  2.44130660e-02, -3.22098508e-02,  1.93344727e-02,\n",
       "        1.40744103e-02, -1.08360834e-02,  1.93515811e-02,  2.11246777e-02,\n",
       "       -8.80963355e-03,  1.06246714e-02,  1.95896477e-02,  1.31832184e-02,\n",
       "        2.81682331e-02,  4.45405114e-03,  1.94502193e-02,  4.50787786e-03,\n",
       "       -6.61980943e-04, -2.95991302e-02,  1.45408260e-02,  2.65612323e-02,\n",
       "        1.33191049e-02,  9.37318522e-03,  6.86303619e-03,  2.07969062e-02,\n",
       "        1.00347372e-02,  2.16542371e-02,  8.74918513e-03,  7.10716890e-03,\n",
       "        2.00118646e-02,  1.20157190e-02, -3.11462814e-03,  1.66650265e-02,\n",
       "        1.83653459e-02,  2.36108787e-02,  1.55193042e-02,  2.27442826e-03,\n",
       "        1.85579155e-02,  2.07110588e-02,  1.99533682e-02, -3.27056795e-02,\n",
       "       -1.17539819e-02,  4.44075577e-02,  1.70408711e-02, -1.24848317e-02,\n",
       "        3.28890383e-02,  1.87430605e-02,  2.35936828e-02,  1.91788990e-02,\n",
       "        2.15631723e-02,  8.80452059e-03,  1.39102377e-02,  1.87933054e-02,\n",
       "        1.94913112e-02,  2.91579142e-02,  5.85532561e-03,  7.80251157e-03,\n",
       "        2.95289848e-02,  1.44844940e-02,  1.09484019e-02,  7.13060377e-03,\n",
       "        1.49052683e-02,  1.91700235e-02,  3.30020152e-02,  3.07549052e-02,\n",
       "        1.99158266e-02, -1.39476648e-02,  4.73671593e-02,  4.35637776e-03,\n",
       "        1.92743614e-02,  1.88270733e-02,  9.87720583e-03,  2.12275889e-02,\n",
       "        2.51051001e-02, -2.04277877e-02,  3.29617783e-02,  1.76428780e-02,\n",
       "        2.13776045e-02,  2.89953779e-02,  1.57395191e-02,  1.66169629e-02,\n",
       "        3.27222794e-02,  3.43931168e-02,  1.63869169e-02,  7.78609375e-03,\n",
       "        1.71285570e-02,  2.66137980e-02, -2.97111198e-02,  2.01644730e-02,\n",
       "       -2.71414630e-02,  2.35596839e-02, -1.73299499e-02,  3.24271619e-02,\n",
       "       -1.14549575e-02, -1.47283528e-04,  1.55476574e-02,  2.81927399e-02,\n",
       "        2.14725137e-02,  2.19096951e-02,  2.25693844e-02,  1.38601875e-02,\n",
       "        2.45983712e-02,  4.31731902e-02,  2.10222416e-02, -4.29428071e-02,\n",
       "        1.73421726e-02,  4.28624041e-02, -4.60676197e-03,  3.76036647e-03,\n",
       "        1.28291734e-02,  2.84222290e-02, -5.99254528e-03,  2.52350997e-02,\n",
       "        1.31222261e-02,  1.02381036e-02,  1.80146974e-02,  4.73318109e-03,\n",
       "        2.02875417e-02,  1.19646564e-02,  2.87611112e-02,  2.43976060e-02,\n",
       "        2.41468102e-02,  1.21153323e-02,  2.57026237e-02,  2.10404675e-02,\n",
       "        1.68746747e-02,  1.34446879e-03,  3.25353891e-02,  2.92910747e-02,\n",
       "        1.93823930e-02,  2.30882764e-02,  3.07272691e-02,  2.55248547e-02,\n",
       "        2.86473259e-02, -2.61130426e-02,  3.13197561e-02,  1.50518604e-02,\n",
       "       -1.55829629e-02,  1.67307276e-02, -3.59883183e-03,  1.82620753e-02,\n",
       "        1.38797332e-02,  2.23517679e-02,  2.83563416e-02,  2.15973202e-02,\n",
       "        1.67511813e-02,  2.17276122e-02,  1.78164262e-02,  1.59111191e-02,\n",
       "        2.25409959e-02,  9.12563689e-03,  2.01231241e-02,  3.49326842e-02,\n",
       "        1.39703937e-02,  1.04424683e-02,  7.38668209e-03, -3.47832916e-03,\n",
       "       -2.19977740e-02,  2.74606291e-02,  4.61960444e-03,  1.15626082e-02,\n",
       "        1.87287051e-02,  1.87176019e-02,  1.24621578e-02,  1.35650458e-02,\n",
       "        1.75757650e-02,  2.00631842e-02, -3.15897018e-02,  2.64364053e-02,\n",
       "        2.86261328e-02, -9.03358310e-03,  7.13212974e-03,  1.39388768e-02,\n",
       "        2.12848354e-02,  1.48096625e-02,  1.02204671e-02,  2.70275138e-02,\n",
       "        2.21389551e-02,  3.97137031e-02,  2.64738295e-02, -9.25124623e-03,\n",
       "        1.23928813e-02,  1.12198405e-02,  2.24603005e-02,  2.29291301e-02,\n",
       "       -1.10374726e-02, -3.62092070e-02,  1.73735935e-02, -3.57254371e-02,\n",
       "        3.18367630e-02,  3.92558193e-03,  2.08346490e-02,  2.74151377e-02,\n",
       "       -2.21261978e-02,  1.73451006e-02, -3.69618908e-02,  1.44121852e-02,\n",
       "        9.55394376e-03,  1.65587924e-02,  4.22716476e-02,  8.46415665e-03,\n",
       "       -3.63136013e-03, -3.09500583e-02,  9.21833608e-03, -4.45649726e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_pred=np.mean(pred,axis=0)\n",
    "mc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_obj(mc_pred, \"../pred_upd_MC_Xx.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
